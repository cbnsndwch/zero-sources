# Next Step: Phase 5 - Testing# MongoDB Array Unwinding Pipeline Implementation - Next Steps



## Project Context## Project: mongo-array-unwind-in-mapping



**Repository**: cbnsndwch/zero-sources  **Branch**: `copilot/vscode1762000567071`  

**Branch**: copilot/vscode1762000567071  **PR**: [#138 - WIP] Design API with the Open-Closed Principle in mind

**PR**: #138 - [WIP] Design API with the Open-Closed Principle in mind  

**Feature**: MongoDB array unwinding in table mappings with pipeline support## Current Status: Phase 3 (75% Complete)



## Implementation Status### ‚úÖ Completed Work



### ‚úÖ Phase 1: Type System (COMPLETE)#### Phase 1: Type System (100% ‚úÖ)

- Created discriminated union: `TableMapping<T> = SimpleTableMapping<T> | PipelineTableMapping<T>`- **Discriminated Union Architecture**: `TableMapping = SimpleTableMapping | PipelineTableMapping`

- Pipeline stage types: `MatchStage`, `UnwindStage`, `SetStage`, `ProjectStage`- **Pipeline Stages**: `MatchStage`, `UnwindStage`, `SetStage`, `ProjectStage`

- Type guards: `isPipelineMapping()`, `isSimpleMapping()`- **Location**: `libs/zero-contracts/src/upstream/`

- Location: `libs/zero-contracts/src/upstream/`  - `pipeline/match.ts` - $match filtering

  - `pipeline/unwind.ts` - $unwind array deconstruction

### ‚úÖ Phase 2: Helper Utilities (COMPLETE)  - `pipeline/set.ts` - $addFields computed fields

- Helper functions: `match()`, `unwind()`, `addFields()`, `project()`  - `pipeline/project.ts` - $project document reshaping (newly added)

- Fluent builder: `PipelineMappingBuilder` class  - `simple/index.ts` - Legacy SimpleTableMapping (backward compatible)

- Location: `libs/zero-contracts/src/upstream/table-mapping.helpers.ts`

#### Phase 2: Helper Utilities (100% ‚úÖ)

### ‚úÖ Phase 3: ChangeMaker Integration (COMPLETE)- **Location**: `libs/zero-contracts/src/upstream/table-mapping.helpers.ts`

- Implemented `PipelineExecutorService` to execute aggregation pipelines on documents- **Type Guards**: `isPipelineMapping()`, `isSimpleMapping()`

- Updated all CRUD operations in `ChangeMakerV0`:- **Stage Builders**: `match()`, `unwind()`, `addFields()`, `project()`

  - **INSERT**: Execute pipeline, emit changes per result row- **Migration Helper**: `toPipelineMapping()` converts legacy to pipeline

  - **UPDATE**: Execute before/after pipelines, use array diffing (Phase 4)- **Fluent Builder**: `PipelineMappingBuilder` class with chainable API

  - **REPLACE**: Execute pipeline, generate changes- **Factory**: `pipelineBuilder()` function

  - **DELETE**: Execute pipeline, handle deletion

- Location: `libs/zero-source-mongodb/src/v0/`#### Phase 3: Change Source Implementation (75% ‚úÖ)



### ‚úÖ Phase 4: Array Diff Optimization (COMPLETE)**Completed**:

- Implemented `ArrayDiffService` with identity-based and index-based matching1. **Pipeline Executor Service** ‚úÖ

- Optimized `makeUpdateChanges()` to use targeted diffs instead of DELETE all + INSERT all   - **Location**: `libs/zero-source-mongodb/src/v0/pipeline-executor.service.ts`

- **Performance**: ~200x reduction in change events for typical scenarios   - **Core Method**: `executePipeline(document, pipeline): any[]`

  - Example: Update 1 member in 100-member array = 1 change vs 200 changes   - **Stage Executors**:

- Location: `libs/zero-source-mongodb/src/v0/array-diff.service.ts`     - `executeMatch()` - Filters using MongoDB query syntax

     - `executeUnwind()` - Array deconstruction with index tracking

### üîÑ Phase 5: Testing (NEXT - START HERE)     - `executeSet()` - Adds computed fields

     - `executeProject()` - Reshapes documents

**Objective**: Create comprehensive test coverage for the new pipeline functionality   - **Expression Evaluator**: Supports 10+ MongoDB operators

     - String: `$concat`

#### 1. Unit Tests Needed     - Comparison: `$eq`, `$ne`, `$gt`, `$gte`, `$lt`, `$lte`

     - Arithmetic: `$add`, `$subtract`, `$multiply`, `$divide`

**`array-diff.service.spec.ts`** (Priority: HIGH)     - Conditional: `$cond`

```typescript   - **Utilities**: Path resolution, field computation

describe('ArrayDiffService', () => {

  // Identity-based matching tests2. **Service Registration** ‚úÖ

  test('should detect added elements by identity', () => {   - **Location**: `libs/zero-source-mongodb/src/v0/index.ts`

    const old = [{ id: 'u1', name: 'Alice' }];   - Exported and registered in `v0ChangeSourceServices` array

    const new = [{ id: 'u1', name: 'Alice' }, { id: 'u2', name: 'Bob' }];   - Available for dependency injection

    const diff = service.computeDiff(old, new, { identityField: 'id' });

    expect(diff.added).toHaveLength(1);3. **Build & Compilation** ‚úÖ

    expect(diff.added[0].value.id).toBe('u2');   - All packages compile successfully

  });   - Fixed TypeScript type narrowing issues

   - Fixed UnwindOptions path handling (string | number)

  test('should detect removed elements by identity', () => { /* ... */ });

  test('should detect modified elements by identity', () => { /* ... */ });**In Progress**:

  test('should handle array reordering without changes', () => { /* ... */ });4. **ChangeMaker Integration** ‚è≥

     - **Location**: `libs/zero-source-mongodb/src/v0/change-maker-v0.ts`

  // Index-based matching tests   - Service imported and injected

  test('should use index-based matching when no identity field', () => { /* ... */ });   - **TODO**: Update change processing methods

  

  // Edge cases### üéØ Immediate Next Steps

  test('should handle empty arrays', () => { /* ... */ });

  test('should handle null/undefined arrays', () => { /* ... */ });#### 1. Update `makeInsertChanges()` Method

  test('should handle missing identity field in elements', () => { /* ... */ });

  test('should handle duplicate identity values', () => { /* ... */ });Current logic handles simple mappings with filter + projection. Need to add pipeline support:

  

  // Deep equality tests```typescript

  test('should detect nested object changes', () => { /* ... */ });makeInsertChanges(watermark, doc, withTransaction = false) {

  test('should detect array changes in elements', () => { /* ... */ });    const changes: v0.ChangeStreamMessage[] = [];

  test('should compare dates correctly', () => { /* ... */ });    const matchingTables = this.getMatchingTables(doc.ns, doc.fullDocument);

});

```    for (const mapping of matchingTables) {

        if (isPipelineMapping(mapping.config)) {

**`pipeline-executor.service.spec.ts`** (Priority: HIGH)            // NEW: Execute pipeline (may produce multiple documents)

```typescript            const transformed = this.pipelineExecutor.executePipeline(

describe('PipelineExecutorService', () => {                doc.fullDocument,

  // $match stage tests                mapping.config.pipeline

  test('should filter documents with $match', () => { /* ... */ });            );

              

  // $unwind stage tests            // Generate one INSERT per transformed document

  test('should unwind simple array', () => {            for (const transformedDoc of transformed) {

    const doc = { _id: 1, items: ['a', 'b', 'c'] };                changes.push([

    const pipeline = [{ $unwind: '$items' }];                    'data',

    const results = service.executePipeline(doc, pipeline);                    {

    expect(results).toHaveLength(3);                        tag: 'insert',

    expect(results[0].items).toBe('a');                        new: transformedDoc,

  });                        relation: {

                              keyColumns: mapping.spec.primaryKey || ['_id'],

  test('should unwind with preserveNullAndEmptyArrays', () => { /* ... */ });                            schema: mapping.spec.schema,

  test('should unwind with includeArrayIndex', () => { /* ... */ });                            name: mapping.tableName

  test('should handle missing/null arrays', () => { /* ... */ });                        }

                      }

  // $addFields stage tests                ]);

  test('should add computed fields', () => { /* ... */ });            }

          } else {

  // $project stage tests            // EXISTING: Legacy path (filter + projection)

  test('should project fields', () => { /* ... */ });            const projectedDoc = applyProjection(

                  doc.fullDocument,

  // Pipeline composition tests                mapping.config.projection || {}

  test('should execute multiple stages in sequence', () => { /* ... */ });            );

});            changes.push([...]);

```        }

    }

**`change-maker-v0.spec.ts`** (Priority: MEDIUM)    

- Test INSERT with pipeline mappings    return withTransaction ? this.#wrapInTransaction(changes, watermark) : changes;

- Test UPDATE with array diffing}

- Test REPLACE with pipeline mappings```

- Test DELETE with pipeline mappings

- Test fallback to simple mappings#### 2. Update `makeUpdateChanges()` Method (Complex)



#### 2. Integration Tests NeededUpdates are tricky because:

- Need to execute pipeline on BOTH `fullDocument` (after) and `fullDocumentBeforeChange` (before)

**`pipeline-integration.spec.ts`** (Priority: HIGH)- Compare results to detect which "rows" were added/removed/changed

```typescript- Handle array element modifications

describe('Pipeline Integration', () => {

  let mongoServer: MongoMemoryServer;**Array Update Scenarios**:

  let connection: Connection;```typescript

  // Before: { members: [{id:'u1', role:'admin'}, {id:'u2', role:'member'}] }

  beforeAll(async () => {// After:  { members: [{id:'u1', role:'owner'}, {id:'u3', role:'member'}] }

    mongoServer = await MongoMemoryServer.create();

    // Setup test MongoDB with change streams enabled// After unwinding:

  });// - u1 changed (admin ‚Üí owner) = UPDATE

  // - u2 removed = DELETE

  test('should handle account.members unwinding on INSERT', async () => {// - u3 added = INSERT

    // Configure mapping with pipeline```

    const mapping: PipelineTableMapping = {

      source: 'accounts',**Required Logic**:

      pipeline: [```typescript

        { $unwind: { path: '$members', includeArrayIndex: 'memberIndex' } },makeUpdateChanges(watermark, doc, withTransaction = false) {

        { $addFields: { accountId: '$_id', memberId: '$members.userId' } }    const changes: v0.ChangeStreamMessage[] = [];

      ]    const matchingTables = this.getMatchingTables(doc.ns, doc.fullDocument);

    };

        for (const mapping of matchingTables) {

    // Insert document with members array        if (isPipelineMapping(mapping.config)) {

    await db.collection('accounts').insertOne({            // Execute pipeline on both versions

      _id: 'acc1',            const docsAfter = this.pipelineExecutor.executePipeline(

      name: 'Test Account',                doc.fullDocument,

      members: [                mapping.config.pipeline

        { userId: 'u1', role: 'admin' },            );

        { userId: 'u2', role: 'member' }            const docsBefore = doc.fullDocumentBeforeChange

      ]                ? this.pipelineExecutor.executePipeline(

    });                      doc.fullDocumentBeforeChange,

                          mapping.config.pipeline

    // Verify change events                  )

    // Should receive 2 INSERT events (one per member)                : [];

  });

              // TODO Phase 4: Array diff logic

  test('should handle array element addition with minimal changes', async () => {            // - Match docs by composite key

    // Start with 2 members, add 1 more            // - Detect: added, removed, changed

    // Verify only 1 INSERT event is generated            // - Generate appropriate INSERT/UPDATE/DELETE

  });        } else {

              // EXISTING: Legacy update logic

  test('should handle array element removal with minimal changes', async () => {        }

    // Start with 3 members, remove 1    }

    // Verify only 1 DELETE event is generated}

  });```

  

  test('should handle array element modification with minimal changes', async () => {#### 3. Update `makeReplaceChanges()` and `makeDeleteChanges()`

    // Modify one member's role

    // Verify only 1 UPDATE event is generatedSimilar patterns to updates - execute pipeline and generate appropriate changes.

  });

  ### üìã Phase 4: Array Diff Handling (Planned)

  test('should handle array reordering without spurious changes', async () => {

    // Reorder members array without changing dataNeed to implement sophisticated diffing for UPDATE events:

    // Verify 0 change events are generated

  });**Key Decision**: How to match array elements?

});- **Option A**: Index-based (fragile, breaks on reordering)

```- **Option B**: Identity field (requires unique ID in elements)

- **Option C**: Content hash (stable, less readable)

#### 3. Test Files to Create

**Recommended Approach**: Identity field with fallback to index:

1. `libs/zero-source-mongodb/src/v0/array-diff.service.spec.ts````typescript

2. `libs/zero-source-mongodb/src/v0/pipeline-executor.service.spec.ts`interface ArrayDiffOptions {

3. `libs/zero-source-mongodb/src/v0/change-maker-v0.spec.ts` (extend existing)    identityField?: string; // e.g., 'id', '_id'

4. `libs/zero-source-mongodb/test/integration/pipeline-integration.spec.ts`    fallbackToIndex?: boolean; // default: true

}

#### 4. Testing Tools/Setup

function computeArrayDiff(

**Dependencies to install** (if not present):    before: any[],

- `@shelf/jest-mongodb` or `mongodb-memory-server` for in-memory MongoDB    after: any[],

- `jest` for testing framework    options: ArrayDiffOptions

- MongoDB with change streams support (replica set required)): ArrayDiffResult {

    // Returns: { added: [], removed: [], updated: [] }

**Test Configuration**:}

```json```

// jest.config.js or similar

{### üîß Technical Details

  "testEnvironment": "node",

  "preset": "@shelf/jest-mongodb",**File Locations**:

  "setupFilesAfterEnv": ["<rootDir>/test/setup.ts"]- Contracts: `libs/zero-contracts/src/upstream/`

}- MongoDB Source: `libs/zero-source-mongodb/src/v0/`

```- Documentation: `docs/projects/mongo-array-unwind-in-mapping/`



#### 5. Performance Benchmarks**Key Interfaces**:

```typescript

Create benchmarks to validate the 200x performance claim:// Pipeline mapping (NEW)

- Measure change events for 1 element change in 100-element arrayinterface PipelineTableMapping<T> {

- Measure change events for reordering operations    source: string;

- Compare Phase 3 naive approach vs Phase 4 optimized approach    pipeline: PipelineStage[];

}

### üìã Phase 6: Documentation (PENDING)

- Update API documentation with pipeline examples// Simple mapping (LEGACY - backward compatible)

- Document identity field configuration best practicesinterface SimpleTableMapping<T> {

- Add migration guide from simple to pipeline mappings    source: string;

- Performance tuning guide    filter?: Filter<T>;

    projection?: Record<keyof T, 1 | 0 | DocumentPath | ProjectionOperator>;

### üöÄ Phase 7: Performance Optimization (PENDING)}

- Benchmark array diff performance

- Consider using `fast-deep-equal` library instead of custom implementation// Discriminated union

- Add caching for pipeline execution if beneficialtype TableMapping<T> = SimpleTableMapping<T> | PipelineTableMapping<T>;

- Profile and optimize hot paths```



## Key Files**Pipeline Stages**:

```typescript

### Core Implementationtype PipelineStage = MatchStage | UnwindStage | SetStage | ProjectStage;

- `libs/zero-contracts/src/upstream/table-mapping.contract.ts` - Type definitions

- `libs/zero-contracts/src/upstream/table-mapping.helpers.ts` - Helper utilitiesinterface MatchStage { $match: Filter }

- `libs/zero-source-mongodb/src/v0/pipeline-executor.service.ts` - Pipeline executioninterface UnwindStage { $unwind: string | UnwindOptions }

- `libs/zero-source-mongodb/src/v0/array-diff.service.ts` - Array diffinginterface SetStage { $addFields: Dict }

- `libs/zero-source-mongodb/src/v0/change-maker-v0.ts` - Change stream handlerinterface ProjectStage { $project: Record<string, 1 | 0 | DocumentPath | ProjectionOperator> }

- `libs/zero-source-mongodb/src/v0/index.ts` - Service registration```



### Documentation### üìñ Example Usage

- `docs/projects/mongo-array-unwind-in-mapping/IMPLEMENTATION_PLAN.md` - Full plan

- `docs/projects/mongo-array-unwind-in-mapping/PHASE_3_COMPLETE.md` - Phase 3 summary**Basic Array Unwinding**:

- `docs/projects/mongo-array-unwind-in-mapping/PHASE_4_COMPLETE.md` - Phase 4 summary```typescript

- `.github/prompts/phase-4-array-diff.prompt.md` - Phase 4 implementation guideconst mapping: TableMapping = {

    source: 'accounts',

## Recent Commits    pipeline: [

        { $match: { bundle: 'ENTERPRISE' } },

### Phase 3 (10 commits total, includes Phase 4)        { $unwind: '$members' },

1-9: Phase 3 implementation (pipeline types, executor, ChangeMaker integration)        { $match: { 'members.role': { $in: ['admin', 'owner'] } } }

    ]

### Phase 4 (4 commits)};

10. `feat(source-mongodb): implement array diff service for optimization````

11. `feat(source-mongodb): register array diff service in module`

12. `feat(source-mongodb): optimize UPDATE with array diffing`**With Projection**:

13. `docs: add Phase 4 completion documentation````typescript

const mapping = pipelineBuilder<IAccountMember>('accounts')

**Total**: 13 commits on branch `copilot/vscode1762000567071`    .match({ bundle: 'ENTERPRISE' })

    .unwind('$members')

## Technical Design    .project({

        _id: { $concat: ['$_id', '_', '$members.id'] },

### Discriminated Union Pattern        accountId: '$_id',

```typescript        userId: '$members.id',

type TableMapping<T> = SimpleTableMapping<T> | PipelineTableMapping<T>;        role: '$members.role'

    })

interface SimpleTableMapping<T> {    .build();

  source: string;```

  filter?: Filter<T>;

  projection?: Projection<T>;### üß™ Testing Strategy (Phase 5)

}

**Unit Tests** (Priority):

interface PipelineTableMapping<T> {1. `PipelineExecutorService`:

  source: string;   - Each stage executor independently

  pipeline: PipelineStage<T>[];   - Expression evaluator for all operators

  projection?: Projection<T>;   - Edge cases: null, undefined, empty arrays

}2. `ChangeMakerV0` integration:

```   - Pipeline vs legacy mapping detection

   - Change generation for each operation type

### Array Diff Algorithm

```typescript**Integration Tests**:

interface ArrayDiffOptions {1. Real MongoDB change streams

  identityField?: string;     // e.g., 'memberId', '_id'2. Pipeline execution with sample data

  fallbackToIndex?: boolean;3. Zero sync protocol compliance

}

**E2E Tests**:

interface ArrayDiff {1. Full change source ‚Üí Zero client sync

  added: Array<{ index: number; value: any }>;2. Array updates propagating correctly

  removed: Array<{ index: number; value: any }>;3. Performance with large arrays

  modified: Array<{ index: number; oldValue: any; newValue: any }>;

}### üêõ Known Issues / Considerations

```

1. **Composite Keys**: Pipeline mappings that unwind need composite primary keys

**Identity-based matching**:   - Format: `{parentId}_{elementId}` or similar

1. Create Map of identity values for old and new arrays   - Must be defined in table spec

2. Elements in new but not old ‚Üí `added`

3. Elements in old but not new ‚Üí `removed`2. **Performance**: Unwinding large arrays in-memory

4. Elements in both but content differs ‚Üí `modified`   - May need streaming/batching for 1000+ elements

   - Consider pipeline stage limits

### Example Configuration

```typescript3. **Expression Coverage**: Current evaluator has 10 operators

// Account members unwinding   - MongoDB has 200+ operators

{   - Add more as needed (extensible architecture)

  tableName: 'account_members',

  spec: {4. **Change Ordering**: Multiple changes from single update

    schema: 'public',   - Must maintain causality

    primaryKey: ['accountId', 'memberId']   - Transaction boundaries important

  },

  config: {### üìö Documentation Created

    source: 'accounts',

    pipeline: [- `docs/projects/mongo-array-unwind-in-mapping/ISSUE.md` - Feature spec

      { $unwind: { path: '$members' } },- `docs/projects/mongo-array-unwind-in-mapping/IMPLEMENTATION_PLAN.md` - 7-phase plan

      { - `docs/projects/mongo-array-unwind-in-mapping/PHASE_1_2_COMPLETE.md` - Phases 1 & 2 summary

        $addFields: { - `docs/projects/mongo-array-unwind-in-mapping/PHASE_3_IN_PROGRESS.md` - Phase 3 progress

          accountId: '$_id',- `docs/projects/mongo-array-unwind-in-mapping/PROJECT_STAGE_COMPLETE.md` - $project stage docs

          memberId: '$members.userId',- `docs/projects/mongo-array-unwind-in-mapping/examples/` - Usage examples

          role: '$members.role'

        } ### üöÄ Commands to Continue

      }

    ]```bash

  }# Build packages

}pn build

```

# Run tests (when written)

## Build & Test Commandspn test



```powershell# Start dev server

# Build all packagespn dev

pnpm build:libs

# Lint/format

# Run tests (once Phase 5 tests are created)pn lint

pnpm testpn format

```

# Run specific test file

pnpm test array-diff.service.spec.ts### üí° Key Design Decisions Made



# Run with coverage1. **Discriminated Union**: Prevents mixing legacy and pipeline approaches at compile-time

pnpm test --coverage2. **Open-Closed Principle**: New pipeline stages can be added without modifying existing code

```3. **Backward Compatibility**: All existing SimpleTableMapping configurations continue to work

4. **Expression Evaluator**: Simplified MongoDB expression language (extensible as needed)

## Next Session Instructions5. **Type Safety**: Strong TypeScript typing throughout, with type guards for runtime checks



1. **Start with Phase 5 testing**---

2. Create unit tests for `ArrayDiffService` first (highest priority)

3. Create unit tests for `PipelineExecutorService`## Quick Start for Next Session

4. Create integration tests with MongoDB

5. Verify all tests pass and build succeeds1. Open `libs/zero-source-mongodb/src/v0/change-maker-v0.ts`

6. Document any issues or edge cases discovered during testing2. Locate `makeInsertChanges()` method (line ~90)

3. Add pipeline detection and execution logic

## Important Notes4. Test with sample mapping

5. Move to `makeUpdateChanges()` for array diff handling

- **Backward Compatibility**: All existing simple mappings continue to work unchanged

- **Performance**: Phase 4 provides ~200x improvement for array updates**Current Build Status**: ‚úÖ All packages compile successfully

- **Identity Fields**: Use single-column primary keys as identity fields when possible
- **Composite Keys**: Currently fall back to index-based matching for composite keys
- **Deep Equality**: Custom implementation, consider `fast-deep-equal` in Phase 7

## Context for AI Assistant

This is a production feature for Zero MongoDB change source that enables unwinding arrays in table mappings. The implementation follows the Open-Closed Principle with discriminated unions for type safety. Phases 1-4 are complete and working. Now we need comprehensive test coverage before moving to documentation and optimization phases.
