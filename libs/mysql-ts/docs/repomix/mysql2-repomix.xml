This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
.editorconfig
.gitattributes
.github/dependabot.yml
.github/FUNDING.yml
.github/workflows/benchmark.yml
.github/workflows/canary.yml
.github/workflows/ci-coverage.yml
.github/workflows/ci-linux.yml
.github/workflows/ci-mysql.yml
.github/workflows/ci-osx.yml
.github/workflows/ci-tsc-build.yml
.github/workflows/ci-website.yml
.github/workflows/ci-windows.yml
.github/workflows/codeql-analysis.yml
.github/workflows/gh-pages.yml
.github/workflows/lint.yml
.github/workflows/release.yml
.gitignore
.nycrc
.prettierignore
.prettierrc
benchmarks/bench-fake-server.js
benchmarks/bench-insert-select-parallel.js
benchmarks/bench-insert-select-prepared.js
benchmarks/bench-insert-select.js
benchmarks/benchmark-query.js
benchmarks/benchmark-server.js
benchmarks/benchmark.js
benchmarks/http-select-and-render.js
benchmarks/httperf.sh
benchmarks/index.html
benchmarks/integration/fake-server-select.js
benchmarks/test-benchmark-select-1.js
benchmarks/unit/packet_parser.js
benchmarks/unit/packets/column_definition.js
Changelog.md
CODE_OF_CONDUCT.md
codecov.yml
Contributing.md
eslint.config.mjs
fixtures/mysql-ssl-ca-cert.pem
index.d.ts
index.js
lib/auth_41.js
lib/auth_plugins/caching_sha2_password.js
lib/auth_plugins/caching_sha2_password.md
lib/auth_plugins/index.js
lib/auth_plugins/mysql_clear_password.js
lib/auth_plugins/mysql_native_password.js
lib/auth_plugins/sha256_password.js
lib/base/connection.js
lib/base/pool_connection.js
lib/base/pool.js
lib/commands/auth_switch.js
lib/commands/binlog_dump.js
lib/commands/change_user.js
lib/commands/client_handshake.js
lib/commands/close_statement.js
lib/commands/command.js
lib/commands/execute.js
lib/commands/index.js
lib/commands/ping.js
lib/commands/prepare.js
lib/commands/query.js
lib/commands/quit.js
lib/commands/register_slave.js
lib/commands/server_handshake.js
lib/compressed_protocol.js
lib/connection_config.js
lib/connection.js
lib/constants/charset_encodings.js
lib/constants/charsets.js
lib/constants/client.js
lib/constants/commands.js
lib/constants/cursor.js
lib/constants/encoding_charset.js
lib/constants/errors.js
lib/constants/field_flags.js
lib/constants/server_status.js
lib/constants/session_track.js
lib/constants/ssl_profiles.js
lib/constants/types.js
lib/create_connection.js
lib/create_pool_cluster.js
lib/create_pool.js
lib/helpers.js
lib/packet_parser.js
lib/packets/auth_next_factor.js
lib/packets/auth_switch_request_more_data.js
lib/packets/auth_switch_request.js
lib/packets/auth_switch_response.js
lib/packets/binary_row.js
lib/packets/binlog_dump.js
lib/packets/binlog_query_statusvars.js
lib/packets/change_user.js
lib/packets/close_statement.js
lib/packets/column_definition.js
lib/packets/execute.js
lib/packets/handshake_response.js
lib/packets/handshake.js
lib/packets/index.js
lib/packets/packet.js
lib/packets/prepare_statement.js
lib/packets/prepared_statement_header.js
lib/packets/query.js
lib/packets/register_slave.js
lib/packets/resultset_header.js
lib/packets/ssl_request.js
lib/packets/text_row.js
lib/parsers/binary_parser.js
lib/parsers/parser_cache.js
lib/parsers/static_binary_parser.js
lib/parsers/static_text_parser.js
lib/parsers/string.js
lib/parsers/text_parser.js
lib/pool_cluster.js
lib/pool_config.js
lib/pool_connection.js
lib/pool.js
lib/promise/connection.js
lib/promise/inherit_events.js
lib/promise/make_done_cb.js
lib/promise/pool_cluster.js
lib/promise/pool_connection.js
lib/promise/pool.js
lib/promise/prepared_statement_info.js
lib/results_stream.js
lib/server.js
License
package.json
promise.d.ts
promise.js
README.md
SECURITY.md
tea.yaml
test/common.test.cjs
test/esm/integration/connection/test-column-inspect.test.mjs
test/esm/integration/connection/test-execute-1.test.mjs
test/esm/integration/connection/test-vector.test.mjs
test/esm/integration/named-placeholders.test.mjs
test/esm/integration/parsers/execute-results-creation.test.mjs
test/esm/integration/parsers/json-parse.test.mjs
test/esm/integration/parsers/json-string.test.mjs
test/esm/integration/parsers/query-results-creation.test.mjs
test/esm/integration/parsers/typecast-field-string.test.mjs
test/esm/integration/pool-cluster/test-promise-wrapper.test.mjs
test/esm/integration/test-pool.test.mjs
test/esm/regressions/2052.test.mjs
test/esm/unit/check-extensions.test.mjs
test/esm/unit/parsers/big-numbers-strings-binary-sanitization.test.mjs
test/esm/unit/parsers/big-numbers-strings-text-sanitization.test.mjs
test/esm/unit/parsers/cache-key-serialization.test.mjs
test/esm/unit/parsers/ensure-safe-binary-fields.test.mjs
test/esm/unit/parsers/ensure-safe-text-fields.test.mjs
test/esm/unit/parsers/support-big-numbers-binary-sanitization.test.mjs
test/esm/unit/parsers/support-big-numbers-text-sanitization.test.mjs
test/esm/unit/parsers/timezone-binary-sanitization.test.mjs
test/esm/unit/parsers/timezone-text-sanitization.test.mjs
test/esm/unit/protocol/SqlString.test.mjs
test/fixtures/custom-conf/config-file.cnf
test/fixtures/data.csv
test/fixtures/ssl/certs/ca.pem
test/fixtures/ssl/certs/mkcerts.sh
test/fixtures/ssl/certs/server-cert.pem
test/fixtures/ssl/certs/server-req.pem
test/fixtures/ssl/client-flags.sh
test/integration/config/test-connect-timeout.test.cjs
test/integration/config/test-typecast-global-false.test.cjs
test/integration/config/test-typecast-global-option.test.cjs
test/integration/connection/encoding/test-charset-results.test.cjs
test/integration/connection/encoding/test-client-encodings.test.cjs
test/integration/connection/encoding/test-non-bmp-chars.test.cjs
test/integration/connection/encoding/test-track-encodings.test.cjs
test/integration/connection/test-binary-charset-string.test.cjs
test/integration/connection/test-binary-longlong.test.cjs
test/integration/connection/test-binary-multiple-results.test.cjs
test/integration/connection/test-binary-notnull-nulls.test.cjs
test/integration/connection/test-buffer-params.test.cjs
test/integration/connection/test-change-user-multi-factor.test.cjs
test/integration/connection/test-change-user-plugin-auth.test.cjs
test/integration/connection/test-change-user.test.cjs
test/integration/connection/test-charset-encoding.test.cjs
test/integration/connection/test-connect-after-connection-error.test.cjs
test/integration/connection/test-connect-after-connection.test.cjs
test/integration/connection/test-connect-connection-closed-error.test.cjs
test/integration/connection/test-connect-sha1.test.cjs
test/integration/connection/test-connect-time-error.test.cjs
test/integration/connection/test-connect-with-uri.test.cjs
test/integration/connection/test-connection-reset-while-closing.test.cjs
test/integration/connection/test-custom-date-parameter.test.cjs
test/integration/connection/test-date-parameter.test.cjs
test/integration/connection/test-datetime.test.cjs
test/integration/connection/test-decimals-as-numbers.test.cjs
test/integration/connection/test-disconnects.test.cjs
test/integration/connection/test-error-events.test.cjs
test/integration/connection/test-errors.test.cjs
test/integration/connection/test-execute-and-unprepare.test.cjs
test/integration/connection/test-execute-bind-boolean.test.cjs
test/integration/connection/test-execute-bind-date.test.cjs
test/integration/connection/test-execute-bind-function.test.cjs
test/integration/connection/test-execute-bind-json.test.cjs
test/integration/connection/test-execute-bind-null.test.cjs
test/integration/connection/test-execute-bind-number.test.cjs
test/integration/connection/test-execute-bind-undefined.test.cjs
test/integration/connection/test-execute-cached.test.cjs
test/integration/connection/test-execute-newdecimal.test.cjs
test/integration/connection/test-execute-nocolumndef.test.cjs
test/integration/connection/test-execute-null-bitmap.test.cjs
test/integration/connection/test-execute-order.test.cjs
test/integration/connection/test-execute-signed.test.cjs
test/integration/connection/test-execute-type-casting.test.cjs
test/integration/connection/test-insert-bigint-big-number-strings.test.cjs
test/integration/connection/test-insert-bigint.test.cjs
test/integration/connection/test-insert-json.test.cjs
test/integration/connection/test-insert-large-blob.test.cjs
test/integration/connection/test-insert-negative-ai.test.cjs
test/integration/connection/test-insert-results.test.cjs
test/integration/connection/test-invalid-date-result.test.cjs
test/integration/connection/test-load-infile.test.cjs
test/integration/connection/test-multiple-results.test.cjs
test/integration/connection/test-named-placeholders.test.cjs
test/integration/connection/test-nested-tables-query.test.cjs
test/integration/connection/test-null-buffer.test.cjs
test/integration/connection/test-null-double.test.cjs
test/integration/connection/test-null-int.test.cjs
test/integration/connection/test-null.test.cjs
test/integration/connection/test-parameters-questionmark.test.cjs
test/integration/connection/test-prepare-and-close.test.cjs
test/integration/connection/test-prepare-simple.test.cjs
test/integration/connection/test-prepare-then-execute.test.cjs
test/integration/connection/test-protocol-errors.test.cjs
test/integration/connection/test-query-timeout.test.cjs
test/integration/connection/test-query-zero.test.cjs
test/integration/connection/test-quit.test.cjs
test/integration/connection/test-select-1.test.cjs
test/integration/connection/test-select-empty-string.test.cjs
test/integration/connection/test-select-json.test.cjs
test/integration/connection/test-select-negative.test.cjs
test/integration/connection/test-select-ssl.test.cjs
test/integration/connection/test-select-utf8.test.cjs
test/integration/connection/test-server-listen.test.cjs
test/integration/connection/test-signed-tinyint.test.cjs
test/integration/connection/test-stream-errors.test.cjs
test/integration/connection/test-stream.test.cjs
test/integration/connection/test-then-on-query.test.cjs
test/integration/connection/test-timestamp.test.cjs
test/integration/connection/test-track-state-change.test.cjs
test/integration/connection/test-transaction-commit.test.cjs
test/integration/connection/test-transaction-rollback.test.cjs
test/integration/connection/test-type-cast-null-fields-execute.test.cjs
test/integration/connection/test-type-cast-null-fields.test.cjs
test/integration/connection/test-type-casting-execute.test.cjs
test/integration/connection/test-type-casting.test.cjs
test/integration/connection/test-typecast-execute.test.cjs
test/integration/connection/test-typecast-geometry-execute.test.cjs
test/integration/connection/test-typecast-geometry.test.cjs
test/integration/connection/test-typecast-overwriting-execute.test.cjs
test/integration/connection/test-typecast-overwriting.test.cjs
test/integration/connection/test-typecast.test.cjs
test/integration/connection/test-update-changed-rows.test.cjs
test/integration/connection/type-casting-tests.test.cjs
test/integration/promise-wrappers/test-async-stack.test.cjs
test/integration/promise-wrappers/test-promise-wrappers.test.cjs
test/integration/regressions/test-#433.test.cjs
test/integration/regressions/test-#442.test.cjs
test/integration/regressions/test-#485.test.cjs
test/integration/regressions/test-#617.test.cjs
test/integration/regressions/test-#629.test.cjs
test/integration/regressions/test-#82.test.cjs
test/integration/test-auth-switch-multi-factor.test.cjs
test/integration/test-auth-switch-plugin-async-error.test.cjs
test/integration/test-auth-switch-plugin-error.test.cjs
test/integration/test-auth-switch.test.cjs
test/integration/test-handshake-unknown-packet-error.test.cjs
test/integration/test-multi-result-streaming.test.cjs
test/integration/test-pool-connect-error.test.cjs
test/integration/test-pool-disconnect.test.cjs
test/integration/test-pool-end.test.cjs
test/integration/test-pool-release-idle-connection-replicate.test.cjs
test/integration/test-pool-release-idle-connection-timeout.test.cjs
test/integration/test-pool-release-idle-connection.test.cjs
test/integration/test-pool-release.test.cjs
test/integration/test-rows-as-array.test.cjs
test/integration/test-server-close.test.cjs
test/tsc-build/helpers.test.ts
test/tsc-build/index.test.ts
test/tsc-build/mysql/baseConnection.test.ts
test/tsc-build/mysql/constants/Charsets.test.ts
test/tsc-build/mysql/constants/CharsetToEncoding.test.ts
test/tsc-build/mysql/constants/Types.test.ts
test/tsc-build/mysql/createConnection/callbacks/execute.test.ts
test/tsc-build/mysql/createConnection/callbacks/query.test.ts
test/tsc-build/mysql/createConnection/promise/execute.test.ts
test/tsc-build/mysql/createConnection/promise/query.test.ts
test/tsc-build/mysql/createPool/callbacks/connection.test.ts
test/tsc-build/mysql/createPool/callbacks/createPool.test.ts
test/tsc-build/mysql/createPool/callbacks/execute.test.ts
test/tsc-build/mysql/createPool/callbacks/getConnection.test.ts
test/tsc-build/mysql/createPool/callbacks/query.test.ts
test/tsc-build/mysql/createPool/callbacks/release.test.ts
test/tsc-build/mysql/createPool/callbacks/releaseConnection.test.ts
test/tsc-build/mysql/createPool/promise/connection.test.ts
test/tsc-build/mysql/createPool/promise/execute.test.ts
test/tsc-build/mysql/createPool/promise/getConnection.test.ts
test/tsc-build/mysql/createPool/promise/promise.test.ts
test/tsc-build/mysql/createPool/promise/query.test.ts
test/tsc-build/mysql/createPool/promise/release.test.ts
test/tsc-build/mysql/createPool/promise/releaseConnection.test.ts
test/tsc-build/mysql/createPoolCluster/add.test.ts
test/tsc-build/mysql/createPoolCluster/getConnection.test.ts
test/tsc-build/mysql/createPoolCluster/of/getConnection.test.ts
test/tsc-build/mysql/createPoolCluster/of/of.test.ts
test/tsc-build/mysql/createPoolCluster/remove.test.ts
test/tsc-build/mysql/parsers/clearParserCache.test.ts
test/tsc-build/mysql/parsers/setMaxParserCache.test.ts
test/tsc-build/promise/baseConnection.test.ts
test/tsc-build/promise/constants/Charsets.test.ts
test/tsc-build/promise/constants/CharsetToEncoding.test.ts
test/tsc-build/promise/constants/Types.test.ts
test/tsc-build/promise/createConnection/execute.test.ts
test/tsc-build/promise/createConnection/query.test.ts
test/tsc-build/promise/createPool/connection.test.ts
test/tsc-build/promise/createPool/createPool.test.ts
test/tsc-build/promise/createPool/execute.test.ts
test/tsc-build/promise/createPool/getConnection.test.ts
test/tsc-build/promise/createPool/query.test.ts
test/tsc-build/promise/createPool/release.test.ts
test/tsc-build/promise/createPool/releaseConnection.test.ts
test/tsc-build/promise/createPoolCluster/add.test.ts
test/tsc-build/promise/createPoolCluster/getConnection.test.ts
test/tsc-build/promise/createPoolCluster/of/getConnection.test.ts
test/tsc-build/promise/createPoolCluster/of/of.test.ts
test/tsc-build/promise/parsers/clearParserCache.test.ts
test/tsc-build/promise/parsers/setMaxParserCache.test.ts
test/tsc-build/strict-checks/enableKeepAlive-and-keepAliveInitialDelay.test.ts
test/tsc-build/strict-checks/execute.test.ts
test/tsc-build/strict-checks/ProcedureCallPacket.test.ts
test/tsc-build/strict-checks/query.test.ts
test/tsc-build/strict-checks/typeCast.test.ts
test/tsc-build/tsconfig.json
test/unit/commands/test-query.test.cjs
test/unit/commands/test-quit.test.cjs
test/unit/connection/test-connection_config.test.cjs
test/unit/packets/test-column-definition.test.cjs
test/unit/packets/test-datetime.test.cjs
test/unit/packets/test-ok-autoinc.test.cjs
test/unit/packets/test-ok-sessiontrack.test.cjs
test/unit/packets/test-text-row.test.cjs
test/unit/packets/test-time.test.cjs
test/unit/parsers/test-text-parser.test.cjs
test/unit/pool-cluster/test-connection-error-remove.test.cjs
test/unit/pool-cluster/test-connection-order.test.cjs
test/unit/pool-cluster/test-connection-retry.test.cjs
test/unit/pool-cluster/test-connection-rr.test.cjs
test/unit/pool-cluster/test-query.test.cjs
test/unit/pool-cluster/test-remove-by-name.test.cjs
test/unit/pool-cluster/test-remove-by-pattern.test.cjs
test/unit/pool-cluster/test-restore-events.test.cjs
test/unit/pool-cluster/test-restore.test.cjs
test/unit/test-packet-parser.test.cjs
tools/.eslintrc
tools/create-db.js
tools/generate-charset-mapping.js
tools/parse-field.js
tools/parse-row.js
tools/wait-up.js
tsconfig.json
website/.gitignore
website/.prettierignore
website/.prettierrc
website/.purc.json
website/babel.config.js
website/biome.json
website/docs/acknowledgements.mdx
website/docs/api-and-configurations.mdx
website/docs/contributing/00-index.mdx
website/docs/contributing/website.mdx
website/docs/documentation/00-index.mdx
website/docs/documentation/authentication-switch.mdx
website/docs/documentation/connect-on-cloudflare.mdx
website/docs/documentation/extras.mdx
website/docs/documentation/mysql-server.mdx
website/docs/documentation/prepared-statements.mdx
website/docs/documentation/promise-wrapper.mdx
website/docs/documentation/ssl.mdx
website/docs/documentation/typescript-examples.mdx
website/docs/examples/00-index.mdx
website/docs/examples/binlog-watcher.mdx
website/docs/examples/connections/_category_.json
website/docs/examples/connections/create-connection.mdx
website/docs/examples/connections/create-pool.mdx
website/docs/examples/connections/createPoolCluster.mdx
website/docs/examples/promise-wrapper/_category_.json
website/docs/examples/promise-wrapper/co-await.mdx
website/docs/examples/queries/_category_.json
website/docs/examples/queries/prepared-statements/_category_.json
website/docs/examples/queries/prepared-statements/delete.mdx
website/docs/examples/queries/prepared-statements/index.mdx
website/docs/examples/queries/prepared-statements/insert.mdx
website/docs/examples/queries/prepared-statements/select.mdx
website/docs/examples/queries/prepared-statements/update.mdx
website/docs/examples/queries/simple-queries/_category_.json
website/docs/examples/queries/simple-queries/delete.mdx
website/docs/examples/queries/simple-queries/index.mdx
website/docs/examples/queries/simple-queries/insert.mdx
website/docs/examples/queries/simple-queries/select.mdx
website/docs/examples/queries/simple-queries/update.mdx
website/docs/examples/tests/_category_.json
website/docs/examples/tests/mysql-proxy.mdx
website/docs/examples/tests/pool.mdx
website/docs/examples/tests/server.mdx
website/docs/examples/typescript/_category_.json
website/docs/examples/typescript/basic-custom-class.mdx
website/docs/examples/typescript/procedure-call/_category_.json
website/docs/examples/typescript/procedure-call/00-index.mdx
website/docs/examples/typescript/procedure-call/01-row-as-array.mdx
website/docs/examples/typescript/row-data/_category_.json
website/docs/examples/typescript/row-data/00-index.mdx
website/docs/examples/typescript/row-data/01-row-as-array.mdx
website/docs/examples/typescript/row-data/02-multi-statements.mdx
website/docs/examples/typescript/row-data/03-row-as-array-multi-statements.mdx
website/docs/faq/00-index.mdx
website/docs/faq/how-to-handle-errors.mdx
website/docs/history-and-why-mysq2.mdx
website/docs/index.mdx
website/docs/stability-badges.mdx
website/docusaurus.config.ts
website/helpers/extract-method-content.ts
website/i18n/pt-BR/docusaurus-plugin-content-docs/current.json
website/i18n/pt-BR/docusaurus-plugin-content-docs/current/acknowledgements.mdx
website/i18n/pt-BR/docusaurus-plugin-content-docs/current/api-and-configurations.mdx
website/i18n/pt-BR/docusaurus-plugin-content-docs/current/contributing/00-index.mdx
website/i18n/pt-BR/docusaurus-plugin-content-docs/current/history-and-why-mysq2.mdx
website/i18n/pt-BR/docusaurus-plugin-content-docs/current/index.mdx
website/i18n/zh-CN/docusaurus-plugin-content-docs/current.json
website/i18n/zh-CN/docusaurus-plugin-content-docs/current/acknowledgements.mdx
website/i18n/zh-CN/docusaurus-plugin-content-docs/current/api-and-configurations.mdx
website/i18n/zh-CN/docusaurus-plugin-content-docs/current/contributing/00-index.mdx
website/i18n/zh-CN/docusaurus-plugin-content-docs/current/history-and-why-mysq2.mdx
website/i18n/zh-CN/docusaurus-plugin-content-docs/current/index.mdx
website/package.json
website/plugins/locale.ts
website/README.md
website/sidebars.ts
website/src/components/ExternalCodeEmbed.tsx
website/src/components/FAQ.tsx
website/src/components/History.tsx
website/src/components/Loading.tsx
website/src/components/PageTitle.tsx
website/src/components/Stability.tsx
website/src/css/_faq.scss
website/src/css/_history.scss
website/src/css/_loading.scss
website/src/css/_mixins.scss
website/src/css/custom.scss
website/src/css/stability/_dark.scss
website/src/css/stability/_light.scss
website/src/css/stability/_main.scss
website/src/pages/index.tsx
website/static/img/favicon.svg
website/test/fixtures/external-code-embed/handleCompressedPacket.txt
website/test/fixtures/external-code-embed/handler.txt
website/test/fixtures/external-code-embed/HistoryRecords.txt
website/test/fixtures/external-code-embed/makeSelector.txt
website/test/fixtures/external-code-embed/Pool.txt
website/test/fixtures/external-code-embed/QueryOptions.txt
website/test/resources/external-code-embed/random-methods.txt
website/test/unit/check-extensions.test.ts
website/test/unit/external-code-embed.test.ts
website/test/utils/gen-expected-extract-results.test.ts
website/tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".editorconfig">
root = true

[*]
indent_size = 2
indent_style = space
trim_trailing_whitespace = true
insert_final_newline = true
</file>

<file path=".gitattributes">
website/** linguist-documentation
</file>

<file path=".github/dependabot.yml">
version: 2
updates:
  - package-ecosystem: 'npm'
    directory: '/'
    schedule:
      interval: 'daily'
  - package-ecosystem: 'npm'
    directory: '/website'
    schedule:
      interval: 'daily'
</file>

<file path=".github/FUNDING.yml">
github: [sidorares]
</file>

<file path=".github/workflows/benchmark.yml">
name: Benchmark

on:
  pull_request:
  push:
    branches: [main]

  workflow_dispatch:

env:
  MYSQL_PORT: 3306
  MYSQL_USER: root
  MYSQL_DATABASE: test

jobs:
  benchmark:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        node-version: [22]
        mysql-version: ['mysql:8.0.18']
        use-compression: [0]
        use-tls: [0]

    name: Performance regression check

    steps:
      - uses: actions/checkout@v4

      # - name: Set up MySQL
      #   run: docker run -d -e MYSQL_ALLOW_EMPTY_PASSWORD=1 -e MYSQL_ROOT_PASSWORD=${{ env.MYSQL_PASSWORD }} -e MYSQL_DATABASE=${{ env.MYSQL_DATABASE }} -v $PWD/mysqldata:/var/lib/mysql/ -v $PWD/test/fixtures/custom-conf:/etc/mysql/conf.d -v $PWD/test/fixtures/ssl/certs:/certs -p ${{ env.MYSQL_PORT }}:3306 ${{ matrix.mysql-version }}
      - name: Set up Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-linux-${{ hashFiles('package-lock.json') }}
          restore-keys: npm-linux-

      - name: Install npm dependencies
        run: npm ci

      # - name: Wait mysql server is ready
      #   run: node tools/wait-up.js

      - name: Run benchmark
        run: node benchmarks/benchmark.js | tee output.txt

      - name: Download previous benchmark data
        uses: actions/cache@v4
        with:
          path: ./cache
          key: ${{ runner.os }}-benchmark

      - name: Store benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: 'benchmarkjs'
          output-file-path: output.txt
          external-data-json-path: ./cache/benchmark-data.json
          fail-on-alert: false
          auto-push: false
          alert-threshold: '150%'
          github-token: ${{ secrets.GITHUB_TOKEN }}
          comment-on-alert: true
          alert-comment-cc-users: '@sidorares'
</file>

<file path=".github/workflows/canary.yml">
name: 'Canary Publishing'

on:
  push:
    branches:
      - master
  workflow_dispatch:

permissions:
  contents: write
  pull-requests: write
  id-token: write

jobs:
  canary:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    name: Canary
    steps:
      - name: Actions - Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check Commit Message
        id: check_commit
        run: |
          MESSAGE=$(git log -1 --pretty=%s --no-merges)
          echo "Commit message: $MESSAGE"

          if [[ "$MESSAGE" =~ build\(deps-dev\) ]] ||
             [[ "$MESSAGE" =~ build\(deps\) ]] ||
             [[ "$MESSAGE" =~ chore\(master\) ]] ||
             [[ "$MESSAGE" =~ chore\(deps\) ]] ||
             [[ "$MESSAGE" =~ chore:\ update\ dependencies ]] ||
             [[ "$MESSAGE" =~ docs: ]] ||
             [[ "$MESSAGE" =~ ci: ]] ||
             [[ "$MESSAGE" =~ cd: ]] ||
             [[ "$MESSAGE" =~ docs\(.*\): ]] ||
             [[ "$MESSAGE" =~ ci\(.*\): ]] ||
             [[ "$MESSAGE" =~ cd\(.*\): ]] ||
             [[ "$MESSAGE" =~ chore\(website\) ]]; then
            echo "publish=false" >> $GITHUB_OUTPUT
            echo "Skip publish"
          else
            echo "publish=true" >> $GITHUB_OUTPUT
          fi

      - name: Actions - Setup Node.js
        if: steps.check_commit.outputs.publish == 'true'
        uses: actions/setup-node@v4
        with:
          node-version: 22
          registry-url: 'https://registry.npmjs.org'

      - name: Cache dependencies
        if: steps.check_commit.outputs.publish == 'true'
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-linux-${{ hashFiles('package-lock.json') }}
          restore-keys: npm-linux-

      - name: Installing Dependencies
        if: steps.check_commit.outputs.publish == 'true'
        run: npm ci

      - name: Git Hash
        if: steps.check_commit.outputs.publish == 'true'
        run: |
          npm version patch --no-git-tag-version
          VERSION=$(node -p "require('./package.json').version")
          SHORT_SHA=$(git rev-parse --short HEAD)
          echo "VERSION=${VERSION}-canary.${SHORT_SHA}" >> $GITHUB_ENV

      - name: Increment Canary Version
        if: steps.check_commit.outputs.publish == 'true'
        run: npm version $VERSION --no-git-tag-version

      - name: Publishing Package
        if: steps.check_commit.outputs.publish == 'true'
        env:
          NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}
        run: npm publish --tag canary --provenance
</file>

<file path=".github/workflows/ci-coverage.yml">
name: CI - Coverage

on:
  pull_request:
  push:
    branches: [master]

  workflow_dispatch:

env:
  MYSQL_PORT: 3306
  MYSQL_USER: root
  MYSQL_DATABASE: test

jobs:
  coverage:
    permissions: write-all
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        node-version: [22]
        mysql-version: ['mysql:5.7', 'mysql:8.0', 'mysql:9.0']
        use-compression: [0, 1]
        use-tls: [0, 1]
        static-parser: [0, 1]
        mysql_connection_url_key: ['']
    env:
      MYSQL_CONNECTION_URL: ${{ secrets[matrix.mysql_connection_url_key] }}
      STATIC_PARSER: ${{ matrix.static-parser }}

    name: Coverage ${{ matrix.node-version }} - DB ${{ matrix.mysql-version }}${{ matrix.mysql_connection_url_key }} - SSL=${{matrix.use-tls}} Compression=${{matrix.use-compression}} Static Parser=${{matrix.static-parser}}

    steps:
      - uses: actions/checkout@v4

      - name: Set up MySQL
        if: ${{ matrix.mysql-version }}
        run: docker run -d -e MYSQL_ALLOW_EMPTY_PASSWORD=1 -e MYSQL_DATABASE=${{ env.MYSQL_DATABASE }} -v $PWD/mysqldata:/var/lib/mysql/ -v $PWD/test/fixtures/custom-conf:/etc/mysql/conf.d -v $PWD/test/fixtures/ssl/certs:/certs -p ${{ env.MYSQL_PORT }}:3306 ${{ matrix.mysql-version }}

      - name: Set up Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-linux-${{ hashFiles('package-lock.json') }}
          restore-keys: npm-linux-

      - name: Install npm dependencies
        run: npm ci

      - name: Wait mysql server is ready
        if: ${{ matrix.mysql-version }}
        run: node tools/wait-up.js

      - name: Run tests
        run: FILTER=${{matrix.filter}} MYSQL_USE_TLS=${{ matrix.use-tls }} MYSQL_USE_COMPRESSION=${{ matrix.use-compression }} npm run coverage-test

      - name: Upload coverage reports to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          flags: compression-${{ matrix.use-compression }},tls-${{ matrix.use-tls }},static-parser-${{ matrix.static-parser }}
          name: codecov-umbrella-${{ matrix.node-version }}-${{ matrix.mysql-version }}-compression-${{ matrix.use-compression }}-tls-${{ matrix.use-tls }}-static-parser-${{ matrix.static-parser }}
</file>

<file path=".github/workflows/ci-linux.yml">
name: CI - Linux

on:
  pull_request:
  push:
    branches: [main]

  workflow_dispatch:

env:
  MYSQL_PORT: 3306
  MYSQL_USER: root
  MYSQL_DATABASE: test

jobs:
  tests-linux:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        node-version: [18, 20, 22, 23]
        mysql-version: ['mysql:8.3']
        use-compression: [0, 1]
        use-tls: [0, 1]
        mysql_connection_url_key: ['']
        # static-parser: [0, 1]  # Already tested in "ci-coverage"
        # TODO - add mariadb to the matrix. currently few tests are broken due to mariadb incompatibilities

    env:
      MYSQL_CONNECTION_URL: ${{ secrets[matrix.mysql_connection_url_key] }}

    name: Node.js ${{ matrix.node-version }} - DB ${{ matrix.mysql-version }}${{ matrix.mysql_connection_url_key }} - SSL=${{matrix.use-tls}} Compression=${{matrix.use-compression}}

    steps:
      - uses: actions/checkout@v4

      - name: Set up MySQL
        if: ${{ matrix.mysql-version }}
        run: docker run -d -e MYSQL_ALLOW_EMPTY_PASSWORD=1 -e MYSQL_DATABASE=${{ env.MYSQL_DATABASE }} -v $PWD/mysqldata:/var/lib/mysql/ -v $PWD/test/fixtures/custom-conf:/etc/mysql/conf.d -v $PWD/test/fixtures/ssl/certs:/certs -p ${{ env.MYSQL_PORT }}:3306 ${{ matrix.mysql-version }}

      - name: Set up Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-linux-${{ hashFiles('package-lock.json') }}
          restore-keys: npm-linux-

      - name: Install npm dependencies
        run: npm ci

      - name: Wait mysql server is ready
        if: ${{ matrix.mysql-version }}
        run: node tools/wait-up.js

      - name: Run tests
        run: FILTER=${{matrix.filter}} MYSQL_USE_TLS=${{ matrix.use-tls }} MYSQL_USE_COMPRESSION=${{ matrix.use-compression }} npm run test
        timeout-minutes: 10

  tests-linux-bun:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        bun-version: [latest, canary]
        mysql-version: ['mysql:8.3']
        use-compression: [0, 1]
        use-tls: [0, 1]
        static-parser: [0, 1]

    env:
      STATIC_PARSER: ${{ matrix.static-parser }}

    name: Bun ${{ matrix.bun-version }} - DB ${{ matrix.mysql-version }} - SSL=${{matrix.use-tls}} Compression=${{matrix.use-compression}} Static Parser=${{matrix.static-parser}}

    steps:
      - uses: actions/checkout@v4
      - name: Set up MySQL
        run: docker run -d -e MYSQL_ALLOW_EMPTY_PASSWORD=1 -e MYSQL_DATABASE=${{ env.MYSQL_DATABASE }} -v $PWD/mysqldata:/var/lib/mysql/ -v $PWD/test/fixtures/custom-conf:/etc/mysql/conf.d -v $PWD/test/fixtures/ssl/certs:/certs -p ${{ env.MYSQL_PORT }}:3306 ${{ matrix.mysql-version }}

      - name: Set up Bun ${{ matrix.bun-version }}
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: ${{ matrix.bun-version }}

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-linux-${{ hashFiles('package-lock.json') }}
          restore-keys: npm-linux-

      - name: Install npm dependencies
        run: npm ci

      - name: Wait mysql server is ready
        run: node tools/wait-up.js

      # todo: run full test suite once test createServer is implemented using Bun.listen
      - name: run tests
        env:
          MYSQL_USER: ${{ env.MYSQL_USER }}
          MYSQL_DATABASE: ${{ env.MYSQL_DATABASE }}
          MYSQL_PORT: ${{ env.MYSQL_PORT }}
          MYSQL_USE_COMPRESSION: ${{ matrix.use-compression }}
          MYSQL_USE_TLS: ${{ matrix.use-tls }}
          FILTER: test-select-1|test-select-ssl
        run: bun run test:bun
        timeout-minutes: 10

  tests-linux-deno-v1:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        deno-version: [v1.x]
        mysql-version: ['mysql:8.3']
        use-compression: [0, 1]
        static-parser: [0, 1]
        # TODO: investigate error when using SSL (1)
        #
        # errno: -4094
        # code: "UNKNOWN"
        # syscall: "read"
        use-tls: [0]

    env:
      STATIC_PARSER: ${{ matrix.static-parser }}

    name: Deno ${{ matrix.deno-version }} - DB ${{ matrix.mysql-version }} - SSL=${{matrix.use-tls}} Compression=${{matrix.use-compression}} Static Parser=${{matrix.static-parser}}

    steps:
      - uses: actions/checkout@v4
      - name: Set up MySQL
        run: docker run -d -e MYSQL_ALLOW_EMPTY_PASSWORD=1 -e MYSQL_DATABASE=${{ env.MYSQL_DATABASE }} -v $PWD/mysqldata:/var/lib/mysql/ -v $PWD/test/fixtures/custom-conf:/etc/mysql/conf.d -v $PWD/test/fixtures/ssl/certs:/certs -p ${{ env.MYSQL_PORT }}:3306 ${{ matrix.mysql-version }}

      - name: Set up Deno ${{ matrix.deno-version }}
        uses: denoland/setup-deno@v1
        with:
          deno-version: ${{ matrix.deno-version }}

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-linux-${{ hashFiles('package-lock.json') }}
          restore-keys: npm-linux-

      - name: Install npm dependencies
        run: npm ci

      - name: Wait mysql server is ready
        run: node tools/wait-up.js

      - name: run tests
        env:
          MYSQL_USER: ${{ env.MYSQL_USER }}
          MYSQL_DATABASE: ${{ env.MYSQL_DATABASE }}
          MYSQL_PORT: ${{ env.MYSQL_PORT }}
          MYSQL_USE_COMPRESSION: ${{ matrix.use-compression }}
          MYSQL_USE_TLS: ${{ matrix.use-tls }}
        run: deno task test:deno -- --denoCjs='.js,.cjs'
        timeout-minutes: 10

  tests-linux-deno-v2:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        deno-version: [v2.x, canary]
        mysql-version: ['mysql:8.3']
        use-compression: [0, 1]
        static-parser: [0, 1]
        # TODO: investigate error when using SSL (1)
        #
        # errno: -4094
        # code: "UNKNOWN"
        # syscall: "read"
        use-tls: [0]

    env:
      STATIC_PARSER: ${{ matrix.static-parser }}

    name: Deno ${{ matrix.deno-version }} - DB ${{ matrix.mysql-version }} - SSL=${{matrix.use-tls}} Compression=${{matrix.use-compression}} Static Parser=${{matrix.static-parser}}

    steps:
      - uses: actions/checkout@v4
      - name: Set up MySQL
        run: docker run -d -e MYSQL_ALLOW_EMPTY_PASSWORD=1 -e MYSQL_DATABASE=${{ env.MYSQL_DATABASE }} -v $PWD/mysqldata:/var/lib/mysql/ -v $PWD/test/fixtures/custom-conf:/etc/mysql/conf.d -v $PWD/test/fixtures/ssl/certs:/certs -p ${{ env.MYSQL_PORT }}:3306 ${{ matrix.mysql-version }}

      - name: Set up Deno ${{ matrix.deno-version }}
        uses: denoland/setup-deno@v1
        with:
          deno-version: ${{ matrix.deno-version }}

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 22
      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-linux-${{ hashFiles('package-lock.json') }}
          restore-keys: npm-linux-

      - name: Install npm dependencies
        run: npm ci

      - name: Wait mysql server is ready
        run: node tools/wait-up.js

      - name: run tests
        env:
          MYSQL_USER: ${{ env.MYSQL_USER }}
          MYSQL_DATABASE: ${{ env.MYSQL_DATABASE }}
          MYSQL_PORT: ${{ env.MYSQL_PORT }}
          MYSQL_USE_COMPRESSION: ${{ matrix.use-compression }}
          MYSQL_USE_TLS: ${{ matrix.use-tls }}
        run: deno task test:deno
        timeout-minutes: 10
</file>

<file path=".github/workflows/ci-mysql.yml">
name: CI - MySQL

on:
  pull_request:
  push:
    branches: [main]
  workflow_dispatch:

env:
  MYSQL_PORT: 3306
  MYSQL_USER: root
  MYSQL_DATABASE: test

jobs:
  tests-linux:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        node-version: [22]
        mysql-version: [
            # 'mysql:5.7', # Already tested in "ci-coverage"
            # 'mysql:8.0', # Already tested in "ci-coverage"
            'mysql:8.1',
            'mysql:8.2',
            # 'mysql:8.3', # Already tested in "ci-linux"
            # 'mysql:8.4', # TODO: Tests never end
            # 'mysql:9.0', # Already tested in "ci-coverage"
            'mysql:9.1',
            'mysql:9.2',
          ]
        use-compression: [0, 1]
        use-tls: [0, 1]
        mysql_connection_url_key: ['']
        include:
          ## MySQL 5.1: A number of tests does not work due to old sql syntax, just testing basic connection
          - filter: 'test-select-1'
            mysql-version: 'datagrip/mysql:5.1'
            use-compression: 0
            use-tls: 0

    env:
      MYSQL_CONNECTION_URL: ${{ secrets[matrix.mysql_connection_url_key] }}

    name: ${{ matrix.mysql-version }}${{ matrix.mysql_connection_url_key }} - SSL=${{matrix.use-tls}} Compression=${{matrix.use-compression}}

    steps:
      - uses: actions/checkout@v4

      - name: Set up MySQL
        if: ${{ matrix.mysql-version }}
        run: docker run -d -e MYSQL_ALLOW_EMPTY_PASSWORD=1 -e MYSQL_DATABASE=${{ env.MYSQL_DATABASE }} -v $PWD/mysqldata:/var/lib/mysql/ -v $PWD/test/fixtures/custom-conf:/etc/mysql/conf.d -v $PWD/test/fixtures/ssl/certs:/certs -p ${{ env.MYSQL_PORT }}:3306 ${{ matrix.mysql-version }}

      - name: Set up Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-linux-${{ hashFiles('package-lock.json') }}
          restore-keys: npm-linux-

      - name: Install npm dependencies
        run: npm ci

      - name: Wait mysql server is ready
        if: ${{ matrix.mysql-version }}
        run: node tools/wait-up.js

      - name: Run tests
        run: FILTER=${{matrix.filter}} npm run test
</file>

<file path=".github/workflows/ci-osx.yml">
name: CI - OSX

on:
  pull_request:
  push:
    branches: [main]

  workflow_dispatch:

env:
  MYSQL_PORT: 3306
  MYSQL_USER: root
  MYSQL_DATABASE: test

jobs:
  tests-osx:
    runs-on: macos-latest
    strategy:
      fail-fast: false
      matrix:
        node-version: [22]
        use-compression: [0, 1]
        use-tls: [0, 1]

    name: Node.js ${{ matrix.node-version }} - DB ${{ matrix.mysql-version }} - SSL=${{matrix.use-tls}} Compression=${{matrix.use-compression}}

    steps:
      - uses: actions/checkout@v4

      - name: Install MySQL
        run: |
          brew install mysql@8.0
          brew link mysql@8.0 --force

      - name: Start MySQL Service
        run: brew services start mysql@8.0

      - name: Set up Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-osx-${{ hashFiles('package-lock.json') }}
          restore-keys: npm-osx-

      - name: Install npm dependencies
        run: npm ci

      - name: Wait mysql server is ready
        run: node tools/wait-up.js

      - name: Configure MySQL
        run: |
          mysql -u root -e "CREATE DATABASE IF NOT EXISTS ${MYSQL_DATABASE};"

      - name: Run tests
        run: FILTER=${{matrix.filter}} MYSQL_USE_TLS=${{ matrix.use-tls }} MYSQL_USE_COMPRESSION=${{ matrix.use-compression }} npm run test
</file>

<file path=".github/workflows/ci-tsc-build.yml">
name: CI - TypeScript Build

on:
  pull_request:
  push:
    branches: [main]

  workflow_dispatch:

jobs:
  tests-tsc-build:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        node-version: [22]

    name: Node.js ${{ matrix.node-version }}
    steps:
      - uses: actions/checkout@v4

      - name: Set up Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-linux-${{ hashFiles('package-lock.json') }}
          restore-keys: npm-linux-

      - name: Install npm dependencies
        run: npm ci

      - name: Testing TypeScript build
        run: npm run test:tsc-build
</file>

<file path=".github/workflows/ci-website.yml">
name: 'CI - Website'
on:
  pull_request:
    paths:
      - 'website/**'
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Actions - Checkout
        uses: actions/checkout@v4

      - name: Actions - Setup NodeJS
        uses: actions/setup-node@v4
        with:
          node-version: 22

      - name: Cache Dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-website-${{ hashFiles('website/package-lock.json') }}
          restore-keys: npm-website-

      - name: Installing Dependencies
        run: cd website && npm ci

      - name: Lint Checking
        run: cd website && npm run lintcheck

      - name: Checking Types
        run: cd website && npm run typecheck

      - name: Run Unit Tests
        run: cd website && npm run test:unit

      - name: Checking Build
        run: cd website && npm run build
</file>

<file path=".github/workflows/ci-windows.yml">
name: CI - Windows

on:
  pull_request:
  push:
    branches: [main]

  workflow_dispatch:

env:
  MYSQL_PORT: 3306
  MYSQL_USER: root
  MYSQL_DATABASE: test

jobs:
  tests-windows:
    runs-on: windows-latest
    strategy:
      fail-fast: false
      matrix:
        node-version: [22]
        mysql-version: ['8.0']
        use-compression: [0, 1]
        use-tls: [0, 1]

    name: Node.js ${{ matrix.node-version }} - DB ${{ matrix.mysql-version }} - SSL=${{matrix.use-tls}} Compression=${{matrix.use-compression}}

    steps:
      - uses: actions/checkout@v4
      - name: Set up MySQL
        uses: shogo82148/actions-setup-mysql@v1
        with:
          mysql-version: ${{ matrix.mysql-version }}

      - name: Set up Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install npm dependencies
        run: npm ci
      - name: Wait mysql server is ready
        run: node tools/wait-up.js
      - run: node tools/create-db.js
      - name: Run tests
        run: npm test
        env:
          MYSQL_USE_TLS: ${{ matrix.use-tls }}
          MYSQL_USE_COMPRESSION: ${{ matrix.use-compression }}
</file>

<file path=".github/workflows/codeql-analysis.yml">
# For most projects, this workflow file will not need changing; you simply need
# to commit it to your repository.
#
# You may wish to alter this file to override the set of languages analyzed,
# or to provide custom queries or build logic.
#
# ******** NOTE ********
# We have attempted to detect the languages in your repository. Please check
# the `language` matrix defined below to confirm you have the correct set of
# supported CodeQL languages.
#
name: 'CodeQL'

on:
  push:
    branches: [master]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [master]
  schedule:
    - cron: '17 2 * * 3'

jobs:
  analyze:
    name: Analyze
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
      security-events: write

    strategy:
      fail-fast: false
      matrix:
        language: ['javascript']
        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]
        # Learn more:
        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # Initializes the CodeQL tools for scanning.
      - name: Initialize CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: ${{ matrix.language }}
          # If you wish to specify custom queries, you can do so here or in a config file.
          # By default, queries listed here will override any specified in a config file.
          # Prefix the list here with "+" to use these queries and those in the config file.
          # queries: ./path/to/local/query, your-org/your-repo/queries@main

      # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).
      # If this step fails, then you should remove it and run the build manually (see below)
      - name: Autobuild
        uses: github/codeql-action/autobuild@v3

      # ℹ️ Command-line programs to run using the OS shell.
      # 📚 https://git.io/JvXDl

      # ✏️ If the Autobuild fails above, remove it and uncomment the following three lines
      #    and modify them (or add more) to build your code if your project
      #    uses a compiled language

      #- run: |
      #   make bootstrap
      #   make release

      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v3
</file>

<file path=".github/workflows/gh-pages.yml">
name: 'GitHub Pages'
on:
  push:
    branches:
      - master
    paths:
      - 'website/**'
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Actions - Checkout
        uses: actions/checkout@v4

      - name: Actions - Setup NodeJS
        uses: actions/setup-node@v4
        with:
          node-version: 22

      - name: Cache Dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-website-${{ hashFiles('website/package-lock.json') }}
          restore-keys: npm-website-

      - name: Installing Dependencies
        run: cd website && npm ci

      - name: Checking Types
        run: cd website && npm run typecheck

      - name: Run Unit Tests
        run: cd website && npm run test:unit

      - name: Building Site
        run: cd website && npm run build

      - name: Deploy
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./website/build
</file>

<file path=".github/workflows/lint.yml">
name: lint

on:
  pull_request:
  push:
    branches: [master]
  workflow_dispatch:

env:
  NODE_VERSION: 22

jobs:
  lint-js:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Use Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-linux-${{ hashFiles('package-lock.json') }}
          restore-keys: npm-linux-

      - name: Install ESLint + ESLint configs/plugins
        run: npm install --only=dev

      - name: Lint
        run: npm run lint
</file>

<file path=".github/workflows/release.yml">
on:
  push:
    branches:
      - master
  workflow_dispatch:
name: release-please
permissions:
  contents: write
  pull-requests: write
  id-token: write
jobs:
  release-please:
    runs-on: ubuntu-latest
    steps:
      - uses: google-github-actions/release-please-action@v3
        id: release
        with:
          release-type: node
          package-name: mysql2
          changelog-path: 'Changelog.md'

      - uses: actions/checkout@v4
        if: ${{ steps.release.outputs.release_created }}

      - uses: actions/setup-node@v4
        if: ${{ steps.release.outputs.release_created }}
        with:
          node-version: 22
          registry-url: 'https://registry.npmjs.org'

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: npm-linux-${{ hashFiles('package-lock.json') }}
          restore-keys: npm-linux-

      - run: npm ci
        if: ${{ steps.release.outputs.release_created }}

      - run: npm publish --provenance
        if: ${{ steps.release.outputs.release_created }}
        env:
          NODE_AUTH_TOKEN: ${{secrets.NPM_TOKEN}}
</file>

<file path=".gitignore">
lib-cov
*.seed
*.log
*.csv
*.dat
*.out
*.pid
*.gz
.DS_Store
.idea/
.vscode/
.npmrc
coverage/
mysqldata/

tmp
pids
logs

node_modules
npm-debug.log
benchmarks/results.json
!test/fixtures/data.csv
</file>

<file path=".nycrc">
{
  "all": true,
  "include": ["index.js", "promise.js", "lib/**/*.js"],
  "exclude": ["mysqldata/**", "node_modules/**", "test/**"],
  "reporter": ["text", "lcov", "cobertura"],
  "statements": 80,
  "branches": 80,
  "functions": 77,
  "lines": 80,
  "checkCoverage": true,
  "clean": true
}
</file>

<file path=".prettierignore">
website/
Changelog.md
</file>

<file path=".prettierrc">
{
  "printWidth": 80,
  "tabWidth": 2,
  "semi": true,
  "singleQuote": true,
  "quoteProps": "as-needed",
  "jsxSingleQuote": true,
  "trailingComma": "es5",
  "bracketSpacing": true,
  "bracketSameLine": false,
  "arrowParens": "always",
  "proseWrap": "preserve",
  "htmlWhitespaceSensitivity": "css",
  "endOfLine": "lf",
  "embeddedLanguageFormatting": "auto",
  "singleAttributePerLine": false
}
</file>

<file path="benchmarks/bench-fake-server.js">
'use strict';

const common = require('../test/common');
let connection = common.createConnection();

// ==== simple pool ===
const connections = new Array(10);
for (let i = 0; i < connections.length; ++i)
  connections[i] = common.createConnection();
let currConn = 0;
function next() {
  currConn++;
  if (currConn === connections.length) currConn = 0;
  connection = connections[currConn];
}
// ======================

function benchmarkSelect(numLeft, callback) {
  //connection.query('query from fake server fixture', function(err, result) {

  // comment if no pool:
  next();

  let rows = 0;
  const q = connection.query('query from fake server fixture');
  q.on('result', () => {
    rows++;
  });
  q.on('end', () => {
    if (numLeft > 1) benchmarkSelect(numLeft - 1, callback);
    else callback(rows);
  });
}

function benchmarkSelects(n, cb) {
  const numSelects = 100000;
  const start = process.hrtime();
  benchmarkSelect(numSelects, (rowsPerQuery) => {
    const end = process.hrtime();
    const diff = common.hrdiff(start, end);
    console.log(
      ` rows: ${(numSelects * 1e9) / diff}} results/sec, ${(rowsPerQuery * numSelects * 1e9) / diff} rows/sec`
    );
    if (n > 1) benchmarkSelects(n - 1, cb);
    else cb();
  });
}

module.exports = function (done) {
  const testStart = process.hrtime();
  benchmarkSelects(5, () => {
    const testEnd = process.hrtime();
    console.log('total time: ', common.hrdiff(testStart, testEnd) / 1e9);
    connection.end();
    if (done) done();
  });
};

module.exports();
</file>

<file path="benchmarks/bench-insert-select-parallel.js">
'use strict';

const common = require('../test/common');
const connection = common.createConnection();

const table = 'insert_test';
//const text = "本日は晴天なり";
const text = 'test abc xyz';
connection.query(`drop table ${table}`).on('error', () => {});
connection.query(
  [
    `CREATE TABLE \`${table}\` (`,
    '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    '`title` varchar(255) NOT NULL,',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n')
);

function benchmarkInsert(numLeft, callback) {
  connection.query(`INSERT INTO ${table} SET title="${text}"`, (err) => {
    if (err) throw err;
    if (numLeft > 1) benchmarkInsert(numLeft - 1, callback);
    else callback();
  });
}

function benchmarkInserts(n, cb) {
  const numInsert = 50000;
  const start = process.hrtime();
  benchmarkInsert(numInsert, () => {
    const end = process.hrtime();
    const diff = common.hrdiff(start, end);
    console.log(`${(numInsert * 1e9) / diff} inserts/sec`);
    if (n > 1) benchmarkInserts(n - 1, cb);
    else cb();
  });
}

function benchmarkParallelSelects(n, size, cb) {
  const start = process.hrtime();
  let numRunning = 0;

  function commandDone() {
    console.log(numRunning);
    numRunning--;
    if (numRunning > 0) return;
    const end = process.hrtime();
    const diff = common.hrdiff(start, end);
    console.log(
      `${size} rows: ${(n * 1e9) / diff} results/sec, ${(size * n * 1e9) / diff} rows/sec`
    );
    cb();
  }

  const connections = new Array(n);
  for (let i = 0; i < n; ++i) {
    numRunning++;
    connections[i] = common.createConnection();
    const cmd = connections[i].execute(
      `select * from ${table} limit ${size}`,
      []
    );
    cmd.on('end', commandDone);
  }
}

module.exports = function (done) {
  const testStart = process.hrtime();
  benchmarkInserts(1, () => {
    benchmarkParallelSelects(8, 50000, () => {
      const testEnd = process.hrtime();
      console.log('total time: ', common.hrdiff(testStart, testEnd) / 1e9);
      if (done) done();
    });
  });
};

if (require.main === module) {
  module.exports();
}
</file>

<file path="benchmarks/bench-insert-select-prepared.js">
'use strict';

const common = require('../test/common');
const connection = common.createConnection();

const table = 'insert_test';
//const text = "本日は晴天なり";
const text = 'test abc xyz';
connection.query(
  [
    `CREATE TEMPORARY TABLE \`${table}\` (`,
    '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    '`title` varchar(255),',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n')
);

function benchmarkInsert(numLeft, callback) {
  connection.execute(`INSERT INTO ${table} SET title="${text}"`, [], (err) => {
    if (err) throw err;
    if (numLeft > 1) benchmarkInsert(numLeft - 1, callback);
    else callback();
  });
}

function benchmarkInserts(n, cb) {
  const numInsert = 10000;
  const start = process.hrtime();
  benchmarkInsert(numInsert, () => {
    const end = process.hrtime();
    const diff = common.hrdiff(start, end);
    console.log(`${(numInsert * 1e9) / diff} inserts/sec`);
    if (n > 1) benchmarkInserts(n - 1, cb);
    else cb();
  });
}

function benchmarkSelect(numLeft, numSelect, callback) {
  connection.execute(`select * from ${table} limit ${numSelect}`, [], (err) => {
    if (err) throw err;
    if (numLeft > 1) benchmarkSelect(numLeft - 1, numSelect, callback);
    else callback();
  });
}

function benchmarkSelects(n, size, cb) {
  const numSelects = 100;
  const start = process.hrtime();
  benchmarkSelect(numSelects, size, () => {
    const end = process.hrtime();
    const diff = common.hrdiff(start, end);
    console.log(
      `${size} rows: ${(numSelects * 1e9) / diff} results/sec, ${(size * numSelects * 1e9) / diff} rows/sec`
    );
    if (n > 1) benchmarkSelects(n - 1, size, cb);
    else cb();
  });
}

module.exports = function (done) {
  const testStart = process.hrtime();
  benchmarkInserts(1, () => {
    benchmarkSelects(5, 100, () => {
      benchmarkSelects(10, 1000, () => {
        benchmarkSelects(2, 50000, () => {
          const testEnd = process.hrtime();
          console.log('total time: ', common.hrdiff(testStart, testEnd) / 1e9);
          connection.end();
          if (done) done();
        });
      });
    });
  });
};

if (require.main === module) {
  module.exports();
}
</file>

<file path="benchmarks/bench-insert-select.js">
'use strict';

const common = require('../test/common');
const connection = common.createConnection();

const table = 'insert_test';
const text = '本日は晴天なり';
connection.query(
  [
    `CREATE TEMPORARY TABLE \`${table}\` (`,
    '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    '`title` varchar(255),',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n')
);

function benchmarkInsert(numLeft, callback) {
  connection.query(`INSERT INTO ${table} SET title="${text}"`, (err) => {
    if (err) throw err;
    if (numLeft > 1) benchmarkInsert(numLeft - 1, callback);
    else callback();
  });
}

function benchmarkInserts(n, cb) {
  const numInsert = 10000;
  const start = process.hrtime();
  benchmarkInsert(numInsert, () => {
    const end = process.hrtime();
    const diff = common.hrdiff(start, end);
    console.log(`${(numInsert * 1e9) / diff} inserts/sec`);
    if (n > 1) benchmarkInserts(n - 1, cb);
    else cb();
  });
}

function benchmarkSelect(numLeft, numSelect, callback) {
  connection.query(`select * from ${table} limit ${numSelect}`, (err) => {
    if (err) throw err;
    if (numLeft > 1) benchmarkSelect(numLeft - 1, numSelect, callback);
    else callback();
  });
}

function benchmarkSelects(n, size, cb) {
  const numSelects = 100;
  const start = process.hrtime();
  benchmarkSelect(numSelects, size, () => {
    const end = process.hrtime();
    const diff = common.hrdiff(start, end);
    console.log(
      `${size} rows: ${(numSelects * 1e9) / diff} results/sec, ${(size * numSelects * 1e9) / diff} rows/sec`
    );
    if (n > 1) benchmarkSelects(n - 1, size, cb);
    else cb();
  });
}

module.exports = function (done) {
  const testStart = process.hrtime();
  benchmarkInserts(5, () => {
    benchmarkSelects(5, 10000, () => {
      benchmarkSelects(10, 1000, () => {
        benchmarkSelects(2, 50000, () => {
          const testEnd = process.hrtime();
          console.log('total time: ', common.hrdiff(testStart, testEnd) / 1e9);
          connection.end();
          if (done) done();
        });
      });
    });
  });
};

if (require.main === module) {
  module.exports();
}
</file>

<file path="benchmarks/benchmark-query.js">
'use strict';

const createConnection = require('../test/common').createConnection;

const sql = process.argv[2];

(function (cb) {
  const db = createConnection();

  let left = 10000;
  const start = Date.now();
  let prev1000 = start;
  function bench() {
    db.query(sql).on('end', () => {
      left--;
      if (left % 1000 === 0) {
        const curTime = Date.now();
        const last1000time = curTime - prev1000;
        prev1000 = curTime;
        console.error(`${1000000 / last1000time} req/sec`);
      }

      if (left > 0) bench();
      else {
        console.error(
          `${10000000 / (Date.now() - start)} req/sec (average 10000 reqs)`
        );
        db.end();
        if (cb) cb();
      }
    });
  }
  bench();
})();
</file>

<file path="benchmarks/benchmark-server.js">
'use strict';

const mysql = require('../index.js');
const Packets = require('../lib/packets/index.js');

function prepareReply(columns, row, n) {
  let length = 0;
  const rsHeader = Packets.ResultSetHeader.toPacket(columns.length);
  length += rsHeader.length();
  const columnPackets = [];
  columns.forEach((column) => {
    const packet = Packets.ColumnDefinition.toPacket(column);
    length += packet.length();
    columnPackets.push(packet);
  });
  const eof = Packets.EOF.toPacket();
  length += 2 * eof.length();
  const rowPacket = Packets.TextRow.toPacket(row, 'utf8');
  length += n * rowPacket.length();

  const replyBuffer = Buffer.allocUnsafe(length);
  let offset = 0;
  let id = 1;
  function add(packet) {
    packet.writeHeader(id);
    id = id + 1;
    packet.buffer.copy(replyBuffer, offset);
    offset += packet.length();
  }

  let i;
  add(rsHeader);
  for (i = 0; i < columns.length; ++i) add(columnPackets[i]);
  add(eof);
  for (i = 0; i < n; ++i) add(rowPacket);
  add(eof);

  return replyBuffer;
}

const buff = prepareReply(
  [
    {
      catalog: 'def',
      schema: 'test',
      table: 'test_table',
      orgTable: 'test_table',
      name: 'beta',
      orgName: 'beta',
      characterSet: 33,
      columnLength: 384,
      columnType: 3, //253,
      flags: 0,
      decimals: 0,
    },
  ],
  ['12345'],
  1
);

const server = mysql.createServer();
server.listen('/tmp/mybench3.sock');
server.on('connection', (conn) => {
  conn.serverHandshake({
    protocolVersion: 10,
    serverVersion: 'node.js rocks',
    connectionId: 1234,
    statusFlags: 2,
    characterSet: 8,
    capabilityFlags: 0xffffff,
  });
  conn.on('query', () => {
    //console.log(query);
    conn.write(buff);
  });
});
</file>

<file path="benchmarks/benchmark.js">
'use strict';

const Benchmark = require('benchmark');
const suite = new Benchmark.Suite();

function addFile(name) {
  const benchmarks = require(name);
  benchmarks.forEach((b) => {
    suite.add(b.name, b.fn);
  });
}

addFile('./unit/packets/column_definition.js');

suite
  .on('start', async () => {})
  .on('complete', () => {})
  .on('cycle', (event) => {
    console.log(String(event.target));
  })
  .run();
</file>

<file path="benchmarks/http-select-and-render.js">
'use strict';

const http = require('http');
const common = require('../test/common');
const url = require('url');

const conn = common.createConnection();
const render = common.createTemplate();
const port = process.env.PORT;

http
  .createServer((req, res) => {
    const q = new url.URL(req.url);
    if (q.pathname === '/render') {
      const sql = q.searchParams.get('q');
      const n = q.searchParams.get('n');
      let rowsTotal = [];
      const doQueries = function (number) {
        if (number === 0) {
          const body = render({ records: rowsTotal });
          res.writeHead(200, {
            'Content-Length': body.length,
            'Content-Type': 'text/html',
          });
          res.end(body);
        } else {
          conn.query(sql, (err, rows) => {
            // TODO: handle error
            rowsTotal = rowsTotal.concat(rows);
            doQueries(number - 1);
          });
        }
      };
      doQueries(n);
    } else {
      res.writeHead(404);
      res.end();
    }
  })
  .listen(port || 1234);
</file>

<file path="benchmarks/httperf.sh">
httperf --port=1234 --uri='/render?q=select%20*%20from%20foos%20limit%205,10000&n=2' --num-conns=10 --num-calls=2 rate=100
</file>

<file path="benchmarks/index.html">
<html>
  <body>
    test
  </body>
</html>
</file>

<file path="benchmarks/integration/fake-server-select.js">
'use strict';

const Benchmark = require('benchmark');
const suite = new Benchmark.Suite();
const portfinder = require('portfinder');

let connection = null;
const mysql = require('../index.js');
const Packets = require('../lib/packets/index.js');

const cache = [];
function prepareReply(columns, row, n) {
  if (cache[n]) {
    return cache[n];
  }
  let length = 0;
  const rsHeader = Packets.ResultSetHeader.toPacket(columns.length);
  length += rsHeader.length();
  const columnPackets = [];
  columns.forEach((column) => {
    const packet = Packets.ColumnDefinition.toPacket(column);
    length += packet.length();
    columnPackets.push(packet);
  });
  const eof = Packets.EOF.toPacket();
  length += 2 * eof.length();
  const rowPacket = Packets.TextRow.toPacket(row, 'utf8');
  length += n * rowPacket.length();

  const replyBuffer = Buffer.allocUnsafe(length);
  let offset = 0;
  let id = 1;
  function add(packet) {
    packet.writeHeader(id);
    id = id + 1;
    packet.buffer.copy(replyBuffer, offset);
    offset += packet.length();
  }

  let i;
  add(rsHeader);
  for (i = 0; i < columns.length; ++i) add(columnPackets[i]);
  add(eof);
  for (i = 0; i < n; ++i) add(rowPacket);
  add(eof);
  cache[n] = replyBuffer;
  return replyBuffer;
}

const server = mysql.createServer((conn) => {
  conn.serverHandshake({
    protocolVersion: 10,
    serverVersion: 'node.js rocks',
    connectionId: 1234,
    statusFlags: 2,
    characterSet: 8,
    capabilityFlags: 0xffffff,
  });
  conn.on('query', (query) => {
    // when client sends "1" query we return 1 trow, when "1000" - 1000
    const limit = parseInt(query, 10);
    const buff = prepareReply(
      [
        {
          catalog: 'def',
          schema: 'test',
          table: 'test_table',
          orgTable: 'test_table',
          name: 'beta',
          orgName: 'beta',
          characterSet: 33,
          columnLength: 384,
          columnType: 3,
          flags: 0,
          decimals: 0,
        },
        {
          catalog: 'def',
          schema: 'test',
          table: 'test_table',
          orgTable: 'test_table',
          name: 'beta2',
          orgName: 'beta2',
          characterSet: 33,
          columnLength: 384,
          columnType: 3,
          flags: 0,
          decimals: 0,
        },
      ],
      ['12345', '1237788'],
      limit
    );
    conn.write(buff);
    conn._resetSequenceId();
  });
});

// add tests
suite
  .add(
    'Select 1 row x 2 small text column from fake server',
    async () =>
      new Promise((accept) => {
        connection.query('1', (err, rows) => {
          const result = rows[0].beta + rows[0].beta2;
          accept(result);
        });
      })
  )
  .add(
    'Select 2 rows x 2 small text column from fake server',
    async () =>
      new Promise((accept) => {
        connection.query('1000', accept);
      })
  )
  .on(
    'start',
    async () =>
      new Promise((accept) => {
        portfinder.getPort((_, port) => {
          server.listen(port);
          connection = mysql.createConnection({
            port: port,
          });
          connection.on('connect', accept);
        });
      })
  )
  .on('complete', () => {
    console.log('done!');
    connection.end();
    server.close();
  })
  .on('cycle', (event) => {
    console.log(String(event.target));
  })
  .run({ async: true, minSamples: 100 });
</file>

<file path="benchmarks/test-benchmark-select-1.js">
'use strict';

const createConnection = require('../test/common').createConnection;

(function (cb) {
  const db = createConnection();

  let left = 10000;
  const start = Date.now();
  let prev1000 = start;
  function bench() {
    db.query('select 1').on('end', () => {
      left--;
      if (left % 1000 === 0) {
        const curTime = Date.now();
        const last1000time = curTime - prev1000;
        prev1000 = curTime;
        console.error(`${1000000 / last1000time} req/sec`);
      }

      if (left > 0) bench();
      else {
        console.error(
          `${10000000 / (Date.now() - start)} req/sec (average 10000 reqs)`
        );
        db.end();
        if (cb) cb();
      }
    });
  }
  bench();
})();
</file>

<file path="benchmarks/unit/packet_parser.js">
'use strict';

const p = Buffer.allocUnsafe(65535 * 10);
let offset = 0;
const plen = 17;
// eslint-disable-next-line no-constant-condition
while (true) {
  if (p.length - offset >= plen + 4) {
    p[offset] = plen;
    p[offset + 1] = 0;
    p[offset + 2] = 0;
    p[offset + 3] = 123; // packet id
    offset += plen + 4;
  } else {
    p[offset] = p.length - offset - 4;
    p[offset + 1] = 0;
    p[offset + 2] = 0;
    p[offset + 3] = 123; // packet id
    break;
  }
}
/*
const PP = require('../../lib/packet_parser.js');

const chunks = [];

function benchmarkPackets() {
  if (chunks.length === 0) {
    for (let csize = 1; csize < plen; ++csize) {
      for (let o = 0; o + csize < p.length; o += csize) {
        chunks.push(p.slice(o, o + csize));
      }
    }
  }

  console.log(chunks);

  let count = 0;
  let cc = 0;

  function handler(packet) {
    //console.log(packet.length(), packet.sequenceId);
    cc += packet.sequenceId;
    count++;
  }

  const start = process.hrtime();
  const packetParser = new PP(handler);
  for (let j = 0; j < chunks.length; ++j) {
    packetParser.execute(chunks[j]);
  }
  return count;
}*/

module.exports = function (next) {
  /*
  const c = benchmarkPackets();
  */
  next();
};

module.exports.comment =
  'WIP - not implemented yet | packet_parser.execute() in chunks of length 1..packet_length x 156035 packets';
module.exports.toSpeed = function (time, timeError) {
  console.log('packet_parser.execute() toSpeed()', time, timeError);
  const value = (1e9 * 5 * 156975) / time;
  return {
    value: value,
    error: value * (timeError / time),
    units: 'packets/second',
  };
};
</file>

<file path="benchmarks/unit/packets/column_definition.js">
'use strict';

const fs = require('fs');
const ColumnDefinition = require('../../../lib/packets/column_definition.js');
const Packet = require('../../../lib/packets/packet.js');
const fixtureFile = `${__dirname}/../fixtures/column_definition`;

const npackets = 43;
const packets = [];
let packet;

for (let i = 0; i < npackets; ++i) {
  const buf = fs.readFileSync(fixtureFile + i);
  packet = new Packet(0, buf, 0, buf.length);
  packets.push(packet);
}

module.exports = [
  {
    name: `read ${npackets} column definitions (select * from mysql.user)`,
    fn: function () {
      const useit = 0;
      for (let j = 0; j < npackets; ++j) {
        packets[j].offset = 0;
        new ColumnDefinition(packets[j], 'utf8');
      }
      return useit;
    },
  },
  {
    name: `read ${npackets} column definitions (select * from mysql.user) and access column lazy fields once`,
    fn: function () {
      let useit = 0;
      for (let j = 0; j < npackets; ++j) {
        packets[j].offset = 0;
        const c = new ColumnDefinition(packets[j], 'utf8');
        useit +=
          c.table.length +
          c.catalog.length +
          c.schema.length +
          c.table.length +
          c.orgTable.length +
          c.orgName.length;
      }
      return useit;
    },
  },
  {
    // see https://github.com/sidorares/node-mysql2/pull/1400 optimisation
    name: `read ${npackets} column definitions (select * from mysql.user) and access column lazy fields 5 times`,
    fn: function () {
      let useit = 0;
      for (let j = 0; j < npackets; ++j) {
        packets[j].offset = 0;
        const c = new ColumnDefinition(packets[j], 'utf8');
        useit +=
          c.table.length +
          c.catalog.length +
          c.schema.length +
          c.table.length +
          c.orgTable.length +
          c.orgName.length;
        useit +=
          c.table.length +
          c.catalog.length +
          c.schema.length +
          c.table.length +
          c.orgTable.length +
          c.orgName.length;
        useit +=
          c.table.length +
          c.catalog.length +
          c.schema.length +
          c.table.length +
          c.orgTable.length +
          c.orgName.length;
        useit +=
          c.table.length +
          c.catalog.length +
          c.schema.length +
          c.table.length +
          c.orgTable.length +
          c.orgName.length;
        useit +=
          c.table.length +
          c.catalog.length +
          c.schema.length +
          c.table.length +
          c.orgTable.length +
          c.orgName.length;
      }
      return useit;
    },
  },
];
</file>

<file path="Changelog.md">
# Changelog

## [3.14.1](https://github.com/sidorares/node-mysql2/compare/v3.14.0...v3.14.1) (2025-04-27)


### Miscellaneous Chores

* release 3.14.1 ([9d097f8](https://github.com/sidorares/node-mysql2/commit/9d097f8dc2105b549e052172bf32fcf360fba742))

## [3.14.0](https://github.com/sidorares/node-mysql2/compare/v3.13.0...v3.14.0) (2025-03-19)


### Features

* add `RegExp` support to PoolCluster ([#3451](https://github.com/sidorares/node-mysql2/issues/3451)) ([2d5050d](https://github.com/sidorares/node-mysql2/commit/2d5050d59c28b269d1ef52b70a726777a34ecf1c))

## [3.13.0](https://github.com/sidorares/node-mysql2/compare/v3.12.0...v3.13.0) (2025-03-06)


### Features

* **`disableEval`:** add static parsers ([#3365](https://github.com/sidorares/node-mysql2/issues/3365)) ([51da653](https://github.com/sidorares/node-mysql2/commit/51da653448855a57f87fa686a10fd8aa482da498))
* support Cloudflare Workers ([#2289](https://github.com/sidorares/node-mysql2/issues/2289)) ([a79253d](https://github.com/sidorares/node-mysql2/commit/a79253d17e5308a71501bbe8ed4df12f5805f0fd))


### Bug Fixes

* `PromisePoolCluster.of` returns `PromisePoolCluster` instead of `PoolNamespace` ([#3261](https://github.com/sidorares/node-mysql2/issues/3261)) ([be22202](https://github.com/sidorares/node-mysql2/commit/be22202e87afce0558dd079c79e0e18f45cd73ad))
* **query:** support `VECTOR` packets in static parser ([#3379](https://github.com/sidorares/node-mysql2/issues/3379)) ([603c246](https://github.com/sidorares/node-mysql2/commit/603c24630da0f999a01227d44cf2633d703e40ed))

## [3.12.0](https://github.com/sidorares/node-mysql2/compare/v3.11.5...v3.12.0) (2024-12-23)


### Features

* **PoolCluster:** `restoreNodeTimeout` implementation ([#3218](https://github.com/sidorares/node-mysql2/issues/3218)) ([9a38601](https://github.com/sidorares/node-mysql2/commit/9a3860186c12452c8e4b60d700d4e1599cc7aefa))

## [3.11.5](https://github.com/sidorares/node-mysql2/compare/v3.11.4...v3.11.5) (2024-11-28)


### Bug Fixes

* 1040 datetime fields returned without time part when time is 00:00:00 ([#3204](https://github.com/sidorares/node-mysql2/issues/3204)) ([bded498](https://github.com/sidorares/node-mysql2/commit/bded4980065319e58a4f87d828cc355fb79f5bd3))
* circular dependencies ([#3081](https://github.com/sidorares/node-mysql2/issues/3081)) ([d5a76e6](https://github.com/sidorares/node-mysql2/commit/d5a76e6c49fbb1bfea405ad809e3076fe5bda39d))
* Deno `v2` requires `commonjs` type explicitly ([#3209](https://github.com/sidorares/node-mysql2/issues/3209)) ([cdc9415](https://github.com/sidorares/node-mysql2/commit/cdc9415c7cbe5806996b05415841b283ae0bd85d))

## [3.11.4](https://github.com/sidorares/node-mysql2/compare/v3.11.3...v3.11.4) (2024-11-05)


### Bug Fixes

* **types:** correct TypeCast's Next callback to return unknown ([#3129](https://github.com/sidorares/node-mysql2/issues/3129)) ([401db79](https://github.com/sidorares/node-mysql2/commit/401db79b88cae8731a9eb334e456528134f821f9))

## [3.11.3](https://github.com/sidorares/node-mysql2/compare/v3.11.2...v3.11.3) (2024-09-14)


### Bug Fixes

* **typings:** synchronize types of sqlstring ([#3047](https://github.com/sidorares/node-mysql2/issues/3047)) ([81be01b](https://github.com/sidorares/node-mysql2/commit/81be01b1bce30cac3f6fcc130aaf859349c5d3d2))

## [3.11.2](https://github.com/sidorares/node-mysql2/compare/v3.11.1...v3.11.2) (2024-09-11)


### Bug Fixes

* resolve LRU conflicts, cache loss and premature engine breaking change ([#2988](https://github.com/sidorares/node-mysql2/issues/2988)) ([2c3c858](https://github.com/sidorares/node-mysql2/commit/2c3c858fd0425b29f488a7cd24df749539c93aa2))

## [3.11.1](https://github.com/sidorares/node-mysql2/compare/v3.11.0...v3.11.1) (2024-09-10)


### Bug Fixes

* **createPoolCluster:** add pattern and selector to promise-based `getConnection` ([#3017](https://github.com/sidorares/node-mysql2/issues/3017)) ([ab7c49f](https://github.com/sidorares/node-mysql2/commit/ab7c49f24fad7b241cdc0046ead9917bbddccced)), closes [#1381](https://github.com/sidorares/node-mysql2/issues/1381)
* update connection cleanup process to handle expired connections and exceeding `config.maxIdle` ([#3022](https://github.com/sidorares/node-mysql2/issues/3022)) ([b091cf4](https://github.com/sidorares/node-mysql2/commit/b091cf49d4165e991cb7c51dd6074be1c996a98e))

## [3.11.0](https://github.com/sidorares/node-mysql2/compare/v3.10.3...v3.11.0) (2024-07-27)


### Features

* fully support VECTOR type results ([9576742](https://github.com/sidorares/node-mysql2/commit/9576742f56f234ac50bfd099bc84c8f593971e74))

## [3.10.3](https://github.com/sidorares/node-mysql2/compare/v3.10.2...v3.10.3) (2024-07-15)


### Bug Fixes

* handshake SSL error with AWS RDS ([#2857](https://github.com/sidorares/node-mysql2/issues/2857)) ([de071bb](https://github.com/sidorares/node-mysql2/commit/de071bb1d7738693793ff3ea24d5f933f6fa4792))

## [3.10.2](https://github.com/sidorares/node-mysql2/compare/v3.10.1...v3.10.2) (2024-07-01)


### Bug Fixes

* **typeCast:** ensure the same behavior for `field.string()` with `query` and `execute` ([#2820](https://github.com/sidorares/node-mysql2/issues/2820)) ([27e38ea](https://github.com/sidorares/node-mysql2/commit/27e38ea3f084f445a8e5a4909341b5e740bdf474))

## [3.10.1](https://github.com/sidorares/node-mysql2/compare/v3.10.0...v3.10.1) (2024-06-13)


### Bug Fixes

* setMaxParserCache throws TypeError ([#2757](https://github.com/sidorares/node-mysql2/issues/2757)) ([aa8604a](https://github.com/sidorares/node-mysql2/commit/aa8604a32b28c2024da006edce30d88ad22d8a06))

## [3.10.0](https://github.com/sidorares/node-mysql2/compare/v3.9.9...v3.10.0) (2024-05-30)


### Features

* add jsonStrings option ([#2642](https://github.com/sidorares/node-mysql2/issues/2642)) ([9820fe5](https://github.com/sidorares/node-mysql2/commit/9820fe51b48cadd48024956e62d9fceac2e5a880))


### Bug Fixes

* **stream:** reads should emit the dataset number for each dataset ([#2628](https://github.com/sidorares/node-mysql2/issues/2628)) ([4dab4ca](https://github.com/sidorares/node-mysql2/commit/4dab4cad2c3b9b165d6118636a179b5443e50442))

## [3.9.9](https://github.com/sidorares/node-mysql2/compare/v3.9.8...v3.9.9) (2024-05-29)


### Bug Fixes

* **connection config:** remove keepAliveInitialDelay default value ([#2712](https://github.com/sidorares/node-mysql2/issues/2712)) ([688ebab](https://github.com/sidorares/node-mysql2/commit/688ebab84961ae82863f811fa772cfd26fbadc0e))

## [3.9.8](https://github.com/sidorares/node-mysql2/compare/v3.9.7...v3.9.8) (2024-05-26)


### Bug Fixes

* **security:** sanitize fields and tables when using nestTables ([#2702](https://github.com/sidorares/node-mysql2/issues/2702)) ([efe3db5](https://github.com/sidorares/node-mysql2/commit/efe3db527a2c94a63c2d14045baba8dfefe922bc))
* support deno + caching_sha2_password FULL_AUTHENTICATION_PACKET flow ([#2704](https://github.com/sidorares/node-mysql2/issues/2704)) ([2e03694](https://github.com/sidorares/node-mysql2/commit/2e0369445ba1581b427f78689a935ac3debfbf07))
* **typings:** typo from `jonServerPublicKey` to `onServerPublicKey` ([#2699](https://github.com/sidorares/node-mysql2/issues/2699)) ([8b5f691](https://github.com/sidorares/node-mysql2/commit/8b5f6911b69b766a3732fa160049d263460da74b))

## [3.9.7](https://github.com/sidorares/node-mysql2/compare/v3.9.6...v3.9.7) (2024-04-21)


### Bug Fixes

* **security:** sanitize timezone parameter value to prevent code injection ([#2608](https://github.com/sidorares/node-mysql2/issues/2608)) ([7d4b098](https://github.com/sidorares/node-mysql2/commit/7d4b098c7e29d5a6cb9eac2633bfcc2f0f1db713))

## [3.9.6](https://github.com/sidorares/node-mysql2/compare/v3.9.5...v3.9.6) (2024-04-18)


### Bug Fixes

* binary parser sometimes reads out of packet bounds when results contain null and typecast is false ([#2601](https://github.com/sidorares/node-mysql2/issues/2601)) ([705835d](https://github.com/sidorares/node-mysql2/commit/705835d06ff437cf0bf3169dac0a5f68002c4f87))

## [3.9.5](https://github.com/sidorares/node-mysql2/compare/v3.9.4...v3.9.5) (2024-04-17)


### Bug Fixes

* revert breaking change in results creation ([#2591](https://github.com/sidorares/node-mysql2/issues/2591)) ([f7c60d0](https://github.com/sidorares/node-mysql2/commit/f7c60d01a49666130f51d3847ccfdd3d6e3d33e9))

## [3.9.4](https://github.com/sidorares/node-mysql2/compare/v3.9.3...v3.9.4) (2024-04-09)


### Bug Fixes

* **docs:** improve the contribution guidelines ([#2552](https://github.com/sidorares/node-mysql2/issues/2552)) ([8a818ce](https://github.com/sidorares/node-mysql2/commit/8a818ce0f30654eba854759e6409c0ac856fc448))
* **security:** improve results object creation ([#2574](https://github.com/sidorares/node-mysql2/issues/2574)) ([4a964a3](https://github.com/sidorares/node-mysql2/commit/4a964a3910a4b8de008696c554ab1b492e9b4691))
* **security:** improve supportBigNumbers and bigNumberStrings sanitization ([#2572](https://github.com/sidorares/node-mysql2/issues/2572)) ([74abf9e](https://github.com/sidorares/node-mysql2/commit/74abf9ef94d76114d9a09415e28b496522a94805))

## [3.9.3](https://github.com/sidorares/node-mysql2/compare/v3.9.2...v3.9.3) (2024-03-26)


### Bug Fixes

* **security:** improve cache key formation ([#2424](https://github.com/sidorares/node-mysql2/issues/2424)) ([0d54b0c](https://github.com/sidorares/node-mysql2/commit/0d54b0ca6498c823098426038162ef10df02c818))
  * Fixes a potential parser cache poisoning attack vulnerability reported by Vsevolod Kokorin (Slonser) of Solidlab
* update Amazon RDS SSL CA cert ([#2131](https://github.com/sidorares/node-mysql2/pull/2131)) ([d9dccfd](https://github.com/sidorares/node-mysql2/commit/d9dccfd837d701f377574b85a05586be89015460))

## [3.9.2](https://github.com/sidorares/node-mysql2/compare/v3.9.1...v3.9.2) (2024-02-26)


### Bug Fixes

* **stream:** premature close when it is paused ([#2416](https://github.com/sidorares/node-mysql2/issues/2416)) ([7c6bc64](https://github.com/sidorares/node-mysql2/commit/7c6bc642addb3e6fee1b1fdc84f83a72ff11ca4a))
* **types:** expose TypeCast types ([#2425](https://github.com/sidorares/node-mysql2/issues/2425)) ([336a7f1](https://github.com/sidorares/node-mysql2/commit/336a7f1259c63d2dfe070fe400b141e89255844e))

## [3.9.1](https://github.com/sidorares/node-mysql2/compare/v3.9.0...v3.9.1) (2024-01-29)


### Bug Fixes

* **types:** support encoding for string type cast ([#2407](https://github.com/sidorares/node-mysql2/issues/2407)) ([1dc2011](https://github.com/sidorares/node-mysql2/commit/1dc201144daceab0b12193ada0f13dbb25e917f6))

## [3.9.0](https://github.com/sidorares/node-mysql2/compare/v3.8.0...v3.9.0) (2024-01-26)


### Features

* introduce typeCast for `execute` method ([#2398](https://github.com/sidorares/node-mysql2/issues/2398)) ([baaa92a](https://github.com/sidorares/node-mysql2/commit/baaa92a228d32012f7da07826674f7a736e3791d))

## [3.8.0](https://github.com/sidorares/node-mysql2/compare/v3.7.1...v3.8.0) (2024-01-23)


### Features

* **perf:** cache iconv decoder ([#2391](https://github.com/sidorares/node-mysql2/issues/2391)) ([b95b3db](https://github.com/sidorares/node-mysql2/commit/b95b3dbe4bb34e36d0d1be6948e4d8a169d28eed))


### Bug Fixes

* **stream:** premature close when using `for await` ([#2389](https://github.com/sidorares/node-mysql2/issues/2389)) ([af47148](https://github.com/sidorares/node-mysql2/commit/af4714845603f70e3c1ef635f6c0750ff1987a9e))
* The removeIdleTimeoutConnectionsTimer did not clean up when the … ([#2384](https://github.com/sidorares/node-mysql2/issues/2384)) ([18a44f6](https://github.com/sidorares/node-mysql2/commit/18a44f6a0a0b7ef41cc874d7a7bb2d3db83ea533))
* **types:** add missing types to TypeCast ([#2390](https://github.com/sidorares/node-mysql2/issues/2390)) ([78ce495](https://github.com/sidorares/node-mysql2/commit/78ce4953e9c66d6cf40ffc2d252fa3701a2d4fe2))

## [3.7.1](https://github.com/sidorares/node-mysql2/compare/v3.7.0...v3.7.1) (2024-01-17)


### Bug Fixes

* add condition which allows code in callback to be reachable ([#2376](https://github.com/sidorares/node-mysql2/issues/2376)) ([8d5b903](https://github.com/sidorares/node-mysql2/commit/8d5b903f5c24ef6378d4aa98d3fd4e13d39be4db))

## [3.7.0](https://github.com/sidorares/node-mysql2/compare/v3.6.5...v3.7.0) (2024-01-07)


### Features

* **docs:** release documentation website ([#2339](https://github.com/sidorares/node-mysql2/issues/2339)) ([c0d77c0](https://github.com/sidorares/node-mysql2/commit/c0d77c02d2f4ad22b46a712d270fc2654d26de4e))

## [3.6.5](https://github.com/sidorares/node-mysql2/compare/v3.6.4...v3.6.5) (2023-11-22)


### Bug Fixes

* add decodeuricomponent to parse uri encoded special characters in host, username, password and datbase keys ([#2277](https://github.com/sidorares/node-mysql2/issues/2277)) ([fe573ad](https://github.com/sidorares/node-mysql2/commit/fe573addffa64a842ae37994fcd8879cefa933f2))

## [3.6.4](https://github.com/sidorares/node-mysql2/compare/v3.6.3...v3.6.4) (2023-11-21)


### Bug Fixes

* malformed FieldPacket ([#2280](https://github.com/sidorares/node-mysql2/issues/2280)) ([8831e09](https://github.com/sidorares/node-mysql2/commit/8831e092024f8d26fe9272adec8e1a5f115735aa))
* move missing options to `ConnectionOptions ` ([#2288](https://github.com/sidorares/node-mysql2/issues/2288)) ([5cd7639](https://github.com/sidorares/node-mysql2/commit/5cd76396d962da070452800597a6f86829b35bd4))

## [3.6.3](https://github.com/sidorares/node-mysql2/compare/v3.6.2...v3.6.3) (2023-11-03)


### Bug Fixes

* correctly pass values when used with sql-template-strings library ([#2266](https://github.com/sidorares/node-mysql2/issues/2266)) ([6444f99](https://github.com/sidorares/node-mysql2/commit/6444f9953ddb08b1b98cd0d7eb0d939d25d3971a))

## [3.6.2](https://github.com/sidorares/node-mysql2/compare/v3.6.1...v3.6.2) (2023-10-15)


### Bug Fixes

* sql-template-strings/tag compatibility ([#2238](https://github.com/sidorares/node-mysql2/issues/2238)) ([f2efe5a](https://github.com/sidorares/node-mysql2/commit/f2efe5a2ddf9e10a83bf24da2af744061b2ae597))

## [3.6.1](https://github.com/sidorares/node-mysql2/compare/v3.6.0...v3.6.1) (2023-09-06)


### Bug Fixes

* EventEmitter on method signatures to use spread syntax ([#2200](https://github.com/sidorares/node-mysql2/issues/2200)) ([5d21b81](https://github.com/sidorares/node-mysql2/commit/5d21b8127b8b6aa4b0308b6482d707d150403990))

## [3.6.0](https://github.com/sidorares/node-mysql2/compare/v3.5.2...v3.6.0) (2023-08-04)


### Features

* add conn-level `infileStreamFactory` option ([#2159](https://github.com/sidorares/node-mysql2/issues/2159)) ([5bed0f8](https://github.com/sidorares/node-mysql2/commit/5bed0f8f195f615844d5dbe322ebfe47b76ba2f5))

## [3.5.2](https://github.com/sidorares/node-mysql2/compare/v3.5.1...v3.5.2) (2023-07-14)


### Bug Fixes

* Update events that are propagated from pool cluster to include remove ([#2114](https://github.com/sidorares/node-mysql2/issues/2114)) ([927d209](https://github.com/sidorares/node-mysql2/commit/927d20945d664c55209fd95b05b2c68904f51acc))

## [3.5.1](https://github.com/sidorares/node-mysql2/compare/v3.5.0...v3.5.1) (2023-07-10)


### Bug Fixes

* improvements to allow to use Bun and tls  ([#2119](https://github.com/sidorares/node-mysql2/issues/2119)) ([fd44a2a](https://github.com/sidorares/node-mysql2/commit/fd44a2ab9c08961a898edcfef5ba0035467a28ce))
* missing `ResultSetHeader[]` to `query` and `execute` ([f649486](https://github.com/sidorares/node-mysql2/commit/f649486fdd0e95ad9f46c002e385986b52224f68))

## [3.5.0](https://github.com/sidorares/node-mysql2/compare/v3.4.5...v3.5.0) (2023-07-06)


### Features

* improved inspection of columns ([#2112](https://github.com/sidorares/node-mysql2/issues/2112)) ([69277aa](https://github.com/sidorares/node-mysql2/commit/69277aa0430d951d61c485d2cd228c3cd9d4a33c))

## [3.4.5](https://github.com/sidorares/node-mysql2/compare/v3.4.4...v3.4.5) (2023-07-05)


### Bug Fixes

* handle prepare response with actual number of parameter definition less than reported in the prepare header. Fixes [#2052](https://github.com/sidorares/node-mysql2/issues/2052) ([b658be0](https://github.com/sidorares/node-mysql2/commit/b658be0cfbfdec378d71a9d9e70de4a52180cd2d))

## [3.4.4](https://github.com/sidorares/node-mysql2/compare/v3.4.3...v3.4.4) (2023-07-04)


### Bug Fixes

* add `ProcedureCallPacket` to `execute` overloads ([3566ef7](https://github.com/sidorares/node-mysql2/commit/3566ef77a1a45d2cb18b1e32e0a5f4fc325a26cd))
* add `ProcedureCallPacket` to `query` overloads ([352c3bc](https://github.com/sidorares/node-mysql2/commit/352c3bc5504d6cb8d9837771a2fa8673db7eb001))
* add `ProcedureCallPacket` to promise-based `execute` overloads ([8292416](https://github.com/sidorares/node-mysql2/commit/829241604cfd4cd45b6f5bfd7c36082287da5ca0))
* add `ProcedureCallPacket` to promise-based `query` overloads ([0f31a41](https://github.com/sidorares/node-mysql2/commit/0f31a41dcfe65d2953447c7f1a8b5c892f2ceed9))
* create `ProcedureCallPacket` typings ([09ad1d2](https://github.com/sidorares/node-mysql2/commit/09ad1d276fcad6c9e3963d54b56c39c26a57b690))

## [3.4.3](https://github.com/sidorares/node-mysql2/compare/v3.4.2...v3.4.3) (2023-06-30)


### Bug Fixes

* remove acquireTimeout invalid option ([#2095](https://github.com/sidorares/node-mysql2/issues/2095)) ([eb311db](https://github.com/sidorares/node-mysql2/commit/eb311dbb988a4d3adada9774d43a79806a453745))

## [3.4.2](https://github.com/sidorares/node-mysql2/compare/v3.4.1...v3.4.2) (2023-06-26)


### Bug Fixes

* changing type files to declaration type files ([98e6f3a](https://github.com/sidorares/node-mysql2/commit/98e6f3a0b1f2d523dc8cb62c67e49d9589c469eb))

## [3.4.1](https://github.com/sidorares/node-mysql2/compare/v3.4.0...v3.4.1) (2023-06-24)


### Bug Fixes

* `createPool` uri overload ([98623dd](https://github.com/sidorares/node-mysql2/commit/98623dd7fc82cfbe556fc4b92828d382b86625d8))
* `PoolCluster` typings ([3902ca6](https://github.com/sidorares/node-mysql2/commit/3902ca6534fd64a798c5b2dc29402fe396d4a67c))
* create promise-based `PoolCluster` typings ([7f38496](https://github.com/sidorares/node-mysql2/commit/7f38496097fa6d9cfbced604fe0ddc392b1b1979))
* missing `parserCache` in `promise.js` ([7f35cf5](https://github.com/sidorares/node-mysql2/commit/7f35cf5f6e69cc8aa3d2008bf5b0434c4d7ee5ac))
* missing constants in `promise.js` ([4ce2c70](https://github.com/sidorares/node-mysql2/commit/4ce2c70313ecbe2c4c5fd73f34b4ce7d32a9c83c))
* missing keys for `Types` constant ([86655ec](https://github.com/sidorares/node-mysql2/commit/86655ec6ad8ab8deae11a3c4919ae2ee553f4120))
* missing typings for `Charsets` constants ([01f77a0](https://github.com/sidorares/node-mysql2/commit/01f77a0db471682e7c4f523bde1189fc5d11d43d))
* missing typings for `CharsetToEncoding` constants ([609229a](https://github.com/sidorares/node-mysql2/commit/609229a973031615cb93b5678b5932cf3714480f))
* missing typings for `parserCache` ([891a523](https://github.com/sidorares/node-mysql2/commit/891a523939120666e8d85db634262889657aff45))
* missing typings for `Types` constant ([04601dd](https://github.com/sidorares/node-mysql2/commit/04601ddbd1430b37a7a7ab8d8d63ad27bd00bb54))
* rename file of typings `Charsets` constants ([51c4196](https://github.com/sidorares/node-mysql2/commit/51c4196d50472eb18e440ea0291f2b571a3e7585))

## [3.4.0](https://github.com/sidorares/node-mysql2/compare/v3.3.5...v3.4.0) (2023-06-19)


### Features

* support STATE_GTIDS session track information ([2b1520f](https://github.com/sidorares/node-mysql2/commit/2b1520f4c5c11cda30d69e8b8b20ff03ec469099))

## [3.3.5](https://github.com/sidorares/node-mysql2/compare/v3.3.4...v3.3.5) (2023-06-12)


### Bug Fixes

* `createPool` `promise` as `PromisePool` ([#2060](https://github.com/sidorares/node-mysql2/issues/2060)) ([ff3c36c](https://github.com/sidorares/node-mysql2/commit/ff3c36ca8b092f8ab16fc81400f6c63524cd971d))
* keepAliveInitialDelay not taking effect ([#2043](https://github.com/sidorares/node-mysql2/issues/2043)) ([585911c](https://github.com/sidorares/node-mysql2/commit/585911c5d5d4b933e32e5a646574af222b63f530))

## [3.3.4](https://github.com/sidorares/node-mysql2/compare/v3.3.3...v3.3.4) (2023-06-11)


### Bug Fixes

* `PromisePoolConnection` import name ([76db54a](https://github.com/sidorares/node-mysql2/commit/76db54a91e2f9861605d5975158701233879d02c))
* `releaseConnection` types and promise ([4aac9d6](https://github.com/sidorares/node-mysql2/commit/4aac9d6a1b379253fa90195ffdc98886b3b87a1b))

## [3.3.3](https://github.com/sidorares/node-mysql2/compare/v3.3.2...v3.3.3) (2023-05-27)


### Bug Fixes

* add package.json to exports ([#2026](https://github.com/sidorares/node-mysql2/issues/2026)) ([09fd305](https://github.com/sidorares/node-mysql2/commit/09fd3059cd91c655e494e40dc4365e58ed069b13))

## [3.3.2](https://github.com/sidorares/node-mysql2/compare/v3.3.1...v3.3.2) (2023-05-23)


### Bug Fixes

* respect enableKeepAlive option ([#2016](https://github.com/sidorares/node-mysql2/issues/2016)) ([f465c3e](https://github.com/sidorares/node-mysql2/commit/f465c3edc707d34a11d9b1796b9472824fdb35df))

## [3.3.1](https://github.com/sidorares/node-mysql2/compare/v3.3.0...v3.3.1) (2023-05-11)


### Bug Fixes

* LRU constructor ([#2004](https://github.com/sidorares/node-mysql2/issues/2004)) ([fd3d117](https://github.com/sidorares/node-mysql2/commit/fd3d117da82cc5c5fa5a3701d7b33ca77691bc61))
* Missing types in "mysql" import ([#1995](https://github.com/sidorares/node-mysql2/issues/1995)) ([b8c79d0](https://github.com/sidorares/node-mysql2/commit/b8c79d055762e927da147d08fb375cd11d303868))

## [3.3.0](https://github.com/sidorares/node-mysql2/compare/v3.2.4...v3.3.0) (2023-05-06)


### Features

* Added updated/new error codes gathered from MySQL 8.0 source code ([#1990](https://github.com/sidorares/node-mysql2/issues/1990)) ([85dc6e5](https://github.com/sidorares/node-mysql2/commit/85dc6e56310db1d78078588f48714f574873eec3))

## [3.2.4](https://github.com/sidorares/node-mysql2/compare/v3.2.3...v3.2.4) (2023-04-25)


### Bug Fixes

* **server:** Added missing encoding argument to server-handshake ([#1976](https://github.com/sidorares/node-mysql2/issues/1976)) ([a4b6b22](https://github.com/sidorares/node-mysql2/commit/a4b6b223434d1cbdb5af9141cf3bd085459bb6b8))

## [3.2.3](https://github.com/sidorares/node-mysql2/compare/v3.2.2...v3.2.3) (2023-04-16)


### Bug Fixes

* **types:** add decimalNumbers to createConnection/createPool typings. fixes [#1803](https://github.com/sidorares/node-mysql2/issues/1803) ([#1817](https://github.com/sidorares/node-mysql2/issues/1817)) ([bb48462](https://github.com/sidorares/node-mysql2/commit/bb48462db7b83bd4825a3d53e192e5363139ec3c))

## [3.2.2](https://github.com/sidorares/node-mysql2/compare/v3.2.1...v3.2.2) (2023-04-16)


### Bug Fixes

* `ConnectionOptions` conflict between `mysql` and `mysql/promise` ([#1955](https://github.com/sidorares/node-mysql2/issues/1955)) ([eca8bda](https://github.com/sidorares/node-mysql2/commit/eca8bda9305ab07cf0e46f16f3f13bf1fd82787d))

## [3.2.1](https://github.com/sidorares/node-mysql2/compare/v3.2.0...v3.2.1) (2023-04-13)


### Bug Fixes

* Add typings for Connection.promise(). ([#1949](https://github.com/sidorares/node-mysql2/issues/1949)) ([e3ca310](https://github.com/sidorares/node-mysql2/commit/e3ca3107cbae0050d307f02514598aff4e8ecd60))
* PoolConnection redundancy when extending Connection interface in TypeScript ([7c62d11](https://github.com/sidorares/node-mysql2/commit/7c62d1177e79b5063a11fa15a2ac4e3dc3e2a2ed))

## [3.2.0](https://github.com/sidorares/node-mysql2/compare/v3.1.2...v3.2.0) (2023-03-03)


### Features

* maxVersion ssl option to tls.createSecureContext ([0c40ef9](https://github.com/sidorares/node-mysql2/commit/0c40ef9f596fa3bc4f046f523c3595fe7065fde3))

## [3.1.2](https://github.com/sidorares/node-mysql2/compare/v3.1.1...v3.1.2) (2023-02-08)


### Bug Fixes

* update `lru-cache` reset method to clear ([114f266](https://github.com/sidorares/node-mysql2/commit/114f266b18802e52d6b130c2cf379f61a996c2b0))

## [3.1.1](https://github.com/sidorares/node-mysql2/compare/v3.1.0...v3.1.1) (2023-02-07)


### Bug Fixes

* remove accidental log in caching_sha2_password.js ([c1202b6](https://github.com/sidorares/node-mysql2/commit/c1202b673c8ba9f709c3ebc0d1717ccffca1bd4b))

## [3.1.0](https://github.com/sidorares/node-mysql2/compare/v3.0.1...v3.1.0) (2023-01-30)


### Features

* cleanup buffer/string conversions in hashing/xor helpers that were failing in Bun ([a2392e2](https://github.com/sidorares/node-mysql2/commit/a2392e27de64630affb6e3f6af26f5c59e2e95f9))


### Bug Fixes

* when port is pased as a string convert it to a number (Bun's net.connect does not automatically convert this) ([703ecb2](https://github.com/sidorares/node-mysql2/commit/703ecb2f788cf32acb1b49c7786ff6845640e215))

## [3.0.1](https://github.com/sidorares/node-mysql2/compare/v3.0.0...v3.0.1) (2023-01-13)


### Miscellaneous Chores

* release 3.0.1 ([d5a6b2c](https://github.com/sidorares/node-mysql2/commit/d5a6b2ccccc7db4176c880e83c70ccd0be4ad81e))

## [3.0.0](https://github.com/sidorares/node-mysql2/compare/v3.0.0-rc.1...v3.0.0) (2023-01-12)

* named-placeholders library is updated to use newer `lru-cache` dependency, allowing it do dedupe and be shared between mysql2 and named-placeholders - https://github.com/sidorares/node-mysql2/issues/1711, https://github.com/mysqljs/named-placeholders/pull/19
* `chai` and `mocha` moved to devDependencies #1774
* Amazon RDS ssl certificates updated including AWS China #1754
* `TCP_NODELAY` flag enabled, avoiding long connect timeout in some scenarios #1751
* typing improvements: #1675, #1674
* fix:  ensure pooled connections get released #1666

### Miscellaneous Chores

* release 3.0.0 ([11692b2](https://github.com/sidorares/node-mysql2/commit/11692b223ff26784089f444ca6291295bd0e405e))

## [3.0.0-rc.1](https://github.com/sidorares/node-mysql2/compare/v2.3.3...v3.0.0-rc.1) (2022-11-06)


### Bug Fixes

* **typings:** Add the infileStreamFactory option to the type definition ([bf9cc4c](https://github.com/sidorares/node-mysql2/commit/bf9cc4c41e72f4a9014659a22b131739524bda1c))
* webpack projects no longer show warning for cardinal dependency ([26c56ae](https://github.com/sidorares/node-mysql2/commit/26c56ae64846814eb8234c0d352871a7b6651d66))


### Miscellaneous Chores

* v3.0.0-rc.1 changes ([1b684bb](https://github.com/sidorares/node-mysql2/commit/1b684bbf8047200e5de5dd18874872880237de2f))

3.0.0-rc.1 ( 6/11/2021 )
  - fix .ping() return value signature #1650
  - documentation: clarify `SUM()` and `AVG()`
    return types difference with mysqljs/myql    #1649
  - misc: add release-please action              #1631, #1647
  - fix: .end() callback is not called
    when connection is in closed state           #1642, #1638
  - typescript: getConnection typings fix        #1620
  - fix uncatchable exception                    #1359
  - add mysql_clear_password built in support    #1552
  - typescript: typings unit test, variouts type
    improvements, server protocol additions      #1610, #1610
  - typescript: more complete way of adding
    typings for the Server module                #1606
  - typescript, documentation: improve prepared
    typings statements                           #1493
  - typescript: add type declarations for Prepare
    & PrepareStatementInfo                       #1565
  - fix: webpack projects no longer show warning
    for cardinal dependency                      #1589
  - typescript: accept Buffer and Buffer[] in
    typings for key, cert, and ca                #1599
  - fix: use rotatingXor instead of xor in
    sha256_password plugin                       #1592, #1044
  - documentation: add Simplified Chinese        #1572
  - fix: add type as an alias to columnType      #1546, #1549
  - Update collation list up to MySQL 8.0.26     #1410
  - typescript: Add minVersion for ssl option.   #1517
  - Add support for multi-factor authentication  #1436
  - typescript: add namedPlaceholders option to
    QueryOptions interface                       #1475
  - fix: update how the ECONNRESET error is
    caught when connection already closing       #1438


2.3.3 ( 14/11/2021 )
  - no changes compared to 2.3.3-rc.0

2.3.3-rc.0 ( 5/11/2021 )
  - fix ColumnDefinition.db is broken when
    encoding is not utf-8                         #1423
  - typeCast: Fix field.length to be number       #1427, #1426
  - initiall support for coverage reporting in CI #1425
  - fix performance regression for results with   #1445, #1432
    large (300+) number of columns


2.3.2 ( 16/10/2021 )
  - fix regression causing typeCast + JSON field
    to error                                      #1418, #1420

2.3.1 ( 15/10/2021 )
  - Update error codes up to mysql 8.0.26          #1411
  - perf: optimize Query.row call                  #1408
  - build: update to node 12/14/16, migrate from
    travis-ci and appveyor to GH actions, add perf
    benchmarking workflow                          #1406, #1399
  - perf: avoid leaking TextRow/BinaryRow object   #1402
  - perf: optimize string decoding by removing
    the use of slice()                             #1401
  - perf: cache lazy-evaluated fields              #1400
  - fix: clear timeout after error                 #1390
  - TS: adds the optional column changedRows to
    ResultSetHeader                                #1377

2.3.0 ( 5/08/2021 )
  - Add PoolCluster promise wrappers               #1369, #1363
  - support for connect and query timeouts         #1364
  - add missing query() method on PoolCluster      #1362
  - fix incorrect parsing of passwords
    containing ":"                                 #1357
  - handle errors generated by asynchronous
    authentication plugins                         #1354
  - add proper handshake fatal error handling      #1352
  - fix tests to work with the latest MySQL
    server versions (up to 8.0.25)                 #1338
  - expose SQL query in errors                     #1295
  - typing and readme docs for rowAsArray          #1288
  - allow unnamed placeholders even if the
    namedPlaceholders flag is enabled              #1251
  - better ESM support                             #1217

2.2.5 ( 21/09/2020 )
  - typings: add ResultSetHeader                   #1213

2.2.4 ( 21/09/2020 )
  - use bundled types/mysql instead of dependency  #1211

2.2.3 ( 21/09/2020 )
  - use github:types/mysql as base for types       #1208

2.2.2 ( 19/09/2020 )
  - Add the authPlugins types to ConnectionOptions #1206

2.2.1 ( 18/09/2020 )
  - update package.json files entry to include
    type definition files                          #1205

2.2.0 ( 18/09/2020 )
  - added TS type definitions                      #1204, #1028
  - better error handling for invalid JSON row
    responses                                      #915
  - fix for iconv-lite and some bundlers issues    #1187
  - error early when callbacks incorrectly passed  #1025
    to a promise wrapper
  - add support for sha256_password authentication #1153, #1152
    plugin
  - handle backpressure when loading data from     #1167
    file
  - Pass in the callback when ending the pool      #1170
    connection
  - allow using `dateStrings` with specific types  #1200
  - Fix incompatibility with code minimizers       #1191
  - fix with connect timeout timer cleanup after   #950
    error
  - Add ES Module Support                          #1169, #1100
  - Release connection on exception                #1108
  - Add table to parser cache key                  #1142, #1143
  - Fix Connection.connect callback may never      #1136, #1137
    be executed
  - "cardinal" no longer is a requred dependency   #1135
  - Fix incompatibility when zero parameter        #1129, #1130

2.1.0
  - added `enableKeepAlive` connection option      #1081, #683

2.0.2
  - Fix for clearing connection timeout state when
    connection is re-attempted (failure or success) #1075
  - Avoid setting numeric config options to NaN     #1074, #721
  - PoolCluster#end now accepts a callback function #1065, #1063

2.0.1
  - Add missing authPlugins assignment in
    ConnectionConfig                                 #1052
  - Fix 4.1 auth on old servers not
    supporting PLUGIN_AUTH                           #1062, #1054, #1053

2.0.0
  - Mysql8 caching_sha2_password - fix bug in
    authenticating when password is longer
    than 19 chars                                     #1044 #1045
  - Support ConnectionConfig.flags as an array        #1003

2.0.0-alpha1
  - MAJOR: new `authPlugins` api replacing
    `authSwitchHandler`, added caching_sha2_password
    and mysql_native_password as default plugins.
    Added tests for mysql 8 and ssl. Mysql 8 server
    now supported with default settings.              #1021, #906, #991
  - MAJOR: LOCAL INFILE does not automatically read   #1034
    from the local fs and now requires an explicit
    `infileStreamFactory` to be specified in query options.
  - Update to 2019 CA Amazon RDS certificates         #1032
  - Update SSL Profile for AWS Serverless Aurora      #1026
  - fix pool ignoring namedPlaceholders config        #1022

1.7.0
  - Fix crashing when session info packet does not
    start with length-coded string                    #1004, #989
  - build: drop node 4 and 6 and add node v12         #997
  - Add support for timezone connection option        #996, #15, #262,
                                                      #642, #877, #888
  - Make mysql2 compatible with minification          #992, #890, #899,
                                                      #890
  - fix serialisation of '00:00:00' time              #968, #967
  - Allow to set minVersion ssl option                #961, #960
  - Fix a MaxListenersExceededWarning with stream
    local infile                                      #965

1.6.5 (08/02/2019)
  - allow to use namedPlaceholders flag per query     #879
  - migrate to more modern code style ( classes /
   arrow functions )                                  #861, #870
  - be more defencive about ssl config object         #895
  - fix(debug): remove usage of callee                #882

1.6.4 (08/11/2018)
 - revert changes breaking node v4 and add v4 to
   build matrix                                       #872, #873

1.6.3 (06/10/2018)
 - Don't treat selector-making function as a class.   #869, #871

1.6.2 (05/10/2018)
 - Fix "Socket ended by other party" error            #447, #867, #868
 - replace var with let/const                         #849
 - Fix "close emitted before end" error               #711, #859
 - fix docs                                           #856
 - migrate to es6 classes where appropriate           #848

1.6.1 (02/08/2018)
 - Fix missing Promise option in checks for Pool      #826

1.6.0 (01/08/2018)
 - Fixed `PromiseConnection.ping()` ignoring errors   #813
 - Added a uri parameter to the connection config     #815
 - Added a `.promise()` method shortcut on Pool,
   Connection and PoolConnection                      #810
 - Added more functions from node-mysql:
   `createQuery`, `raw`, `escape`, `escapeId`,
   `format`                                           #799
 - Added `acquire` and `release` and release events
   on Connection                                      #783
 - Added support for a Japanese charset `ujis`        #772
 - Improved error handling on `ECONNRESET`            #768
 - Drop support for Node 4                            #791

1.5.3 (19/03/2018)
 - fix incorrect denque dependency                     #740
 - build: bump to node 8.10 and 6.16
 - use strich lru-cache version                        #751
 - bump sqlstring to 2.3.1
 - remove noAssert flag from Buffer functions          #748

1.5.2 (06/02/2018)
 - perf: Store Compiled Packet Parsers in a global
   cache                                               #722, #723
 - Improve performance of removing connections from
   pools                                               #720
 - use source parameters types with execute, fix
   crash when parameter is undefined                   #718, #705
 - PromisePool to always use the specified promises
   library                                             #697

1.5.1 (19/11/2017)
 - Fix empty buffer incorrectly returned instead of
   NULL value                                          #668, #671
 - promise wrapper: pass sqlMessage from original
   error                                               #682, #678

1.5.0 (13/11/2017)
 - Added sqlMessage to Error callback object           #665
 - Normalized sqlState to a string of 5 chars          #667
   as Mysql specifies it
 - Remove destroyed promise pool connections from
   pool                                                #674, #672
 - Expose escape & format methods on connection pool   #669, #663
 - Support fractional seconds variable precision for
   the temporal types                                  #660, #659
 - fix null values breaking typeCast behaviour         #652

1.4.2 ( 27/08/2017 )
 - fix null value incorrectly returned as empty
   string from int values in text protocol             #637

 - build: bump to node 8.4
 - promise wrapper: use promise implementation passed
   to PromisePool                                      #631, #632

1.4.1 ( 16/08/2017 )
 - add missing encodings                               #628, #630
 - (binary protocol) Fix parsing microsecond in
   datatime type                                       #629
 - (promise wrapper) Fix handling of errors in promise
   prepared statement execute                          #622

1.4.0 ( 30/07/2017 )
 - fix DATETIME going into incorrect state when
   milliseconds part present                           #618
 - (promise wrapper) add changeUser                    #615, #614, #613
 - redo event delegation in promise wrappers to be     #577, #620, #577, #568
   lazy, self-cleaning

1.3.6 ( 12/07/2017 )
 - fix crash when initial packet from server is error  #607

1.3.5 ( 15/06/2017 )
 - update iconv-lite to 0.4.18 to fix node 8 cesu8
   encoding regression. Add node 8 to  build matrix     #591

1.3.4 ( 13/06/2017 )
 - use safe-buffer in string decoder                    #589, #585
 - allow to use pool.execute() without parameters       #589

1.3.3 ( 8/06/2017 )
 - fix node encodings lookup in string parser           #583, #582
 - fix connection not released to the pool on error     #579, #551, #540, #508, #569
 - better stack traces in promise wrapper               #580, #530

1.3.2 ( 31/05/2017 )
 - fix PromiseConnection.prepare and add                 #574, #575
   PromisePreparedStatementInfo

1.3.1 ( 31/05/2017 )
 - move lint-staged to devDependencies                   #573

1.3.0 ( 29/05/2017 )
 - Make Promise Pool wrapper extend EventEmitter         #567, #468
 - build: integrate prettier                             #563
 - do not send 23 unallocated bytes over wire            #547
 - fix: PromiseConnection missing interface functions
   from Connection                                       #531, #495


1.2.0 ( 17/02/2017 )
 - add new MySQL 5.6/8.0 charsets                        #494
 - build: drop support for node 0.10 and 0.12
 - fix: Connection not released when Pool.Execute
   called without values                                 #509, #485, #488, #475

1.1.2 ( 15/11/2016 )
 - (fix) memory leak introduced with iconv
   encoder/decoder cache                                 #459, #458
 - remove use of domains                                 #451, #449
 - (fix) handle correctly packets over 0xffffff bytes
   long + compressed protocol rewrite                    #421, #248, #419, #426
 - (perf) replace double-ended-queue with denqueue       #444
 - (feat) automatically track client encoding change     #437, #389
 - (feat) add support for CLIENT_SESSION_TRACK info      #388, #436

1.1.1 ( 06/10/2016 )
 - (fix) do not crash when result of execute().stream()
   is paused                                             #174, #424
 - (fix) do not call .destroy() on stream when connect timeout
   is fired (destroy() method exist only on Net stream
   but not on custom streams)                             #417, #414
 - (internal) parser generator now uses generate-function
   package to prepare dynamically generated parser func   #412, #167
 - (docs) fix readme test/code errors                     #413
 - (tests) use docker+mysql 5.7 on travis                 #410
 - (fix) use correct encoding for JSON type (despite
   reported by server BINARY enc utf8 should be used
   instead)                                               #410, #409
 - (docs) refactor readmy to be more firendly for first
   time readers


1.1.0 ( 20/09/2016 )
 - promise wrappers: fix object form parameters being
   ignored                                                #405
 - listen for errors in socket.write, prevent from crash
   when server disconnects mid query. In LOAD INFILE
   command disconnect from input stream when there is
   error                                                  #404 #289 #57 #38
 - ensure prepare+execute commands are enqueued one after
   another (previously execute was appended at the end
   of the queue)                                          #404
 - add linting to readme and docs code                    #403 405
 - build: bump to node 6.6
 - (SEMVER MINOR) use LRU cache to store prepared
   statements add maxPreparedStatements options parameter #401
 - (SEMVER MINOR) support connectTimeout option           #396 #376
 - (SEMVER MINOR) support changedRows in insert results   #400 #299
 - (SEMVER MINOR) allow to use nestTables as connection
   options in addition to query/execute option            #399

1.0.0 ( 16/09/2016 )
 - set default server encoding so that strings from server
   can be decoded before initiol connection handshake packet
   is sent
 - add files section to package.json                      #398

1.0.0-rc.13 ( 14/09/2016 )
 - text protocol: fix a bug the prevented row parser
   from being used                                        #397

1.0.0-rc-12 ( 06/09/2016 )
 - support for non-utf8 server, results, and client
   encodings                                               #302, #374
 - replace deprecated Buffer APIs with Buffer.from
   and Buffer.allocUnsafe                                  #381, #380
 - build: bump to node v6.5

1.0.0-rc-11 ( 14/08/2016 )
 - pool: support namedPlaceholder flag in `pool.query`
   and `pool.execute` helpers                              #369
 - pool: do not emit error on query command if callback    #372
   was passed
 - pool: propagate connection time error back
   to .getConnection()                                     #372

1.0.0-rc-10 ( 09/08/2016 )
 - ssl: do not use deprecated tls.createSecurePair
   if TLSSocket is avaiable                                #367, 363

 - use supportBigNumbers and bigNumberStrings flags in
   parser
 - pass supportBigNumbers and bigNumberStrings from
   `query({sql, ...opts})` and `execute({sql, ...opts})`
   type of calls
 - use supportBigNumbers and bigNumberStrings as part of
   parser key
 - binary protocol: use long.js to calculate resulting
   number from two 32 byte valuse
 - text protocol: fix in detecting potentially big number.
   Split parseLong* into functions with and without big
   number checks, use no check version if type is < long    #366

   documentation:
 - Split documentation into `/documentation` folder with sub
   docs inside this folder
 - Use badge for license
 - Added `.npmignore`                                       #365

 - handle correctly negative insert IDs                     #364, #341, #336
 - build: add v6.3 to matrix
 - docs: add CONTRIBUTING.md                                #138, #359

1.0.0-rc-9 ( 01/08/2016 )
 - remember and send credentials for initial
   AuthSwitch request                                       #331, #357
 - fix re-emitting error event during initial handshake     #356

1.0.0-rc-8 ( 22/07/2016 )
 - enabled use of global typeCast                           #347, #351
 - custom typeCast: fix incorrect buffer() and geometry()   #349
   functions
 - documentation: fix async/await example                   #342

1.0.0-rc-7 ( 03/07/2016 )
 - fix incorrect MockBuffer property assignment             #333
 - implement typeCast option                                #338

1.0.0-rc-6 ( 29/06/2016 )
 - AuthSwitch support and partial support for
   plugin-based authentication                               #331

1.0.0-rc-5 ( 16/06/2016 )
 - Fix incorrect releasing of dead pool connections          #326, #325
 - Allow pool options to be specified as URL params          #327

1.0.0-rc.4 ( 14/06/2016 )
 - fix double-interpolation in pool.query                    #323, #324

1.0.0-rc.3 ( 08/06/2016 )
 - switch to external sqlstring labrary, same
   as used by node-mysql                                     6b559c565f88cf471e52c4e6bbb9ebd631673cb8
 - new built-in Promise api                                  #269
 - server: allow to listen to all packets via 'packet' event #297
 - fix broken rowAsArray flag                                05585aa2420327e5cdbb4d160a22fba30f8a4a39

1.0.0-rc.2 (02/06/2016)
 - add eslintrc                                              #268
 - callbacks on pool.query are never called                  #281 #182 #218
 - allow namedParameters for queries on pool as well         #281
 - (semver-major) server: pass handshake packet in
   'connect' event instead of 'true'                         2c066aca203785bb92ebc3381289813de464e144
 - server: fix packet length calculation for
   multibyte characters input                                #295

1.0.0-rc.1 (17/02/2016)

- (semver-major) remove 'number of statements'
   from callback parameter                                   #192, #266, #45, #46
- fix in deserealisation of binary datetime packet           #260
- return null date as null, not INVALID_DATE.                #244, #247
- fix incorrect name for flag ( binary protocol )            #245, #246
- completely refactored compression protocol support         #252, #173
- server: add serailisation of NULL strings                  #232
- security: SSL does not verify remote certificate           #103, #171
- Allow parameters in query(options) object                  #216, #230
- Pool query now returns query reference                     #183 #230
- perf: use double-ended queue in the pool instead of arrays #227 #228 #156
- JSON type support                                          #207 #208
- build: add node 4.2 and 5.1 to matrix
- Make SSL ciphers configurable                              #190 #103
- Emit enqueue event if conn is queued                       #177 #189
- call command callback if stream was disconnected mid
  command                                                    #202, 204
- use correct variable in error reporting                    #197
- build: add mariadb to tests.                               #191
- add support for named placeholders for field & tables      #176, 205
- update error codes from node-mysql                         #201 209
- bump named-placeholders to 1.0.0, fixes problems with
  placeholders inside quotation ( https://github.com/sidorares/named-placeholders/issues/2 )
- catch exceptions during named placeholders processing      #187


0.15.8 - 22/06/2015
- Add .escapeId() to Connection and Pool                     #180
- Build: iojs 2.2.1 & 2.3.0
- Binary protocol: fix crash when server return null
  for 'NOT NULL' column                                      #178

0.15.7 - ?

0.15.6 - 04/06/2015
- Include errno in error object                              #168
- server: fix fields in OK and column header packets
  (fix errors when connecting with node-mysql)
- build: add iojs 1.8.x to matrix

0.15.5 - 08/04/2015
- fix broken 'stream rows' functionality                     #165, #166
- add io.js 1.6 to build matrix

0.15.4 - 11/03/2015
- added COM_QUIT command, sent from conn.end()               #163, #150
- io.js 1.5
- don't crash on unexpected protocol packets, emit           #164, #160
  connection error event instead

0.15.3 - 24/02/2015
 - multiple results support in binary protocol               #157 #26 #27
 - add io.js 1.4 to CI matrix

0.15.2 - 24/02/2015
 - update Amazon RDS certificates                           #154
 - add io.js 1.3 to CI matrix
 - fix packet parser bug                                     #155

0.15.1 - 18/02/2015
 - add io.js 1.0 - 1.2 to build matrix
 - add windows CI using Appveyor                             #151 #152

0.15.0 - 1/10/2015
 - connection.threadId
 - connection.changeUser()                                   #63
 - named placeholders                                        #117
 - new prepared statements api                               #132 #139
 - support LOAD INFILE                                       #64 #142
 - refactored faster packet parser                           #140
 - lazy parse rarely used column definition fields           #137

0.14.1 - 9/12/2014
 - stream connection option now can be a function            #80
 - bugfix/prepared statements: fix case when no columns
   in statement header but there are columns in results      #130

0.14.0 - 26/11/2014
  - added connection.pause() and connection.resume()         #129

0.13.0
  - connection errors sent to all commands in queue
  - server-side authentication support                       #122
  - server.listen() is now chainable (returns server)
  - allow to login using sha1(password)                      #124
  - Query.sql as alias to Query.query                        #121

0.12.5 - 30/07/2014
  - add 'execute' pool method similar to Pool##query         #114
  - more debug output behind debug flag

0.12.4 - 17/07/2014
  - 'debug' connection option now result in lots of
     debug output                                            #112 #77
  - send corectly compression flag if compression is on      #102


0.12.3 - 11/07/2014
  - fix node 0.8 - incompatible dependency version

0.12.2 - 11/07/2014

  - output milliseconds in date type                         #107
  - deserialise length coded int with > 24 bit numbers
    to js int / float (and not throw "Bignts not supported") #108
  - support for Bigint numbers in insertId

0.12.1 - 30/04/2014

  - 'dateStrings' connection option support                  #99
  - use anonymous function for packet routing instead
    of .bind() 3-5% speed improvement
  - GEOMETRY type support in binary protocol                 #97

0.12.0 - 29/04/2014

  - route connection time errors from handshke command to
    connection                                               #96

  - support for nestTables and rowsAsArray options in query()
    and execute()                                            #95, #94

  - bugfix: date as parameter in prepared statement,
    day of week was used incorrectly
    instead of day of month                                  #89     ab28dfca839728dfe40d941091902185d7c19b57

   - GEOMETRY type support ported from node-mysql            #93     ebd30fd12b3b7f53d97b9d09f947b12f61e0c2c5

0.11.8

  - add DATE type support                                    #84     1d49651d8e40bf43b79937d9de9b2909126b892c
  - faster DATE parsing in text protocol                             cdfed2881462798bd85fbf906ea604875a3bd625


0.11.7
  - initial implementaion of binlog protocol            #83 #78      c8d45da6fc13a56d95ce6d57c3c8aa9524548770
  - interpret null DOUBLE values as null instead 0 #85               4c03b23f30949be0608d9543d69243944d79bb4a
  - use srcEscape for null values (bunary parser)                    ef50bcafa452588eda4a40037b41f6b961085046

0.11.6
  - minor cleanups

0.11.5
  - fix for non-utf strings serialisation (binary protocol only)     cf9594aaab5b3d51a112bd1f43b39a55f508eef7

0.11.4
  - support YEAR type in prepared statements                         a0f33b5a4de4529130b3c4137f7a1dd3c02aed9e

0.11.3
  - add transaction helpers                             #56, #76     cc0a9f9b721900d3a22c7fc84a5244c74cd33dd5

0.11.2

  - wrap callbacks in nextTick for exception safety                  b73ac9868804b603a0ab6df6129cf3682476d118
  - domains support                                          #73     36cba61359c83018a847ac4e7748d920b6f863c4

0.11.1

  - buxfix: connection.connect callback was called more than once
                                                             #72      0352eefdafc0986f1ec79c0ce285f722ca12af16

0.11.0
  - Bundle Amazon RDS cert and allow to connect using                 e6af097b5facc089f1999c1fb076ada0ce2e7e99
    'Amazon RDS' as ssl value

0.10.7

  - Amazon RDS+ssl example and public CA cert                         709394a4afbbaf0500439e72caec5d37e949fe26
  - pool updated from node-mysql                   #71, #68, #61      db561dbe10a55bb0f9893eb0e2c4b429edd6ee3a

0.10.6
  - handle TIMESTAMP type                                    #59      6dd6fc82d95a16e18092c4db4e8da225b37e9314
  - rename pool's connection.end() to connection.release()   #53      c63b2442e3c0fb5ea3953725ba9c1b3e08b2b831

0.10.5

  - node-mysql compatibility: remove 'number of results in response'
    callback argument (Brian White)                          #46       40af0530403a3892743d32974055c5ea23cbd3ec
  - node 0.11 (use on('data') instead of ondata )                      39906c78b85a77e468694814a50f99714d7bbbd6
  - fix again ssl (#41)                                                713051bf997a186774b618cde583707320a1d551

0.10.4
  - node-mysql compatibility: remove 'number of results in response'
    callback argument (Brian White)                          #45       c9cb926360da5e4028f7d2f83f4b4e94897cd8b8
  - 'resultIndex' parameter for non-multiple results query             8879bdde397b6cd730d234383fa322becd1134de

0.10.3
  - various ssl fixes and refactoring (ssl was broken for some time)   213d375f7263cb6f5e724fdac3ea156ccee4bbd4
  - Server protocol: handle null values serialisation
     (Michael Muturi Njonge)                                 #36       831b2a100795f36649f0c3d79b7839a95f771a05

0.10.2
  - return DECIMAL and NEWDECIMAL as string in binary prot   #40       969fba6ff1dbf14d53d3efc9f94083b8306cf0b5

0.10.1
  - Added ping command                                       #38       cbca8648d1282fb57e55b3735c3b4d9a46d89d7b

0.9.2
  - correctly parse NULL result for string and number        #35       0a4ac65ec812f75861dc00c9243921d5d6602914
  - do not pollute global namespace from evaled parser       #11       4b6ddaf0f70150945d0fea804db9106f343a0e51

0.9.1
  - PoolClaster ported from node-mysql                       #34

0.8.21
  - Fix in error message parsing (Noam Wasersprung)          #31       6cc80a67eaa3baac7dd8eee7182c9eb00977e81a
  - return insert/delete header for insert/delete commands   #32       72aa8fe70981d7410a10edb9d7921e5d6ce1d3ca

0.8.20
  - Make packet parser work with 0.11 ondata(buffer) with no start,end 9005fd1
  - Allow to use Date-like objects as date parameters (Amir Livneh)    6138dad0581fd5e2c45e1ce0b999e334db8979cf

0.8.19
  - Multiple results support in text protocol #15                      4812adaf1aa5b1dfa775a6cf0fa3bae54a7827d0
  - Use connection flags from createConnection parameters/url string   9218f055ceeb95ae7205348e06c07b89b799d031
</file>

<file path="CODE_OF_CONDUCT.md">
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

- Demonstrating empathy and kindness toward other people
- Being respectful of differing opinions, viewpoints, and experiences
- Giving and gracefully accepting constructive feedback
- Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
- Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

- The use of sexualized language or imagery, and sexual attention or
  advances of any kind
- Trolling, insulting or derogatory comments, and personal or political attacks
- Public or private harassment
- Publishing others' private information, such as a physical or email
  address, without their explicit permission
- Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
andrey.sidorov@gmail.com.
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior, harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
https://www.contributor-covenant.org/faq. Translations are available at
https://www.contributor-covenant.org/translations.
</file>

<file path="codecov.yml">
coverage:
  status:
    project:
      default:
        target: 88%
        threshold: 2%
    patch:
      default:
        target: 0%
        threshold: 100%
</file>

<file path="Contributing.md">
[node-mysql]: https://github.com/mysqljs/mysql
[docs-contributing]: https://sidorares.github.io/node-mysql2/docs/contributing/website

# Contributing Guidelines

## Introduction

Contributions are always welcomed. You can help **MySQL2** community in various ways. Here are our major priorities, listed in order of importance:

- [Node MySQL][node-mysql] API incompatibility fixes
- [Documentation][docs-contributing]
- Adding tests or improving existing ones
- Improving benchmarks
- Bug Fixes
- TODO from source
- Performance improvements
- Add Features

---

## Security Issues

Please contact project maintainers privately before opening a security issue on Github. It will allow us to fix the issue before attackers know about it.

### Contact

- Andrey Sidorov, sidorares@yandex.ru

---

## New Features

It's better to discuss an API before actually start implementing it. You can open an issue on Github. We can discuss design of API and implementation ideas.

---

## Development

We assume you already have these tools installed on your system:

- MySQL Server
- Node.JS

As **MySQL2** is purely JS based, you can develop it on Linux, Mac or Windows. Please follow these steps

```bash
# clone node-mysql2
git clone https://github.com/sidorares/node-mysql2.git

cd /path/to/node-mysql2

# install node modules
npm install
```

---

### Commits and Pull Request Titles

To ensure a clean commit history pattern, please use the [Conventional Commits](https://www.conventionalcommits.org/en/v1.0.0/#summary) format.

Prefixes that will trigger a new release version:

- `fix:` for patches, e.g., bug fixes that result in a patch version release.
- `feat:` for new features, e.g., additions that result in a minor version release.

Examples:

- `fix: message`
- `feat: message`
- `docs: message`
- `fix(module): message`
- `feat(module): message`
- etc.

---

### Including Tests

#### Fixes

Where possible, provide an error test case that your fix covers.

#### Features

Please ensure test cases to cover your features.

---

### Running Tests

Running tests requires MySQL server and an empty database. You can run `bash` command given below to create `test` database

```bash
# assuming MySQL have a user root with no password
echo "CREATE DATABASE test;" | mysql -uroot
```

```sh
# Run once to setup the local environment variables.
export CI=1;
export MYSQL_HOST='0.0.0.0';
export MYSQL_USER='root';
export MYSQL_PASSWORD='root';
export MYSQL_DATABASE='test';

# If test user has no password, unset the `CI` variable.

# Run the full test suite
npm run test
```

Use `FILTER` environment variable to run a subset of tests with matching names, e.g.

```sh
FILTER='test-timestamp' npm run test
# or
FILTER='timeout' npm run test
```

> [!Tip]
> You can also run a single test by performing `node ./test/path-to-test-file`.

For testing **coverage**:

```bash
npm run coverage-test
```
</file>

<file path="eslint.config.mjs">
import markdown from 'eslint-plugin-markdown';
import asyncAwait from 'eslint-plugin-async-await';
import globals from 'globals';
import typescriptEslint from '@typescript-eslint/eslint-plugin';
import tsParser from '@typescript-eslint/parser';
import path from 'node:path';
import { fileURLToPath } from 'node:url';
import js from '@eslint/js';
import { FlatCompat } from '@eslint/eslintrc';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
const compat = new FlatCompat({
  baseDirectory: __dirname,
  recommendedConfig: js.configs.recommended,
  allConfig: js.configs.all,
});

export default [
  {
    ignores: ['website/'],
  },
  ...compat.extends('eslint:recommended', 'plugin:prettier/recommended'),
  {
    plugins: {
      markdown,
      'async-await': asyncAwait,
    },
    languageOptions: {
      globals: {
        ...globals.node,
      },

      ecmaVersion: 'latest',
      sourceType: 'commonjs',
    },
    rules: {
      'template-curly-spacing': ['error', 'never'],
      'prefer-template': 'error',
      'no-useless-call': 'error',
      'no-lonely-if': 'error',
      'no-else-return': [
        'error',
        {
          allowElseIf: false,
        },
      ],
      eqeqeq: 'error',
      'no-invalid-this': 'error',
      'consistent-this': 'error',
      'prefer-arrow-callback': 'error',
      'prefer-const': 'error',
      'arrow-body-style': ['error', 'as-needed'],
      'no-var': 'error',
      'no-use-before-define': 'error',
      strict: ['error', 'global'],
    },
  },
  ...compat.extends('plugin:@typescript-eslint/recommended').map((config) => ({
    ...config,
    files: ['**/*.ts'],
  })),
  {
    files: ['**/*.ts'],
    plugins: {
      '@typescript-eslint': typescriptEslint,
    },
    languageOptions: {
      parser: tsParser,
    },
    rules: {
      '@typescript-eslint/no-empty-interface': 'off',
      '@typescript-eslint/no-explicit-any': 'off',
      'arrow-parens': 'off',
      '@typescript-eslint/no-empty-object-type': 'off',
      'no-restricted-syntax': [
        'error',
        {
          selector:
            'ImportDeclaration[source.value=/^\\./][source.value!=/\\.(js)$/]',
          message: 'Local imports must have the explicit extension',
        },
      ],
    },
  },
  {
    files: ['**/*.md'],
    processor: 'markdown/markdown',
  },
  {
    files: ['**/*.md/*js', '**/*.md/*ts'],
    processor: 'markdown/markdown',
    languageOptions: {
      ecmaVersion: 'latest',
      sourceType: 'module',
    },
    rules: {
      'no-undef': 'off',
      'no-unused-vars': 'off',
      '@typescript-eslint/no-unused-vars': 'off',
      'no-console': 'off',
      'no-unused-labels': 'off',
      strict: 'off',
      'prefer-arrow-callback': 'off',
    },
  },
  {
    files: ['**/**/*.test.*'],
    rules: {
      'arrow-parens': ['error', 'always'],
    },
  },
  {
    files: ['**/**/*.test.ts'],
    rules: {
      '@typescript-eslint/no-unused-expressions': 'off',
      'arrow-parens': ['error', 'always'],
    },
  },
  {
    files: ['**/*.mjs'],
    languageOptions: {
      ecmaVersion: 'latest',
      sourceType: 'module',
    },
  },
];
</file>

<file path="fixtures/mysql-ssl-ca-cert.pem">
-----BEGIN CERTIFICATE-----
MIIDQzCCAqygAwIBAgIJAOd1tlfiGoEoMA0GCSqGSIb3DQEBBQUAMHUxCzAJBgNV
BAYTAlVTMRMwEQYDVQQIEwpXYXNoaW5ndG9uMRAwDgYDVQQHEwdTZWF0dGxlMRMw
EQYDVQQKEwpBbWF6b24uY29tMQwwCgYDVQQLEwNSRFMxHDAaBgNVBAMTE2F3cy5h
bWF6b24uY29tL3Jkcy8wHhcNMTAwNDA1MjI0NDMxWhcNMTUwNDA0MjI0NDMxWjB1
MQswCQYDVQQGEwJVUzETMBEGA1UECBMKV2FzaGluZ3RvbjEQMA4GA1UEBxMHU2Vh
dHRsZTETMBEGA1UEChMKQW1hem9uLmNvbTEMMAoGA1UECxMDUkRTMRwwGgYDVQQD
ExNhd3MuYW1hem9uLmNvbS9yZHMvMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKB
gQDKhXGU7tizxUR5WaFoMTFcxNxa05PEjZaIOEN5ctkWrqYSRov0/nOMoZjqk8bC
med9vPFoQGD0OTakPs0jVe3wwmR735hyVwmKIPPsGlaBYj1O6llIpZeQVyupNx56
UzqtiLaDzh1KcmfqP3qP2dInzBfJQKjiRudo1FWnpPt33QIDAQABo4HaMIHXMB0G
A1UdDgQWBBT/H3x+cqSkR/ePSIinPtc4yWKe3DCBpwYDVR0jBIGfMIGcgBT/H3x+
cqSkR/ePSIinPtc4yWKe3KF5pHcwdTELMAkGA1UEBhMCVVMxEzARBgNVBAgTCldh
c2hpbmd0b24xEDAOBgNVBAcTB1NlYXR0bGUxEzARBgNVBAoTCkFtYXpvbi5jb20x
DDAKBgNVBAsTA1JEUzEcMBoGA1UEAxMTYXdzLmFtYXpvbi5jb20vcmRzL4IJAOd1
tlfiGoEoMAwGA1UdEwQFMAMBAf8wDQYJKoZIhvcNAQEFBQADgYEAvguZy/BDT66x
GfgnJlyQwnFSeVLQm9u/FIvz4huGjbq9dqnD6h/Gm56QPFdyMEyDiZWaqY6V08lY
LTBNb4kcIc9/6pc0/ojKciP5QJRm6OiZ4vgG05nF4fYjhU7WClUx7cxq1fKjNc2J
UCmmYqgiVkAGWRETVo+byOSDZ4swb10=
-----END CERTIFICATE-----
</file>

<file path="index.d.ts">
export * from './typings/mysql/index.js';
</file>

<file path="index.js">
'use strict';

const SqlString = require('sqlstring');

const ConnectionConfig = require('./lib/connection_config.js');
const parserCache = require('./lib/parsers/parser_cache.js');

const Connection = require('./lib/connection.js');

exports.createConnection = require('./lib/create_connection.js');
exports.connect = exports.createConnection;
exports.Connection = Connection;
exports.ConnectionConfig = ConnectionConfig;

const Pool = require('./lib/pool.js');
const PoolCluster = require('./lib/pool_cluster.js');
const createPool = require('./lib/create_pool.js');
const createPoolCluster = require('./lib/create_pool_cluster.js');

exports.createPool = createPool;

exports.createPoolCluster = createPoolCluster;

exports.createQuery = Connection.createQuery;

exports.Pool = Pool;

exports.PoolCluster = PoolCluster;

exports.createServer = function (handler) {
  const Server = require('./lib/server.js');
  const s = new Server();
  if (handler) {
    s.on('connection', handler);
  }
  return s;
};

exports.PoolConnection = require('./lib/pool_connection.js');
exports.authPlugins = require('./lib/auth_plugins');
exports.escape = SqlString.escape;
exports.escapeId = SqlString.escapeId;
exports.format = SqlString.format;
exports.raw = SqlString.raw;

exports.__defineGetter__(
  'createConnectionPromise',
  () => require('./promise.js').createConnection
);

exports.__defineGetter__(
  'createPoolPromise',
  () => require('./promise.js').createPool
);

exports.__defineGetter__(
  'createPoolClusterPromise',
  () => require('./promise.js').createPoolCluster
);

exports.__defineGetter__('Types', () => require('./lib/constants/types.js'));

exports.__defineGetter__('Charsets', () =>
  require('./lib/constants/charsets.js')
);

exports.__defineGetter__('CharsetToEncoding', () =>
  require('./lib/constants/charset_encodings.js')
);

exports.setMaxParserCache = function (max) {
  parserCache.setMaxCache(max);
};

exports.clearParserCache = function () {
  parserCache.clearCache();
};
</file>

<file path="lib/auth_41.js">
'use strict';

/*
4.1 authentication: (http://bazaar.launchpad.net/~mysql/mysql-server/5.5/view/head:/sql/password.c)

  SERVER:  public_seed=create_random_string()
           send(public_seed)

  CLIENT:  recv(public_seed)
           hash_stage1=sha1("password")
           hash_stage2=sha1(hash_stage1)
           reply=xor(hash_stage1, sha1(public_seed,hash_stage2)

           // this three steps are done in scramble()

           send(reply)


  SERVER:  recv(reply)
           hash_stage1=xor(reply, sha1(public_seed,hash_stage2))
           candidate_hash2=sha1(hash_stage1)
           check(candidate_hash2==hash_stage2)

server stores sha1(sha1(password)) ( hash_stag2)
*/

const crypto = require('crypto');

function sha1(msg, msg1, msg2) {
  const hash = crypto.createHash('sha1');
  hash.update(msg);
  if (msg1) {
    hash.update(msg1);
  }

  if (msg2) {
    hash.update(msg2);
  }

  return hash.digest();
}

function xor(a, b) {
  const result = Buffer.allocUnsafe(a.length);
  for (let i = 0; i < a.length; i++) {
    result[i] = a[i] ^ b[i];
  }
  return result;
}

exports.xor = xor;

function token(password, scramble1, scramble2) {
  if (!password) {
    return Buffer.alloc(0);
  }
  const stage1 = sha1(password);
  return exports.calculateTokenFromPasswordSha(stage1, scramble1, scramble2);
}

exports.calculateTokenFromPasswordSha = function (
  passwordSha,
  scramble1,
  scramble2
) {
  // we use AUTH 41 here, and we need only the bytes we just need.
  const authPluginData1 = scramble1.slice(0, 8);
  const authPluginData2 = scramble2.slice(0, 12);
  const stage2 = sha1(passwordSha);
  const stage3 = sha1(authPluginData1, authPluginData2, stage2);
  return xor(stage3, passwordSha);
};

exports.calculateToken = token;

exports.verifyToken = function (publicSeed1, publicSeed2, token, doubleSha) {
  const hashStage1 = xor(token, sha1(publicSeed1, publicSeed2, doubleSha));
  const candidateHash2 = sha1(hashStage1);
  return candidateHash2.compare(doubleSha) === 0;
};

exports.doubleSha1 = function (password) {
  return sha1(sha1(password));
};

function xorRotating(a, seed) {
  const result = Buffer.allocUnsafe(a.length);
  const seedLen = seed.length;

  for (let i = 0; i < a.length; i++) {
    result[i] = a[i] ^ seed[i % seedLen];
  }
  return result;
}
exports.xorRotating = xorRotating;
</file>

<file path="lib/auth_plugins/caching_sha2_password.js">
'use strict';

// https://mysqlserverteam.com/mysql-8-0-4-new-default-authentication-plugin-caching_sha2_password/

const PLUGIN_NAME = 'caching_sha2_password';
const crypto = require('crypto');
const { xor, xorRotating } = require('../auth_41');

const REQUEST_SERVER_KEY_PACKET = Buffer.from([2]);
const FAST_AUTH_SUCCESS_PACKET = Buffer.from([3]);
const PERFORM_FULL_AUTHENTICATION_PACKET = Buffer.from([4]);

const STATE_INITIAL = 0;
const STATE_TOKEN_SENT = 1;
const STATE_WAIT_SERVER_KEY = 2;
const STATE_FINAL = -1;

function sha256(msg) {
  const hash = crypto.createHash('sha256');
  hash.update(msg);
  return hash.digest();
}

function calculateToken(password, scramble) {
  if (!password) {
    return Buffer.alloc(0);
  }
  const stage1 = sha256(Buffer.from(password));
  const stage2 = sha256(stage1);
  const stage3 = sha256(Buffer.concat([stage2, scramble]));
  return xor(stage1, stage3);
}

function encrypt(password, scramble, key) {
  const stage1 = xorRotating(Buffer.from(`${password}\0`, 'utf8'), scramble);
  return crypto.publicEncrypt(
    {
      key,
      padding: crypto.constants.RSA_PKCS1_OAEP_PADDING,
    },
    stage1
  );
}

module.exports =
  (pluginOptions = {}) =>
  ({ connection }) => {
    let state = 0;
    let scramble = null;

    const password = connection.config.password;

    const authWithKey = (serverKey) => {
      const _password = encrypt(password, scramble, serverKey);
      state = STATE_FINAL;
      return _password;
    };

    return (data) => {
      switch (state) {
        case STATE_INITIAL:
          scramble = data.slice(0, 20);
          state = STATE_TOKEN_SENT;
          return calculateToken(password, scramble);

        case STATE_TOKEN_SENT:
          if (FAST_AUTH_SUCCESS_PACKET.equals(data)) {
            state = STATE_FINAL;
            return null;
          }

          if (PERFORM_FULL_AUTHENTICATION_PACKET.equals(data)) {
            const isSecureConnection =
              typeof pluginOptions.overrideIsSecure === 'undefined'
                ? connection.config.ssl || connection.config.socketPath
                : pluginOptions.overrideIsSecure;
            if (isSecureConnection) {
              state = STATE_FINAL;
              return Buffer.from(`${password}\0`, 'utf8');
            }

            // if client provides key we can save one extra roundrip on first connection
            if (pluginOptions.serverPublicKey) {
              return authWithKey(pluginOptions.serverPublicKey);
            }

            state = STATE_WAIT_SERVER_KEY;
            return REQUEST_SERVER_KEY_PACKET;
          }
          throw new Error(
            `Invalid AuthMoreData packet received by ${PLUGIN_NAME} plugin in STATE_TOKEN_SENT state.`
          );
        case STATE_WAIT_SERVER_KEY:
          if (pluginOptions.onServerPublicKey) {
            pluginOptions.onServerPublicKey(data);
          }
          return authWithKey(data);
        case STATE_FINAL:
          throw new Error(
            `Unexpected data in AuthMoreData packet received by ${PLUGIN_NAME} plugin in STATE_FINAL state.`
          );
      }

      throw new Error(
        `Unexpected data in AuthMoreData packet received by ${PLUGIN_NAME} plugin in state ${state}`
      );
    };
  };
</file>

<file path="lib/auth_plugins/caching_sha2_password.md">
##

https://dev.mysql.com/doc/refman/8.0/en/caching-sha2-pluggable-authentication.html

```js
const mysql = require('mysql');
mysql.createConnection({
  authPlugins: {
    caching_sha2_password: mysql.authPlugins.caching_sha2_password({
      onServerPublikKey: function (key) {
        console.log(key);
      },
      serverPublicKey: 'xxxyyy',
      overrideIsSecure: true, //
    }),
  },
});
```
</file>

<file path="lib/auth_plugins/index.js">
'use strict';

module.exports = {
  caching_sha2_password: require('./caching_sha2_password'),
  mysql_clear_password: require('./mysql_clear_password'),
  mysql_native_password: require('./mysql_native_password'),
  sha256_password: require('./sha256_password'),
};
</file>

<file path="lib/auth_plugins/mysql_clear_password.js">
'use strict';

function bufferFromStr(str) {
  return Buffer.from(`${str}\0`);
}

const create_mysql_clear_password_plugin = (pluginOptions) =>
  function mysql_clear_password_plugin({ connection, command }) {
    const password =
      command.password || pluginOptions.password || connection.config.password;

    return function (/* pluginData */) {
      return bufferFromStr(password);
    };
  };

module.exports = create_mysql_clear_password_plugin;
</file>

<file path="lib/auth_plugins/mysql_native_password.js">
'use strict';

//const PLUGIN_NAME = 'mysql_native_password';
const auth41 = require('../auth_41.js');

module.exports =
  (pluginOptions) =>
  ({ connection, command }) => {
    const password =
      command.password || pluginOptions.password || connection.config.password;
    const passwordSha1 =
      command.passwordSha1 ||
      pluginOptions.passwordSha1 ||
      connection.config.passwordSha1;
    return (data) => {
      const authPluginData1 = data.slice(0, 8);
      const authPluginData2 = data.slice(8, 20);
      let authToken;
      if (passwordSha1) {
        authToken = auth41.calculateTokenFromPasswordSha(
          passwordSha1,
          authPluginData1,
          authPluginData2
        );
      } else {
        authToken = auth41.calculateToken(
          password,
          authPluginData1,
          authPluginData2
        );
      }
      return authToken;
    };
  };
</file>

<file path="lib/auth_plugins/sha256_password.js">
'use strict';

const PLUGIN_NAME = 'sha256_password';
const crypto = require('crypto');
const { xorRotating } = require('../auth_41');

const REQUEST_SERVER_KEY_PACKET = Buffer.from([1]);

const STATE_INITIAL = 0;
const STATE_WAIT_SERVER_KEY = 1;
const STATE_FINAL = -1;

function encrypt(password, scramble, key) {
  const stage1 = xorRotating(Buffer.from(`${password}\0`, 'utf8'), scramble);
  return crypto.publicEncrypt(key, stage1);
}

module.exports =
  (pluginOptions = {}) =>
  ({ connection }) => {
    let state = 0;
    let scramble = null;

    const password = connection.config.password;

    const authWithKey = (serverKey) => {
      const _password = encrypt(password, scramble, serverKey);
      state = STATE_FINAL;
      return _password;
    };

    return (data) => {
      switch (state) {
        case STATE_INITIAL:
          scramble = data.slice(0, 20);
          // if client provides key we can save one extra roundrip on first connection
          if (pluginOptions.serverPublicKey) {
            return authWithKey(pluginOptions.serverPublicKey);
          }

          state = STATE_WAIT_SERVER_KEY;
          return REQUEST_SERVER_KEY_PACKET;

        case STATE_WAIT_SERVER_KEY:
          if (pluginOptions.onServerPublicKey) {
            pluginOptions.onServerPublicKey(data);
          }
          return authWithKey(data);
        case STATE_FINAL:
          throw new Error(
            `Unexpected data in AuthMoreData packet received by ${PLUGIN_NAME} plugin in STATE_FINAL state.`
          );
      }

      throw new Error(
        `Unexpected data in AuthMoreData packet received by ${PLUGIN_NAME} plugin in state ${state}`
      );
    };
  };
</file>

<file path="lib/base/connection.js">
// This file was modified by Oracle on June 1, 2021.
// The changes involve new logic to handle an additional ERR Packet sent by
// the MySQL server when the connection is closed unexpectedly.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

// This file was modified by Oracle on June 17, 2021.
// The changes involve logic to ensure the socket connection is closed when
// there is a fatal error.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

// This file was modified by Oracle on September 21, 2021.
// The changes involve passing additional authentication factor passwords
// to the ChangeUser Command instance.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const Net = require('net');
const Tls = require('tls');
const Timers = require('timers');
const EventEmitter = require('events').EventEmitter;
const Readable = require('stream').Readable;
const Queue = require('denque');
const SqlString = require('sqlstring');
const { createLRU } = require('lru.min');
const PacketParser = require('../packet_parser.js');
const Packets = require('../packets/index.js');
const Commands = require('../commands/index.js');
const ConnectionConfig = require('../connection_config.js');
const CharsetToEncoding = require('../constants/charset_encodings.js');

let _connectionId = 0;

let convertNamedPlaceholders = null;

class BaseConnection extends EventEmitter {
  constructor(opts) {
    super();
    this.config = opts.config;
    // TODO: fill defaults
    // if no params, connect to /var/lib/mysql/mysql.sock ( /tmp/mysql.sock on OSX )
    // if host is given, connect to host:3306
    // TODO: use `/usr/local/mysql/bin/mysql_config --socket` output? as default socketPath
    // if there is no host/port and no socketPath parameters?
    if (!opts.config.stream) {
      if (opts.config.socketPath) {
        this.stream = Net.connect(opts.config.socketPath);
      } else {
        this.stream = Net.connect(opts.config.port, opts.config.host);

        // Optionally enable keep-alive on the socket.
        if (this.config.enableKeepAlive) {
          this.stream.on('connect', () => {
            this.stream.setKeepAlive(true, this.config.keepAliveInitialDelay);
          });
        }

        // Enable TCP_NODELAY flag. This is needed so that the network packets
        // are sent immediately to the server
        this.stream.setNoDelay(true);
      }
      // if stream is a function, treat it as "stream agent / factory"
    } else if (typeof opts.config.stream === 'function') {
      this.stream = opts.config.stream(opts);
    } else {
      this.stream = opts.config.stream;
    }

    this._internalId = _connectionId++;
    this._commands = new Queue();
    this._command = null;
    this._paused = false;
    this._paused_packets = new Queue();
    this._statements = createLRU({
      max: this.config.maxPreparedStatements,
      onEviction: function (_, statement) {
        statement.close();
      },
    });
    this.serverCapabilityFlags = 0;
    this.authorized = false;
    this.sequenceId = 0;
    this.compressedSequenceId = 0;
    this.threadId = null;
    this._handshakePacket = null;
    this._fatalError = null;
    this._protocolError = null;
    this._outOfOrderPackets = [];
    this.clientEncoding = CharsetToEncoding[this.config.charsetNumber];
    this.stream.on('error', this._handleNetworkError.bind(this));
    // see https://gist.github.com/khoomeister/4985691#use-that-instead-of-bind
    this.packetParser = new PacketParser((p) => {
      this.handlePacket(p);
    });
    this.stream.on('data', (data) => {
      if (this.connectTimeout) {
        Timers.clearTimeout(this.connectTimeout);
        this.connectTimeout = null;
      }
      this.packetParser.execute(data);
    });
    this.stream.on('end', () => {
      // emit the end event so that the pooled connection can close the connection
      this.emit('end');
    });
    this.stream.on('close', () => {
      // we need to set this flag everywhere where we want connection to close
      if (this._closing) {
        return;
      }
      if (!this._protocolError) {
        // no particular error message before disconnect
        this._protocolError = new Error(
          'Connection lost: The server closed the connection.'
        );
        this._protocolError.fatal = true;
        this._protocolError.code = 'PROTOCOL_CONNECTION_LOST';
      }
      this._notifyError(this._protocolError);
    });
    let handshakeCommand;
    if (!this.config.isServer) {
      handshakeCommand = new Commands.ClientHandshake(this.config.clientFlags);
      handshakeCommand.on('end', () => {
        // this happens when handshake finishes early either because there was
        // some fatal error or the server sent an error packet instead of
        // an hello packet (for example, 'Too many connections' error)
        if (
          !handshakeCommand.handshake ||
          this._fatalError ||
          this._protocolError
        ) {
          return;
        }
        this._handshakePacket = handshakeCommand.handshake;
        this.threadId = handshakeCommand.handshake.connectionId;
        this.emit('connect', handshakeCommand.handshake);
      });
      handshakeCommand.on('error', (err) => {
        this._closing = true;
        this._notifyError(err);
      });
      this.addCommand(handshakeCommand);
    }
    // in case there was no initial handshake but we need to read sting, assume it utf-8
    // most common example: "Too many connections" error ( packet is sent immediately on connection attempt, we don't know server encoding yet)
    // will be overwritten with actual encoding value as soon as server handshake packet is received
    this.serverEncoding = 'utf8';
    if (this.config.connectTimeout) {
      const timeoutHandler = this._handleTimeoutError.bind(this);
      this.connectTimeout = Timers.setTimeout(
        timeoutHandler,
        this.config.connectTimeout
      );
    }
  }

  _addCommandClosedState(cmd) {
    const err = new Error(
      "Can't add new command when connection is in closed state"
    );
    err.fatal = true;
    if (cmd.onResult) {
      cmd.onResult(err);
    } else {
      this.emit('error', err);
    }
  }

  _handleFatalError(err) {
    err.fatal = true;
    // stop receiving packets
    this.stream.removeAllListeners('data');
    this.addCommand = this._addCommandClosedState;
    this.write = () => {
      this.emit('error', new Error("Can't write in closed state"));
    };
    this._notifyError(err);
    this._fatalError = err;
  }

  _handleNetworkError(err) {
    if (this.connectTimeout) {
      Timers.clearTimeout(this.connectTimeout);
      this.connectTimeout = null;
    }
    // Do not throw an error when a connection ends with a RST,ACK packet
    if (err.code === 'ECONNRESET' && this._closing) {
      return;
    }
    this._handleFatalError(err);
  }

  _handleTimeoutError() {
    if (this.connectTimeout) {
      Timers.clearTimeout(this.connectTimeout);
      this.connectTimeout = null;
    }
    this.stream.destroy && this.stream.destroy();
    const err = new Error('connect ETIMEDOUT');
    err.errorno = 'ETIMEDOUT';
    err.code = 'ETIMEDOUT';
    err.syscall = 'connect';
    this._handleNetworkError(err);
  }

  // notify all commands in the queue and bubble error as connection "error"
  // called on stream error or unexpected termination
  _notifyError(err) {
    if (this.connectTimeout) {
      Timers.clearTimeout(this.connectTimeout);
      this.connectTimeout = null;
    }
    // prevent from emitting 'PROTOCOL_CONNECTION_LOST' after EPIPE or ECONNRESET
    if (this._fatalError) {
      return;
    }
    let command;
    // if there is no active command, notify connection
    // if there are commands and all of them have callbacks, pass error via callback
    let bubbleErrorToConnection = !this._command;
    if (this._command && this._command.onResult) {
      this._command.onResult(err);
      this._command = null;
      // connection handshake is special because we allow it to be implicit
      // if error happened during handshake, but there are others commands in queue
      // then bubble error to other commands and not to connection
    } else if (
      !(
        this._command &&
        this._command.constructor === Commands.ClientHandshake &&
        this._commands.length > 0
      )
    ) {
      bubbleErrorToConnection = true;
    }
    while ((command = this._commands.shift())) {
      if (command.onResult) {
        command.onResult(err);
      } else {
        bubbleErrorToConnection = true;
      }
    }
    // notify connection if some comands in the queue did not have callbacks
    // or if this is pool connection ( so it can be removed from pool )
    if (bubbleErrorToConnection || this._pool) {
      this.emit('error', err);
    }
    // close connection after emitting the event in case of a fatal error
    if (err.fatal) {
      this.close();
    }
  }

  write(buffer) {
    const result = this.stream.write(buffer, (err) => {
      if (err) {
        this._handleNetworkError(err);
      }
    });

    if (!result) {
      this.stream.emit('pause');
    }
  }

  // http://dev.mysql.com/doc/internals/en/sequence-id.html
  //
  // The sequence-id is incremented with each packet and may wrap around.
  // It starts at 0 and is reset to 0 when a new command
  // begins in the Command Phase.
  // http://dev.mysql.com/doc/internals/en/example-several-mysql-packets.html
  _resetSequenceId() {
    this.sequenceId = 0;
    this.compressedSequenceId = 0;
  }

  _bumpCompressedSequenceId(numPackets) {
    this.compressedSequenceId += numPackets;
    this.compressedSequenceId %= 256;
  }

  _bumpSequenceId(numPackets) {
    this.sequenceId += numPackets;
    this.sequenceId %= 256;
  }

  writePacket(packet) {
    const MAX_PACKET_LENGTH = 16777215;
    const length = packet.length();
    let chunk, offset, header;
    if (length < MAX_PACKET_LENGTH) {
      packet.writeHeader(this.sequenceId);
      if (this.config.debug) {
        console.log(
          `${this._internalId} ${this.connectionId} <== ${this._command._commandName}#${this._command.stateName()}(${[this.sequenceId, packet._name, packet.length()].join(',')})`
        );
        console.log(
          `${this._internalId} ${this.connectionId} <== ${packet.buffer.toString('hex')}`
        );
      }
      this._bumpSequenceId(1);
      this.write(packet.buffer);
    } else {
      if (this.config.debug) {
        console.log(
          `${this._internalId} ${this.connectionId} <== Writing large packet, raw content not written:`
        );
        console.log(
          `${this._internalId} ${this.connectionId} <== ${this._command._commandName}#${this._command.stateName()}(${[this.sequenceId, packet._name, packet.length()].join(',')})`
        );
      }
      for (offset = 4; offset < 4 + length; offset += MAX_PACKET_LENGTH) {
        chunk = packet.buffer.slice(offset, offset + MAX_PACKET_LENGTH);
        if (chunk.length === MAX_PACKET_LENGTH) {
          header = Buffer.from([0xff, 0xff, 0xff, this.sequenceId]);
        } else {
          header = Buffer.from([
            chunk.length & 0xff,
            (chunk.length >> 8) & 0xff,
            (chunk.length >> 16) & 0xff,
            this.sequenceId,
          ]);
        }
        this._bumpSequenceId(1);
        this.write(header);
        this.write(chunk);
      }
    }
  }

  // 0.11+ environment
  startTLS(onSecure) {
    if (this.config.debug) {
      console.log('Upgrading connection to TLS');
    }
    const secureContext = Tls.createSecureContext({
      ca: this.config.ssl.ca,
      cert: this.config.ssl.cert,
      ciphers: this.config.ssl.ciphers,
      key: this.config.ssl.key,
      passphrase: this.config.ssl.passphrase,
      minVersion: this.config.ssl.minVersion,
      maxVersion: this.config.ssl.maxVersion,
    });
    const rejectUnauthorized = this.config.ssl.rejectUnauthorized;
    const verifyIdentity = this.config.ssl.verifyIdentity;
    const servername = this.config.host;

    let secureEstablished = false;
    this.stream.removeAllListeners('data');
    const secureSocket = Tls.connect(
      {
        rejectUnauthorized,
        requestCert: rejectUnauthorized,
        checkServerIdentity: verifyIdentity
          ? Tls.checkServerIdentity
          : function () {
              return undefined;
            },
        secureContext,
        isServer: false,
        socket: this.stream,
        servername,
      },
      () => {
        secureEstablished = true;
        if (rejectUnauthorized) {
          if (typeof servername === 'string' && verifyIdentity) {
            const cert = secureSocket.getPeerCertificate(true);
            const serverIdentityCheckError = Tls.checkServerIdentity(
              servername,
              cert
            );
            if (serverIdentityCheckError) {
              onSecure(serverIdentityCheckError);
              return;
            }
          }
        }
        onSecure();
      }
    );
    // error handler for secure socket
    secureSocket.on('error', (err) => {
      if (secureEstablished) {
        this._handleNetworkError(err);
      } else {
        onSecure(err);
      }
    });
    secureSocket.on('data', (data) => {
      this.packetParser.execute(data);
    });
    this.write = (buffer) => secureSocket.write(buffer);
  }

  protocolError(message, code) {
    // Starting with MySQL 8.0.24, if the client closes the connection
    // unexpectedly, the server will send a last ERR Packet, which we can
    // safely ignore.
    // https://dev.mysql.com/worklog/task/?id=12999
    if (this._closing) {
      return;
    }

    const err = new Error(message);
    err.fatal = true;
    err.code = code || 'PROTOCOL_ERROR';
    this.emit('error', err);
  }

  get fatalError() {
    return this._fatalError;
  }

  handlePacket(packet) {
    if (this._paused) {
      this._paused_packets.push(packet);
      return;
    }
    if (this.config.debug) {
      if (packet) {
        console.log(
          ` raw: ${packet.buffer
            .slice(packet.offset, packet.offset + packet.length())
            .toString('hex')}`
        );
        console.trace();
        const commandName = this._command
          ? this._command._commandName
          : '(no command)';
        const stateName = this._command
          ? this._command.stateName()
          : '(no command)';
        console.log(
          `${this._internalId} ${this.connectionId} ==> ${commandName}#${stateName}(${[packet.sequenceId, packet.type(), packet.length()].join(',')})`
        );
      }
    }
    if (!this._command) {
      const marker = packet.peekByte();
      // If it's an Err Packet, we should use it.
      if (marker === 0xff) {
        const error = Packets.Error.fromPacket(packet);
        this.protocolError(error.message, error.code);
      } else {
        // Otherwise, it means it's some other unexpected packet.
        this.protocolError(
          'Unexpected packet while no commands in the queue',
          'PROTOCOL_UNEXPECTED_PACKET'
        );
      }
      this.close();
      return;
    }
    if (packet) {
      // Note: when server closes connection due to inactivity, Err packet ER_CLIENT_INTERACTION_TIMEOUT from MySQL 8.0.24, sequenceId will be 0
      if (this.sequenceId !== packet.sequenceId) {
        const err = new Error(
          `Warning: got packets out of order. Expected ${this.sequenceId} but received ${packet.sequenceId}`
        );
        err.expected = this.sequenceId;
        err.received = packet.sequenceId;
        this.emit('warn', err); // REVIEW
        console.error(err.message);
      }
      this._bumpSequenceId(packet.numPackets);
    }
    try {
      if (this._fatalError) {
        // skip remaining packets after client is in the error state
        return;
      }
      const done = this._command.execute(packet, this);
      if (done) {
        this._command = this._commands.shift();
        if (this._command) {
          this.sequenceId = 0;
          this.compressedSequenceId = 0;
          this.handlePacket();
        }
      }
    } catch (err) {
      this._handleFatalError(err);
      this.stream.destroy();
    }
  }

  addCommand(cmd) {
    // this.compressedSequenceId = 0;
    // this.sequenceId = 0;
    if (this.config.debug) {
      const commandName = cmd.constructor.name;
      console.log(`Add command: ${commandName}`);
      cmd._commandName = commandName;
    }
    if (!this._command) {
      this._command = cmd;
      this.handlePacket();
    } else {
      this._commands.push(cmd);
    }
    return cmd;
  }

  format(sql, values) {
    if (typeof this.config.queryFormat === 'function') {
      return this.config.queryFormat.call(
        this,
        sql,
        values,
        this.config.timezone
      );
    }
    const opts = {
      sql: sql,
      values: values,
    };
    this._resolveNamedPlaceholders(opts);
    return SqlString.format(
      opts.sql,
      opts.values,
      this.config.stringifyObjects,
      this.config.timezone
    );
  }

  escape(value) {
    return SqlString.escape(value, false, this.config.timezone);
  }

  escapeId(value) {
    return SqlString.escapeId(value, false);
  }

  raw(sql) {
    return SqlString.raw(sql);
  }

  _resolveNamedPlaceholders(options) {
    let unnamed;
    if (this.config.namedPlaceholders || options.namedPlaceholders) {
      if (Array.isArray(options.values)) {
        // if an array is provided as the values, assume the conversion is not necessary.
        // this allows the usage of unnamed placeholders even if the namedPlaceholders flag is enabled.
        return;
      }
      if (convertNamedPlaceholders === null) {
        convertNamedPlaceholders = require('named-placeholders')();
      }
      unnamed = convertNamedPlaceholders(options.sql, options.values);
      options.sql = unnamed[0];
      options.values = unnamed[1];
    }
  }

  query(sql, values, cb) {
    let cmdQuery;
    if (sql.constructor === Commands.Query) {
      cmdQuery = sql;
    } else {
      cmdQuery = BaseConnection.createQuery(sql, values, cb, this.config);
    }
    this._resolveNamedPlaceholders(cmdQuery);
    const rawSql = this.format(
      cmdQuery.sql,
      cmdQuery.values !== undefined ? cmdQuery.values : []
    );
    cmdQuery.sql = rawSql;
    return this.addCommand(cmdQuery);
  }

  pause() {
    this._paused = true;
    this.stream.pause();
  }

  resume() {
    let packet;
    this._paused = false;
    while ((packet = this._paused_packets.shift())) {
      this.handlePacket(packet);
      // don't resume if packet handler paused connection
      if (this._paused) {
        return;
      }
    }
    this.stream.resume();
  }

  // TODO: named placeholders support
  prepare(options, cb) {
    if (typeof options === 'string') {
      options = { sql: options };
    }
    return this.addCommand(new Commands.Prepare(options, cb));
  }

  unprepare(sql) {
    let options = {};
    if (typeof sql === 'object') {
      options = sql;
    } else {
      options.sql = sql;
    }
    const key = BaseConnection.statementKey(options);
    const stmt = this._statements.get(key);
    if (stmt) {
      this._statements.delete(key);
      stmt.close();
    }
    return stmt;
  }

  execute(sql, values, cb) {
    let options = {
      infileStreamFactory: this.config.infileStreamFactory,
    };
    if (typeof sql === 'object') {
      // execute(options, cb)
      options = {
        ...options,
        ...sql,
        sql: sql.sql,
        values: sql.values,
      };
      if (typeof values === 'function') {
        cb = values;
      } else {
        options.values = options.values || values;
      }
    } else if (typeof values === 'function') {
      // execute(sql, cb)
      cb = values;
      options.sql = sql;
      options.values = undefined;
    } else {
      // execute(sql, values, cb)
      options.sql = sql;
      options.values = values;
    }
    this._resolveNamedPlaceholders(options);
    // check for values containing undefined
    if (options.values) {
      //If namedPlaceholder is not enabled and object is passed as bind parameters
      if (!Array.isArray(options.values)) {
        throw new TypeError(
          'Bind parameters must be array if namedPlaceholders parameter is not enabled'
        );
      }
      options.values.forEach((val) => {
        //If namedPlaceholder is not enabled and object is passed as bind parameters
        if (!Array.isArray(options.values)) {
          throw new TypeError(
            'Bind parameters must be array if namedPlaceholders parameter is not enabled'
          );
        }
        if (val === undefined) {
          throw new TypeError(
            'Bind parameters must not contain undefined. To pass SQL NULL specify JS null'
          );
        }
        if (typeof val === 'function') {
          throw new TypeError(
            'Bind parameters must not contain function(s). To pass the body of a function as a string call .toString() first'
          );
        }
      });
    }
    const executeCommand = new Commands.Execute(options, cb);
    const prepareCommand = new Commands.Prepare(options, (err, stmt) => {
      if (err) {
        // skip execute command if prepare failed, we have main
        // combined callback here
        executeCommand.start = function () {
          return null;
        };
        if (cb) {
          cb(err);
        } else {
          executeCommand.emit('error', err);
        }
        executeCommand.emit('end');
        return;
      }
      executeCommand.statement = stmt;
    });
    this.addCommand(prepareCommand);
    this.addCommand(executeCommand);
    return executeCommand;
  }

  changeUser(options, callback) {
    if (!callback && typeof options === 'function') {
      callback = options;
      options = {};
    }
    const charsetNumber = options.charset
      ? ConnectionConfig.getCharsetNumber(options.charset)
      : this.config.charsetNumber;
    return this.addCommand(
      new Commands.ChangeUser(
        {
          user: options.user || this.config.user,
          // for the purpose of multi-factor authentication, or not, the main
          // password (used for the 1st authentication factor) can also be
          // provided via the "password1" option
          password:
            options.password ||
            options.password1 ||
            this.config.password ||
            this.config.password1,
          password2: options.password2 || this.config.password2,
          password3: options.password3 || this.config.password3,
          passwordSha1: options.passwordSha1 || this.config.passwordSha1,
          database: options.database || this.config.database,
          timeout: options.timeout,
          charsetNumber: charsetNumber,
          currentConfig: this.config,
        },
        (err) => {
          if (err) {
            err.fatal = true;
          }
          if (callback) {
            callback(err);
          }
        }
      )
    );
  }

  // transaction helpers
  beginTransaction(cb) {
    return this.query('START TRANSACTION', cb);
  }

  commit(cb) {
    return this.query('COMMIT', cb);
  }

  rollback(cb) {
    return this.query('ROLLBACK', cb);
  }

  ping(cb) {
    return this.addCommand(new Commands.Ping(cb));
  }

  _registerSlave(opts, cb) {
    return this.addCommand(new Commands.RegisterSlave(opts, cb));
  }

  _binlogDump(opts, cb) {
    return this.addCommand(new Commands.BinlogDump(opts, cb));
  }

  // currently just alias to close
  destroy() {
    this.close();
  }

  close() {
    if (this.connectTimeout) {
      Timers.clearTimeout(this.connectTimeout);
      this.connectTimeout = null;
    }
    this._closing = true;
    this.stream.end();
    this.addCommand = this._addCommandClosedState;
  }

  createBinlogStream(opts) {
    // TODO: create proper stream class
    // TODO: use through2
    let test = 1;
    const stream = new Readable({ objectMode: true });
    stream._read = function () {
      return {
        data: test++,
      };
    };
    this._registerSlave(opts, () => {
      const dumpCmd = this._binlogDump(opts);
      dumpCmd.on('event', (ev) => {
        stream.push(ev);
      });
      dumpCmd.on('eof', () => {
        stream.push(null);
        // if non-blocking, then close stream to prevent errors
        if (opts.flags && opts.flags & 0x01) {
          this.close();
        }
      });
      // TODO: pipe errors as well
    });
    return stream;
  }

  connect(cb) {
    if (!cb) {
      return;
    }
    if (this._fatalError || this._protocolError) {
      return cb(this._fatalError || this._protocolError);
    }
    if (this._handshakePacket) {
      return cb(null, this);
    }
    let connectCalled = 0;
    function callbackOnce(isErrorHandler) {
      return function (param) {
        if (!connectCalled) {
          if (isErrorHandler) {
            cb(param);
          } else {
            cb(null, param);
          }
        }
        connectCalled = 1;
      };
    }
    this.once('error', callbackOnce(true));
    this.once('connect', callbackOnce(false));
  }

  // ===================================
  // outgoing server connection methods
  // ===================================
  writeColumns(columns) {
    this.writePacket(Packets.ResultSetHeader.toPacket(columns.length));
    columns.forEach((column) => {
      this.writePacket(
        Packets.ColumnDefinition.toPacket(column, this.serverConfig.encoding)
      );
    });
    this.writeEof();
  }

  // row is array of columns, not hash
  writeTextRow(column) {
    this.writePacket(
      Packets.TextRow.toPacket(column, this.serverConfig.encoding)
    );
  }

  writeBinaryRow(column) {
    this.writePacket(
      Packets.BinaryRow.toPacket(column, this.serverConfig.encoding)
    );
  }

  writeTextResult(rows, columns, binary = false) {
    this.writeColumns(columns);
    rows.forEach((row) => {
      const arrayRow = new Array(columns.length);
      columns.forEach((column) => {
        arrayRow.push(row[column.name]);
      });
      if (binary) {
        this.writeBinaryRow(arrayRow);
      } else this.writeTextRow(arrayRow);
    });
    this.writeEof();
  }

  writeEof(warnings, statusFlags) {
    this.writePacket(Packets.EOF.toPacket(warnings, statusFlags));
  }

  writeOk(args) {
    if (!args) {
      args = { affectedRows: 0 };
    }
    this.writePacket(Packets.OK.toPacket(args, this.serverConfig.encoding));
  }

  writeError(args) {
    // if we want to send error before initial hello was sent, use default encoding
    const encoding = this.serverConfig ? this.serverConfig.encoding : 'cesu8';
    this.writePacket(Packets.Error.toPacket(args, encoding));
  }

  serverHandshake(args) {
    this.serverConfig = args;
    this.serverConfig.encoding =
      CharsetToEncoding[this.serverConfig.characterSet];
    return this.addCommand(new Commands.ServerHandshake(args));
  }

  // ===============================================================
  end(callback) {
    if (this.config.isServer) {
      this._closing = true;
      const quitCmd = new EventEmitter();
      setImmediate(() => {
        this.stream.end();
        quitCmd.emit('end');
      });
      return quitCmd;
    }
    // trigger error if more commands enqueued after end command
    const quitCmd = this.addCommand(new Commands.Quit(callback));
    this.addCommand = this._addCommandClosedState;
    return quitCmd;
  }

  static createQuery(sql, values, cb, config) {
    let options = {
      rowsAsArray: config.rowsAsArray,
      infileStreamFactory: config.infileStreamFactory,
    };
    if (typeof sql === 'object') {
      // query(options, cb)
      options = {
        ...options,
        ...sql,
        sql: sql.sql,
        values: sql.values,
      };
      if (typeof values === 'function') {
        cb = values;
      } else if (values !== undefined) {
        options.values = values;
      }
    } else if (typeof values === 'function') {
      // query(sql, cb)
      cb = values;
      options.sql = sql;
      options.values = undefined;
    } else {
      // query(sql, values, cb)
      options.sql = sql;
      options.values = values;
    }
    return new Commands.Query(options, cb);
  }

  static statementKey(options) {
    return `${typeof options.nestTables}/${options.nestTables}/${options.rowsAsArray}${options.sql}`;
  }
}

module.exports = BaseConnection;
</file>

<file path="lib/base/pool_connection.js">
'use strict';

const BaseConnection = require('./connection.js');

class BasePoolConnection extends BaseConnection {
  constructor(pool, options) {
    super(options);
    this._pool = pool;
    // The last active time of this connection
    this.lastActiveTime = Date.now();
    // When a fatal error occurs the connection's protocol ends, which will cause
    // the connection to end as well, thus we only need to watch for the end event
    // and we will be notified of disconnects.
    // REVIEW: Moved to `once`
    this.once('end', () => {
      this._removeFromPool();
    });
    this.once('error', () => {
      this._removeFromPool();
    });
  }

  release() {
    if (!this._pool || this._pool._closed) {
      return;
    }
    // update last active time
    this.lastActiveTime = Date.now();
    this._pool.releaseConnection(this);
  }

  end() {
    const err = new Error(
      'Calling conn.end() to release a pooled connection is ' +
        'deprecated. In next version calling conn.end() will be ' +
        'restored to default conn.end() behavior. Use ' +
        'conn.release() instead.'
    );
    this.emit('warn', err);
    console.warn(err.message);
    this.release();
  }

  destroy() {
    this._removeFromPool();
    super.destroy();
  }

  _removeFromPool() {
    if (!this._pool || this._pool._closed) {
      return;
    }
    const pool = this._pool;
    this._pool = null;
    pool._removeConnection(this);
  }
}

BasePoolConnection.statementKey = BaseConnection.statementKey;
module.exports = BasePoolConnection;

// TODO: Remove this when we are removing PoolConnection#end
BasePoolConnection.prototype._realEnd = BaseConnection.prototype.end;
</file>

<file path="lib/base/pool.js">
'use strict';

const process = require('process');
const SqlString = require('sqlstring');
const EventEmitter = require('events').EventEmitter;
const PoolConnection = require('../pool_connection.js');
const Queue = require('denque');
const BaseConnection = require('./connection.js');

function spliceConnection(queue, connection) {
  const len = queue.length;
  for (let i = 0; i < len; i++) {
    if (queue.get(i) === connection) {
      queue.removeOne(i);
      break;
    }
  }
}

class BasePool extends EventEmitter {
  constructor(options) {
    super();
    this.config = options.config;
    this.config.connectionConfig.pool = this;
    this._allConnections = new Queue();
    this._freeConnections = new Queue();
    this._connectionQueue = new Queue();
    this._closed = false;
    if (this.config.maxIdle < this.config.connectionLimit) {
      // create idle connection timeout automatically release job
      this._removeIdleTimeoutConnections();
    }
  }

  getConnection(cb) {
    if (this._closed) {
      return process.nextTick(() => cb(new Error('Pool is closed.')));
    }
    let connection;
    if (this._freeConnections.length > 0) {
      connection = this._freeConnections.pop();
      this.emit('acquire', connection);
      return process.nextTick(() => cb(null, connection));
    }
    if (
      this.config.connectionLimit === 0 ||
      this._allConnections.length < this.config.connectionLimit
    ) {
      connection = new PoolConnection(this, {
        config: this.config.connectionConfig,
      });
      this._allConnections.push(connection);
      return connection.connect((err) => {
        if (this._closed) {
          return cb(new Error('Pool is closed.'));
        }
        if (err) {
          return cb(err);
        }
        this.emit('connection', connection);
        this.emit('acquire', connection);
        return cb(null, connection);
      });
    }
    if (!this.config.waitForConnections) {
      return process.nextTick(() => cb(new Error('No connections available.')));
    }
    if (
      this.config.queueLimit &&
      this._connectionQueue.length >= this.config.queueLimit
    ) {
      return cb(new Error('Queue limit reached.'));
    }
    this.emit('enqueue');
    return this._connectionQueue.push(cb);
  }

  releaseConnection(connection) {
    let cb;
    if (!connection._pool) {
      // The connection has been removed from the pool and is no longer good.
      if (this._connectionQueue.length) {
        cb = this._connectionQueue.shift();
        process.nextTick(this.getConnection.bind(this, cb));
      }
    } else if (this._connectionQueue.length) {
      cb = this._connectionQueue.shift();
      process.nextTick(cb.bind(null, null, connection));
    } else {
      this._freeConnections.push(connection);
      this.emit('release', connection);
    }
  }

  end(cb) {
    this._closed = true;
    clearTimeout(this._removeIdleTimeoutConnectionsTimer);
    if (typeof cb !== 'function') {
      cb = function (err) {
        if (err) {
          throw err;
        }
      };
    }
    let calledBack = false;
    let closedConnections = 0;
    let connection;
    const endCB = function (err) {
      if (calledBack) {
        return;
      }
      if (err || ++closedConnections >= this._allConnections.length) {
        calledBack = true;
        cb(err);
        return;
      }
    }.bind(this);
    if (this._allConnections.length === 0) {
      endCB();
      return;
    }
    for (let i = 0; i < this._allConnections.length; i++) {
      connection = this._allConnections.get(i);
      connection._realEnd(endCB);
    }
  }

  query(sql, values, cb) {
    const cmdQuery = BaseConnection.createQuery(
      sql,
      values,
      cb,
      this.config.connectionConfig
    );
    if (typeof cmdQuery.namedPlaceholders === 'undefined') {
      cmdQuery.namedPlaceholders =
        this.config.connectionConfig.namedPlaceholders;
    }
    this.getConnection((err, conn) => {
      if (err) {
        if (typeof cmdQuery.onResult === 'function') {
          cmdQuery.onResult(err);
        } else {
          cmdQuery.emit('error', err);
        }
        return;
      }
      try {
        conn.query(cmdQuery).once('end', () => {
          conn.release();
        });
      } catch (e) {
        conn.release();
        throw e;
      }
    });
    return cmdQuery;
  }

  execute(sql, values, cb) {
    // TODO construct execute command first here and pass it to connection.execute
    // so that polymorphic arguments logic is there in one place
    if (typeof values === 'function') {
      cb = values;
      values = [];
    }
    this.getConnection((err, conn) => {
      if (err) {
        return cb(err);
      }
      try {
        conn.execute(sql, values, cb).once('end', () => {
          conn.release();
        });
      } catch (e) {
        conn.release();
        return cb(e);
      }
    });
  }

  _removeConnection(connection) {
    // Remove connection from all connections
    spliceConnection(this._allConnections, connection);
    // Remove connection from free connections
    spliceConnection(this._freeConnections, connection);
    this.releaseConnection(connection);
  }

  _removeIdleTimeoutConnections() {
    if (this._removeIdleTimeoutConnectionsTimer) {
      clearTimeout(this._removeIdleTimeoutConnectionsTimer);
    }

    this._removeIdleTimeoutConnectionsTimer = setTimeout(() => {
      try {
        while (
          this._freeConnections.length > this.config.maxIdle ||
          (this._freeConnections.length > 0 &&
            Date.now() - this._freeConnections.get(0).lastActiveTime >
              this.config.idleTimeout)
        ) {
          this._freeConnections.get(0).destroy();
        }
      } finally {
        this._removeIdleTimeoutConnections();
      }
    }, 1000);
  }

  format(sql, values) {
    return SqlString.format(
      sql,
      values,
      this.config.connectionConfig.stringifyObjects,
      this.config.connectionConfig.timezone
    );
  }

  escape(value) {
    return SqlString.escape(
      value,
      this.config.connectionConfig.stringifyObjects,
      this.config.connectionConfig.timezone
    );
  }

  escapeId(value) {
    return SqlString.escapeId(value, false);
  }
}

module.exports = BasePool;
</file>

<file path="lib/commands/auth_switch.js">
// This file was modified by Oracle on July 5, 2021.
// Errors generated by asynchronous authentication plugins are now being
// handled and subsequently emitted at the command level.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const Packets = require('../packets/index.js');
const sha256_password = require('../auth_plugins/sha256_password');
const caching_sha2_password = require('../auth_plugins/caching_sha2_password.js');
const mysql_native_password = require('../auth_plugins/mysql_native_password.js');
const mysql_clear_password = require('../auth_plugins/mysql_clear_password.js');

const standardAuthPlugins = {
  sha256_password: sha256_password({}),
  caching_sha2_password: caching_sha2_password({}),
  mysql_native_password: mysql_native_password({}),
  mysql_clear_password: mysql_clear_password({}),
};

function warnLegacyAuthSwitch() {
  console.warn(
    'WARNING! authSwitchHandler api is deprecated, please use new authPlugins api'
  );
}

function authSwitchPluginError(error, command) {
  // Authentication errors are fatal
  error.code = 'AUTH_SWITCH_PLUGIN_ERROR';
  error.fatal = true;

  command.emit('error', error);
}

function authSwitchRequest(packet, connection, command) {
  const { pluginName, pluginData } =
    Packets.AuthSwitchRequest.fromPacket(packet);
  let authPlugin =
    connection.config.authPlugins && connection.config.authPlugins[pluginName];

  // legacy plugin api don't allow to override mysql_native_password
  // if pluginName is mysql_native_password it's using standard auth4.1 auth
  if (
    connection.config.authSwitchHandler &&
    pluginName !== 'mysql_native_password'
  ) {
    const legacySwitchHandler = connection.config.authSwitchHandler;
    warnLegacyAuthSwitch();
    legacySwitchHandler({ pluginName, pluginData }, (err, data) => {
      if (err) {
        return authSwitchPluginError(err, command);
      }
      connection.writePacket(new Packets.AuthSwitchResponse(data).toPacket());
    });
    return;
  }
  if (!authPlugin) {
    authPlugin = standardAuthPlugins[pluginName];
  }
  if (!authPlugin) {
    throw new Error(
      `Server requests authentication using unknown plugin ${pluginName}. See ${'TODO: add plugins doco here'} on how to configure or author authentication plugins.`
    );
  }
  connection._authPlugin = authPlugin({ connection, command });
  Promise.resolve(connection._authPlugin(pluginData))
    .then((data) => {
      if (data) {
        connection.writePacket(new Packets.AuthSwitchResponse(data).toPacket());
      }
    })
    .catch((err) => {
      authSwitchPluginError(err, command);
    });
}

function authSwitchRequestMoreData(packet, connection, command) {
  const { data } = Packets.AuthSwitchRequestMoreData.fromPacket(packet);

  if (connection.config.authSwitchHandler) {
    const legacySwitchHandler = connection.config.authSwitchHandler;
    warnLegacyAuthSwitch();
    legacySwitchHandler({ pluginData: data }, (err, data) => {
      if (err) {
        return authSwitchPluginError(err, command);
      }
      connection.writePacket(new Packets.AuthSwitchResponse(data).toPacket());
    });
    return;
  }

  if (!connection._authPlugin) {
    throw new Error(
      'AuthPluginMoreData received but no auth plugin instance found'
    );
  }
  Promise.resolve(connection._authPlugin(data))
    .then((data) => {
      if (data) {
        connection.writePacket(new Packets.AuthSwitchResponse(data).toPacket());
      }
    })
    .catch((err) => {
      authSwitchPluginError(err, command);
    });
}

module.exports = {
  authSwitchRequest,
  authSwitchRequestMoreData,
};
</file>

<file path="lib/commands/binlog_dump.js">
'use strict';

const Command = require('./command');
const Packets = require('../packets');

const eventParsers = [];

class BinlogEventHeader {
  constructor(packet) {
    this.timestamp = packet.readInt32();
    this.eventType = packet.readInt8();
    this.serverId = packet.readInt32();
    this.eventSize = packet.readInt32();
    this.logPos = packet.readInt32();
    this.flags = packet.readInt16();
  }
}

class BinlogDump extends Command {
  constructor(opts) {
    super();
    // this.onResult = callback;
    this.opts = opts;
  }

  start(packet, connection) {
    const newPacket = new Packets.BinlogDump(this.opts);
    connection.writePacket(newPacket.toPacket(1));
    return BinlogDump.prototype.binlogData;
  }

  binlogData(packet) {
    // ok - continue consuming events
    // error - error
    // eof - end of binlog
    if (packet.isEOF()) {
      this.emit('eof');
      return null;
    }
    // binlog event header
    packet.readInt8();
    const header = new BinlogEventHeader(packet);
    const EventParser = eventParsers[header.eventType];
    let event;
    if (EventParser) {
      event = new EventParser(packet);
    } else {
      event = {
        name: 'UNKNOWN',
      };
    }
    event.header = header;
    this.emit('event', event);
    return BinlogDump.prototype.binlogData;
  }
}

class RotateEvent {
  constructor(packet) {
    this.pposition = packet.readInt32();
    // TODO: read uint64 here
    packet.readInt32(); // positionDword2
    this.nextBinlog = packet.readString();
    this.name = 'RotateEvent';
  }
}

class FormatDescriptionEvent {
  constructor(packet) {
    this.binlogVersion = packet.readInt16();
    this.serverVersion = packet.readString(50).replace(/\u0000.*/, ''); // eslint-disable-line no-control-regex
    this.createTimestamp = packet.readInt32();
    this.eventHeaderLength = packet.readInt8(); // should be 19
    this.eventsLength = packet.readBuffer();
    this.name = 'FormatDescriptionEvent';
  }
}

class QueryEvent {
  constructor(packet) {
    const parseStatusVars = require('../packets/binlog_query_statusvars.js');
    this.slaveProxyId = packet.readInt32();
    this.executionTime = packet.readInt32();
    const schemaLength = packet.readInt8();
    this.errorCode = packet.readInt16();
    const statusVarsLength = packet.readInt16();
    const statusVars = packet.readBuffer(statusVarsLength);
    this.schema = packet.readString(schemaLength);
    packet.readInt8(); // should be zero
    this.statusVars = parseStatusVars(statusVars);
    this.query = packet.readString();
    this.name = 'QueryEvent';
  }
}

class XidEvent {
  constructor(packet) {
    this.binlogVersion = packet.readInt16();
    this.xid = packet.readInt64();
    this.name = 'XidEvent';
  }
}

eventParsers[2] = QueryEvent;
eventParsers[4] = RotateEvent;
eventParsers[15] = FormatDescriptionEvent;
eventParsers[16] = XidEvent;

module.exports = BinlogDump;
</file>

<file path="lib/commands/change_user.js">
// This file was modified by Oracle on September 21, 2021.
// The changes involve saving additional authentication factor passwords
// in the command scope and enabling multi-factor authentication in the
// client-side when the server supports it.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const Command = require('./command.js');
const Packets = require('../packets/index.js');
const ClientConstants = require('../constants/client');
const ClientHandshake = require('./client_handshake.js');
const CharsetToEncoding = require('../constants/charset_encodings.js');

class ChangeUser extends Command {
  constructor(options, callback) {
    super();
    this.onResult = callback;
    this.user = options.user;
    this.password = options.password;
    // "password1" is an alias of "password"
    this.password1 = options.password;
    this.password2 = options.password2;
    this.password3 = options.password3;
    this.database = options.database;
    this.passwordSha1 = options.passwordSha1;
    this.charsetNumber = options.charsetNumber;
    this.currentConfig = options.currentConfig;
    this.authenticationFactor = 0;
  }
  start(packet, connection) {
    const newPacket = new Packets.ChangeUser({
      flags: connection.config.clientFlags,
      user: this.user,
      database: this.database,
      charsetNumber: this.charsetNumber,
      password: this.password,
      passwordSha1: this.passwordSha1,
      authPluginData1: connection._handshakePacket.authPluginData1,
      authPluginData2: connection._handshakePacket.authPluginData2,
    });
    this.currentConfig.user = this.user;
    this.currentConfig.password = this.password;
    this.currentConfig.database = this.database;
    this.currentConfig.charsetNumber = this.charsetNumber;
    connection.clientEncoding = CharsetToEncoding[this.charsetNumber];
    // clear prepared statements cache as all statements become invalid after changeUser
    connection._statements.clear();
    connection.writePacket(newPacket.toPacket());
    // check if the server supports multi-factor authentication
    const multiFactorAuthentication =
      connection.serverCapabilityFlags &
      ClientConstants.MULTI_FACTOR_AUTHENTICATION;
    if (multiFactorAuthentication) {
      // if the server supports multi-factor authentication, we enable it in
      // the client
      this.authenticationFactor = 1;
    }
    return ChangeUser.prototype.handshakeResult;
  }
}

ChangeUser.prototype.handshakeResult =
  ClientHandshake.prototype.handshakeResult;
ChangeUser.prototype.calculateNativePasswordAuthToken =
  ClientHandshake.prototype.calculateNativePasswordAuthToken;

module.exports = ChangeUser;
</file>

<file path="lib/commands/client_handshake.js">
// This file was modified by Oracle on June 17, 2021.
// Handshake errors are now maked as fatal and the corresponding events are
// emitted in the command instance itself.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

// This file was modified by Oracle on September 21, 2021.
// Handshake workflow now supports additional authentication factors requested
// by the server.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const Command = require('./command.js');
const Packets = require('../packets/index.js');
const ClientConstants = require('../constants/client.js');
const CharsetToEncoding = require('../constants/charset_encodings.js');
const auth41 = require('../auth_41.js');

function flagNames(flags) {
  const res = [];
  for (const c in ClientConstants) {
    if (flags & ClientConstants[c]) {
      res.push(c.replace(/_/g, ' ').toLowerCase());
    }
  }
  return res;
}

class ClientHandshake extends Command {
  constructor(clientFlags) {
    super();
    this.handshake = null;
    this.clientFlags = clientFlags;
    this.authenticationFactor = 0;
  }

  start() {
    return ClientHandshake.prototype.handshakeInit;
  }

  sendSSLRequest(connection) {
    const sslRequest = new Packets.SSLRequest(
      this.clientFlags,
      connection.config.charsetNumber
    );
    connection.writePacket(sslRequest.toPacket());
  }

  sendCredentials(connection) {
    if (connection.config.debug) {
      // eslint-disable-next-line
      console.log(
        'Sending handshake packet: flags:%d=(%s)',
        this.clientFlags,
        flagNames(this.clientFlags).join(', ')
      );
    }
    this.user = connection.config.user;
    this.password = connection.config.password;
    // "password1" is an alias to the original "password" value
    // to make it easier to integrate multi-factor authentication
    this.password1 = connection.config.password;
    // "password2" and "password3" are the 2nd and 3rd factor authentication
    // passwords, which can be undefined depending on the authentication
    // plugin being used
    this.password2 = connection.config.password2;
    this.password3 = connection.config.password3;
    this.passwordSha1 = connection.config.passwordSha1;
    this.database = connection.config.database;
    this.authPluginName = this.handshake.authPluginName;
    const handshakeResponse = new Packets.HandshakeResponse({
      flags: this.clientFlags,
      user: this.user,
      database: this.database,
      password: this.password,
      passwordSha1: this.passwordSha1,
      charsetNumber: connection.config.charsetNumber,
      authPluginData1: this.handshake.authPluginData1,
      authPluginData2: this.handshake.authPluginData2,
      compress: connection.config.compress,
      connectAttributes: connection.config.connectAttributes,
    });
    connection.writePacket(handshakeResponse.toPacket());
  }

  calculateNativePasswordAuthToken(authPluginData) {
    // TODO: dont split into authPluginData1 and authPluginData2, instead join when 1 & 2 received
    const authPluginData1 = authPluginData.slice(0, 8);
    const authPluginData2 = authPluginData.slice(8, 20);
    let authToken;
    if (this.passwordSha1) {
      authToken = auth41.calculateTokenFromPasswordSha(
        this.passwordSha1,
        authPluginData1,
        authPluginData2
      );
    } else {
      authToken = auth41.calculateToken(
        this.password,
        authPluginData1,
        authPluginData2
      );
    }
    return authToken;
  }

  handshakeInit(helloPacket, connection) {
    this.on('error', (e) => {
      connection._fatalError = e;
      connection._protocolError = e;
    });
    this.handshake = Packets.Handshake.fromPacket(helloPacket);
    if (connection.config.debug) {
      // eslint-disable-next-line
      console.log(
        'Server hello packet: capability flags:%d=(%s)',
        this.handshake.capabilityFlags,
        flagNames(this.handshake.capabilityFlags).join(', ')
      );
    }
    connection.serverCapabilityFlags = this.handshake.capabilityFlags;
    connection.serverEncoding = CharsetToEncoding[this.handshake.characterSet];
    connection.connectionId = this.handshake.connectionId;
    const serverSSLSupport =
      this.handshake.capabilityFlags & ClientConstants.SSL;
    // multi factor authentication is enabled with the
    // "MULTI_FACTOR_AUTHENTICATION" capability and should only be used if it
    // is supported by the server
    const multiFactorAuthentication =
      this.handshake.capabilityFlags &
      ClientConstants.MULTI_FACTOR_AUTHENTICATION;
    this.clientFlags = this.clientFlags | multiFactorAuthentication;
    // use compression only if requested by client and supported by server
    connection.config.compress =
      connection.config.compress &&
      this.handshake.capabilityFlags & ClientConstants.COMPRESS;
    this.clientFlags = this.clientFlags | connection.config.compress;
    if (connection.config.ssl) {
      // client requires SSL but server does not support it
      if (!serverSSLSupport) {
        const err = new Error('Server does not support secure connection');
        err.code = 'HANDSHAKE_NO_SSL_SUPPORT';
        err.fatal = true;
        this.emit('error', err);
        return false;
      }
      // send ssl upgrade request and immediately upgrade connection to secure
      this.clientFlags |= ClientConstants.SSL;
      this.sendSSLRequest(connection);
      connection.startTLS((err) => {
        // after connection is secure
        if (err) {
          // SSL negotiation error are fatal
          err.code = 'HANDSHAKE_SSL_ERROR';
          err.fatal = true;
          this.emit('error', err);
          return;
        }
        // rest of communication is encrypted
        this.sendCredentials(connection);
      });
    } else {
      this.sendCredentials(connection);
    }
    if (multiFactorAuthentication) {
      // if the server supports multi-factor authentication, we enable it in
      // the client
      this.authenticationFactor = 1;
    }
    return ClientHandshake.prototype.handshakeResult;
  }

  handshakeResult(packet, connection) {
    const marker = packet.peekByte();
    // packet can be OK_Packet, ERR_Packet, AuthSwitchRequest, AuthNextFactor
    // or AuthMoreData
    if (marker === 0xfe || marker === 1 || marker === 0x02) {
      const authSwitch = require('./auth_switch');
      try {
        if (marker === 1) {
          authSwitch.authSwitchRequestMoreData(packet, connection, this);
        } else {
          // if authenticationFactor === 0, it means the server does not support
          // the multi-factor authentication capability
          if (this.authenticationFactor !== 0) {
            // if we are past the first authentication factor, we should use the
            // corresponding password (if there is one)
            connection.config.password =
              this[`password${this.authenticationFactor}`];
            // update the current authentication factor
            this.authenticationFactor += 1;
          }
          // if marker === 0x02, it means it is an AuthNextFactor packet,
          // which is similar in structure to an AuthSwitchRequest packet,
          // so, we can use it directly
          authSwitch.authSwitchRequest(packet, connection, this);
        }
        return ClientHandshake.prototype.handshakeResult;
      } catch (err) {
        // Authentication errors are fatal
        err.code = 'AUTH_SWITCH_PLUGIN_ERROR';
        err.fatal = true;

        if (this.onResult) {
          this.onResult(err);
        } else {
          this.emit('error', err);
        }
        return null;
      }
    }
    if (marker !== 0) {
      const err = new Error('Unexpected packet during handshake phase');
      // Unknown handshake errors are fatal
      err.code = 'HANDSHAKE_UNKNOWN_ERROR';
      err.fatal = true;

      if (this.onResult) {
        this.onResult(err);
      } else {
        this.emit('error', err);
      }
      return null;
    }
    // this should be called from ClientHandshake command only
    // and skipped when called from ChangeUser command
    if (!connection.authorized) {
      connection.authorized = true;
      if (connection.config.compress) {
        const enableCompression =
          require('../compressed_protocol.js').enableCompression;
        enableCompression(connection);
      }
    }
    if (this.onResult) {
      this.onResult(null);
    }
    return null;
  }
}
module.exports = ClientHandshake;
</file>

<file path="lib/commands/close_statement.js">
'use strict';

const Command = require('./command');
const Packets = require('../packets/index.js');

class CloseStatement extends Command {
  constructor(id) {
    super();
    this.id = id;
  }

  start(packet, connection) {
    connection.writePacket(new Packets.CloseStatement(this.id).toPacket(1));
    return null;
  }
}

module.exports = CloseStatement;
</file>

<file path="lib/commands/command.js">
'use strict';

const EventEmitter = require('events').EventEmitter;
const Timers = require('timers');

class Command extends EventEmitter {
  constructor() {
    super();
    this.next = null;
  }

  // slow. debug only
  stateName() {
    const state = this.next;
    for (const i in this) {
      if (this[i] === state && i !== 'next') {
        return i;
      }
    }
    return 'unknown name';
  }

  execute(packet, connection) {
    if (!this.next) {
      this.next = this.start;
      connection._resetSequenceId();
    }
    if (packet && packet.isError()) {
      const err = packet.asError(connection.clientEncoding);
      err.sql = this.sql || this.query;
      if (this.queryTimeout) {
        Timers.clearTimeout(this.queryTimeout);
        this.queryTimeout = null;
      }
      if (this.onResult) {
        this.onResult(err);
        this.emit('end');
      } else {
        this.emit('error', err);
        this.emit('end');
      }
      return true;
    }
    // TODO: don't return anything from execute, it's ugly and error-prone. Listen for 'end' event in connection
    this.next = this.next(packet, connection);
    if (this.next) {
      return false;
    }
    this.emit('end');
    return true;
  }
}

module.exports = Command;
</file>

<file path="lib/commands/execute.js">
'use strict';

const Command = require('./command.js');
const Query = require('./query.js');
const Packets = require('../packets/index.js');

const getBinaryParser = require('../parsers/binary_parser.js');
const getStaticBinaryParser = require('../parsers/static_binary_parser.js');

class Execute extends Command {
  constructor(options, callback) {
    super();
    this.statement = options.statement;
    this.sql = options.sql;
    this.values = options.values;
    this.onResult = callback;
    this.parameters = options.values;
    this.insertId = 0;
    this.timeout = options.timeout;
    this.queryTimeout = null;
    this._rows = [];
    this._fields = [];
    this._result = [];
    this._fieldCount = 0;
    this._rowParser = null;
    this._executeOptions = options;
    this._resultIndex = 0;
    this._localStream = null;
    this._unpipeStream = function () {};
    this._streamFactory = options.infileStreamFactory;
    this._connection = null;
  }

  buildParserFromFields(fields, connection) {
    if (this.options.disableEval) {
      return getStaticBinaryParser(fields, this.options, connection.config);
    }

    return getBinaryParser(fields, this.options, connection.config);
  }

  start(packet, connection) {
    this._connection = connection;
    this.options = Object.assign({}, connection.config, this._executeOptions);
    this._setTimeout();
    const executePacket = new Packets.Execute(
      this.statement.id,
      this.parameters,
      connection.config.charsetNumber,
      connection.config.timezone
    );
    //For reasons why this try-catch is here, please see
    // https://github.com/sidorares/node-mysql2/pull/689
    //For additional discussion, see
    // 1. https://github.com/sidorares/node-mysql2/issues/493
    // 2. https://github.com/sidorares/node-mysql2/issues/187
    // 3. https://github.com/sidorares/node-mysql2/issues/480
    try {
      connection.writePacket(executePacket.toPacket(1));
    } catch (error) {
      this.onResult(error);
    }
    return Execute.prototype.resultsetHeader;
  }

  readField(packet, connection) {
    let fields;
    // disabling for now, but would be great to find reliable way to parse fields only once
    // fields reported by prepare can be empty at all or just incorrect - see #169
    //
    // perfomance optimisation: if we already have this field parsed in statement header, use one from header
    // const field = this.statement.columns.length == this._fieldCount ?
    //  this.statement.columns[this._receivedFieldsCount] : new Packets.ColumnDefinition(packet);
    const field = new Packets.ColumnDefinition(
      packet,
      connection.clientEncoding
    );
    this._receivedFieldsCount++;
    this._fields[this._resultIndex].push(field);
    if (this._receivedFieldsCount === this._fieldCount) {
      fields = this._fields[this._resultIndex];
      this.emit('fields', fields, this._resultIndex);
      return Execute.prototype.fieldsEOF;
    }
    return Execute.prototype.readField;
  }

  fieldsEOF(packet, connection) {
    // check EOF
    if (!packet.isEOF()) {
      return connection.protocolError('Expected EOF packet');
    }
    this._rowParser = new (this.buildParserFromFields(
      this._fields[this._resultIndex],
      connection
    ))();
    return Execute.prototype.row;
  }
}

Execute.prototype.done = Query.prototype.done;
Execute.prototype.doneInsert = Query.prototype.doneInsert;
Execute.prototype.resultsetHeader = Query.prototype.resultsetHeader;
Execute.prototype._findOrCreateReadStream =
  Query.prototype._findOrCreateReadStream;
Execute.prototype._streamLocalInfile = Query.prototype._streamLocalInfile;
Execute.prototype._setTimeout = Query.prototype._setTimeout;
Execute.prototype._handleTimeoutError = Query.prototype._handleTimeoutError;
Execute.prototype.row = Query.prototype.row;
Execute.prototype.stream = Query.prototype.stream;

module.exports = Execute;
</file>

<file path="lib/commands/index.js">
'use strict';

const ClientHandshake = require('./client_handshake.js');
const ServerHandshake = require('./server_handshake.js');
const Query = require('./query.js');
const Prepare = require('./prepare.js');
const CloseStatement = require('./close_statement.js');
const Execute = require('./execute.js');
const Ping = require('./ping.js');
const RegisterSlave = require('./register_slave.js');
const BinlogDump = require('./binlog_dump.js');
const ChangeUser = require('./change_user.js');
const Quit = require('./quit.js');

module.exports = {
  ClientHandshake,
  ServerHandshake,
  Query,
  Prepare,
  CloseStatement,
  Execute,
  Ping,
  RegisterSlave,
  BinlogDump,
  ChangeUser,
  Quit,
};
</file>

<file path="lib/commands/ping.js">
'use strict';

const Command = require('./command');
const CommandCode = require('../constants/commands');
const Packet = require('../packets/packet');

// TODO: time statistics?
// usefull for queue size and network latency monitoring
// store created,sent,reply timestamps
class Ping extends Command {
  constructor(callback) {
    super();
    this.onResult = callback;
  }

  start(packet, connection) {
    const ping = new Packet(
      0,
      Buffer.from([1, 0, 0, 0, CommandCode.PING]),
      0,
      5
    );
    connection.writePacket(ping);
    return Ping.prototype.pingResponse;
  }

  pingResponse() {
    // TODO: check it's OK packet. error check already done in caller
    if (this.onResult) {
      process.nextTick(this.onResult.bind(this));
    }
    return null;
  }
}

module.exports = Ping;
</file>

<file path="lib/commands/prepare.js">
'use strict';

const Packets = require('../packets/index.js');
const Command = require('./command.js');
const CloseStatement = require('./close_statement.js');
const Execute = require('./execute.js');

class PreparedStatementInfo {
  constructor(query, id, columns, parameters, connection) {
    this.query = query;
    this.id = id;
    this.columns = columns;
    this.parameters = parameters;
    this.rowParser = null;
    this._connection = connection;
  }

  close() {
    return this._connection.addCommand(new CloseStatement(this.id));
  }

  execute(parameters, callback) {
    if (typeof parameters === 'function') {
      callback = parameters;
      parameters = [];
    }
    return this._connection.addCommand(
      new Execute({ statement: this, values: parameters }, callback)
    );
  }
}

class Prepare extends Command {
  constructor(options, callback) {
    super();
    this.query = options.sql;
    this.onResult = callback;
    this.id = 0;
    this.fieldCount = 0;
    this.parameterCount = 0;
    this.fields = [];
    this.parameterDefinitions = [];
    this.options = options;
  }

  start(packet, connection) {
    const Connection = connection.constructor;
    this.key = Connection.statementKey(this.options);
    const statement = connection._statements.get(this.key);
    if (statement) {
      if (this.onResult) {
        this.onResult(null, statement);
      }
      return null;
    }
    const cmdPacket = new Packets.PrepareStatement(
      this.query,
      connection.config.charsetNumber,
      this.options.values
    );
    connection.writePacket(cmdPacket.toPacket(1));
    return Prepare.prototype.prepareHeader;
  }

  prepareHeader(packet, connection) {
    const header = new Packets.PreparedStatementHeader(packet);
    this.id = header.id;
    this.fieldCount = header.fieldCount;
    this.parameterCount = header.parameterCount;
    if (this.parameterCount > 0) {
      return Prepare.prototype.readParameter;
    }
    if (this.fieldCount > 0) {
      return Prepare.prototype.readField;
    }
    return this.prepareDone(connection);
  }

  readParameter(packet, connection) {
    // there might be scenarios when mysql server reports more parameters than
    // are actually present in the array of parameter definitions.
    // if EOF packet is received we switch to "read fields" state if there are
    // any fields reported by the server, otherwise we finish the command.
    if (packet.isEOF()) {
      if (this.fieldCount > 0) {
        return Prepare.prototype.readField;
      }
      return this.prepareDone(connection);
    }
    const def = new Packets.ColumnDefinition(packet, connection.clientEncoding);
    this.parameterDefinitions.push(def);
    if (this.parameterDefinitions.length === this.parameterCount) {
      return Prepare.prototype.parametersEOF;
    }
    return this.readParameter;
  }

  readField(packet, connection) {
    if (packet.isEOF()) {
      return this.prepareDone(connection);
    }
    const def = new Packets.ColumnDefinition(packet, connection.clientEncoding);
    this.fields.push(def);
    if (this.fields.length === this.fieldCount) {
      return Prepare.prototype.fieldsEOF;
    }
    return Prepare.prototype.readField;
  }

  parametersEOF(packet, connection) {
    if (!packet.isEOF()) {
      return connection.protocolError('Expected EOF packet after parameters');
    }
    if (this.fieldCount > 0) {
      return Prepare.prototype.readField;
    }
    return this.prepareDone(connection);
  }

  fieldsEOF(packet, connection) {
    if (!packet.isEOF()) {
      return connection.protocolError('Expected EOF packet after fields');
    }
    return this.prepareDone(connection);
  }

  prepareDone(connection) {
    const statement = new PreparedStatementInfo(
      this.query,
      this.id,
      this.fields,
      this.parameterDefinitions,
      connection
    );
    connection._statements.set(this.key, statement);
    if (this.onResult) {
      this.onResult(null, statement);
    }
    return null;
  }
}

module.exports = Prepare;
</file>

<file path="lib/commands/query.js">
'use strict';

const process = require('process');
const Timers = require('timers');

const Readable = require('stream').Readable;

const Command = require('./command.js');
const Packets = require('../packets/index.js');
const getTextParser = require('../parsers/text_parser.js');
const staticParser = require('../parsers/static_text_parser.js');
const ServerStatus = require('../constants/server_status.js');

const EmptyPacket = new Packets.Packet(0, Buffer.allocUnsafe(4), 0, 4);

// http://dev.mysql.com/doc/internals/en/com-query.html
class Query extends Command {
  constructor(options, callback) {
    super();
    this.sql = options.sql;
    this.values = options.values;
    this._queryOptions = options;
    this.namedPlaceholders = options.namedPlaceholders || false;
    this.onResult = callback;
    this.timeout = options.timeout;
    this.queryTimeout = null;
    this._fieldCount = 0;
    this._rowParser = null;
    this._fields = [];
    this._rows = [];
    this._receivedFieldsCount = 0;
    this._resultIndex = 0;
    this._localStream = null;
    this._unpipeStream = function () {};
    this._streamFactory = options.infileStreamFactory;
    this._connection = null;
  }

  then() {
    const err =
      "You have tried to call .then(), .catch(), or invoked await on the result of query that is not a promise, which is a programming error. Try calling con.promise().query(), or require('mysql2/promise') instead of 'mysql2' for a promise-compatible version of the query interface. To learn how to use async/await or Promises check out documentation at https://sidorares.github.io/node-mysql2/docs#using-promise-wrapper, or the mysql2 documentation at https://sidorares.github.io/node-mysql2/docs/documentation/promise-wrapper";
    // eslint-disable-next-line
    console.log(err);
    throw new Error(err);
  }

  /* eslint no-unused-vars: ["error", { "argsIgnorePattern": "^_" }] */
  start(_packet, connection) {
    if (connection.config.debug) {
      // eslint-disable-next-line
      console.log('        Sending query command: %s', this.sql);
    }
    this._connection = connection;
    this.options = Object.assign({}, connection.config, this._queryOptions);
    this._setTimeout();

    const cmdPacket = new Packets.Query(
      this.sql,
      connection.config.charsetNumber
    );
    connection.writePacket(cmdPacket.toPacket(1));
    return Query.prototype.resultsetHeader;
  }

  done() {
    this._unpipeStream();
    // if all ready timeout, return null directly
    if (this.timeout && !this.queryTimeout) {
      return null;
    }
    // else clear timer
    if (this.queryTimeout) {
      Timers.clearTimeout(this.queryTimeout);
      this.queryTimeout = null;
    }
    if (this.onResult) {
      let rows, fields;
      if (this._resultIndex === 0) {
        rows = this._rows[0];
        fields = this._fields[0];
      } else {
        rows = this._rows;
        fields = this._fields;
      }
      if (fields) {
        process.nextTick(() => {
          this.onResult(null, rows, fields);
        });
      } else {
        process.nextTick(() => {
          this.onResult(null, rows);
        });
      }
    }
    return null;
  }

  doneInsert(rs) {
    if (this._localStreamError) {
      if (this.onResult) {
        this.onResult(this._localStreamError, rs);
      } else {
        this.emit('error', this._localStreamError);
      }
      return null;
    }
    this._rows.push(rs);
    this._fields.push(void 0);
    this.emit('fields', void 0);
    this.emit('result', rs);
    if (rs.serverStatus & ServerStatus.SERVER_MORE_RESULTS_EXISTS) {
      this._resultIndex++;
      return this.resultsetHeader;
    }
    return this.done();
  }

  resultsetHeader(packet, connection) {
    const rs = new Packets.ResultSetHeader(packet, connection);
    this._fieldCount = rs.fieldCount;
    if (connection.config.debug) {
      // eslint-disable-next-line
      console.log(
        `        Resultset header received, expecting ${rs.fieldCount} column definition packets`
      );
    }
    if (this._fieldCount === 0) {
      return this.doneInsert(rs);
    }
    if (this._fieldCount === null) {
      return this._streamLocalInfile(connection, rs.infileName);
    }
    this._receivedFieldsCount = 0;
    this._rows.push([]);
    this._fields.push([]);
    return this.readField;
  }

  _streamLocalInfile(connection, path) {
    if (this._streamFactory) {
      this._localStream = this._streamFactory(path);
    } else {
      this._localStreamError = new Error(
        `As a result of LOCAL INFILE command server wants to read ${path} file, but as of v2.0 you must provide streamFactory option returning ReadStream.`
      );
      connection.writePacket(EmptyPacket);
      return this.infileOk;
    }

    const onConnectionError = () => {
      this._unpipeStream();
    };
    const onDrain = () => {
      this._localStream.resume();
    };
    const onPause = () => {
      this._localStream.pause();
    };
    const onData = function (data) {
      const dataWithHeader = Buffer.allocUnsafe(data.length + 4);
      data.copy(dataWithHeader, 4);
      connection.writePacket(
        new Packets.Packet(0, dataWithHeader, 0, dataWithHeader.length)
      );
    };
    const onEnd = () => {
      connection.removeListener('error', onConnectionError);
      connection.writePacket(EmptyPacket);
    };
    const onError = (err) => {
      this._localStreamError = err;
      connection.removeListener('error', onConnectionError);
      connection.writePacket(EmptyPacket);
    };
    this._unpipeStream = () => {
      connection.stream.removeListener('pause', onPause);
      connection.stream.removeListener('drain', onDrain);
      this._localStream.removeListener('data', onData);
      this._localStream.removeListener('end', onEnd);
      this._localStream.removeListener('error', onError);
    };
    connection.stream.on('pause', onPause);
    connection.stream.on('drain', onDrain);
    this._localStream.on('data', onData);
    this._localStream.on('end', onEnd);
    this._localStream.on('error', onError);
    connection.once('error', onConnectionError);
    return this.infileOk;
  }

  readField(packet, connection) {
    this._receivedFieldsCount++;
    // Often there is much more data in the column definition than in the row itself
    // If you set manually _fields[0] to array of ColumnDefinition's (from previous call)
    // you can 'cache' result of parsing. Field packets still received, but ignored in that case
    // this is the reason _receivedFieldsCount exist (otherwise we could just use current length of fields array)
    if (this._fields[this._resultIndex].length !== this._fieldCount) {
      const field = new Packets.ColumnDefinition(
        packet,
        connection.clientEncoding
      );
      this._fields[this._resultIndex].push(field);
      if (connection.config.debug) {
        /* eslint-disable no-console */
        console.log('        Column definition:');
        console.log(`          name: ${field.name}`);
        console.log(`          type: ${field.columnType}`);
        console.log(`         flags: ${field.flags}`);
        /* eslint-enable no-console */
      }
    }
    // last field received
    if (this._receivedFieldsCount === this._fieldCount) {
      const fields = this._fields[this._resultIndex];
      this.emit('fields', fields);
      if (this.options.disableEval) {
        this._rowParser = staticParser(fields, this.options, connection.config);
      } else {
        this._rowParser = new (getTextParser(
          fields,
          this.options,
          connection.config
        ))(fields);
      }
      return Query.prototype.fieldsEOF;
    }
    return Query.prototype.readField;
  }

  fieldsEOF(packet, connection) {
    // check EOF
    if (!packet.isEOF()) {
      return connection.protocolError('Expected EOF packet');
    }
    return this.row;
  }

  /* eslint no-unused-vars: ["error", { "argsIgnorePattern": "^_" }] */
  row(packet, _connection) {
    if (packet.isEOF()) {
      const status = packet.eofStatusFlags();
      const moreResults = status & ServerStatus.SERVER_MORE_RESULTS_EXISTS;
      if (moreResults) {
        this._resultIndex++;
        return Query.prototype.resultsetHeader;
      }
      return this.done();
    }
    let row;
    try {
      row = this._rowParser.next(
        packet,
        this._fields[this._resultIndex],
        this.options
      );
    } catch (err) {
      this._localStreamError = err;
      return this.doneInsert(null);
    }
    if (this.onResult) {
      this._rows[this._resultIndex].push(row);
    } else {
      this.emit('result', row, this._resultIndex);
    }
    return Query.prototype.row;
  }

  infileOk(packet, connection) {
    const rs = new Packets.ResultSetHeader(packet, connection);
    return this.doneInsert(rs);
  }

  stream(options) {
    options = options || {};
    options.objectMode = true;
    const stream = new Readable(options);
    stream._read = () => {
      this._connection && this._connection.resume();
    };
    this.on('result', (row, resultSetIndex) => {
      if (!stream.push(row)) {
        this._connection.pause();
      }
      stream.emit('result', row, resultSetIndex); // replicate old emitter
    });
    this.on('error', (err) => {
      stream.emit('error', err); // Pass on any errors
    });
    this.on('end', () => {
      stream.push(null); // pushing null, indicating EOF
    });
    this.on('fields', (fields) => {
      stream.emit('fields', fields); // replicate old emitter
    });
    stream.on('end', () => {
      stream.emit('close');
    });
    return stream;
  }

  _setTimeout() {
    if (this.timeout) {
      const timeoutHandler = this._handleTimeoutError.bind(this);
      this.queryTimeout = Timers.setTimeout(timeoutHandler, this.timeout);
    }
  }

  _handleTimeoutError() {
    if (this.queryTimeout) {
      Timers.clearTimeout(this.queryTimeout);
      this.queryTimeout = null;
    }

    const err = new Error('Query inactivity timeout');
    err.errorno = 'PROTOCOL_SEQUENCE_TIMEOUT';
    err.code = 'PROTOCOL_SEQUENCE_TIMEOUT';
    err.syscall = 'query';

    if (this.onResult) {
      this.onResult(err);
    } else {
      this.emit('error', err);
    }
  }
}

Query.prototype.catch = Query.prototype.then;

module.exports = Query;
</file>

<file path="lib/commands/quit.js">
'use strict';

const Command = require('./command.js');
const CommandCode = require('../constants/commands.js');
const Packet = require('../packets/packet.js');

class Quit extends Command {
  constructor(callback) {
    super();
    this.onResult = callback;
  }

  start(packet, connection) {
    connection._closing = true;
    const quit = new Packet(
      0,
      Buffer.from([1, 0, 0, 0, CommandCode.QUIT]),
      0,
      5
    );
    if (this.onResult) {
      this.onResult();
    }
    connection.writePacket(quit);
    return null;
  }
}

module.exports = Quit;
</file>

<file path="lib/commands/register_slave.js">
'use strict';

const Command = require('./command');
const Packets = require('../packets');

class RegisterSlave extends Command {
  constructor(opts, callback) {
    super();
    this.onResult = callback;
    this.opts = opts;
  }

  start(packet, connection) {
    const newPacket = new Packets.RegisterSlave(this.opts);
    connection.writePacket(newPacket.toPacket(1));
    return RegisterSlave.prototype.registerResponse;
  }

  registerResponse() {
    if (this.onResult) {
      process.nextTick(this.onResult.bind(this));
    }
    return null;
  }
}

module.exports = RegisterSlave;
</file>

<file path="lib/commands/server_handshake.js">
'use strict';

const CommandCode = require('../constants/commands.js');
const Errors = require('../constants/errors.js');

const Command = require('./command.js');
const Packets = require('../packets/index.js');

class ServerHandshake extends Command {
  constructor(args) {
    super();
    this.args = args;
    /*
    this.protocolVersion = args.protocolVersion || 10;
    this.serverVersion   = args.serverVersion;
    this.connectionId    = args.connectionId,
    this.statusFlags     = args.statusFlags,
    this.characterSet    = args.characterSet,
    this.capabilityFlags = args.capabilityFlags || 512;
    */
  }

  start(packet, connection) {
    const serverHelloPacket = new Packets.Handshake(this.args);
    this.serverHello = serverHelloPacket;
    serverHelloPacket.setScrambleData((err) => {
      if (err) {
        connection.emit('error', new Error('Error generating random bytes'));
        return;
      }
      connection.writePacket(serverHelloPacket.toPacket(0));
    });
    return ServerHandshake.prototype.readClientReply;
  }

  readClientReply(packet, connection) {
    // check auth here
    const clientHelloReply = Packets.HandshakeResponse.fromPacket(packet);
    // TODO check we don't have something similar already
    connection.clientHelloReply = clientHelloReply;
    if (this.args.authCallback) {
      this.args.authCallback(
        {
          user: clientHelloReply.user,
          database: clientHelloReply.database,
          address: connection.stream.remoteAddress,
          authPluginData1: this.serverHello.authPluginData1,
          authPluginData2: this.serverHello.authPluginData2,
          authToken: clientHelloReply.authToken,
        },
        (err, mysqlError) => {
          // if (err)
          if (!mysqlError) {
            connection.writeOk();
          } else {
            // TODO create constants / errorToCode
            // 1045 = ER_ACCESS_DENIED_ERROR
            connection.writeError({
              message: mysqlError.message || '',
              code: mysqlError.code || 1045,
            });
            connection.close();
          }
        }
      );
    } else {
      connection.writeOk();
    }
    return ServerHandshake.prototype.dispatchCommands;
  }

  _isStatement(query, name) {
    const firstWord = query.split(' ')[0].toUpperCase();
    return firstWord === name;
  }

  dispatchCommands(packet, connection) {
    // command from client to server
    let knownCommand = true;
    const encoding = connection.clientHelloReply.encoding;
    const commandCode = packet.readInt8();
    switch (commandCode) {
      case CommandCode.STMT_PREPARE:
        if (connection.listeners('stmt_prepare').length) {
          const query = packet.readString(undefined, encoding);
          connection.emit('stmt_prepare', query);
        } else {
          connection.writeError({
            code: Errors.HA_ERR_INTERNAL_ERROR,
            message: 'No query handler for prepared statements.',
          });
        }
        break;
      case CommandCode.STMT_EXECUTE:
        if (connection.listeners('stmt_execute').length) {
          const { stmtId, flags, iterationCount, values } =
            Packets.Execute.fromPacket(packet, encoding);
          connection.emit(
            'stmt_execute',
            stmtId,
            flags,
            iterationCount,
            values
          );
        } else {
          connection.writeError({
            code: Errors.HA_ERR_INTERNAL_ERROR,
            message: 'No query handler for execute statements.',
          });
        }
        break;
      case CommandCode.QUIT:
        if (connection.listeners('quit').length) {
          connection.emit('quit');
        } else {
          connection.stream.end();
        }
        break;
      case CommandCode.INIT_DB:
        if (connection.listeners('init_db').length) {
          const schemaName = packet.readString(undefined, encoding);
          connection.emit('init_db', schemaName);
        } else {
          connection.writeOk();
        }
        break;
      case CommandCode.QUERY:
        if (connection.listeners('query').length) {
          const query = packet.readString(undefined, encoding);
          if (
            this._isStatement(query, 'PREPARE') ||
            this._isStatement(query, 'SET')
          ) {
            connection.emit('stmt_prepare', query);
          } else if (this._isStatement(query, 'EXECUTE')) {
            connection.emit('stmt_execute', null, null, null, null, query);
          } else connection.emit('query', query);
        } else {
          connection.writeError({
            code: Errors.HA_ERR_INTERNAL_ERROR,
            message: 'No query handler',
          });
        }
        break;
      case CommandCode.FIELD_LIST:
        if (connection.listeners('field_list').length) {
          const table = packet.readNullTerminatedString(encoding);
          const fields = packet.readString(undefined, encoding);
          connection.emit('field_list', table, fields);
        } else {
          connection.writeError({
            code: Errors.ER_WARN_DEPRECATED_SYNTAX,
            message:
              'As of MySQL 5.7.11, COM_FIELD_LIST is deprecated and will be removed in a future version of MySQL.',
          });
        }
        break;
      case CommandCode.PING:
        if (connection.listeners('ping').length) {
          connection.emit('ping');
        } else {
          connection.writeOk();
        }
        break;
      default:
        knownCommand = false;
    }
    if (connection.listeners('packet').length) {
      connection.emit('packet', packet.clone(), knownCommand, commandCode);
    } else if (!knownCommand) {
      // eslint-disable-next-line no-console
      console.log('Unknown command:', commandCode);
    }
    return ServerHandshake.prototype.dispatchCommands;
  }
}

module.exports = ServerHandshake;

// TODO: implement server-side 4.1 authentication
/*
4.1 authentication: (http://bazaar.launchpad.net/~mysql/mysql-server/5.5/view/head:/sql/password.c)

  SERVER:  public_seed=create_random_string()
           send(public_seed)

  CLIENT:  recv(public_seed)
           hash_stage1=sha1("password")
           hash_stage2=sha1(hash_stage1)
           reply=xor(hash_stage1, sha1(public_seed,hash_stage2)

           // this three steps are done in scramble()

           send(reply)


  SERVER:  recv(reply)
           hash_stage1=xor(reply, sha1(public_seed,hash_stage2))
           candidate_hash2=sha1(hash_stage1)
           check(candidate_hash2==hash_stage2)

server stores sha1(sha1(password)) ( hash_stag2)
*/
</file>

<file path="lib/compressed_protocol.js">
'use strict';

// connection mixins
// implementation of http://dev.mysql.com/doc/internals/en/compression.html

const zlib = require('zlib');
const PacketParser = require('./packet_parser.js');

function handleCompressedPacket(packet) {
  // eslint-disable-next-line consistent-this, no-invalid-this
  const connection = this;
  const deflatedLength = packet.readInt24();
  const body = packet.readBuffer();

  if (deflatedLength !== 0) {
    connection.inflateQueue.push((task) => {
      zlib.inflate(body, (err, data) => {
        if (err) {
          connection._handleNetworkError(err);
          return;
        }
        connection._bumpCompressedSequenceId(packet.numPackets);
        connection._inflatedPacketsParser.execute(data);
        task.done();
      });
    });
  } else {
    connection.inflateQueue.push((task) => {
      connection._bumpCompressedSequenceId(packet.numPackets);
      connection._inflatedPacketsParser.execute(body);
      task.done();
    });
  }
}

function writeCompressed(buffer) {
  // http://dev.mysql.com/doc/internals/en/example-several-mysql-packets.html
  // note: sending a MySQL Packet of the size 2^24−5 to 2^24−1 via compression
  // leads to at least one extra compressed packet.
  // (this is because "length of the packet before compression" need to fit
  // into 3 byte unsigned int. "length of the packet before compression" includes
  // 4 byte packet header, hence 2^24−5)
  const MAX_COMPRESSED_LENGTH = 16777210;
  let start;
  if (buffer.length > MAX_COMPRESSED_LENGTH) {
    for (start = 0; start < buffer.length; start += MAX_COMPRESSED_LENGTH) {
      writeCompressed.call(
        // eslint-disable-next-line no-invalid-this
        this,
        buffer.slice(start, start + MAX_COMPRESSED_LENGTH)
      );
    }
    return;
  }

  // eslint-disable-next-line no-invalid-this, consistent-this
  const connection = this;

  let packetLen = buffer.length;
  const compressHeader = Buffer.allocUnsafe(7);

  // seqqueue is used here because zlib async execution is routed via thread pool
  // internally and when we have multiple compressed packets arriving we need
  // to assemble uncompressed result sequentially
  (function (seqId) {
    connection.deflateQueue.push((task) => {
      zlib.deflate(buffer, (err, compressed) => {
        if (err) {
          connection._handleFatalError(err);
          return;
        }
        let compressedLength = compressed.length;

        if (compressedLength < packetLen) {
          compressHeader.writeUInt8(compressedLength & 0xff, 0);
          compressHeader.writeUInt16LE(compressedLength >> 8, 1);
          compressHeader.writeUInt8(seqId, 3);
          compressHeader.writeUInt8(packetLen & 0xff, 4);
          compressHeader.writeUInt16LE(packetLen >> 8, 5);
          connection.writeUncompressed(compressHeader);
          connection.writeUncompressed(compressed);
        } else {
          // http://dev.mysql.com/doc/internals/en/uncompressed-payload.html
          // To send an uncompressed payload:
          //   - set length of payload before compression to 0
          //   - the compressed payload contains the uncompressed payload instead.
          compressedLength = packetLen;
          packetLen = 0;
          compressHeader.writeUInt8(compressedLength & 0xff, 0);
          compressHeader.writeUInt16LE(compressedLength >> 8, 1);
          compressHeader.writeUInt8(seqId, 3);
          compressHeader.writeUInt8(packetLen & 0xff, 4);
          compressHeader.writeUInt16LE(packetLen >> 8, 5);
          connection.writeUncompressed(compressHeader);
          connection.writeUncompressed(buffer);
        }
        task.done();
      });
    });
  })(connection.compressedSequenceId);
  connection._bumpCompressedSequenceId(1);
}

function enableCompression(connection) {
  connection._lastWrittenPacketId = 0;
  connection._lastReceivedPacketId = 0;

  connection._handleCompressedPacket = handleCompressedPacket;
  connection._inflatedPacketsParser = new PacketParser((p) => {
    connection.handlePacket(p);
  }, 4);
  connection._inflatedPacketsParser._lastPacket = 0;
  connection.packetParser = new PacketParser((packet) => {
    connection._handleCompressedPacket(packet);
  }, 7);

  connection.writeUncompressed = connection.write;
  connection.write = writeCompressed;

  const seqqueue = require('seq-queue');
  connection.inflateQueue = seqqueue.createQueue();
  connection.deflateQueue = seqqueue.createQueue();
}

module.exports = {
  enableCompression: enableCompression,
};
</file>

<file path="lib/connection_config.js">
// This file was modified by Oracle on September 21, 2021.
// New connection options for additional authentication factors were
// introduced.
// Multi-factor authentication capability is now enabled if one of these
// options is used.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const { URL } = require('url');
const ClientConstants = require('./constants/client');
const Charsets = require('./constants/charsets');
const { version } = require('../package.json');
let SSLProfiles = null;

const validOptions = {
  authPlugins: 1,
  authSwitchHandler: 1,
  bigNumberStrings: 1,
  charset: 1,
  charsetNumber: 1,
  compress: 1,
  connectAttributes: 1,
  connectTimeout: 1,
  database: 1,
  dateStrings: 1,
  debug: 1,
  decimalNumbers: 1,
  enableKeepAlive: 1,
  flags: 1,
  host: 1,
  insecureAuth: 1,
  infileStreamFactory: 1,
  isServer: 1,
  keepAliveInitialDelay: 1,
  localAddress: 1,
  maxPreparedStatements: 1,
  multipleStatements: 1,
  namedPlaceholders: 1,
  nestTables: 1,
  password: 1,
  // with multi-factor authentication, the main password (used for the first
  // authentication factor) can be provided via password1
  password1: 1,
  password2: 1,
  password3: 1,
  passwordSha1: 1,
  pool: 1,
  port: 1,
  queryFormat: 1,
  rowsAsArray: 1,
  socketPath: 1,
  ssl: 1,
  stream: 1,
  stringifyObjects: 1,
  supportBigNumbers: 1,
  timezone: 1,
  trace: 1,
  typeCast: 1,
  uri: 1,
  user: 1,
  disableEval: 1,
  // These options are used for Pool
  connectionLimit: 1,
  maxIdle: 1,
  idleTimeout: 1,
  Promise: 1,
  queueLimit: 1,
  waitForConnections: 1,
  jsonStrings: 1,
};

class ConnectionConfig {
  constructor(options) {
    if (typeof options === 'string') {
      options = ConnectionConfig.parseUrl(options);
    } else if (options && options.uri) {
      const uriOptions = ConnectionConfig.parseUrl(options.uri);
      for (const key in uriOptions) {
        if (!Object.prototype.hasOwnProperty.call(uriOptions, key)) continue;
        if (options[key]) continue;
        options[key] = uriOptions[key];
      }
    }
    for (const key in options) {
      if (!Object.prototype.hasOwnProperty.call(options, key)) continue;
      if (validOptions[key] !== 1) {
        // REVIEW: Should this be emitted somehow?
        // eslint-disable-next-line no-console
        console.error(
          `Ignoring invalid configuration option passed to Connection: ${key}. This is currently a warning, but in future versions of MySQL2, an error will be thrown if you pass an invalid configuration option to a Connection`
        );
      }
    }
    this.isServer = options.isServer;
    this.stream = options.stream;
    this.host = options.host || 'localhost';
    this.port =
      (typeof options.port === 'string'
        ? parseInt(options.port, 10)
        : options.port) || 3306;
    this.localAddress = options.localAddress;
    this.socketPath = options.socketPath;
    this.user = options.user || undefined;
    // for the purpose of multi-factor authentication, or not, the main
    // password (used for the 1st authentication factor) can also be
    // provided via the "password1" option
    this.password = options.password || options.password1 || undefined;
    this.password2 = options.password2 || undefined;
    this.password3 = options.password3 || undefined;
    this.passwordSha1 = options.passwordSha1 || undefined;
    this.database = options.database;
    this.connectTimeout = isNaN(options.connectTimeout)
      ? 10 * 1000
      : options.connectTimeout;
    this.insecureAuth = options.insecureAuth || false;
    this.infileStreamFactory = options.infileStreamFactory || undefined;
    this.supportBigNumbers = options.supportBigNumbers || false;
    this.bigNumberStrings = options.bigNumberStrings || false;
    this.decimalNumbers = options.decimalNumbers || false;
    this.dateStrings = options.dateStrings || false;
    this.debug = options.debug;
    this.trace = options.trace !== false;
    this.stringifyObjects = options.stringifyObjects || false;
    this.enableKeepAlive = options.enableKeepAlive !== false;
    this.keepAliveInitialDelay = options.keepAliveInitialDelay;
    if (
      options.timezone &&
      !/^(?:local|Z|[ +-]\d\d:\d\d)$/.test(options.timezone)
    ) {
      // strictly supports timezones specified by mysqljs/mysql:
      // https://github.com/mysqljs/mysql#user-content-connection-options
      // eslint-disable-next-line no-console
      console.error(
        `Ignoring invalid timezone passed to Connection: ${options.timezone}. This is currently a warning, but in future versions of MySQL2, an error will be thrown if you pass an invalid configuration option to a Connection`
      );
      // SqlStrings falls back to UTC on invalid timezone
      this.timezone = 'Z';
    } else {
      this.timezone = options.timezone || 'local';
    }
    this.queryFormat = options.queryFormat;
    this.pool = options.pool || undefined;
    this.ssl =
      typeof options.ssl === 'string'
        ? ConnectionConfig.getSSLProfile(options.ssl)
        : options.ssl || false;
    this.multipleStatements = options.multipleStatements || false;
    this.rowsAsArray = options.rowsAsArray || false;
    this.namedPlaceholders = options.namedPlaceholders || false;
    this.nestTables =
      options.nestTables === undefined ? undefined : options.nestTables;
    this.typeCast = options.typeCast === undefined ? true : options.typeCast;
    this.disableEval = Boolean(options.disableEval);
    if (this.timezone[0] === ' ') {
      // "+" is a url encoded char for space so it
      // gets translated to space when giving a
      // connection string..
      this.timezone = `+${this.timezone.slice(1)}`;
    }
    if (this.ssl) {
      if (typeof this.ssl !== 'object') {
        throw new TypeError(
          `SSL profile must be an object, instead it's a ${typeof this.ssl}`
        );
      }
      // Default rejectUnauthorized to true
      this.ssl.rejectUnauthorized = this.ssl.rejectUnauthorized !== false;
    }
    this.maxPacketSize = 0;
    this.charsetNumber = options.charset
      ? ConnectionConfig.getCharsetNumber(options.charset)
      : options.charsetNumber || Charsets.UTF8MB4_UNICODE_CI;
    this.compress = options.compress || false;
    this.authPlugins = options.authPlugins;
    this.authSwitchHandler = options.authSwitchHandler;
    this.clientFlags = ConnectionConfig.mergeFlags(
      ConnectionConfig.getDefaultFlags(options),
      options.flags || ''
    );
    // Default connection attributes
    // https://dev.mysql.com/doc/refman/8.0/en/performance-schema-connection-attribute-tables.html
    const defaultConnectAttributes = {
      _client_name: 'Node-MySQL-2',
      _client_version: version,
    };
    this.connectAttributes = {
      ...defaultConnectAttributes,
      ...(options.connectAttributes || {}),
    };
    this.maxPreparedStatements = options.maxPreparedStatements || 16000;
    this.jsonStrings = options.jsonStrings || false;
  }

  static mergeFlags(default_flags, user_flags) {
    let flags = 0x0,
      i;
    if (!Array.isArray(user_flags)) {
      user_flags = String(user_flags || '')
        .toUpperCase()
        .split(/\s*,+\s*/);
    }
    // add default flags unless "blacklisted"
    for (i in default_flags) {
      if (user_flags.indexOf(`-${default_flags[i]}`) >= 0) {
        continue;
      }
      flags |= ClientConstants[default_flags[i]] || 0x0;
    }
    // add user flags unless already already added
    for (i in user_flags) {
      if (user_flags[i][0] === '-') {
        continue;
      }
      if (default_flags.indexOf(user_flags[i]) >= 0) {
        continue;
      }
      flags |= ClientConstants[user_flags[i]] || 0x0;
    }
    return flags;
  }

  static getDefaultFlags(options) {
    const defaultFlags = [
      'LONG_PASSWORD',
      'FOUND_ROWS',
      'LONG_FLAG',
      'CONNECT_WITH_DB',
      'ODBC',
      'LOCAL_FILES',
      'IGNORE_SPACE',
      'PROTOCOL_41',
      'IGNORE_SIGPIPE',
      'TRANSACTIONS',
      'RESERVED',
      'SECURE_CONNECTION',
      'MULTI_RESULTS',
      'TRANSACTIONS',
      'SESSION_TRACK',
      'CONNECT_ATTRS',
    ];
    if (options && options.multipleStatements) {
      defaultFlags.push('MULTI_STATEMENTS');
    }
    defaultFlags.push('PLUGIN_AUTH');
    defaultFlags.push('PLUGIN_AUTH_LENENC_CLIENT_DATA');

    return defaultFlags;
  }

  static getCharsetNumber(charset) {
    const num = Charsets[charset.toUpperCase()];
    if (num === undefined) {
      throw new TypeError(`Unknown charset '${charset}'`);
    }
    return num;
  }

  static getSSLProfile(name) {
    if (!SSLProfiles) {
      SSLProfiles = require('./constants/ssl_profiles.js');
    }
    const ssl = SSLProfiles[name];
    if (ssl === undefined) {
      throw new TypeError(`Unknown SSL profile '${name}'`);
    }
    return ssl;
  }

  static parseUrl(url) {
    const parsedUrl = new URL(url);
    const options = {
      host: decodeURIComponent(parsedUrl.hostname),
      port: parseInt(parsedUrl.port, 10),
      database: decodeURIComponent(parsedUrl.pathname.slice(1)),
      user: decodeURIComponent(parsedUrl.username),
      password: decodeURIComponent(parsedUrl.password),
    };
    parsedUrl.searchParams.forEach((value, key) => {
      try {
        // Try to parse this as a JSON expression first
        options[key] = JSON.parse(value);
      } catch (err) {
        // Otherwise assume it is a plain string
        options[key] = value;
      }
    });
    return options;
  }
}

module.exports = ConnectionConfig;
</file>

<file path="lib/connection.js">
'use strict';

const BaseConnection = require('./base/connection.js');

class Connection extends BaseConnection {
  promise(promiseImpl) {
    const PromiseConnection = require('./promise/connection.js');
    return new PromiseConnection(this, promiseImpl);
  }
}

module.exports = Connection;
</file>

<file path="lib/constants/charset_encodings.js">
'use strict';

// see tools/generate-charset-mapping.js
// basicalliy result of "SHOW COLLATION" query

module.exports = [
  'utf8',
  'big5',
  'latin2',
  'dec8',
  'cp850',
  'latin1',
  'hp8',
  'koi8r',
  'latin1',
  'latin2',
  'swe7',
  'ascii',
  'eucjp',
  'sjis',
  'cp1251',
  'latin1',
  'hebrew',
  'utf8',
  'tis620',
  'euckr',
  'latin7',
  'latin2',
  'koi8u',
  'cp1251',
  'gb2312',
  'greek',
  'cp1250',
  'latin2',
  'gbk',
  'cp1257',
  'latin5',
  'latin1',
  'armscii8',
  'cesu8',
  'cp1250',
  'ucs2',
  'cp866',
  'keybcs2',
  'macintosh',
  'macroman',
  'cp852',
  'latin7',
  'latin7',
  'macintosh',
  'cp1250',
  'utf8',
  'utf8',
  'latin1',
  'latin1',
  'latin1',
  'cp1251',
  'cp1251',
  'cp1251',
  'macroman',
  'utf16',
  'utf16',
  'utf16-le',
  'cp1256',
  'cp1257',
  'cp1257',
  'utf32',
  'utf32',
  'utf16-le',
  'binary',
  'armscii8',
  'ascii',
  'cp1250',
  'cp1256',
  'cp866',
  'dec8',
  'greek',
  'hebrew',
  'hp8',
  'keybcs2',
  'koi8r',
  'koi8u',
  'cesu8',
  'latin2',
  'latin5',
  'latin7',
  'cp850',
  'cp852',
  'swe7',
  'cesu8',
  'big5',
  'euckr',
  'gb2312',
  'gbk',
  'sjis',
  'tis620',
  'ucs2',
  'eucjp',
  'geostd8',
  'geostd8',
  'latin1',
  'cp932',
  'cp932',
  'eucjpms',
  'eucjpms',
  'cp1250',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf16',
  'utf8',
  'utf8',
  'utf8',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'ucs2',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'ucs2',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf32',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'cesu8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'cesu8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'gb18030',
  'gb18030',
  'gb18030',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
  'utf8',
];
</file>

<file path="lib/constants/charsets.js">
'use strict';

exports.BIG5_CHINESE_CI = 1;
exports.LATIN2_CZECH_CS = 2;
exports.DEC8_SWEDISH_CI = 3;
exports.CP850_GENERAL_CI = 4;
exports.LATIN1_GERMAN1_CI = 5;
exports.HP8_ENGLISH_CI = 6;
exports.KOI8R_GENERAL_CI = 7;
exports.LATIN1_SWEDISH_CI = 8;
exports.LATIN2_GENERAL_CI = 9;
exports.SWE7_SWEDISH_CI = 10;
exports.ASCII_GENERAL_CI = 11;
exports.UJIS_JAPANESE_CI = 12;
exports.SJIS_JAPANESE_CI = 13;
exports.CP1251_BULGARIAN_CI = 14;
exports.LATIN1_DANISH_CI = 15;
exports.HEBREW_GENERAL_CI = 16;
exports.TIS620_THAI_CI = 18;
exports.EUCKR_KOREAN_CI = 19;
exports.LATIN7_ESTONIAN_CS = 20;
exports.LATIN2_HUNGARIAN_CI = 21;
exports.KOI8U_GENERAL_CI = 22;
exports.CP1251_UKRAINIAN_CI = 23;
exports.GB2312_CHINESE_CI = 24;
exports.GREEK_GENERAL_CI = 25;
exports.CP1250_GENERAL_CI = 26;
exports.LATIN2_CROATIAN_CI = 27;
exports.GBK_CHINESE_CI = 28;
exports.CP1257_LITHUANIAN_CI = 29;
exports.LATIN5_TURKISH_CI = 30;
exports.LATIN1_GERMAN2_CI = 31;
exports.ARMSCII8_GENERAL_CI = 32;
exports.UTF8_GENERAL_CI = 33;
exports.CP1250_CZECH_CS = 34;
exports.UCS2_GENERAL_CI = 35;
exports.CP866_GENERAL_CI = 36;
exports.KEYBCS2_GENERAL_CI = 37;
exports.MACCE_GENERAL_CI = 38;
exports.MACROMAN_GENERAL_CI = 39;
exports.CP852_GENERAL_CI = 40;
exports.LATIN7_GENERAL_CI = 41;
exports.LATIN7_GENERAL_CS = 42;
exports.MACCE_BIN = 43;
exports.CP1250_CROATIAN_CI = 44;
exports.UTF8MB4_GENERAL_CI = 45;
exports.UTF8MB4_BIN = 46;
exports.LATIN1_BIN = 47;
exports.LATIN1_GENERAL_CI = 48;
exports.LATIN1_GENERAL_CS = 49;
exports.CP1251_BIN = 50;
exports.CP1251_GENERAL_CI = 51;
exports.CP1251_GENERAL_CS = 52;
exports.MACROMAN_BIN = 53;
exports.UTF16_GENERAL_CI = 54;
exports.UTF16_BIN = 55;
exports.UTF16LE_GENERAL_CI = 56;
exports.CP1256_GENERAL_CI = 57;
exports.CP1257_BIN = 58;
exports.CP1257_GENERAL_CI = 59;
exports.UTF32_GENERAL_CI = 60;
exports.UTF32_BIN = 61;
exports.UTF16LE_BIN = 62;
exports.BINARY = 63;
exports.ARMSCII8_BIN = 64;
exports.ASCII_BIN = 65;
exports.CP1250_BIN = 66;
exports.CP1256_BIN = 67;
exports.CP866_BIN = 68;
exports.DEC8_BIN = 69;
exports.GREEK_BIN = 70;
exports.HEBREW_BIN = 71;
exports.HP8_BIN = 72;
exports.KEYBCS2_BIN = 73;
exports.KOI8R_BIN = 74;
exports.KOI8U_BIN = 75;
exports.UTF8_TOLOWER_CI = 76;
exports.LATIN2_BIN = 77;
exports.LATIN5_BIN = 78;
exports.LATIN7_BIN = 79;
exports.CP850_BIN = 80;
exports.CP852_BIN = 81;
exports.SWE7_BIN = 82;
exports.UTF8_BIN = 83;
exports.BIG5_BIN = 84;
exports.EUCKR_BIN = 85;
exports.GB2312_BIN = 86;
exports.GBK_BIN = 87;
exports.SJIS_BIN = 88;
exports.TIS620_BIN = 89;
exports.UCS2_BIN = 90;
exports.UJIS_BIN = 91;
exports.GEOSTD8_GENERAL_CI = 92;
exports.GEOSTD8_BIN = 93;
exports.LATIN1_SPANISH_CI = 94;
exports.CP932_JAPANESE_CI = 95;
exports.CP932_BIN = 96;
exports.EUCJPMS_JAPANESE_CI = 97;
exports.EUCJPMS_BIN = 98;
exports.CP1250_POLISH_CI = 99;
exports.UTF16_UNICODE_CI = 101;
exports.UTF16_ICELANDIC_CI = 102;
exports.UTF16_LATVIAN_CI = 103;
exports.UTF16_ROMANIAN_CI = 104;
exports.UTF16_SLOVENIAN_CI = 105;
exports.UTF16_POLISH_CI = 106;
exports.UTF16_ESTONIAN_CI = 107;
exports.UTF16_SPANISH_CI = 108;
exports.UTF16_SWEDISH_CI = 109;
exports.UTF16_TURKISH_CI = 110;
exports.UTF16_CZECH_CI = 111;
exports.UTF16_DANISH_CI = 112;
exports.UTF16_LITHUANIAN_CI = 113;
exports.UTF16_SLOVAK_CI = 114;
exports.UTF16_SPANISH2_CI = 115;
exports.UTF16_ROMAN_CI = 116;
exports.UTF16_PERSIAN_CI = 117;
exports.UTF16_ESPERANTO_CI = 118;
exports.UTF16_HUNGARIAN_CI = 119;
exports.UTF16_SINHALA_CI = 120;
exports.UTF16_GERMAN2_CI = 121;
exports.UTF16_CROATIAN_CI = 122;
exports.UTF16_UNICODE_520_CI = 123;
exports.UTF16_VIETNAMESE_CI = 124;
exports.UCS2_UNICODE_CI = 128;
exports.UCS2_ICELANDIC_CI = 129;
exports.UCS2_LATVIAN_CI = 130;
exports.UCS2_ROMANIAN_CI = 131;
exports.UCS2_SLOVENIAN_CI = 132;
exports.UCS2_POLISH_CI = 133;
exports.UCS2_ESTONIAN_CI = 134;
exports.UCS2_SPANISH_CI = 135;
exports.UCS2_SWEDISH_CI = 136;
exports.UCS2_TURKISH_CI = 137;
exports.UCS2_CZECH_CI = 138;
exports.UCS2_DANISH_CI = 139;
exports.UCS2_LITHUANIAN_CI = 140;
exports.UCS2_SLOVAK_CI = 141;
exports.UCS2_SPANISH2_CI = 142;
exports.UCS2_ROMAN_CI = 143;
exports.UCS2_PERSIAN_CI = 144;
exports.UCS2_ESPERANTO_CI = 145;
exports.UCS2_HUNGARIAN_CI = 146;
exports.UCS2_SINHALA_CI = 147;
exports.UCS2_GERMAN2_CI = 148;
exports.UCS2_CROATIAN_CI = 149;
exports.UCS2_UNICODE_520_CI = 150;
exports.UCS2_VIETNAMESE_CI = 151;
exports.UCS2_GENERAL_MYSQL500_CI = 159;
exports.UTF32_UNICODE_CI = 160;
exports.UTF32_ICELANDIC_CI = 161;
exports.UTF32_LATVIAN_CI = 162;
exports.UTF32_ROMANIAN_CI = 163;
exports.UTF32_SLOVENIAN_CI = 164;
exports.UTF32_POLISH_CI = 165;
exports.UTF32_ESTONIAN_CI = 166;
exports.UTF32_SPANISH_CI = 167;
exports.UTF32_SWEDISH_CI = 168;
exports.UTF32_TURKISH_CI = 169;
exports.UTF32_CZECH_CI = 170;
exports.UTF32_DANISH_CI = 171;
exports.UTF32_LITHUANIAN_CI = 172;
exports.UTF32_SLOVAK_CI = 173;
exports.UTF32_SPANISH2_CI = 174;
exports.UTF32_ROMAN_CI = 175;
exports.UTF32_PERSIAN_CI = 176;
exports.UTF32_ESPERANTO_CI = 177;
exports.UTF32_HUNGARIAN_CI = 178;
exports.UTF32_SINHALA_CI = 179;
exports.UTF32_GERMAN2_CI = 180;
exports.UTF32_CROATIAN_CI = 181;
exports.UTF32_UNICODE_520_CI = 182;
exports.UTF32_VIETNAMESE_CI = 183;
exports.UTF8_UNICODE_CI = 192;
exports.UTF8_ICELANDIC_CI = 193;
exports.UTF8_LATVIAN_CI = 194;
exports.UTF8_ROMANIAN_CI = 195;
exports.UTF8_SLOVENIAN_CI = 196;
exports.UTF8_POLISH_CI = 197;
exports.UTF8_ESTONIAN_CI = 198;
exports.UTF8_SPANISH_CI = 199;
exports.UTF8_SWEDISH_CI = 200;
exports.UTF8_TURKISH_CI = 201;
exports.UTF8_CZECH_CI = 202;
exports.UTF8_DANISH_CI = 203;
exports.UTF8_LITHUANIAN_CI = 204;
exports.UTF8_SLOVAK_CI = 205;
exports.UTF8_SPANISH2_CI = 206;
exports.UTF8_ROMAN_CI = 207;
exports.UTF8_PERSIAN_CI = 208;
exports.UTF8_ESPERANTO_CI = 209;
exports.UTF8_HUNGARIAN_CI = 210;
exports.UTF8_SINHALA_CI = 211;
exports.UTF8_GERMAN2_CI = 212;
exports.UTF8_CROATIAN_CI = 213;
exports.UTF8_UNICODE_520_CI = 214;
exports.UTF8_VIETNAMESE_CI = 215;
exports.UTF8_GENERAL_MYSQL500_CI = 223;
exports.UTF8MB4_UNICODE_CI = 224;
exports.UTF8MB4_ICELANDIC_CI = 225;
exports.UTF8MB4_LATVIAN_CI = 226;
exports.UTF8MB4_ROMANIAN_CI = 227;
exports.UTF8MB4_SLOVENIAN_CI = 228;
exports.UTF8MB4_POLISH_CI = 229;
exports.UTF8MB4_ESTONIAN_CI = 230;
exports.UTF8MB4_SPANISH_CI = 231;
exports.UTF8MB4_SWEDISH_CI = 232;
exports.UTF8MB4_TURKISH_CI = 233;
exports.UTF8MB4_CZECH_CI = 234;
exports.UTF8MB4_DANISH_CI = 235;
exports.UTF8MB4_LITHUANIAN_CI = 236;
exports.UTF8MB4_SLOVAK_CI = 237;
exports.UTF8MB4_SPANISH2_CI = 238;
exports.UTF8MB4_ROMAN_CI = 239;
exports.UTF8MB4_PERSIAN_CI = 240;
exports.UTF8MB4_ESPERANTO_CI = 241;
exports.UTF8MB4_HUNGARIAN_CI = 242;
exports.UTF8MB4_SINHALA_CI = 243;
exports.UTF8MB4_GERMAN2_CI = 244;
exports.UTF8MB4_CROATIAN_CI = 245;
exports.UTF8MB4_UNICODE_520_CI = 246;
exports.UTF8MB4_VIETNAMESE_CI = 247;
exports.GB18030_CHINESE_CI = 248;
exports.GB18030_BIN = 249;
exports.GB18030_UNICODE_520_CI = 250;
exports.UTF8_GENERAL50_CI = 253; // deprecated
exports.UTF8MB4_0900_AI_CI = 255;
exports.UTF8MB4_DE_PB_0900_AI_CI = 256;
exports.UTF8MB4_IS_0900_AI_CI = 257;
exports.UTF8MB4_LV_0900_AI_CI = 258;
exports.UTF8MB4_RO_0900_AI_CI = 259;
exports.UTF8MB4_SL_0900_AI_CI = 260;
exports.UTF8MB4_PL_0900_AI_CI = 261;
exports.UTF8MB4_ET_0900_AI_CI = 262;
exports.UTF8MB4_ES_0900_AI_CI = 263;
exports.UTF8MB4_SV_0900_AI_CI = 264;
exports.UTF8MB4_TR_0900_AI_CI = 265;
exports.UTF8MB4_CS_0900_AI_CI = 266;
exports.UTF8MB4_DA_0900_AI_CI = 267;
exports.UTF8MB4_LT_0900_AI_CI = 268;
exports.UTF8MB4_SK_0900_AI_CI = 269;
exports.UTF8MB4_ES_TRAD_0900_AI_CI = 270;
exports.UTF8MB4_LA_0900_AI_CI = 271;
exports.UTF8MB4_EO_0900_AI_CI = 273;
exports.UTF8MB4_HU_0900_AI_CI = 274;
exports.UTF8MB4_HR_0900_AI_CI = 275;
exports.UTF8MB4_VI_0900_AI_CI = 277;
exports.UTF8MB4_0900_AS_CS = 278;
exports.UTF8MB4_DE_PB_0900_AS_CS = 279;
exports.UTF8MB4_IS_0900_AS_CS = 280;
exports.UTF8MB4_LV_0900_AS_CS = 281;
exports.UTF8MB4_RO_0900_AS_CS = 282;
exports.UTF8MB4_SL_0900_AS_CS = 283;
exports.UTF8MB4_PL_0900_AS_CS = 284;
exports.UTF8MB4_ET_0900_AS_CS = 285;
exports.UTF8MB4_ES_0900_AS_CS = 286;
exports.UTF8MB4_SV_0900_AS_CS = 287;
exports.UTF8MB4_TR_0900_AS_CS = 288;
exports.UTF8MB4_CS_0900_AS_CS = 289;
exports.UTF8MB4_DA_0900_AS_CS = 290;
exports.UTF8MB4_LT_0900_AS_CS = 291;
exports.UTF8MB4_SK_0900_AS_CS = 292;
exports.UTF8MB4_ES_TRAD_0900_AS_CS = 293;
exports.UTF8MB4_LA_0900_AS_CS = 294;
exports.UTF8MB4_EO_0900_AS_CS = 296;
exports.UTF8MB4_HU_0900_AS_CS = 297;
exports.UTF8MB4_HR_0900_AS_CS = 298;
exports.UTF8MB4_VI_0900_AS_CS = 300;
exports.UTF8MB4_JA_0900_AS_CS = 303;
exports.UTF8MB4_JA_0900_AS_CS_KS = 304;
exports.UTF8MB4_0900_AS_CI = 305;
exports.UTF8MB4_RU_0900_AI_CI = 306;
exports.UTF8MB4_RU_0900_AS_CS = 307;
exports.UTF8MB4_ZH_0900_AS_CS = 308;
exports.UTF8MB4_0900_BIN = 309;

// short aliases
exports.BIG5 = exports.BIG5_CHINESE_CI;
exports.DEC8 = exports.DEC8_SWEDISH_CI;
exports.CP850 = exports.CP850_GENERAL_CI;
exports.HP8 = exports.HP8_ENGLISH_CI;
exports.KOI8R = exports.KOI8R_GENERAL_CI;
exports.LATIN1 = exports.LATIN1_SWEDISH_CI;
exports.LATIN2 = exports.LATIN2_GENERAL_CI;
exports.SWE7 = exports.SWE7_SWEDISH_CI;
exports.ASCII = exports.ASCII_GENERAL_CI;
exports.UJIS = exports.UJIS_JAPANESE_CI;
exports.SJIS = exports.SJIS_JAPANESE_CI;
exports.HEBREW = exports.HEBREW_GENERAL_CI;
exports.TIS620 = exports.TIS620_THAI_CI;
exports.EUCKR = exports.EUCKR_KOREAN_CI;
exports.KOI8U = exports.KOI8U_GENERAL_CI;
exports.GB2312 = exports.GB2312_CHINESE_CI;
exports.GREEK = exports.GREEK_GENERAL_CI;
exports.CP1250 = exports.CP1250_GENERAL_CI;
exports.GBK = exports.GBK_CHINESE_CI;
exports.LATIN5 = exports.LATIN5_TURKISH_CI;
exports.ARMSCII8 = exports.ARMSCII8_GENERAL_CI;
exports.UTF8 = exports.UTF8_GENERAL_CI;
exports.UCS2 = exports.UCS2_GENERAL_CI;
exports.CP866 = exports.CP866_GENERAL_CI;
exports.KEYBCS2 = exports.KEYBCS2_GENERAL_CI;
exports.MACCE = exports.MACCE_GENERAL_CI;
exports.MACROMAN = exports.MACROMAN_GENERAL_CI;
exports.CP852 = exports.CP852_GENERAL_CI;
exports.LATIN7 = exports.LATIN7_GENERAL_CI;
exports.UTF8MB4 = exports.UTF8MB4_GENERAL_CI;
exports.CP1251 = exports.CP1251_GENERAL_CI;
exports.UTF16 = exports.UTF16_GENERAL_CI;
exports.UTF16LE = exports.UTF16LE_GENERAL_CI;
exports.CP1256 = exports.CP1256_GENERAL_CI;
exports.CP1257 = exports.CP1257_GENERAL_CI;
exports.UTF32 = exports.UTF32_GENERAL_CI;
exports.CP932 = exports.CP932_JAPANESE_CI;
exports.EUCJPMS = exports.EUCJPMS_JAPANESE_CI;
exports.GB18030 = exports.GB18030_CHINESE_CI;
exports.GEOSTD8 = exports.GEOSTD8_GENERAL_CI;
</file>

<file path="lib/constants/client.js">
// This file was modified by Oracle on September 21, 2021.
// New capability for multi-factor authentication based on mandatory session
// trackers, that are signaled with an extra single-byte prefix on new
// versions of the MySQL server.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

// Manually extracted from mysql-5.5.23/include/mysql_com.h
exports.LONG_PASSWORD = 0x00000001; /* new more secure passwords */
exports.FOUND_ROWS = 0x00000002; /* found instead of affected rows */
exports.LONG_FLAG = 0x00000004; /* get all column flags */
exports.CONNECT_WITH_DB = 0x00000008; /* one can specify db on connect */
exports.NO_SCHEMA = 0x00000010; /* don't allow database.table.column */
exports.COMPRESS = 0x00000020; /* can use compression protocol */
exports.ODBC = 0x00000040; /* odbc client */
exports.LOCAL_FILES = 0x00000080; /* can use LOAD DATA LOCAL */
exports.IGNORE_SPACE = 0x00000100; /* ignore spaces before '' */
exports.PROTOCOL_41 = 0x00000200; /* new 4.1 protocol */
exports.INTERACTIVE = 0x00000400; /* this is an interactive client */
exports.SSL = 0x00000800; /* switch to ssl after handshake */
exports.IGNORE_SIGPIPE = 0x00001000; /* IGNORE sigpipes */
exports.TRANSACTIONS = 0x00002000; /* client knows about transactions */
exports.RESERVED = 0x00004000; /* old flag for 4.1 protocol  */
exports.SECURE_CONNECTION = 0x00008000; /* new 4.1 authentication */
exports.MULTI_STATEMENTS = 0x00010000; /* enable/disable multi-stmt support */
exports.MULTI_RESULTS = 0x00020000; /* enable/disable multi-results */
exports.PS_MULTI_RESULTS = 0x00040000; /* multi-results in ps-protocol */
exports.PLUGIN_AUTH = 0x00080000; /* client supports plugin authentication */
exports.CONNECT_ATTRS = 0x00100000; /* permits connection attributes */
exports.PLUGIN_AUTH_LENENC_CLIENT_DATA = 0x00200000; /* Understands length-encoded integer for auth response data in Protocol::HandshakeResponse41. */
exports.CAN_HANDLE_EXPIRED_PASSWORDS = 0x00400000; /* Announces support for expired password extension. */
exports.SESSION_TRACK = 0x00800000; /* Can set SERVER_SESSION_STATE_CHANGED in the Status Flags and send session-state change data after a OK packet. */
exports.DEPRECATE_EOF = 0x01000000; /* Can send OK after a Text Resultset. */

exports.SSL_VERIFY_SERVER_CERT = 0x40000000;
exports.REMEMBER_OPTIONS = 0x80000000;

exports.MULTI_FACTOR_AUTHENTICATION = 0x10000000; /* multi-factor authentication */
</file>

<file path="lib/constants/commands.js">
'use strict';

module.exports = {
  SLEEP: 0x00, // deprecated
  QUIT: 0x01,
  INIT_DB: 0x02,
  QUERY: 0x03,
  FIELD_LIST: 0x04,
  CREATE_DB: 0x05,
  DROP_DB: 0x06,
  REFRESH: 0x07,
  SHUTDOWN: 0x08,
  STATISTICS: 0x09,
  PROCESS_INFO: 0x0a, // deprecated
  CONNECT: 0x0b, // deprecated
  PROCESS_KILL: 0x0c,
  DEBUG: 0x0d,
  PING: 0x0e,
  TIME: 0x0f, // deprecated
  DELAYED_INSERT: 0x10, // deprecated
  CHANGE_USER: 0x11,
  BINLOG_DUMP: 0x12,
  TABLE_DUMP: 0x13,
  CONNECT_OUT: 0x14,
  REGISTER_SLAVE: 0x15,
  STMT_PREPARE: 0x16,
  STMT_EXECUTE: 0x17,
  STMT_SEND_LONG_DATA: 0x18,
  STMT_CLOSE: 0x19,
  STMT_RESET: 0x1a,
  SET_OPTION: 0x1b,
  STMT_FETCH: 0x1c,
  DAEMON: 0x1d, // deprecated
  BINLOG_DUMP_GTID: 0x1e,
  UNKNOWN: 0xff, // bad!
};
</file>

<file path="lib/constants/cursor.js">
'use strict';

module.exports = {
  NO_CURSOR: 0,
  READ_ONLY: 1,
  FOR_UPDATE: 2,
  SCROLLABLE: 3,
};
</file>

<file path="lib/constants/encoding_charset.js">
'use strict';

// inverse of charset_encodings
// given encoding, get matching mysql charset number

module.exports = {
  big5: 1,
  latin2: 2,
  dec8: 3,
  cp850: 4,
  latin1: 5,
  hp8: 6,
  koi8r: 7,
  swe7: 10,
  ascii: 11,
  eucjp: 12,
  sjis: 13,
  cp1251: 14,
  hebrew: 16,
  tis620: 18,
  euckr: 19,
  latin7: 20,
  koi8u: 22,
  gb2312: 24,
  greek: 25,
  cp1250: 26,
  gbk: 28,
  cp1257: 29,
  latin5: 30,
  armscii8: 32,
  cesu8: 33,
  ucs2: 35,
  cp866: 36,
  keybcs2: 37,
  macintosh: 38,
  macroman: 39,
  cp852: 40,
  utf8: 45,
  utf8mb4: 45,
  utf16: 54,
  utf16le: 56,
  cp1256: 57,
  utf32: 60,
  binary: 63,
  geostd8: 92,
  cp932: 95,
  eucjpms: 97,
  gb18030: 248,
  utf8mb3: 192,
};
</file>

<file path="lib/constants/errors.js">
// This file was modified by Oracle on June 1, 2021.
// An entry was created for a new error reported by the MySQL server due to
// client inactivity.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

// originally copied from https://raw.githubusercontent.com/mysqljs/mysql/7770ee5bb13260c56a160b91fe480d9165dbeeba/lib/protocol/constants/errors.js
// (c) node-mysql authors

// updated to contain error codes as is contained in MySQL 8.0
// by adapting node-mysql: /.../generate-error-constants.js

/**
 * MySQL error constants
 *
 * Extracted from version 8.0.33
 *
 * !! Generated by generate-error-constants.js, do not modify by hand !!
 */

exports.EE_CANTCREATEFILE = 1;
exports.EE_READ = 2;
exports.EE_WRITE = 3;
exports.EE_BADCLOSE = 4;
exports.EE_OUTOFMEMORY = 5;
exports.EE_DELETE = 6;
exports.EE_LINK = 7;
exports.EE_EOFERR = 9;
exports.EE_CANTLOCK = 10;
exports.EE_CANTUNLOCK = 11;
exports.EE_DIR = 12;
exports.EE_STAT = 13;
exports.EE_CANT_CHSIZE = 14;
exports.EE_CANT_OPEN_STREAM = 15;
exports.EE_GETWD = 16;
exports.EE_SETWD = 17;
exports.EE_LINK_WARNING = 18;
exports.EE_OPEN_WARNING = 19;
exports.EE_DISK_FULL = 20;
exports.EE_CANT_MKDIR = 21;
exports.EE_UNKNOWN_CHARSET = 22;
exports.EE_OUT_OF_FILERESOURCES = 23;
exports.EE_CANT_READLINK = 24;
exports.EE_CANT_SYMLINK = 25;
exports.EE_REALPATH = 26;
exports.EE_SYNC = 27;
exports.EE_UNKNOWN_COLLATION = 28;
exports.EE_FILENOTFOUND = 29;
exports.EE_FILE_NOT_CLOSED = 30;
exports.EE_CHANGE_OWNERSHIP = 31;
exports.EE_CHANGE_PERMISSIONS = 32;
exports.EE_CANT_SEEK = 33;
exports.EE_CAPACITY_EXCEEDED = 34;
exports.EE_DISK_FULL_WITH_RETRY_MSG = 35;
exports.EE_FAILED_TO_CREATE_TIMER = 36;
exports.EE_FAILED_TO_DELETE_TIMER = 37;
exports.EE_FAILED_TO_CREATE_TIMER_QUEUE = 38;
exports.EE_FAILED_TO_START_TIMER_NOTIFY_THREAD = 39;
exports.EE_FAILED_TO_CREATE_TIMER_NOTIFY_THREAD_INTERRUPT_EVENT = 40;
exports.EE_EXITING_TIMER_NOTIFY_THREAD = 41;
exports.EE_WIN_LIBRARY_LOAD_FAILED = 42;
exports.EE_WIN_RUN_TIME_ERROR_CHECK = 43;
exports.EE_FAILED_TO_DETERMINE_LARGE_PAGE_SIZE = 44;
exports.EE_FAILED_TO_KILL_ALL_THREADS = 45;
exports.EE_FAILED_TO_CREATE_IO_COMPLETION_PORT = 46;
exports.EE_FAILED_TO_OPEN_DEFAULTS_FILE = 47;
exports.EE_FAILED_TO_HANDLE_DEFAULTS_FILE = 48;
exports.EE_WRONG_DIRECTIVE_IN_CONFIG_FILE = 49;
exports.EE_SKIPPING_DIRECTIVE_DUE_TO_MAX_INCLUDE_RECURSION = 50;
exports.EE_INCORRECT_GRP_DEFINITION_IN_CONFIG_FILE = 51;
exports.EE_OPTION_WITHOUT_GRP_IN_CONFIG_FILE = 52;
exports.EE_CONFIG_FILE_PERMISSION_ERROR = 53;
exports.EE_IGNORE_WORLD_WRITABLE_CONFIG_FILE = 54;
exports.EE_USING_DISABLED_OPTION = 55;
exports.EE_USING_DISABLED_SHORT_OPTION = 56;
exports.EE_USING_PASSWORD_ON_CLI_IS_INSECURE = 57;
exports.EE_UNKNOWN_SUFFIX_FOR_VARIABLE = 58;
exports.EE_SSL_ERROR_FROM_FILE = 59;
exports.EE_SSL_ERROR = 60;
exports.EE_NET_SEND_ERROR_IN_BOOTSTRAP = 61;
exports.EE_PACKETS_OUT_OF_ORDER = 62;
exports.EE_UNKNOWN_PROTOCOL_OPTION = 63;
exports.EE_FAILED_TO_LOCATE_SERVER_PUBLIC_KEY = 64;
exports.EE_PUBLIC_KEY_NOT_IN_PEM_FORMAT = 65;
exports.EE_DEBUG_INFO = 66;
exports.EE_UNKNOWN_VARIABLE = 67;
exports.EE_UNKNOWN_OPTION = 68;
exports.EE_UNKNOWN_SHORT_OPTION = 69;
exports.EE_OPTION_WITHOUT_ARGUMENT = 70;
exports.EE_OPTION_REQUIRES_ARGUMENT = 71;
exports.EE_SHORT_OPTION_REQUIRES_ARGUMENT = 72;
exports.EE_OPTION_IGNORED_DUE_TO_INVALID_VALUE = 73;
exports.EE_OPTION_WITH_EMPTY_VALUE = 74;
exports.EE_FAILED_TO_ASSIGN_MAX_VALUE_TO_OPTION = 75;
exports.EE_INCORRECT_BOOLEAN_VALUE_FOR_OPTION = 76;
exports.EE_FAILED_TO_SET_OPTION_VALUE = 77;
exports.EE_INCORRECT_INT_VALUE_FOR_OPTION = 78;
exports.EE_INCORRECT_UINT_VALUE_FOR_OPTION = 79;
exports.EE_ADJUSTED_SIGNED_VALUE_FOR_OPTION = 80;
exports.EE_ADJUSTED_UNSIGNED_VALUE_FOR_OPTION = 81;
exports.EE_ADJUSTED_ULONGLONG_VALUE_FOR_OPTION = 82;
exports.EE_ADJUSTED_DOUBLE_VALUE_FOR_OPTION = 83;
exports.EE_INVALID_DECIMAL_VALUE_FOR_OPTION = 84;
exports.EE_COLLATION_PARSER_ERROR = 85;
exports.EE_FAILED_TO_RESET_BEFORE_PRIMARY_IGNORABLE_CHAR = 86;
exports.EE_FAILED_TO_RESET_BEFORE_TERTIARY_IGNORABLE_CHAR = 87;
exports.EE_SHIFT_CHAR_OUT_OF_RANGE = 88;
exports.EE_RESET_CHAR_OUT_OF_RANGE = 89;
exports.EE_UNKNOWN_LDML_TAG = 90;
exports.EE_FAILED_TO_RESET_BEFORE_SECONDARY_IGNORABLE_CHAR = 91;
exports.EE_FAILED_PROCESSING_DIRECTIVE = 92;
exports.EE_PTHREAD_KILL_FAILED = 93;
exports.HA_ERR_KEY_NOT_FOUND = 120;
exports.HA_ERR_FOUND_DUPP_KEY = 121;
exports.HA_ERR_INTERNAL_ERROR = 122;
exports.HA_ERR_RECORD_CHANGED = 123;
exports.HA_ERR_WRONG_INDEX = 124;
exports.HA_ERR_ROLLED_BACK = 125;
exports.HA_ERR_CRASHED = 126;
exports.HA_ERR_WRONG_IN_RECORD = 127;
exports.HA_ERR_OUT_OF_MEM = 128;
exports.HA_ERR_NOT_A_TABLE = 130;
exports.HA_ERR_WRONG_COMMAND = 131;
exports.HA_ERR_OLD_FILE = 132;
exports.HA_ERR_NO_ACTIVE_RECORD = 133;
exports.HA_ERR_RECORD_DELETED = 134;
exports.HA_ERR_RECORD_FILE_FULL = 135;
exports.HA_ERR_INDEX_FILE_FULL = 136;
exports.HA_ERR_END_OF_FILE = 137;
exports.HA_ERR_UNSUPPORTED = 138;
exports.HA_ERR_TOO_BIG_ROW = 139;
exports.HA_WRONG_CREATE_OPTION = 140;
exports.HA_ERR_FOUND_DUPP_UNIQUE = 141;
exports.HA_ERR_UNKNOWN_CHARSET = 142;
exports.HA_ERR_WRONG_MRG_TABLE_DEF = 143;
exports.HA_ERR_CRASHED_ON_REPAIR = 144;
exports.HA_ERR_CRASHED_ON_USAGE = 145;
exports.HA_ERR_LOCK_WAIT_TIMEOUT = 146;
exports.HA_ERR_LOCK_TABLE_FULL = 147;
exports.HA_ERR_READ_ONLY_TRANSACTION = 148;
exports.HA_ERR_LOCK_DEADLOCK = 149;
exports.HA_ERR_CANNOT_ADD_FOREIGN = 150;
exports.HA_ERR_NO_REFERENCED_ROW = 151;
exports.HA_ERR_ROW_IS_REFERENCED = 152;
exports.HA_ERR_NO_SAVEPOINT = 153;
exports.HA_ERR_NON_UNIQUE_BLOCK_SIZE = 154;
exports.HA_ERR_NO_SUCH_TABLE = 155;
exports.HA_ERR_TABLE_EXIST = 156;
exports.HA_ERR_NO_CONNECTION = 157;
exports.HA_ERR_NULL_IN_SPATIAL = 158;
exports.HA_ERR_TABLE_DEF_CHANGED = 159;
exports.HA_ERR_NO_PARTITION_FOUND = 160;
exports.HA_ERR_RBR_LOGGING_FAILED = 161;
exports.HA_ERR_DROP_INDEX_FK = 162;
exports.HA_ERR_FOREIGN_DUPLICATE_KEY = 163;
exports.HA_ERR_TABLE_NEEDS_UPGRADE = 164;
exports.HA_ERR_TABLE_READONLY = 165;
exports.HA_ERR_AUTOINC_READ_FAILED = 166;
exports.HA_ERR_AUTOINC_ERANGE = 167;
exports.HA_ERR_GENERIC = 168;
exports.HA_ERR_RECORD_IS_THE_SAME = 169;
exports.HA_ERR_LOGGING_IMPOSSIBLE = 170;
exports.HA_ERR_CORRUPT_EVENT = 171;
exports.HA_ERR_NEW_FILE = 172;
exports.HA_ERR_ROWS_EVENT_APPLY = 173;
exports.HA_ERR_INITIALIZATION = 174;
exports.HA_ERR_FILE_TOO_SHORT = 175;
exports.HA_ERR_WRONG_CRC = 176;
exports.HA_ERR_TOO_MANY_CONCURRENT_TRXS = 177;
exports.HA_ERR_NOT_IN_LOCK_PARTITIONS = 178;
exports.HA_ERR_INDEX_COL_TOO_LONG = 179;
exports.HA_ERR_INDEX_CORRUPT = 180;
exports.HA_ERR_UNDO_REC_TOO_BIG = 181;
exports.HA_FTS_INVALID_DOCID = 182;
exports.HA_ERR_TABLE_IN_FK_CHECK = 183;
exports.HA_ERR_TABLESPACE_EXISTS = 184;
exports.HA_ERR_TOO_MANY_FIELDS = 185;
exports.HA_ERR_ROW_IN_WRONG_PARTITION = 186;
exports.HA_ERR_INNODB_READ_ONLY = 187;
exports.HA_ERR_FTS_EXCEED_RESULT_CACHE_LIMIT = 188;
exports.HA_ERR_TEMP_FILE_WRITE_FAILURE = 189;
exports.HA_ERR_INNODB_FORCED_RECOVERY = 190;
exports.HA_ERR_FTS_TOO_MANY_WORDS_IN_PHRASE = 191;
exports.HA_ERR_FK_DEPTH_EXCEEDED = 192;
exports.HA_MISSING_CREATE_OPTION = 193;
exports.HA_ERR_SE_OUT_OF_MEMORY = 194;
exports.HA_ERR_TABLE_CORRUPT = 195;
exports.HA_ERR_QUERY_INTERRUPTED = 196;
exports.HA_ERR_TABLESPACE_MISSING = 197;
exports.HA_ERR_TABLESPACE_IS_NOT_EMPTY = 198;
exports.HA_ERR_WRONG_FILE_NAME = 199;
exports.HA_ERR_NOT_ALLOWED_COMMAND = 200;
exports.HA_ERR_COMPUTE_FAILED = 201;
exports.HA_ERR_ROW_FORMAT_CHANGED = 202;
exports.HA_ERR_NO_WAIT_LOCK = 203;
exports.HA_ERR_DISK_FULL_NOWAIT = 204;
exports.HA_ERR_NO_SESSION_TEMP = 205;
exports.HA_ERR_WRONG_TABLE_NAME = 206;
exports.HA_ERR_TOO_LONG_PATH = 207;
exports.HA_ERR_SAMPLING_INIT_FAILED = 208;
exports.HA_ERR_FTS_TOO_MANY_NESTED_EXP = 209;
exports.ER_HASHCHK = 1000;
exports.ER_NISAMCHK = 1001;
exports.ER_NO = 1002;
exports.ER_YES = 1003;
exports.ER_CANT_CREATE_FILE = 1004;
exports.ER_CANT_CREATE_TABLE = 1005;
exports.ER_CANT_CREATE_DB = 1006;
exports.ER_DB_CREATE_EXISTS = 1007;
exports.ER_DB_DROP_EXISTS = 1008;
exports.ER_DB_DROP_DELETE = 1009;
exports.ER_DB_DROP_RMDIR = 1010;
exports.ER_CANT_DELETE_FILE = 1011;
exports.ER_CANT_FIND_SYSTEM_REC = 1012;
exports.ER_CANT_GET_STAT = 1013;
exports.ER_CANT_GET_WD = 1014;
exports.ER_CANT_LOCK = 1015;
exports.ER_CANT_OPEN_FILE = 1016;
exports.ER_FILE_NOT_FOUND = 1017;
exports.ER_CANT_READ_DIR = 1018;
exports.ER_CANT_SET_WD = 1019;
exports.ER_CHECKREAD = 1020;
exports.ER_DISK_FULL = 1021;
exports.ER_DUP_KEY = 1022;
exports.ER_ERROR_ON_CLOSE = 1023;
exports.ER_ERROR_ON_READ = 1024;
exports.ER_ERROR_ON_RENAME = 1025;
exports.ER_ERROR_ON_WRITE = 1026;
exports.ER_FILE_USED = 1027;
exports.ER_FILSORT_ABORT = 1028;
exports.ER_FORM_NOT_FOUND = 1029;
exports.ER_GET_ERRNO = 1030;
exports.ER_ILLEGAL_HA = 1031;
exports.ER_KEY_NOT_FOUND = 1032;
exports.ER_NOT_FORM_FILE = 1033;
exports.ER_NOT_KEYFILE = 1034;
exports.ER_OLD_KEYFILE = 1035;
exports.ER_OPEN_AS_READONLY = 1036;
exports.ER_OUTOFMEMORY = 1037;
exports.ER_OUT_OF_SORTMEMORY = 1038;
exports.ER_UNEXPECTED_EOF = 1039;
exports.ER_CON_COUNT_ERROR = 1040;
exports.ER_OUT_OF_RESOURCES = 1041;
exports.ER_BAD_HOST_ERROR = 1042;
exports.ER_HANDSHAKE_ERROR = 1043;
exports.ER_DBACCESS_DENIED_ERROR = 1044;
exports.ER_ACCESS_DENIED_ERROR = 1045;
exports.ER_NO_DB_ERROR = 1046;
exports.ER_UNKNOWN_COM_ERROR = 1047;
exports.ER_BAD_NULL_ERROR = 1048;
exports.ER_BAD_DB_ERROR = 1049;
exports.ER_TABLE_EXISTS_ERROR = 1050;
exports.ER_BAD_TABLE_ERROR = 1051;
exports.ER_NON_UNIQ_ERROR = 1052;
exports.ER_SERVER_SHUTDOWN = 1053;
exports.ER_BAD_FIELD_ERROR = 1054;
exports.ER_WRONG_FIELD_WITH_GROUP = 1055;
exports.ER_WRONG_GROUP_FIELD = 1056;
exports.ER_WRONG_SUM_SELECT = 1057;
exports.ER_WRONG_VALUE_COUNT = 1058;
exports.ER_TOO_LONG_IDENT = 1059;
exports.ER_DUP_FIELDNAME = 1060;
exports.ER_DUP_KEYNAME = 1061;
exports.ER_DUP_ENTRY = 1062;
exports.ER_WRONG_FIELD_SPEC = 1063;
exports.ER_PARSE_ERROR = 1064;
exports.ER_EMPTY_QUERY = 1065;
exports.ER_NONUNIQ_TABLE = 1066;
exports.ER_INVALID_DEFAULT = 1067;
exports.ER_MULTIPLE_PRI_KEY = 1068;
exports.ER_TOO_MANY_KEYS = 1069;
exports.ER_TOO_MANY_KEY_PARTS = 1070;
exports.ER_TOO_LONG_KEY = 1071;
exports.ER_KEY_COLUMN_DOES_NOT_EXITS = 1072;
exports.ER_BLOB_USED_AS_KEY = 1073;
exports.ER_TOO_BIG_FIELDLENGTH = 1074;
exports.ER_WRONG_AUTO_KEY = 1075;
exports.ER_READY = 1076;
exports.ER_NORMAL_SHUTDOWN = 1077;
exports.ER_GOT_SIGNAL = 1078;
exports.ER_SHUTDOWN_COMPLETE = 1079;
exports.ER_FORCING_CLOSE = 1080;
exports.ER_IPSOCK_ERROR = 1081;
exports.ER_NO_SUCH_INDEX = 1082;
exports.ER_WRONG_FIELD_TERMINATORS = 1083;
exports.ER_BLOBS_AND_NO_TERMINATED = 1084;
exports.ER_TEXTFILE_NOT_READABLE = 1085;
exports.ER_FILE_EXISTS_ERROR = 1086;
exports.ER_LOAD_INFO = 1087;
exports.ER_ALTER_INFO = 1088;
exports.ER_WRONG_SUB_KEY = 1089;
exports.ER_CANT_REMOVE_ALL_FIELDS = 1090;
exports.ER_CANT_DROP_FIELD_OR_KEY = 1091;
exports.ER_INSERT_INFO = 1092;
exports.ER_UPDATE_TABLE_USED = 1093;
exports.ER_NO_SUCH_THREAD = 1094;
exports.ER_KILL_DENIED_ERROR = 1095;
exports.ER_NO_TABLES_USED = 1096;
exports.ER_TOO_BIG_SET = 1097;
exports.ER_NO_UNIQUE_LOGFILE = 1098;
exports.ER_TABLE_NOT_LOCKED_FOR_WRITE = 1099;
exports.ER_TABLE_NOT_LOCKED = 1100;
exports.ER_BLOB_CANT_HAVE_DEFAULT = 1101;
exports.ER_WRONG_DB_NAME = 1102;
exports.ER_WRONG_TABLE_NAME = 1103;
exports.ER_TOO_BIG_SELECT = 1104;
exports.ER_UNKNOWN_ERROR = 1105;
exports.ER_UNKNOWN_PROCEDURE = 1106;
exports.ER_WRONG_PARAMCOUNT_TO_PROCEDURE = 1107;
exports.ER_WRONG_PARAMETERS_TO_PROCEDURE = 1108;
exports.ER_UNKNOWN_TABLE = 1109;
exports.ER_FIELD_SPECIFIED_TWICE = 1110;
exports.ER_INVALID_GROUP_FUNC_USE = 1111;
exports.ER_UNSUPPORTED_EXTENSION = 1112;
exports.ER_TABLE_MUST_HAVE_COLUMNS = 1113;
exports.ER_RECORD_FILE_FULL = 1114;
exports.ER_UNKNOWN_CHARACTER_SET = 1115;
exports.ER_TOO_MANY_TABLES = 1116;
exports.ER_TOO_MANY_FIELDS = 1117;
exports.ER_TOO_BIG_ROWSIZE = 1118;
exports.ER_STACK_OVERRUN = 1119;
exports.ER_WRONG_OUTER_JOIN = 1120;
exports.ER_NULL_COLUMN_IN_INDEX = 1121;
exports.ER_CANT_FIND_UDF = 1122;
exports.ER_CANT_INITIALIZE_UDF = 1123;
exports.ER_UDF_NO_PATHS = 1124;
exports.ER_UDF_EXISTS = 1125;
exports.ER_CANT_OPEN_LIBRARY = 1126;
exports.ER_CANT_FIND_DL_ENTRY = 1127;
exports.ER_FUNCTION_NOT_DEFINED = 1128;
exports.ER_HOST_IS_BLOCKED = 1129;
exports.ER_HOST_NOT_PRIVILEGED = 1130;
exports.ER_PASSWORD_ANONYMOUS_USER = 1131;
exports.ER_PASSWORD_NOT_ALLOWED = 1132;
exports.ER_PASSWORD_NO_MATCH = 1133;
exports.ER_UPDATE_INFO = 1134;
exports.ER_CANT_CREATE_THREAD = 1135;
exports.ER_WRONG_VALUE_COUNT_ON_ROW = 1136;
exports.ER_CANT_REOPEN_TABLE = 1137;
exports.ER_INVALID_USE_OF_NULL = 1138;
exports.ER_REGEXP_ERROR = 1139;
exports.ER_MIX_OF_GROUP_FUNC_AND_FIELDS = 1140;
exports.ER_NONEXISTING_GRANT = 1141;
exports.ER_TABLEACCESS_DENIED_ERROR = 1142;
exports.ER_COLUMNACCESS_DENIED_ERROR = 1143;
exports.ER_ILLEGAL_GRANT_FOR_TABLE = 1144;
exports.ER_GRANT_WRONG_HOST_OR_USER = 1145;
exports.ER_NO_SUCH_TABLE = 1146;
exports.ER_NONEXISTING_TABLE_GRANT = 1147;
exports.ER_NOT_ALLOWED_COMMAND = 1148;
exports.ER_SYNTAX_ERROR = 1149;
exports.ER_UNUSED1 = 1150;
exports.ER_UNUSED2 = 1151;
exports.ER_ABORTING_CONNECTION = 1152;
exports.ER_NET_PACKET_TOO_LARGE = 1153;
exports.ER_NET_READ_ERROR_FROM_PIPE = 1154;
exports.ER_NET_FCNTL_ERROR = 1155;
exports.ER_NET_PACKETS_OUT_OF_ORDER = 1156;
exports.ER_NET_UNCOMPRESS_ERROR = 1157;
exports.ER_NET_READ_ERROR = 1158;
exports.ER_NET_READ_INTERRUPTED = 1159;
exports.ER_NET_ERROR_ON_WRITE = 1160;
exports.ER_NET_WRITE_INTERRUPTED = 1161;
exports.ER_TOO_LONG_STRING = 1162;
exports.ER_TABLE_CANT_HANDLE_BLOB = 1163;
exports.ER_TABLE_CANT_HANDLE_AUTO_INCREMENT = 1164;
exports.ER_UNUSED3 = 1165;
exports.ER_WRONG_COLUMN_NAME = 1166;
exports.ER_WRONG_KEY_COLUMN = 1167;
exports.ER_WRONG_MRG_TABLE = 1168;
exports.ER_DUP_UNIQUE = 1169;
exports.ER_BLOB_KEY_WITHOUT_LENGTH = 1170;
exports.ER_PRIMARY_CANT_HAVE_NULL = 1171;
exports.ER_TOO_MANY_ROWS = 1172;
exports.ER_REQUIRES_PRIMARY_KEY = 1173;
exports.ER_NO_RAID_COMPILED = 1174;
exports.ER_UPDATE_WITHOUT_KEY_IN_SAFE_MODE = 1175;
exports.ER_KEY_DOES_NOT_EXITS = 1176;
exports.ER_CHECK_NO_SUCH_TABLE = 1177;
exports.ER_CHECK_NOT_IMPLEMENTED = 1178;
exports.ER_CANT_DO_THIS_DURING_AN_TRANSACTION = 1179;
exports.ER_ERROR_DURING_COMMIT = 1180;
exports.ER_ERROR_DURING_ROLLBACK = 1181;
exports.ER_ERROR_DURING_FLUSH_LOGS = 1182;
exports.ER_ERROR_DURING_CHECKPOINT = 1183;
exports.ER_NEW_ABORTING_CONNECTION = 1184;
exports.ER_DUMP_NOT_IMPLEMENTED = 1185;
exports.ER_FLUSH_MASTER_BINLOG_CLOSED = 1186;
exports.ER_INDEX_REBUILD = 1187;
exports.ER_SOURCE = 1188;
exports.ER_SOURCE_NET_READ = 1189;
exports.ER_SOURCE_NET_WRITE = 1190;
exports.ER_FT_MATCHING_KEY_NOT_FOUND = 1191;
exports.ER_LOCK_OR_ACTIVE_TRANSACTION = 1192;
exports.ER_UNKNOWN_SYSTEM_VARIABLE = 1193;
exports.ER_CRASHED_ON_USAGE = 1194;
exports.ER_CRASHED_ON_REPAIR = 1195;
exports.ER_WARNING_NOT_COMPLETE_ROLLBACK = 1196;
exports.ER_TRANS_CACHE_FULL = 1197;
exports.ER_SLAVE_MUST_STOP = 1198;
exports.ER_REPLICA_NOT_RUNNING = 1199;
exports.ER_BAD_REPLICA = 1200;
exports.ER_CONNECTION_METADATA = 1201;
exports.ER_REPLICA_THREAD = 1202;
exports.ER_TOO_MANY_USER_CONNECTIONS = 1203;
exports.ER_SET_CONSTANTS_ONLY = 1204;
exports.ER_LOCK_WAIT_TIMEOUT = 1205;
exports.ER_LOCK_TABLE_FULL = 1206;
exports.ER_READ_ONLY_TRANSACTION = 1207;
exports.ER_DROP_DB_WITH_READ_LOCK = 1208;
exports.ER_CREATE_DB_WITH_READ_LOCK = 1209;
exports.ER_WRONG_ARGUMENTS = 1210;
exports.ER_NO_PERMISSION_TO_CREATE_USER = 1211;
exports.ER_UNION_TABLES_IN_DIFFERENT_DIR = 1212;
exports.ER_LOCK_DEADLOCK = 1213;
exports.ER_TABLE_CANT_HANDLE_FT = 1214;
exports.ER_CANNOT_ADD_FOREIGN = 1215;
exports.ER_NO_REFERENCED_ROW = 1216;
exports.ER_ROW_IS_REFERENCED = 1217;
exports.ER_CONNECT_TO_SOURCE = 1218;
exports.ER_QUERY_ON_MASTER = 1219;
exports.ER_ERROR_WHEN_EXECUTING_COMMAND = 1220;
exports.ER_WRONG_USAGE = 1221;
exports.ER_WRONG_NUMBER_OF_COLUMNS_IN_SELECT = 1222;
exports.ER_CANT_UPDATE_WITH_READLOCK = 1223;
exports.ER_MIXING_NOT_ALLOWED = 1224;
exports.ER_DUP_ARGUMENT = 1225;
exports.ER_USER_LIMIT_REACHED = 1226;
exports.ER_SPECIFIC_ACCESS_DENIED_ERROR = 1227;
exports.ER_LOCAL_VARIABLE = 1228;
exports.ER_GLOBAL_VARIABLE = 1229;
exports.ER_NO_DEFAULT = 1230;
exports.ER_WRONG_VALUE_FOR_VAR = 1231;
exports.ER_WRONG_TYPE_FOR_VAR = 1232;
exports.ER_VAR_CANT_BE_READ = 1233;
exports.ER_CANT_USE_OPTION_HERE = 1234;
exports.ER_NOT_SUPPORTED_YET = 1235;
exports.ER_SOURCE_FATAL_ERROR_READING_BINLOG = 1236;
exports.ER_REPLICA_IGNORED_TABLE = 1237;
exports.ER_INCORRECT_GLOBAL_LOCAL_VAR = 1238;
exports.ER_WRONG_FK_DEF = 1239;
exports.ER_KEY_REF_DO_NOT_MATCH_TABLE_REF = 1240;
exports.ER_OPERAND_COLUMNS = 1241;
exports.ER_SUBQUERY_NO_1_ROW = 1242;
exports.ER_UNKNOWN_STMT_HANDLER = 1243;
exports.ER_CORRUPT_HELP_DB = 1244;
exports.ER_CYCLIC_REFERENCE = 1245;
exports.ER_AUTO_CONVERT = 1246;
exports.ER_ILLEGAL_REFERENCE = 1247;
exports.ER_DERIVED_MUST_HAVE_ALIAS = 1248;
exports.ER_SELECT_REDUCED = 1249;
exports.ER_TABLENAME_NOT_ALLOWED_HERE = 1250;
exports.ER_NOT_SUPPORTED_AUTH_MODE = 1251;
exports.ER_SPATIAL_CANT_HAVE_NULL = 1252;
exports.ER_COLLATION_CHARSET_MISMATCH = 1253;
exports.ER_SLAVE_WAS_RUNNING = 1254;
exports.ER_SLAVE_WAS_NOT_RUNNING = 1255;
exports.ER_TOO_BIG_FOR_UNCOMPRESS = 1256;
exports.ER_ZLIB_Z_MEM_ERROR = 1257;
exports.ER_ZLIB_Z_BUF_ERROR = 1258;
exports.ER_ZLIB_Z_DATA_ERROR = 1259;
exports.ER_CUT_VALUE_GROUP_CONCAT = 1260;
exports.ER_WARN_TOO_FEW_RECORDS = 1261;
exports.ER_WARN_TOO_MANY_RECORDS = 1262;
exports.ER_WARN_NULL_TO_NOTNULL = 1263;
exports.ER_WARN_DATA_OUT_OF_RANGE = 1264;
exports.WARN_DATA_TRUNCATED = 1265;
exports.ER_WARN_USING_OTHER_HANDLER = 1266;
exports.ER_CANT_AGGREGATE_2COLLATIONS = 1267;
exports.ER_DROP_USER = 1268;
exports.ER_REVOKE_GRANTS = 1269;
exports.ER_CANT_AGGREGATE_3COLLATIONS = 1270;
exports.ER_CANT_AGGREGATE_NCOLLATIONS = 1271;
exports.ER_VARIABLE_IS_NOT_STRUCT = 1272;
exports.ER_UNKNOWN_COLLATION = 1273;
exports.ER_REPLICA_IGNORED_SSL_PARAMS = 1274;
exports.ER_SERVER_IS_IN_SECURE_AUTH_MODE = 1275;
exports.ER_WARN_FIELD_RESOLVED = 1276;
exports.ER_BAD_REPLICA_UNTIL_COND = 1277;
exports.ER_MISSING_SKIP_REPLICA = 1278;
exports.ER_UNTIL_COND_IGNORED = 1279;
exports.ER_WRONG_NAME_FOR_INDEX = 1280;
exports.ER_WRONG_NAME_FOR_CATALOG = 1281;
exports.ER_WARN_QC_RESIZE = 1282;
exports.ER_BAD_FT_COLUMN = 1283;
exports.ER_UNKNOWN_KEY_CACHE = 1284;
exports.ER_WARN_HOSTNAME_WONT_WORK = 1285;
exports.ER_UNKNOWN_STORAGE_ENGINE = 1286;
exports.ER_WARN_DEPRECATED_SYNTAX = 1287;
exports.ER_NON_UPDATABLE_TABLE = 1288;
exports.ER_FEATURE_DISABLED = 1289;
exports.ER_OPTION_PREVENTS_STATEMENT = 1290;
exports.ER_DUPLICATED_VALUE_IN_TYPE = 1291;
exports.ER_TRUNCATED_WRONG_VALUE = 1292;
exports.ER_TOO_MUCH_AUTO_TIMESTAMP_COLS = 1293;
exports.ER_INVALID_ON_UPDATE = 1294;
exports.ER_UNSUPPORTED_PS = 1295;
exports.ER_GET_ERRMSG = 1296;
exports.ER_GET_TEMPORARY_ERRMSG = 1297;
exports.ER_UNKNOWN_TIME_ZONE = 1298;
exports.ER_WARN_INVALID_TIMESTAMP = 1299;
exports.ER_INVALID_CHARACTER_STRING = 1300;
exports.ER_WARN_ALLOWED_PACKET_OVERFLOWED = 1301;
exports.ER_CONFLICTING_DECLARATIONS = 1302;
exports.ER_SP_NO_RECURSIVE_CREATE = 1303;
exports.ER_SP_ALREADY_EXISTS = 1304;
exports.ER_SP_DOES_NOT_EXIST = 1305;
exports.ER_SP_DROP_FAILED = 1306;
exports.ER_SP_STORE_FAILED = 1307;
exports.ER_SP_LILABEL_MISMATCH = 1308;
exports.ER_SP_LABEL_REDEFINE = 1309;
exports.ER_SP_LABEL_MISMATCH = 1310;
exports.ER_SP_UNINIT_VAR = 1311;
exports.ER_SP_BADSELECT = 1312;
exports.ER_SP_BADRETURN = 1313;
exports.ER_SP_BADSTATEMENT = 1314;
exports.ER_UPDATE_LOG_DEPRECATED_IGNORED = 1315;
exports.ER_UPDATE_LOG_DEPRECATED_TRANSLATED = 1316;
exports.ER_QUERY_INTERRUPTED = 1317;
exports.ER_SP_WRONG_NO_OF_ARGS = 1318;
exports.ER_SP_COND_MISMATCH = 1319;
exports.ER_SP_NORETURN = 1320;
exports.ER_SP_NORETURNEND = 1321;
exports.ER_SP_BAD_CURSOR_QUERY = 1322;
exports.ER_SP_BAD_CURSOR_SELECT = 1323;
exports.ER_SP_CURSOR_MISMATCH = 1324;
exports.ER_SP_CURSOR_ALREADY_OPEN = 1325;
exports.ER_SP_CURSOR_NOT_OPEN = 1326;
exports.ER_SP_UNDECLARED_VAR = 1327;
exports.ER_SP_WRONG_NO_OF_FETCH_ARGS = 1328;
exports.ER_SP_FETCH_NO_DATA = 1329;
exports.ER_SP_DUP_PARAM = 1330;
exports.ER_SP_DUP_VAR = 1331;
exports.ER_SP_DUP_COND = 1332;
exports.ER_SP_DUP_CURS = 1333;
exports.ER_SP_CANT_ALTER = 1334;
exports.ER_SP_SUBSELECT_NYI = 1335;
exports.ER_STMT_NOT_ALLOWED_IN_SF_OR_TRG = 1336;
exports.ER_SP_VARCOND_AFTER_CURSHNDLR = 1337;
exports.ER_SP_CURSOR_AFTER_HANDLER = 1338;
exports.ER_SP_CASE_NOT_FOUND = 1339;
exports.ER_FPARSER_TOO_BIG_FILE = 1340;
exports.ER_FPARSER_BAD_HEADER = 1341;
exports.ER_FPARSER_EOF_IN_COMMENT = 1342;
exports.ER_FPARSER_ERROR_IN_PARAMETER = 1343;
exports.ER_FPARSER_EOF_IN_UNKNOWN_PARAMETER = 1344;
exports.ER_VIEW_NO_EXPLAIN = 1345;
exports.ER_FRM_UNKNOWN_TYPE = 1346;
exports.ER_WRONG_OBJECT = 1347;
exports.ER_NONUPDATEABLE_COLUMN = 1348;
exports.ER_VIEW_SELECT_DERIVED = 1349;
exports.ER_VIEW_SELECT_CLAUSE = 1350;
exports.ER_VIEW_SELECT_VARIABLE = 1351;
exports.ER_VIEW_SELECT_TMPTABLE = 1352;
exports.ER_VIEW_WRONG_LIST = 1353;
exports.ER_WARN_VIEW_MERGE = 1354;
exports.ER_WARN_VIEW_WITHOUT_KEY = 1355;
exports.ER_VIEW_INVALID = 1356;
exports.ER_SP_NO_DROP_SP = 1357;
exports.ER_SP_GOTO_IN_HNDLR = 1358;
exports.ER_TRG_ALREADY_EXISTS = 1359;
exports.ER_TRG_DOES_NOT_EXIST = 1360;
exports.ER_TRG_ON_VIEW_OR_TEMP_TABLE = 1361;
exports.ER_TRG_CANT_CHANGE_ROW = 1362;
exports.ER_TRG_NO_SUCH_ROW_IN_TRG = 1363;
exports.ER_NO_DEFAULT_FOR_FIELD = 1364;
exports.ER_DIVISION_BY_ZERO = 1365;
exports.ER_TRUNCATED_WRONG_VALUE_FOR_FIELD = 1366;
exports.ER_ILLEGAL_VALUE_FOR_TYPE = 1367;
exports.ER_VIEW_NONUPD_CHECK = 1368;
exports.ER_VIEW_CHECK_FAILED = 1369;
exports.ER_PROCACCESS_DENIED_ERROR = 1370;
exports.ER_RELAY_LOG_FAIL = 1371;
exports.ER_PASSWD_LENGTH = 1372;
exports.ER_UNKNOWN_TARGET_BINLOG = 1373;
exports.ER_IO_ERR_LOG_INDEX_READ = 1374;
exports.ER_BINLOG_PURGE_PROHIBITED = 1375;
exports.ER_FSEEK_FAIL = 1376;
exports.ER_BINLOG_PURGE_FATAL_ERR = 1377;
exports.ER_LOG_IN_USE = 1378;
exports.ER_LOG_PURGE_UNKNOWN_ERR = 1379;
exports.ER_RELAY_LOG_INIT = 1380;
exports.ER_NO_BINARY_LOGGING = 1381;
exports.ER_RESERVED_SYNTAX = 1382;
exports.ER_WSAS_FAILED = 1383;
exports.ER_DIFF_GROUPS_PROC = 1384;
exports.ER_NO_GROUP_FOR_PROC = 1385;
exports.ER_ORDER_WITH_PROC = 1386;
exports.ER_LOGGING_PROHIBIT_CHANGING_OF = 1387;
exports.ER_NO_FILE_MAPPING = 1388;
exports.ER_WRONG_MAGIC = 1389;
exports.ER_PS_MANY_PARAM = 1390;
exports.ER_KEY_PART_0 = 1391;
exports.ER_VIEW_CHECKSUM = 1392;
exports.ER_VIEW_MULTIUPDATE = 1393;
exports.ER_VIEW_NO_INSERT_FIELD_LIST = 1394;
exports.ER_VIEW_DELETE_MERGE_VIEW = 1395;
exports.ER_CANNOT_USER = 1396;
exports.ER_XAER_NOTA = 1397;
exports.ER_XAER_INVAL = 1398;
exports.ER_XAER_RMFAIL = 1399;
exports.ER_XAER_OUTSIDE = 1400;
exports.ER_XAER_RMERR = 1401;
exports.ER_XA_RBROLLBACK = 1402;
exports.ER_NONEXISTING_PROC_GRANT = 1403;
exports.ER_PROC_AUTO_GRANT_FAIL = 1404;
exports.ER_PROC_AUTO_REVOKE_FAIL = 1405;
exports.ER_DATA_TOO_LONG = 1406;
exports.ER_SP_BAD_SQLSTATE = 1407;
exports.ER_STARTUP = 1408;
exports.ER_LOAD_FROM_FIXED_SIZE_ROWS_TO_VAR = 1409;
exports.ER_CANT_CREATE_USER_WITH_GRANT = 1410;
exports.ER_WRONG_VALUE_FOR_TYPE = 1411;
exports.ER_TABLE_DEF_CHANGED = 1412;
exports.ER_SP_DUP_HANDLER = 1413;
exports.ER_SP_NOT_VAR_ARG = 1414;
exports.ER_SP_NO_RETSET = 1415;
exports.ER_CANT_CREATE_GEOMETRY_OBJECT = 1416;
exports.ER_FAILED_ROUTINE_BREAK_BINLOG = 1417;
exports.ER_BINLOG_UNSAFE_ROUTINE = 1418;
exports.ER_BINLOG_CREATE_ROUTINE_NEED_SUPER = 1419;
exports.ER_EXEC_STMT_WITH_OPEN_CURSOR = 1420;
exports.ER_STMT_HAS_NO_OPEN_CURSOR = 1421;
exports.ER_COMMIT_NOT_ALLOWED_IN_SF_OR_TRG = 1422;
exports.ER_NO_DEFAULT_FOR_VIEW_FIELD = 1423;
exports.ER_SP_NO_RECURSION = 1424;
exports.ER_TOO_BIG_SCALE = 1425;
exports.ER_TOO_BIG_PRECISION = 1426;
exports.ER_M_BIGGER_THAN_D = 1427;
exports.ER_WRONG_LOCK_OF_SYSTEM_TABLE = 1428;
exports.ER_CONNECT_TO_FOREIGN_DATA_SOURCE = 1429;
exports.ER_QUERY_ON_FOREIGN_DATA_SOURCE = 1430;
exports.ER_FOREIGN_DATA_SOURCE_DOESNT_EXIST = 1431;
exports.ER_FOREIGN_DATA_STRING_INVALID_CANT_CREATE = 1432;
exports.ER_FOREIGN_DATA_STRING_INVALID = 1433;
exports.ER_CANT_CREATE_FEDERATED_TABLE = 1434;
exports.ER_TRG_IN_WRONG_SCHEMA = 1435;
exports.ER_STACK_OVERRUN_NEED_MORE = 1436;
exports.ER_TOO_LONG_BODY = 1437;
exports.ER_WARN_CANT_DROP_DEFAULT_KEYCACHE = 1438;
exports.ER_TOO_BIG_DISPLAYWIDTH = 1439;
exports.ER_XAER_DUPID = 1440;
exports.ER_DATETIME_FUNCTION_OVERFLOW = 1441;
exports.ER_CANT_UPDATE_USED_TABLE_IN_SF_OR_TRG = 1442;
exports.ER_VIEW_PREVENT_UPDATE = 1443;
exports.ER_PS_NO_RECURSION = 1444;
exports.ER_SP_CANT_SET_AUTOCOMMIT = 1445;
exports.ER_MALFORMED_DEFINER = 1446;
exports.ER_VIEW_FRM_NO_USER = 1447;
exports.ER_VIEW_OTHER_USER = 1448;
exports.ER_NO_SUCH_USER = 1449;
exports.ER_FORBID_SCHEMA_CHANGE = 1450;
exports.ER_ROW_IS_REFERENCED_2 = 1451;
exports.ER_NO_REFERENCED_ROW_2 = 1452;
exports.ER_SP_BAD_VAR_SHADOW = 1453;
exports.ER_TRG_NO_DEFINER = 1454;
exports.ER_OLD_FILE_FORMAT = 1455;
exports.ER_SP_RECURSION_LIMIT = 1456;
exports.ER_SP_PROC_TABLE_CORRUPT = 1457;
exports.ER_SP_WRONG_NAME = 1458;
exports.ER_TABLE_NEEDS_UPGRADE = 1459;
exports.ER_SP_NO_AGGREGATE = 1460;
exports.ER_MAX_PREPARED_STMT_COUNT_REACHED = 1461;
exports.ER_VIEW_RECURSIVE = 1462;
exports.ER_NON_GROUPING_FIELD_USED = 1463;
exports.ER_TABLE_CANT_HANDLE_SPKEYS = 1464;
exports.ER_NO_TRIGGERS_ON_SYSTEM_SCHEMA = 1465;
exports.ER_REMOVED_SPACES = 1466;
exports.ER_AUTOINC_READ_FAILED = 1467;
exports.ER_USERNAME = 1468;
exports.ER_HOSTNAME = 1469;
exports.ER_WRONG_STRING_LENGTH = 1470;
exports.ER_NON_INSERTABLE_TABLE = 1471;
exports.ER_ADMIN_WRONG_MRG_TABLE = 1472;
exports.ER_TOO_HIGH_LEVEL_OF_NESTING_FOR_SELECT = 1473;
exports.ER_NAME_BECOMES_EMPTY = 1474;
exports.ER_AMBIGUOUS_FIELD_TERM = 1475;
exports.ER_FOREIGN_SERVER_EXISTS = 1476;
exports.ER_FOREIGN_SERVER_DOESNT_EXIST = 1477;
exports.ER_ILLEGAL_HA_CREATE_OPTION = 1478;
exports.ER_PARTITION_REQUIRES_VALUES_ERROR = 1479;
exports.ER_PARTITION_WRONG_VALUES_ERROR = 1480;
exports.ER_PARTITION_MAXVALUE_ERROR = 1481;
exports.ER_PARTITION_SUBPARTITION_ERROR = 1482;
exports.ER_PARTITION_SUBPART_MIX_ERROR = 1483;
exports.ER_PARTITION_WRONG_NO_PART_ERROR = 1484;
exports.ER_PARTITION_WRONG_NO_SUBPART_ERROR = 1485;
exports.ER_WRONG_EXPR_IN_PARTITION_FUNC_ERROR = 1486;
exports.ER_NO_CONST_EXPR_IN_RANGE_OR_LIST_ERROR = 1487;
exports.ER_FIELD_NOT_FOUND_PART_ERROR = 1488;
exports.ER_LIST_OF_FIELDS_ONLY_IN_HASH_ERROR = 1489;
exports.ER_INCONSISTENT_PARTITION_INFO_ERROR = 1490;
exports.ER_PARTITION_FUNC_NOT_ALLOWED_ERROR = 1491;
exports.ER_PARTITIONS_MUST_BE_DEFINED_ERROR = 1492;
exports.ER_RANGE_NOT_INCREASING_ERROR = 1493;
exports.ER_INCONSISTENT_TYPE_OF_FUNCTIONS_ERROR = 1494;
exports.ER_MULTIPLE_DEF_CONST_IN_LIST_PART_ERROR = 1495;
exports.ER_PARTITION_ENTRY_ERROR = 1496;
exports.ER_MIX_HANDLER_ERROR = 1497;
exports.ER_PARTITION_NOT_DEFINED_ERROR = 1498;
exports.ER_TOO_MANY_PARTITIONS_ERROR = 1499;
exports.ER_SUBPARTITION_ERROR = 1500;
exports.ER_CANT_CREATE_HANDLER_FILE = 1501;
exports.ER_BLOB_FIELD_IN_PART_FUNC_ERROR = 1502;
exports.ER_UNIQUE_KEY_NEED_ALL_FIELDS_IN_PF = 1503;
exports.ER_NO_PARTS_ERROR = 1504;
exports.ER_PARTITION_MGMT_ON_NONPARTITIONED = 1505;
exports.ER_FOREIGN_KEY_ON_PARTITIONED = 1506;
exports.ER_DROP_PARTITION_NON_EXISTENT = 1507;
exports.ER_DROP_LAST_PARTITION = 1508;
exports.ER_COALESCE_ONLY_ON_HASH_PARTITION = 1509;
exports.ER_REORG_HASH_ONLY_ON_SAME_NO = 1510;
exports.ER_REORG_NO_PARAM_ERROR = 1511;
exports.ER_ONLY_ON_RANGE_LIST_PARTITION = 1512;
exports.ER_ADD_PARTITION_SUBPART_ERROR = 1513;
exports.ER_ADD_PARTITION_NO_NEW_PARTITION = 1514;
exports.ER_COALESCE_PARTITION_NO_PARTITION = 1515;
exports.ER_REORG_PARTITION_NOT_EXIST = 1516;
exports.ER_SAME_NAME_PARTITION = 1517;
exports.ER_NO_BINLOG_ERROR = 1518;
exports.ER_CONSECUTIVE_REORG_PARTITIONS = 1519;
exports.ER_REORG_OUTSIDE_RANGE = 1520;
exports.ER_PARTITION_FUNCTION_FAILURE = 1521;
exports.ER_PART_STATE_ERROR = 1522;
exports.ER_LIMITED_PART_RANGE = 1523;
exports.ER_PLUGIN_IS_NOT_LOADED = 1524;
exports.ER_WRONG_VALUE = 1525;
exports.ER_NO_PARTITION_FOR_GIVEN_VALUE = 1526;
exports.ER_FILEGROUP_OPTION_ONLY_ONCE = 1527;
exports.ER_CREATE_FILEGROUP_FAILED = 1528;
exports.ER_DROP_FILEGROUP_FAILED = 1529;
exports.ER_TABLESPACE_AUTO_EXTEND_ERROR = 1530;
exports.ER_WRONG_SIZE_NUMBER = 1531;
exports.ER_SIZE_OVERFLOW_ERROR = 1532;
exports.ER_ALTER_FILEGROUP_FAILED = 1533;
exports.ER_BINLOG_ROW_LOGGING_FAILED = 1534;
exports.ER_BINLOG_ROW_WRONG_TABLE_DEF = 1535;
exports.ER_BINLOG_ROW_RBR_TO_SBR = 1536;
exports.ER_EVENT_ALREADY_EXISTS = 1537;
exports.ER_EVENT_STORE_FAILED = 1538;
exports.ER_EVENT_DOES_NOT_EXIST = 1539;
exports.ER_EVENT_CANT_ALTER = 1540;
exports.ER_EVENT_DROP_FAILED = 1541;
exports.ER_EVENT_INTERVAL_NOT_POSITIVE_OR_TOO_BIG = 1542;
exports.ER_EVENT_ENDS_BEFORE_STARTS = 1543;
exports.ER_EVENT_EXEC_TIME_IN_THE_PAST = 1544;
exports.ER_EVENT_OPEN_TABLE_FAILED = 1545;
exports.ER_EVENT_NEITHER_M_EXPR_NOR_M_AT = 1546;
exports.ER_COL_COUNT_DOESNT_MATCH_CORRUPTED = 1547;
exports.ER_CANNOT_LOAD_FROM_TABLE = 1548;
exports.ER_EVENT_CANNOT_DELETE = 1549;
exports.ER_EVENT_COMPILE_ERROR = 1550;
exports.ER_EVENT_SAME_NAME = 1551;
exports.ER_EVENT_DATA_TOO_LONG = 1552;
exports.ER_DROP_INDEX_FK = 1553;
exports.ER_WARN_DEPRECATED_SYNTAX_WITH_VER = 1554;
exports.ER_CANT_WRITE_LOCK_LOG_TABLE = 1555;
exports.ER_CANT_LOCK_LOG_TABLE = 1556;
exports.ER_FOREIGN_DUPLICATE_KEY = 1557;
exports.ER_COL_COUNT_DOESNT_MATCH_PLEASE_UPDATE = 1558;
exports.ER_TEMP_TABLE_PREVENTS_SWITCH_OUT_OF_RBR = 1559;
exports.ER_STORED_FUNCTION_PREVENTS_SWITCH_BINLOG_FORMAT = 1560;
exports.ER_NDB_CANT_SWITCH_BINLOG_FORMAT = 1561;
exports.ER_PARTITION_NO_TEMPORARY = 1562;
exports.ER_PARTITION_CONST_DOMAIN_ERROR = 1563;
exports.ER_PARTITION_FUNCTION_IS_NOT_ALLOWED = 1564;
exports.ER_DDL_LOG_ERROR = 1565;
exports.ER_NULL_IN_VALUES_LESS_THAN = 1566;
exports.ER_WRONG_PARTITION_NAME = 1567;
exports.ER_CANT_CHANGE_TX_CHARACTERISTICS = 1568;
exports.ER_DUP_ENTRY_AUTOINCREMENT_CASE = 1569;
exports.ER_EVENT_MODIFY_QUEUE_ERROR = 1570;
exports.ER_EVENT_SET_VAR_ERROR = 1571;
exports.ER_PARTITION_MERGE_ERROR = 1572;
exports.ER_CANT_ACTIVATE_LOG = 1573;
exports.ER_RBR_NOT_AVAILABLE = 1574;
exports.ER_BASE64_DECODE_ERROR = 1575;
exports.ER_EVENT_RECURSION_FORBIDDEN = 1576;
exports.ER_EVENTS_DB_ERROR = 1577;
exports.ER_ONLY_INTEGERS_ALLOWED = 1578;
exports.ER_UNSUPORTED_LOG_ENGINE = 1579;
exports.ER_BAD_LOG_STATEMENT = 1580;
exports.ER_CANT_RENAME_LOG_TABLE = 1581;
exports.ER_WRONG_PARAMCOUNT_TO_NATIVE_FCT = 1582;
exports.ER_WRONG_PARAMETERS_TO_NATIVE_FCT = 1583;
exports.ER_WRONG_PARAMETERS_TO_STORED_FCT = 1584;
exports.ER_NATIVE_FCT_NAME_COLLISION = 1585;
exports.ER_DUP_ENTRY_WITH_KEY_NAME = 1586;
exports.ER_BINLOG_PURGE_EMFILE = 1587;
exports.ER_EVENT_CANNOT_CREATE_IN_THE_PAST = 1588;
exports.ER_EVENT_CANNOT_ALTER_IN_THE_PAST = 1589;
exports.ER_SLAVE_INCIDENT = 1590;
exports.ER_NO_PARTITION_FOR_GIVEN_VALUE_SILENT = 1591;
exports.ER_BINLOG_UNSAFE_STATEMENT = 1592;
exports.ER_BINLOG_FATAL_ERROR = 1593;
exports.ER_SLAVE_RELAY_LOG_READ_FAILURE = 1594;
exports.ER_SLAVE_RELAY_LOG_WRITE_FAILURE = 1595;
exports.ER_SLAVE_CREATE_EVENT_FAILURE = 1596;
exports.ER_SLAVE_MASTER_COM_FAILURE = 1597;
exports.ER_BINLOG_LOGGING_IMPOSSIBLE = 1598;
exports.ER_VIEW_NO_CREATION_CTX = 1599;
exports.ER_VIEW_INVALID_CREATION_CTX = 1600;
exports.ER_SR_INVALID_CREATION_CTX = 1601;
exports.ER_TRG_CORRUPTED_FILE = 1602;
exports.ER_TRG_NO_CREATION_CTX = 1603;
exports.ER_TRG_INVALID_CREATION_CTX = 1604;
exports.ER_EVENT_INVALID_CREATION_CTX = 1605;
exports.ER_TRG_CANT_OPEN_TABLE = 1606;
exports.ER_CANT_CREATE_SROUTINE = 1607;
exports.ER_NEVER_USED = 1608;
exports.ER_NO_FORMAT_DESCRIPTION_EVENT_BEFORE_BINLOG_STATEMENT = 1609;
exports.ER_REPLICA_CORRUPT_EVENT = 1610;
exports.ER_LOAD_DATA_INVALID_COLUMN = 1611;
exports.ER_LOG_PURGE_NO_FILE = 1612;
exports.ER_XA_RBTIMEOUT = 1613;
exports.ER_XA_RBDEADLOCK = 1614;
exports.ER_NEED_REPREPARE = 1615;
exports.ER_DELAYED_NOT_SUPPORTED = 1616;
exports.WARN_NO_CONNECTION_METADATA = 1617;
exports.WARN_OPTION_IGNORED = 1618;
exports.ER_PLUGIN_DELETE_BUILTIN = 1619;
exports.WARN_PLUGIN_BUSY = 1620;
exports.ER_VARIABLE_IS_READONLY = 1621;
exports.ER_WARN_ENGINE_TRANSACTION_ROLLBACK = 1622;
exports.ER_SLAVE_HEARTBEAT_FAILURE = 1623;
exports.ER_REPLICA_HEARTBEAT_VALUE_OUT_OF_RANGE = 1624;
exports.ER_NDB_REPLICATION_SCHEMA_ERROR = 1625;
exports.ER_CONFLICT_FN_PARSE_ERROR = 1626;
exports.ER_EXCEPTIONS_WRITE_ERROR = 1627;
exports.ER_TOO_LONG_TABLE_COMMENT = 1628;
exports.ER_TOO_LONG_FIELD_COMMENT = 1629;
exports.ER_FUNC_INEXISTENT_NAME_COLLISION = 1630;
exports.ER_DATABASE_NAME = 1631;
exports.ER_TABLE_NAME = 1632;
exports.ER_PARTITION_NAME = 1633;
exports.ER_SUBPARTITION_NAME = 1634;
exports.ER_TEMPORARY_NAME = 1635;
exports.ER_RENAMED_NAME = 1636;
exports.ER_TOO_MANY_CONCURRENT_TRXS = 1637;
exports.WARN_NON_ASCII_SEPARATOR_NOT_IMPLEMENTED = 1638;
exports.ER_DEBUG_SYNC_TIMEOUT = 1639;
exports.ER_DEBUG_SYNC_HIT_LIMIT = 1640;
exports.ER_DUP_SIGNAL_SET = 1641;
exports.ER_SIGNAL_WARN = 1642;
exports.ER_SIGNAL_NOT_FOUND = 1643;
exports.ER_SIGNAL_EXCEPTION = 1644;
exports.ER_RESIGNAL_WITHOUT_ACTIVE_HANDLER = 1645;
exports.ER_SIGNAL_BAD_CONDITION_TYPE = 1646;
exports.WARN_COND_ITEM_TRUNCATED = 1647;
exports.ER_COND_ITEM_TOO_LONG = 1648;
exports.ER_UNKNOWN_LOCALE = 1649;
exports.ER_REPLICA_IGNORE_SERVER_IDS = 1650;
exports.ER_QUERY_CACHE_DISABLED = 1651;
exports.ER_SAME_NAME_PARTITION_FIELD = 1652;
exports.ER_PARTITION_COLUMN_LIST_ERROR = 1653;
exports.ER_WRONG_TYPE_COLUMN_VALUE_ERROR = 1654;
exports.ER_TOO_MANY_PARTITION_FUNC_FIELDS_ERROR = 1655;
exports.ER_MAXVALUE_IN_VALUES_IN = 1656;
exports.ER_TOO_MANY_VALUES_ERROR = 1657;
exports.ER_ROW_SINGLE_PARTITION_FIELD_ERROR = 1658;
exports.ER_FIELD_TYPE_NOT_ALLOWED_AS_PARTITION_FIELD = 1659;
exports.ER_PARTITION_FIELDS_TOO_LONG = 1660;
exports.ER_BINLOG_ROW_ENGINE_AND_STMT_ENGINE = 1661;
exports.ER_BINLOG_ROW_MODE_AND_STMT_ENGINE = 1662;
exports.ER_BINLOG_UNSAFE_AND_STMT_ENGINE = 1663;
exports.ER_BINLOG_ROW_INJECTION_AND_STMT_ENGINE = 1664;
exports.ER_BINLOG_STMT_MODE_AND_ROW_ENGINE = 1665;
exports.ER_BINLOG_ROW_INJECTION_AND_STMT_MODE = 1666;
exports.ER_BINLOG_MULTIPLE_ENGINES_AND_SELF_LOGGING_ENGINE = 1667;
exports.ER_BINLOG_UNSAFE_LIMIT = 1668;
exports.ER_UNUSED4 = 1669;
exports.ER_BINLOG_UNSAFE_SYSTEM_TABLE = 1670;
exports.ER_BINLOG_UNSAFE_AUTOINC_COLUMNS = 1671;
exports.ER_BINLOG_UNSAFE_UDF = 1672;
exports.ER_BINLOG_UNSAFE_SYSTEM_VARIABLE = 1673;
exports.ER_BINLOG_UNSAFE_SYSTEM_FUNCTION = 1674;
exports.ER_BINLOG_UNSAFE_NONTRANS_AFTER_TRANS = 1675;
exports.ER_MESSAGE_AND_STATEMENT = 1676;
exports.ER_SLAVE_CONVERSION_FAILED = 1677;
exports.ER_REPLICA_CANT_CREATE_CONVERSION = 1678;
exports.ER_INSIDE_TRANSACTION_PREVENTS_SWITCH_BINLOG_FORMAT = 1679;
exports.ER_PATH_LENGTH = 1680;
exports.ER_WARN_DEPRECATED_SYNTAX_NO_REPLACEMENT = 1681;
exports.ER_WRONG_NATIVE_TABLE_STRUCTURE = 1682;
exports.ER_WRONG_PERFSCHEMA_USAGE = 1683;
exports.ER_WARN_I_S_SKIPPED_TABLE = 1684;
exports.ER_INSIDE_TRANSACTION_PREVENTS_SWITCH_BINLOG_DIRECT = 1685;
exports.ER_STORED_FUNCTION_PREVENTS_SWITCH_BINLOG_DIRECT = 1686;
exports.ER_SPATIAL_MUST_HAVE_GEOM_COL = 1687;
exports.ER_TOO_LONG_INDEX_COMMENT = 1688;
exports.ER_LOCK_ABORTED = 1689;
exports.ER_DATA_OUT_OF_RANGE = 1690;
exports.ER_WRONG_SPVAR_TYPE_IN_LIMIT = 1691;
exports.ER_BINLOG_UNSAFE_MULTIPLE_ENGINES_AND_SELF_LOGGING_ENGINE = 1692;
exports.ER_BINLOG_UNSAFE_MIXED_STATEMENT = 1693;
exports.ER_INSIDE_TRANSACTION_PREVENTS_SWITCH_SQL_LOG_BIN = 1694;
exports.ER_STORED_FUNCTION_PREVENTS_SWITCH_SQL_LOG_BIN = 1695;
exports.ER_FAILED_READ_FROM_PAR_FILE = 1696;
exports.ER_VALUES_IS_NOT_INT_TYPE_ERROR = 1697;
exports.ER_ACCESS_DENIED_NO_PASSWORD_ERROR = 1698;
exports.ER_SET_PASSWORD_AUTH_PLUGIN = 1699;
exports.ER_GRANT_PLUGIN_USER_EXISTS = 1700;
exports.ER_TRUNCATE_ILLEGAL_FK = 1701;
exports.ER_PLUGIN_IS_PERMANENT = 1702;
exports.ER_REPLICA_HEARTBEAT_VALUE_OUT_OF_RANGE_MIN = 1703;
exports.ER_REPLICA_HEARTBEAT_VALUE_OUT_OF_RANGE_MAX = 1704;
exports.ER_STMT_CACHE_FULL = 1705;
exports.ER_MULTI_UPDATE_KEY_CONFLICT = 1706;
exports.ER_TABLE_NEEDS_REBUILD = 1707;
exports.WARN_OPTION_BELOW_LIMIT = 1708;
exports.ER_INDEX_COLUMN_TOO_LONG = 1709;
exports.ER_ERROR_IN_TRIGGER_BODY = 1710;
exports.ER_ERROR_IN_UNKNOWN_TRIGGER_BODY = 1711;
exports.ER_INDEX_CORRUPT = 1712;
exports.ER_UNDO_RECORD_TOO_BIG = 1713;
exports.ER_BINLOG_UNSAFE_INSERT_IGNORE_SELECT = 1714;
exports.ER_BINLOG_UNSAFE_INSERT_SELECT_UPDATE = 1715;
exports.ER_BINLOG_UNSAFE_REPLACE_SELECT = 1716;
exports.ER_BINLOG_UNSAFE_CREATE_IGNORE_SELECT = 1717;
exports.ER_BINLOG_UNSAFE_CREATE_REPLACE_SELECT = 1718;
exports.ER_BINLOG_UNSAFE_UPDATE_IGNORE = 1719;
exports.ER_PLUGIN_NO_UNINSTALL = 1720;
exports.ER_PLUGIN_NO_INSTALL = 1721;
exports.ER_BINLOG_UNSAFE_WRITE_AUTOINC_SELECT = 1722;
exports.ER_BINLOG_UNSAFE_CREATE_SELECT_AUTOINC = 1723;
exports.ER_BINLOG_UNSAFE_INSERT_TWO_KEYS = 1724;
exports.ER_TABLE_IN_FK_CHECK = 1725;
exports.ER_UNSUPPORTED_ENGINE = 1726;
exports.ER_BINLOG_UNSAFE_AUTOINC_NOT_FIRST = 1727;
exports.ER_CANNOT_LOAD_FROM_TABLE_V2 = 1728;
exports.ER_SOURCE_DELAY_VALUE_OUT_OF_RANGE = 1729;
exports.ER_ONLY_FD_AND_RBR_EVENTS_ALLOWED_IN_BINLOG_STATEMENT = 1730;
exports.ER_PARTITION_EXCHANGE_DIFFERENT_OPTION = 1731;
exports.ER_PARTITION_EXCHANGE_PART_TABLE = 1732;
exports.ER_PARTITION_EXCHANGE_TEMP_TABLE = 1733;
exports.ER_PARTITION_INSTEAD_OF_SUBPARTITION = 1734;
exports.ER_UNKNOWN_PARTITION = 1735;
exports.ER_TABLES_DIFFERENT_METADATA = 1736;
exports.ER_ROW_DOES_NOT_MATCH_PARTITION = 1737;
exports.ER_BINLOG_CACHE_SIZE_GREATER_THAN_MAX = 1738;
exports.ER_WARN_INDEX_NOT_APPLICABLE = 1739;
exports.ER_PARTITION_EXCHANGE_FOREIGN_KEY = 1740;
exports.ER_NO_SUCH_KEY_VALUE = 1741;
exports.ER_RPL_INFO_DATA_TOO_LONG = 1742;
exports.ER_NETWORK_READ_EVENT_CHECKSUM_FAILURE = 1743;
exports.ER_BINLOG_READ_EVENT_CHECKSUM_FAILURE = 1744;
exports.ER_BINLOG_STMT_CACHE_SIZE_GREATER_THAN_MAX = 1745;
exports.ER_CANT_UPDATE_TABLE_IN_CREATE_TABLE_SELECT = 1746;
exports.ER_PARTITION_CLAUSE_ON_NONPARTITIONED = 1747;
exports.ER_ROW_DOES_NOT_MATCH_GIVEN_PARTITION_SET = 1748;
exports.ER_NO_SUCH_PARTITION = 1749;
exports.ER_CHANGE_RPL_INFO_REPOSITORY_FAILURE = 1750;
exports.ER_WARNING_NOT_COMPLETE_ROLLBACK_WITH_CREATED_TEMP_TABLE = 1751;
exports.ER_WARNING_NOT_COMPLETE_ROLLBACK_WITH_DROPPED_TEMP_TABLE = 1752;
exports.ER_MTA_FEATURE_IS_NOT_SUPPORTED = 1753;
exports.ER_MTA_UPDATED_DBS_GREATER_MAX = 1754;
exports.ER_MTA_CANT_PARALLEL = 1755;
exports.ER_MTA_INCONSISTENT_DATA = 1756;
exports.ER_FULLTEXT_NOT_SUPPORTED_WITH_PARTITIONING = 1757;
exports.ER_DA_INVALID_CONDITION_NUMBER = 1758;
exports.ER_INSECURE_PLAIN_TEXT = 1759;
exports.ER_INSECURE_CHANGE_SOURCE = 1760;
exports.ER_FOREIGN_DUPLICATE_KEY_WITH_CHILD_INFO = 1761;
exports.ER_FOREIGN_DUPLICATE_KEY_WITHOUT_CHILD_INFO = 1762;
exports.ER_SQLTHREAD_WITH_SECURE_REPLICA = 1763;
exports.ER_TABLE_HAS_NO_FT = 1764;
exports.ER_VARIABLE_NOT_SETTABLE_IN_SF_OR_TRIGGER = 1765;
exports.ER_VARIABLE_NOT_SETTABLE_IN_TRANSACTION = 1766;
exports.ER_GTID_NEXT_IS_NOT_IN_GTID_NEXT_LIST = 1767;
exports.ER_CANT_CHANGE_GTID_NEXT_IN_TRANSACTION = 1768;
exports.ER_SET_STATEMENT_CANNOT_INVOKE_FUNCTION = 1769;
exports.ER_GTID_NEXT_CANT_BE_AUTOMATIC_IF_GTID_NEXT_LIST_IS_NON_NULL = 1770;
exports.ER_SKIPPING_LOGGED_TRANSACTION = 1771;
exports.ER_MALFORMED_GTID_SET_SPECIFICATION = 1772;
exports.ER_MALFORMED_GTID_SET_ENCODING = 1773;
exports.ER_MALFORMED_GTID_SPECIFICATION = 1774;
exports.ER_GNO_EXHAUSTED = 1775;
exports.ER_BAD_REPLICA_AUTO_POSITION = 1776;
exports.ER_AUTO_POSITION_REQUIRES_GTID_MODE_NOT_OFF = 1777;
exports.ER_CANT_DO_IMPLICIT_COMMIT_IN_TRX_WHEN_GTID_NEXT_IS_SET = 1778;
exports.ER_GTID_MODE_ON_REQUIRES_ENFORCE_GTID_CONSISTENCY_ON = 1779;
exports.ER_GTID_MODE_REQUIRES_BINLOG = 1780;
exports.ER_CANT_SET_GTID_NEXT_TO_GTID_WHEN_GTID_MODE_IS_OFF = 1781;
exports.ER_CANT_SET_GTID_NEXT_TO_ANONYMOUS_WHEN_GTID_MODE_IS_ON = 1782;
exports.ER_CANT_SET_GTID_NEXT_LIST_TO_NON_NULL_WHEN_GTID_MODE_IS_OFF = 1783;
exports.ER_FOUND_GTID_EVENT_WHEN_GTID_MODE_IS_OFF = 1784;
exports.ER_GTID_UNSAFE_NON_TRANSACTIONAL_TABLE = 1785;
exports.ER_GTID_UNSAFE_CREATE_SELECT = 1786;
exports.ER_GTID_UNSAFE_CREATE_DROP_TEMP_TABLE_IN_TRANSACTION = 1787;
exports.ER_GTID_MODE_CAN_ONLY_CHANGE_ONE_STEP_AT_A_TIME = 1788;
exports.ER_SOURCE_HAS_PURGED_REQUIRED_GTIDS = 1789;
exports.ER_CANT_SET_GTID_NEXT_WHEN_OWNING_GTID = 1790;
exports.ER_UNKNOWN_EXPLAIN_FORMAT = 1791;
exports.ER_CANT_EXECUTE_IN_READ_ONLY_TRANSACTION = 1792;
exports.ER_TOO_LONG_TABLE_PARTITION_COMMENT = 1793;
exports.ER_REPLICA_CONFIGURATION = 1794;
exports.ER_INNODB_FT_LIMIT = 1795;
exports.ER_INNODB_NO_FT_TEMP_TABLE = 1796;
exports.ER_INNODB_FT_WRONG_DOCID_COLUMN = 1797;
exports.ER_INNODB_FT_WRONG_DOCID_INDEX = 1798;
exports.ER_INNODB_ONLINE_LOG_TOO_BIG = 1799;
exports.ER_UNKNOWN_ALTER_ALGORITHM = 1800;
exports.ER_UNKNOWN_ALTER_LOCK = 1801;
exports.ER_MTA_CHANGE_SOURCE_CANT_RUN_WITH_GAPS = 1802;
exports.ER_MTA_RECOVERY_FAILURE = 1803;
exports.ER_MTA_RESET_WORKERS = 1804;
exports.ER_COL_COUNT_DOESNT_MATCH_CORRUPTED_V2 = 1805;
exports.ER_REPLICA_SILENT_RETRY_TRANSACTION = 1806;
exports.ER_DISCARD_FK_CHECKS_RUNNING = 1807;
exports.ER_TABLE_SCHEMA_MISMATCH = 1808;
exports.ER_TABLE_IN_SYSTEM_TABLESPACE = 1809;
exports.ER_IO_READ_ERROR = 1810;
exports.ER_IO_WRITE_ERROR = 1811;
exports.ER_TABLESPACE_MISSING = 1812;
exports.ER_TABLESPACE_EXISTS = 1813;
exports.ER_TABLESPACE_DISCARDED = 1814;
exports.ER_INTERNAL_ERROR = 1815;
exports.ER_INNODB_IMPORT_ERROR = 1816;
exports.ER_INNODB_INDEX_CORRUPT = 1817;
exports.ER_INVALID_YEAR_COLUMN_LENGTH = 1818;
exports.ER_NOT_VALID_PASSWORD = 1819;
exports.ER_MUST_CHANGE_PASSWORD = 1820;
exports.ER_FK_NO_INDEX_CHILD = 1821;
exports.ER_FK_NO_INDEX_PARENT = 1822;
exports.ER_FK_FAIL_ADD_SYSTEM = 1823;
exports.ER_FK_CANNOT_OPEN_PARENT = 1824;
exports.ER_FK_INCORRECT_OPTION = 1825;
exports.ER_FK_DUP_NAME = 1826;
exports.ER_PASSWORD_FORMAT = 1827;
exports.ER_FK_COLUMN_CANNOT_DROP = 1828;
exports.ER_FK_COLUMN_CANNOT_DROP_CHILD = 1829;
exports.ER_FK_COLUMN_NOT_NULL = 1830;
exports.ER_DUP_INDEX = 1831;
exports.ER_FK_COLUMN_CANNOT_CHANGE = 1832;
exports.ER_FK_COLUMN_CANNOT_CHANGE_CHILD = 1833;
exports.ER_UNUSED5 = 1834;
exports.ER_MALFORMED_PACKET = 1835;
exports.ER_READ_ONLY_MODE = 1836;
exports.ER_GTID_NEXT_TYPE_UNDEFINED_GTID = 1837;
exports.ER_VARIABLE_NOT_SETTABLE_IN_SP = 1838;
exports.ER_CANT_SET_GTID_PURGED_WHEN_GTID_MODE_IS_OFF = 1839;
exports.ER_CANT_SET_GTID_PURGED_WHEN_GTID_EXECUTED_IS_NOT_EMPTY = 1840;
exports.ER_CANT_SET_GTID_PURGED_WHEN_OWNED_GTIDS_IS_NOT_EMPTY = 1841;
exports.ER_GTID_PURGED_WAS_CHANGED = 1842;
exports.ER_GTID_EXECUTED_WAS_CHANGED = 1843;
exports.ER_BINLOG_STMT_MODE_AND_NO_REPL_TABLES = 1844;
exports.ER_ALTER_OPERATION_NOT_SUPPORTED = 1845;
exports.ER_ALTER_OPERATION_NOT_SUPPORTED_REASON = 1846;
exports.ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_COPY = 1847;
exports.ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_PARTITION = 1848;
exports.ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_FK_RENAME = 1849;
exports.ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_COLUMN_TYPE = 1850;
exports.ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_FK_CHECK = 1851;
exports.ER_UNUSED6 = 1852;
exports.ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_NOPK = 1853;
exports.ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_AUTOINC = 1854;
exports.ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_HIDDEN_FTS = 1855;
exports.ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_CHANGE_FTS = 1856;
exports.ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_FTS = 1857;
exports.ER_SQL_REPLICA_SKIP_COUNTER_NOT_SETTABLE_IN_GTID_MODE = 1858;
exports.ER_DUP_UNKNOWN_IN_INDEX = 1859;
exports.ER_IDENT_CAUSES_TOO_LONG_PATH = 1860;
exports.ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_NOT_NULL = 1861;
exports.ER_MUST_CHANGE_PASSWORD_LOGIN = 1862;
exports.ER_ROW_IN_WRONG_PARTITION = 1863;
exports.ER_MTA_EVENT_BIGGER_PENDING_JOBS_SIZE_MAX = 1864;
exports.ER_INNODB_NO_FT_USES_PARSER = 1865;
exports.ER_BINLOG_LOGICAL_CORRUPTION = 1866;
exports.ER_WARN_PURGE_LOG_IN_USE = 1867;
exports.ER_WARN_PURGE_LOG_IS_ACTIVE = 1868;
exports.ER_AUTO_INCREMENT_CONFLICT = 1869;
exports.WARN_ON_BLOCKHOLE_IN_RBR = 1870;
exports.ER_REPLICA_CM_INIT_REPOSITORY = 1871;
exports.ER_REPLICA_AM_INIT_REPOSITORY = 1872;
exports.ER_ACCESS_DENIED_CHANGE_USER_ERROR = 1873;
exports.ER_INNODB_READ_ONLY = 1874;
exports.ER_STOP_REPLICA_SQL_THREAD_TIMEOUT = 1875;
exports.ER_STOP_REPLICA_IO_THREAD_TIMEOUT = 1876;
exports.ER_TABLE_CORRUPT = 1877;
exports.ER_TEMP_FILE_WRITE_FAILURE = 1878;
exports.ER_INNODB_FT_AUX_NOT_HEX_ID = 1879;
exports.ER_OLD_TEMPORALS_UPGRADED = 1880;
exports.ER_INNODB_FORCED_RECOVERY = 1881;
exports.ER_AES_INVALID_IV = 1882;
exports.ER_PLUGIN_CANNOT_BE_UNINSTALLED = 1883;
exports.ER_GTID_UNSAFE_BINLOG_SPLITTABLE_STATEMENT_AND_ASSIGNED_GTID = 1884;
exports.ER_REPLICA_HAS_MORE_GTIDS_THAN_SOURCE = 1885;
exports.ER_MISSING_KEY = 1886;
exports.WARN_NAMED_PIPE_ACCESS_EVERYONE = 1887;
exports.ER_FILE_CORRUPT = 3000;
exports.ER_ERROR_ON_SOURCE = 3001;
exports.ER_INCONSISTENT_ERROR = 3002;
exports.ER_STORAGE_ENGINE_NOT_LOADED = 3003;
exports.ER_GET_STACKED_DA_WITHOUT_ACTIVE_HANDLER = 3004;
exports.ER_WARN_LEGACY_SYNTAX_CONVERTED = 3005;
exports.ER_BINLOG_UNSAFE_FULLTEXT_PLUGIN = 3006;
exports.ER_CANNOT_DISCARD_TEMPORARY_TABLE = 3007;
exports.ER_FK_DEPTH_EXCEEDED = 3008;
exports.ER_COL_COUNT_DOESNT_MATCH_PLEASE_UPDATE_V2 = 3009;
exports.ER_WARN_TRIGGER_DOESNT_HAVE_CREATED = 3010;
exports.ER_REFERENCED_TRG_DOES_NOT_EXIST = 3011;
exports.ER_EXPLAIN_NOT_SUPPORTED = 3012;
exports.ER_INVALID_FIELD_SIZE = 3013;
exports.ER_MISSING_HA_CREATE_OPTION = 3014;
exports.ER_ENGINE_OUT_OF_MEMORY = 3015;
exports.ER_PASSWORD_EXPIRE_ANONYMOUS_USER = 3016;
exports.ER_REPLICA_SQL_THREAD_MUST_STOP = 3017;
exports.ER_NO_FT_MATERIALIZED_SUBQUERY = 3018;
exports.ER_INNODB_UNDO_LOG_FULL = 3019;
exports.ER_INVALID_ARGUMENT_FOR_LOGARITHM = 3020;
exports.ER_REPLICA_CHANNEL_IO_THREAD_MUST_STOP = 3021;
exports.ER_WARN_OPEN_TEMP_TABLES_MUST_BE_ZERO = 3022;
exports.ER_WARN_ONLY_SOURCE_LOG_FILE_NO_POS = 3023;
exports.ER_QUERY_TIMEOUT = 3024;
exports.ER_NON_RO_SELECT_DISABLE_TIMER = 3025;
exports.ER_DUP_LIST_ENTRY = 3026;
exports.ER_SQL_MODE_NO_EFFECT = 3027;
exports.ER_AGGREGATE_ORDER_FOR_UNION = 3028;
exports.ER_AGGREGATE_ORDER_NON_AGG_QUERY = 3029;
exports.ER_REPLICA_WORKER_STOPPED_PREVIOUS_THD_ERROR = 3030;
exports.ER_DONT_SUPPORT_REPLICA_PRESERVE_COMMIT_ORDER = 3031;
exports.ER_SERVER_OFFLINE_MODE = 3032;
exports.ER_GIS_DIFFERENT_SRIDS = 3033;
exports.ER_GIS_UNSUPPORTED_ARGUMENT = 3034;
exports.ER_GIS_UNKNOWN_ERROR = 3035;
exports.ER_GIS_UNKNOWN_EXCEPTION = 3036;
exports.ER_GIS_INVALID_DATA = 3037;
exports.ER_BOOST_GEOMETRY_EMPTY_INPUT_EXCEPTION = 3038;
exports.ER_BOOST_GEOMETRY_CENTROID_EXCEPTION = 3039;
exports.ER_BOOST_GEOMETRY_OVERLAY_INVALID_INPUT_EXCEPTION = 3040;
exports.ER_BOOST_GEOMETRY_TURN_INFO_EXCEPTION = 3041;
exports.ER_BOOST_GEOMETRY_SELF_INTERSECTION_POINT_EXCEPTION = 3042;
exports.ER_BOOST_GEOMETRY_UNKNOWN_EXCEPTION = 3043;
exports.ER_STD_BAD_ALLOC_ERROR = 3044;
exports.ER_STD_DOMAIN_ERROR = 3045;
exports.ER_STD_LENGTH_ERROR = 3046;
exports.ER_STD_INVALID_ARGUMENT = 3047;
exports.ER_STD_OUT_OF_RANGE_ERROR = 3048;
exports.ER_STD_OVERFLOW_ERROR = 3049;
exports.ER_STD_RANGE_ERROR = 3050;
exports.ER_STD_UNDERFLOW_ERROR = 3051;
exports.ER_STD_LOGIC_ERROR = 3052;
exports.ER_STD_RUNTIME_ERROR = 3053;
exports.ER_STD_UNKNOWN_EXCEPTION = 3054;
exports.ER_GIS_DATA_WRONG_ENDIANESS = 3055;
exports.ER_CHANGE_SOURCE_PASSWORD_LENGTH = 3056;
exports.ER_USER_LOCK_WRONG_NAME = 3057;
exports.ER_USER_LOCK_DEADLOCK = 3058;
exports.ER_REPLACE_INACCESSIBLE_ROWS = 3059;
exports.ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_GIS = 3060;
exports.ER_ILLEGAL_USER_VAR = 3061;
exports.ER_GTID_MODE_OFF = 3062;
exports.ER_UNSUPPORTED_BY_REPLICATION_THREAD = 3063;
exports.ER_INCORRECT_TYPE = 3064;
exports.ER_FIELD_IN_ORDER_NOT_SELECT = 3065;
exports.ER_AGGREGATE_IN_ORDER_NOT_SELECT = 3066;
exports.ER_INVALID_RPL_WILD_TABLE_FILTER_PATTERN = 3067;
exports.ER_NET_OK_PACKET_TOO_LARGE = 3068;
exports.ER_INVALID_JSON_DATA = 3069;
exports.ER_INVALID_GEOJSON_MISSING_MEMBER = 3070;
exports.ER_INVALID_GEOJSON_WRONG_TYPE = 3071;
exports.ER_INVALID_GEOJSON_UNSPECIFIED = 3072;
exports.ER_DIMENSION_UNSUPPORTED = 3073;
exports.ER_REPLICA_CHANNEL_DOES_NOT_EXIST = 3074;
exports.ER_SLAVE_MULTIPLE_CHANNELS_HOST_PORT = 3075;
exports.ER_REPLICA_CHANNEL_NAME_INVALID_OR_TOO_LONG = 3076;
exports.ER_REPLICA_NEW_CHANNEL_WRONG_REPOSITORY = 3077;
exports.ER_SLAVE_CHANNEL_DELETE = 3078;
exports.ER_REPLICA_MULTIPLE_CHANNELS_CMD = 3079;
exports.ER_REPLICA_MAX_CHANNELS_EXCEEDED = 3080;
exports.ER_REPLICA_CHANNEL_MUST_STOP = 3081;
exports.ER_REPLICA_CHANNEL_NOT_RUNNING = 3082;
exports.ER_REPLICA_CHANNEL_WAS_RUNNING = 3083;
exports.ER_REPLICA_CHANNEL_WAS_NOT_RUNNING = 3084;
exports.ER_REPLICA_CHANNEL_SQL_THREAD_MUST_STOP = 3085;
exports.ER_REPLICA_CHANNEL_SQL_SKIP_COUNTER = 3086;
exports.ER_WRONG_FIELD_WITH_GROUP_V2 = 3087;
exports.ER_MIX_OF_GROUP_FUNC_AND_FIELDS_V2 = 3088;
exports.ER_WARN_DEPRECATED_SYSVAR_UPDATE = 3089;
exports.ER_WARN_DEPRECATED_SQLMODE = 3090;
exports.ER_CANNOT_LOG_PARTIAL_DROP_DATABASE_WITH_GTID = 3091;
exports.ER_GROUP_REPLICATION_CONFIGURATION = 3092;
exports.ER_GROUP_REPLICATION_RUNNING = 3093;
exports.ER_GROUP_REPLICATION_APPLIER_INIT_ERROR = 3094;
exports.ER_GROUP_REPLICATION_STOP_APPLIER_THREAD_TIMEOUT = 3095;
exports.ER_GROUP_REPLICATION_COMMUNICATION_LAYER_SESSION_ERROR = 3096;
exports.ER_GROUP_REPLICATION_COMMUNICATION_LAYER_JOIN_ERROR = 3097;
exports.ER_BEFORE_DML_VALIDATION_ERROR = 3098;
exports.ER_PREVENTS_VARIABLE_WITHOUT_RBR = 3099;
exports.ER_RUN_HOOK_ERROR = 3100;
exports.ER_TRANSACTION_ROLLBACK_DURING_COMMIT = 3101;
exports.ER_GENERATED_COLUMN_FUNCTION_IS_NOT_ALLOWED = 3102;
exports.ER_UNSUPPORTED_ALTER_INPLACE_ON_VIRTUAL_COLUMN = 3103;
exports.ER_WRONG_FK_OPTION_FOR_GENERATED_COLUMN = 3104;
exports.ER_NON_DEFAULT_VALUE_FOR_GENERATED_COLUMN = 3105;
exports.ER_UNSUPPORTED_ACTION_ON_GENERATED_COLUMN = 3106;
exports.ER_GENERATED_COLUMN_NON_PRIOR = 3107;
exports.ER_DEPENDENT_BY_GENERATED_COLUMN = 3108;
exports.ER_GENERATED_COLUMN_REF_AUTO_INC = 3109;
exports.ER_FEATURE_NOT_AVAILABLE = 3110;
exports.ER_CANT_SET_GTID_MODE = 3111;
exports.ER_CANT_USE_AUTO_POSITION_WITH_GTID_MODE_OFF = 3112;
exports.ER_CANT_REPLICATE_ANONYMOUS_WITH_AUTO_POSITION = 3113;
exports.ER_CANT_REPLICATE_ANONYMOUS_WITH_GTID_MODE_ON = 3114;
exports.ER_CANT_REPLICATE_GTID_WITH_GTID_MODE_OFF = 3115;
exports.ER_CANT_ENFORCE_GTID_CONSISTENCY_WITH_ONGOING_GTID_VIOLATING_TX = 3116;
exports.ER_ENFORCE_GTID_CONSISTENCY_WARN_WITH_ONGOING_GTID_VIOLATING_TX = 3117;
exports.ER_ACCOUNT_HAS_BEEN_LOCKED = 3118;
exports.ER_WRONG_TABLESPACE_NAME = 3119;
exports.ER_TABLESPACE_IS_NOT_EMPTY = 3120;
exports.ER_WRONG_FILE_NAME = 3121;
exports.ER_BOOST_GEOMETRY_INCONSISTENT_TURNS_EXCEPTION = 3122;
exports.ER_WARN_OPTIMIZER_HINT_SYNTAX_ERROR = 3123;
exports.ER_WARN_BAD_MAX_EXECUTION_TIME = 3124;
exports.ER_WARN_UNSUPPORTED_MAX_EXECUTION_TIME = 3125;
exports.ER_WARN_CONFLICTING_HINT = 3126;
exports.ER_WARN_UNKNOWN_QB_NAME = 3127;
exports.ER_UNRESOLVED_HINT_NAME = 3128;
exports.ER_WARN_ON_MODIFYING_GTID_EXECUTED_TABLE = 3129;
exports.ER_PLUGGABLE_PROTOCOL_COMMAND_NOT_SUPPORTED = 3130;
exports.ER_LOCKING_SERVICE_WRONG_NAME = 3131;
exports.ER_LOCKING_SERVICE_DEADLOCK = 3132;
exports.ER_LOCKING_SERVICE_TIMEOUT = 3133;
exports.ER_GIS_MAX_POINTS_IN_GEOMETRY_OVERFLOWED = 3134;
exports.ER_SQL_MODE_MERGED = 3135;
exports.ER_VTOKEN_PLUGIN_TOKEN_MISMATCH = 3136;
exports.ER_VTOKEN_PLUGIN_TOKEN_NOT_FOUND = 3137;
exports.ER_CANT_SET_VARIABLE_WHEN_OWNING_GTID = 3138;
exports.ER_REPLICA_CHANNEL_OPERATION_NOT_ALLOWED = 3139;
exports.ER_INVALID_JSON_TEXT = 3140;
exports.ER_INVALID_JSON_TEXT_IN_PARAM = 3141;
exports.ER_INVALID_JSON_BINARY_DATA = 3142;
exports.ER_INVALID_JSON_PATH = 3143;
exports.ER_INVALID_JSON_CHARSET = 3144;
exports.ER_INVALID_JSON_CHARSET_IN_FUNCTION = 3145;
exports.ER_INVALID_TYPE_FOR_JSON = 3146;
exports.ER_INVALID_CAST_TO_JSON = 3147;
exports.ER_INVALID_JSON_PATH_CHARSET = 3148;
exports.ER_INVALID_JSON_PATH_WILDCARD = 3149;
exports.ER_JSON_VALUE_TOO_BIG = 3150;
exports.ER_JSON_KEY_TOO_BIG = 3151;
exports.ER_JSON_USED_AS_KEY = 3152;
exports.ER_JSON_VACUOUS_PATH = 3153;
exports.ER_JSON_BAD_ONE_OR_ALL_ARG = 3154;
exports.ER_NUMERIC_JSON_VALUE_OUT_OF_RANGE = 3155;
exports.ER_INVALID_JSON_VALUE_FOR_CAST = 3156;
exports.ER_JSON_DOCUMENT_TOO_DEEP = 3157;
exports.ER_JSON_DOCUMENT_NULL_KEY = 3158;
exports.ER_SECURE_TRANSPORT_REQUIRED = 3159;
exports.ER_NO_SECURE_TRANSPORTS_CONFIGURED = 3160;
exports.ER_DISABLED_STORAGE_ENGINE = 3161;
exports.ER_USER_DOES_NOT_EXIST = 3162;
exports.ER_USER_ALREADY_EXISTS = 3163;
exports.ER_AUDIT_API_ABORT = 3164;
exports.ER_INVALID_JSON_PATH_ARRAY_CELL = 3165;
exports.ER_BUFPOOL_RESIZE_INPROGRESS = 3166;
exports.ER_FEATURE_DISABLED_SEE_DOC = 3167;
exports.ER_SERVER_ISNT_AVAILABLE = 3168;
exports.ER_SESSION_WAS_KILLED = 3169;
exports.ER_CAPACITY_EXCEEDED = 3170;
exports.ER_CAPACITY_EXCEEDED_IN_RANGE_OPTIMIZER = 3171;
exports.ER_TABLE_NEEDS_UPG_PART = 3172;
exports.ER_CANT_WAIT_FOR_EXECUTED_GTID_SET_WHILE_OWNING_A_GTID = 3173;
exports.ER_CANNOT_ADD_FOREIGN_BASE_COL_VIRTUAL = 3174;
exports.ER_CANNOT_CREATE_VIRTUAL_INDEX_CONSTRAINT = 3175;
exports.ER_ERROR_ON_MODIFYING_GTID_EXECUTED_TABLE = 3176;
exports.ER_LOCK_REFUSED_BY_ENGINE = 3177;
exports.ER_UNSUPPORTED_ALTER_ONLINE_ON_VIRTUAL_COLUMN = 3178;
exports.ER_MASTER_KEY_ROTATION_NOT_SUPPORTED_BY_SE = 3179;
exports.ER_MASTER_KEY_ROTATION_ERROR_BY_SE = 3180;
exports.ER_MASTER_KEY_ROTATION_BINLOG_FAILED = 3181;
exports.ER_MASTER_KEY_ROTATION_SE_UNAVAILABLE = 3182;
exports.ER_TABLESPACE_CANNOT_ENCRYPT = 3183;
exports.ER_INVALID_ENCRYPTION_OPTION = 3184;
exports.ER_CANNOT_FIND_KEY_IN_KEYRING = 3185;
exports.ER_CAPACITY_EXCEEDED_IN_PARSER = 3186;
exports.ER_UNSUPPORTED_ALTER_ENCRYPTION_INPLACE = 3187;
exports.ER_KEYRING_UDF_KEYRING_SERVICE_ERROR = 3188;
exports.ER_USER_COLUMN_OLD_LENGTH = 3189;
exports.ER_CANT_RESET_SOURCE = 3190;
exports.ER_GROUP_REPLICATION_MAX_GROUP_SIZE = 3191;
exports.ER_CANNOT_ADD_FOREIGN_BASE_COL_STORED = 3192;
exports.ER_TABLE_REFERENCED = 3193;
exports.ER_PARTITION_ENGINE_DEPRECATED_FOR_TABLE = 3194;
exports.ER_WARN_USING_GEOMFROMWKB_TO_SET_SRID_ZERO = 3195;
exports.ER_WARN_USING_GEOMFROMWKB_TO_SET_SRID = 3196;
exports.ER_XA_RETRY = 3197;
exports.ER_KEYRING_AWS_UDF_AWS_KMS_ERROR = 3198;
exports.ER_BINLOG_UNSAFE_XA = 3199;
exports.ER_UDF_ERROR = 3200;
exports.ER_KEYRING_MIGRATION_FAILURE = 3201;
exports.ER_KEYRING_ACCESS_DENIED_ERROR = 3202;
exports.ER_KEYRING_MIGRATION_STATUS = 3203;
exports.ER_PLUGIN_FAILED_TO_OPEN_TABLES = 3204;
exports.ER_PLUGIN_FAILED_TO_OPEN_TABLE = 3205;
exports.ER_AUDIT_LOG_NO_KEYRING_PLUGIN_INSTALLED = 3206;
exports.ER_AUDIT_LOG_ENCRYPTION_PASSWORD_HAS_NOT_BEEN_SET = 3207;
exports.ER_AUDIT_LOG_COULD_NOT_CREATE_AES_KEY = 3208;
exports.ER_AUDIT_LOG_ENCRYPTION_PASSWORD_CANNOT_BE_FETCHED = 3209;
exports.ER_AUDIT_LOG_JSON_FILTERING_NOT_ENABLED = 3210;
exports.ER_AUDIT_LOG_UDF_INSUFFICIENT_PRIVILEGE = 3211;
exports.ER_AUDIT_LOG_SUPER_PRIVILEGE_REQUIRED = 3212;
exports.ER_COULD_NOT_REINITIALIZE_AUDIT_LOG_FILTERS = 3213;
exports.ER_AUDIT_LOG_UDF_INVALID_ARGUMENT_TYPE = 3214;
exports.ER_AUDIT_LOG_UDF_INVALID_ARGUMENT_COUNT = 3215;
exports.ER_AUDIT_LOG_HAS_NOT_BEEN_INSTALLED = 3216;
exports.ER_AUDIT_LOG_UDF_READ_INVALID_MAX_ARRAY_LENGTH_ARG_TYPE = 3217;
exports.ER_AUDIT_LOG_UDF_READ_INVALID_MAX_ARRAY_LENGTH_ARG_VALUE = 3218;
exports.ER_AUDIT_LOG_JSON_FILTER_PARSING_ERROR = 3219;
exports.ER_AUDIT_LOG_JSON_FILTER_NAME_CANNOT_BE_EMPTY = 3220;
exports.ER_AUDIT_LOG_JSON_USER_NAME_CANNOT_BE_EMPTY = 3221;
exports.ER_AUDIT_LOG_JSON_FILTER_DOES_NOT_EXISTS = 3222;
exports.ER_AUDIT_LOG_USER_FIRST_CHARACTER_MUST_BE_ALPHANUMERIC = 3223;
exports.ER_AUDIT_LOG_USER_NAME_INVALID_CHARACTER = 3224;
exports.ER_AUDIT_LOG_HOST_NAME_INVALID_CHARACTER = 3225;
exports.WARN_DEPRECATED_MAXDB_SQL_MODE_FOR_TIMESTAMP = 3226;
exports.ER_XA_REPLICATION_FILTERS = 3227;
exports.ER_CANT_OPEN_ERROR_LOG = 3228;
exports.ER_GROUPING_ON_TIMESTAMP_IN_DST = 3229;
exports.ER_CANT_START_SERVER_NAMED_PIPE = 3230;
exports.ER_WRITE_SET_EXCEEDS_LIMIT = 3231;
exports.ER_DEPRECATED_TLS_VERSION_SESSION_57 = 3232;
exports.ER_WARN_DEPRECATED_TLS_VERSION_57 = 3233;
exports.ER_WARN_WRONG_NATIVE_TABLE_STRUCTURE = 3234;
exports.ER_AES_INVALID_KDF_NAME = 3235;
exports.ER_AES_INVALID_KDF_ITERATIONS = 3236;
exports.WARN_AES_KEY_SIZE = 3237;
exports.ER_AES_INVALID_KDF_OPTION_SIZE = 3238;
exports.ER_UNSUPPORT_COMPRESSED_TEMPORARY_TABLE = 3500;
exports.ER_ACL_OPERATION_FAILED = 3501;
exports.ER_UNSUPPORTED_INDEX_ALGORITHM = 3502;
exports.ER_NO_SUCH_DB = 3503;
exports.ER_TOO_BIG_ENUM = 3504;
exports.ER_TOO_LONG_SET_ENUM_VALUE = 3505;
exports.ER_INVALID_DD_OBJECT = 3506;
exports.ER_UPDATING_DD_TABLE = 3507;
exports.ER_INVALID_DD_OBJECT_ID = 3508;
exports.ER_INVALID_DD_OBJECT_NAME = 3509;
exports.ER_TABLESPACE_MISSING_WITH_NAME = 3510;
exports.ER_TOO_LONG_ROUTINE_COMMENT = 3511;
exports.ER_SP_LOAD_FAILED = 3512;
exports.ER_INVALID_BITWISE_OPERANDS_SIZE = 3513;
exports.ER_INVALID_BITWISE_AGGREGATE_OPERANDS_SIZE = 3514;
exports.ER_WARN_UNSUPPORTED_HINT = 3515;
exports.ER_UNEXPECTED_GEOMETRY_TYPE = 3516;
exports.ER_SRS_PARSE_ERROR = 3517;
exports.ER_SRS_PROJ_PARAMETER_MISSING = 3518;
exports.ER_WARN_SRS_NOT_FOUND = 3519;
exports.ER_SRS_NOT_CARTESIAN = 3520;
exports.ER_SRS_NOT_CARTESIAN_UNDEFINED = 3521;
exports.ER_PK_INDEX_CANT_BE_INVISIBLE = 3522;
exports.ER_UNKNOWN_AUTHID = 3523;
exports.ER_FAILED_ROLE_GRANT = 3524;
exports.ER_OPEN_ROLE_TABLES = 3525;
exports.ER_FAILED_DEFAULT_ROLES = 3526;
exports.ER_COMPONENTS_NO_SCHEME = 3527;
exports.ER_COMPONENTS_NO_SCHEME_SERVICE = 3528;
exports.ER_COMPONENTS_CANT_LOAD = 3529;
exports.ER_ROLE_NOT_GRANTED = 3530;
exports.ER_FAILED_REVOKE_ROLE = 3531;
exports.ER_RENAME_ROLE = 3532;
exports.ER_COMPONENTS_CANT_ACQUIRE_SERVICE_IMPLEMENTATION = 3533;
exports.ER_COMPONENTS_CANT_SATISFY_DEPENDENCY = 3534;
exports.ER_COMPONENTS_LOAD_CANT_REGISTER_SERVICE_IMPLEMENTATION = 3535;
exports.ER_COMPONENTS_LOAD_CANT_INITIALIZE = 3536;
exports.ER_COMPONENTS_UNLOAD_NOT_LOADED = 3537;
exports.ER_COMPONENTS_UNLOAD_CANT_DEINITIALIZE = 3538;
exports.ER_COMPONENTS_CANT_RELEASE_SERVICE = 3539;
exports.ER_COMPONENTS_UNLOAD_CANT_UNREGISTER_SERVICE = 3540;
exports.ER_COMPONENTS_CANT_UNLOAD = 3541;
exports.ER_WARN_UNLOAD_THE_NOT_PERSISTED = 3542;
exports.ER_COMPONENT_TABLE_INCORRECT = 3543;
exports.ER_COMPONENT_MANIPULATE_ROW_FAILED = 3544;
exports.ER_COMPONENTS_UNLOAD_DUPLICATE_IN_GROUP = 3545;
exports.ER_CANT_SET_GTID_PURGED_DUE_SETS_CONSTRAINTS = 3546;
exports.ER_CANNOT_LOCK_USER_MANAGEMENT_CACHES = 3547;
exports.ER_SRS_NOT_FOUND = 3548;
exports.ER_VARIABLE_NOT_PERSISTED = 3549;
exports.ER_IS_QUERY_INVALID_CLAUSE = 3550;
exports.ER_UNABLE_TO_STORE_STATISTICS = 3551;
exports.ER_NO_SYSTEM_SCHEMA_ACCESS = 3552;
exports.ER_NO_SYSTEM_TABLESPACE_ACCESS = 3553;
exports.ER_NO_SYSTEM_TABLE_ACCESS = 3554;
exports.ER_NO_SYSTEM_TABLE_ACCESS_FOR_DICTIONARY_TABLE = 3555;
exports.ER_NO_SYSTEM_TABLE_ACCESS_FOR_SYSTEM_TABLE = 3556;
exports.ER_NO_SYSTEM_TABLE_ACCESS_FOR_TABLE = 3557;
exports.ER_INVALID_OPTION_KEY = 3558;
exports.ER_INVALID_OPTION_VALUE = 3559;
exports.ER_INVALID_OPTION_KEY_VALUE_PAIR = 3560;
exports.ER_INVALID_OPTION_START_CHARACTER = 3561;
exports.ER_INVALID_OPTION_END_CHARACTER = 3562;
exports.ER_INVALID_OPTION_CHARACTERS = 3563;
exports.ER_DUPLICATE_OPTION_KEY = 3564;
exports.ER_WARN_SRS_NOT_FOUND_AXIS_ORDER = 3565;
exports.ER_NO_ACCESS_TO_NATIVE_FCT = 3566;
exports.ER_RESET_SOURCE_TO_VALUE_OUT_OF_RANGE = 3567;
exports.ER_UNRESOLVED_TABLE_LOCK = 3568;
exports.ER_DUPLICATE_TABLE_LOCK = 3569;
exports.ER_BINLOG_UNSAFE_SKIP_LOCKED = 3570;
exports.ER_BINLOG_UNSAFE_NOWAIT = 3571;
exports.ER_LOCK_NOWAIT = 3572;
exports.ER_CTE_RECURSIVE_REQUIRES_UNION = 3573;
exports.ER_CTE_RECURSIVE_REQUIRES_NONRECURSIVE_FIRST = 3574;
exports.ER_CTE_RECURSIVE_FORBIDS_AGGREGATION = 3575;
exports.ER_CTE_RECURSIVE_FORBIDDEN_JOIN_ORDER = 3576;
exports.ER_CTE_RECURSIVE_REQUIRES_SINGLE_REFERENCE = 3577;
exports.ER_SWITCH_TMP_ENGINE = 3578;
exports.ER_WINDOW_NO_SUCH_WINDOW = 3579;
exports.ER_WINDOW_CIRCULARITY_IN_WINDOW_GRAPH = 3580;
exports.ER_WINDOW_NO_CHILD_PARTITIONING = 3581;
exports.ER_WINDOW_NO_INHERIT_FRAME = 3582;
exports.ER_WINDOW_NO_REDEFINE_ORDER_BY = 3583;
exports.ER_WINDOW_FRAME_START_ILLEGAL = 3584;
exports.ER_WINDOW_FRAME_END_ILLEGAL = 3585;
exports.ER_WINDOW_FRAME_ILLEGAL = 3586;
exports.ER_WINDOW_RANGE_FRAME_ORDER_TYPE = 3587;
exports.ER_WINDOW_RANGE_FRAME_TEMPORAL_TYPE = 3588;
exports.ER_WINDOW_RANGE_FRAME_NUMERIC_TYPE = 3589;
exports.ER_WINDOW_RANGE_BOUND_NOT_CONSTANT = 3590;
exports.ER_WINDOW_DUPLICATE_NAME = 3591;
exports.ER_WINDOW_ILLEGAL_ORDER_BY = 3592;
exports.ER_WINDOW_INVALID_WINDOW_FUNC_USE = 3593;
exports.ER_WINDOW_INVALID_WINDOW_FUNC_ALIAS_USE = 3594;
exports.ER_WINDOW_NESTED_WINDOW_FUNC_USE_IN_WINDOW_SPEC = 3595;
exports.ER_WINDOW_ROWS_INTERVAL_USE = 3596;
exports.ER_WINDOW_NO_GROUP_ORDER = 3597;
exports.ER_WINDOW_EXPLAIN_JSON = 3598;
exports.ER_WINDOW_FUNCTION_IGNORES_FRAME = 3599;
exports.ER_WL9236_NOW = 3600;
exports.ER_INVALID_NO_OF_ARGS = 3601;
exports.ER_FIELD_IN_GROUPING_NOT_GROUP_BY = 3602;
exports.ER_TOO_LONG_TABLESPACE_COMMENT = 3603;
exports.ER_ENGINE_CANT_DROP_TABLE = 3604;
exports.ER_ENGINE_CANT_DROP_MISSING_TABLE = 3605;
exports.ER_TABLESPACE_DUP_FILENAME = 3606;
exports.ER_DB_DROP_RMDIR2 = 3607;
exports.ER_IMP_NO_FILES_MATCHED = 3608;
exports.ER_IMP_SCHEMA_DOES_NOT_EXIST = 3609;
exports.ER_IMP_TABLE_ALREADY_EXISTS = 3610;
exports.ER_IMP_INCOMPATIBLE_MYSQLD_VERSION = 3611;
exports.ER_IMP_INCOMPATIBLE_DD_VERSION = 3612;
exports.ER_IMP_INCOMPATIBLE_SDI_VERSION = 3613;
exports.ER_WARN_INVALID_HINT = 3614;
exports.ER_VAR_DOES_NOT_EXIST = 3615;
exports.ER_LONGITUDE_OUT_OF_RANGE = 3616;
exports.ER_LATITUDE_OUT_OF_RANGE = 3617;
exports.ER_NOT_IMPLEMENTED_FOR_GEOGRAPHIC_SRS = 3618;
exports.ER_ILLEGAL_PRIVILEGE_LEVEL = 3619;
exports.ER_NO_SYSTEM_VIEW_ACCESS = 3620;
exports.ER_COMPONENT_FILTER_FLABBERGASTED = 3621;
exports.ER_PART_EXPR_TOO_LONG = 3622;
exports.ER_UDF_DROP_DYNAMICALLY_REGISTERED = 3623;
exports.ER_UNABLE_TO_STORE_COLUMN_STATISTICS = 3624;
exports.ER_UNABLE_TO_UPDATE_COLUMN_STATISTICS = 3625;
exports.ER_UNABLE_TO_DROP_COLUMN_STATISTICS = 3626;
exports.ER_UNABLE_TO_BUILD_HISTOGRAM = 3627;
exports.ER_MANDATORY_ROLE = 3628;
exports.ER_MISSING_TABLESPACE_FILE = 3629;
exports.ER_PERSIST_ONLY_ACCESS_DENIED_ERROR = 3630;
exports.ER_CMD_NEED_SUPER = 3631;
exports.ER_PATH_IN_DATADIR = 3632;
exports.ER_CLONE_DDL_IN_PROGRESS = 3633;
exports.ER_CLONE_TOO_MANY_CONCURRENT_CLONES = 3634;
exports.ER_APPLIER_LOG_EVENT_VALIDATION_ERROR = 3635;
exports.ER_CTE_MAX_RECURSION_DEPTH = 3636;
exports.ER_NOT_HINT_UPDATABLE_VARIABLE = 3637;
exports.ER_CREDENTIALS_CONTRADICT_TO_HISTORY = 3638;
exports.ER_WARNING_PASSWORD_HISTORY_CLAUSES_VOID = 3639;
exports.ER_CLIENT_DOES_NOT_SUPPORT = 3640;
exports.ER_I_S_SKIPPED_TABLESPACE = 3641;
exports.ER_TABLESPACE_ENGINE_MISMATCH = 3642;
exports.ER_WRONG_SRID_FOR_COLUMN = 3643;
exports.ER_CANNOT_ALTER_SRID_DUE_TO_INDEX = 3644;
exports.ER_WARN_BINLOG_PARTIAL_UPDATES_DISABLED = 3645;
exports.ER_WARN_BINLOG_V1_ROW_EVENTS_DISABLED = 3646;
exports.ER_WARN_BINLOG_PARTIAL_UPDATES_SUGGESTS_PARTIAL_IMAGES = 3647;
exports.ER_COULD_NOT_APPLY_JSON_DIFF = 3648;
exports.ER_CORRUPTED_JSON_DIFF = 3649;
exports.ER_RESOURCE_GROUP_EXISTS = 3650;
exports.ER_RESOURCE_GROUP_NOT_EXISTS = 3651;
exports.ER_INVALID_VCPU_ID = 3652;
exports.ER_INVALID_VCPU_RANGE = 3653;
exports.ER_INVALID_THREAD_PRIORITY = 3654;
exports.ER_DISALLOWED_OPERATION = 3655;
exports.ER_RESOURCE_GROUP_BUSY = 3656;
exports.ER_RESOURCE_GROUP_DISABLED = 3657;
exports.ER_FEATURE_UNSUPPORTED = 3658;
exports.ER_ATTRIBUTE_IGNORED = 3659;
exports.ER_INVALID_THREAD_ID = 3660;
exports.ER_RESOURCE_GROUP_BIND_FAILED = 3661;
exports.ER_INVALID_USE_OF_FORCE_OPTION = 3662;
exports.ER_GROUP_REPLICATION_COMMAND_FAILURE = 3663;
exports.ER_SDI_OPERATION_FAILED = 3664;
exports.ER_MISSING_JSON_TABLE_VALUE = 3665;
exports.ER_WRONG_JSON_TABLE_VALUE = 3666;
exports.ER_TF_MUST_HAVE_ALIAS = 3667;
exports.ER_TF_FORBIDDEN_JOIN_TYPE = 3668;
exports.ER_JT_VALUE_OUT_OF_RANGE = 3669;
exports.ER_JT_MAX_NESTED_PATH = 3670;
exports.ER_PASSWORD_EXPIRATION_NOT_SUPPORTED_BY_AUTH_METHOD = 3671;
exports.ER_INVALID_GEOJSON_CRS_NOT_TOP_LEVEL = 3672;
exports.ER_BAD_NULL_ERROR_NOT_IGNORED = 3673;
exports.WARN_USELESS_SPATIAL_INDEX = 3674;
exports.ER_DISK_FULL_NOWAIT = 3675;
exports.ER_PARSE_ERROR_IN_DIGEST_FN = 3676;
exports.ER_UNDISCLOSED_PARSE_ERROR_IN_DIGEST_FN = 3677;
exports.ER_SCHEMA_DIR_EXISTS = 3678;
exports.ER_SCHEMA_DIR_MISSING = 3679;
exports.ER_SCHEMA_DIR_CREATE_FAILED = 3680;
exports.ER_SCHEMA_DIR_UNKNOWN = 3681;
exports.ER_ONLY_IMPLEMENTED_FOR_SRID_0_AND_4326 = 3682;
exports.ER_BINLOG_EXPIRE_LOG_DAYS_AND_SECS_USED_TOGETHER = 3683;
exports.ER_REGEXP_BUFFER_OVERFLOW = 3684;
exports.ER_REGEXP_ILLEGAL_ARGUMENT = 3685;
exports.ER_REGEXP_INDEX_OUTOFBOUNDS_ERROR = 3686;
exports.ER_REGEXP_INTERNAL_ERROR = 3687;
exports.ER_REGEXP_RULE_SYNTAX = 3688;
exports.ER_REGEXP_BAD_ESCAPE_SEQUENCE = 3689;
exports.ER_REGEXP_UNIMPLEMENTED = 3690;
exports.ER_REGEXP_MISMATCHED_PAREN = 3691;
exports.ER_REGEXP_BAD_INTERVAL = 3692;
exports.ER_REGEXP_MAX_LT_MIN = 3693;
exports.ER_REGEXP_INVALID_BACK_REF = 3694;
exports.ER_REGEXP_LOOK_BEHIND_LIMIT = 3695;
exports.ER_REGEXP_MISSING_CLOSE_BRACKET = 3696;
exports.ER_REGEXP_INVALID_RANGE = 3697;
exports.ER_REGEXP_STACK_OVERFLOW = 3698;
exports.ER_REGEXP_TIME_OUT = 3699;
exports.ER_REGEXP_PATTERN_TOO_BIG = 3700;
exports.ER_CANT_SET_ERROR_LOG_SERVICE = 3701;
exports.ER_EMPTY_PIPELINE_FOR_ERROR_LOG_SERVICE = 3702;
exports.ER_COMPONENT_FILTER_DIAGNOSTICS = 3703;
exports.ER_NOT_IMPLEMENTED_FOR_CARTESIAN_SRS = 3704;
exports.ER_NOT_IMPLEMENTED_FOR_PROJECTED_SRS = 3705;
exports.ER_NONPOSITIVE_RADIUS = 3706;
exports.ER_RESTART_SERVER_FAILED = 3707;
exports.ER_SRS_MISSING_MANDATORY_ATTRIBUTE = 3708;
exports.ER_SRS_MULTIPLE_ATTRIBUTE_DEFINITIONS = 3709;
exports.ER_SRS_NAME_CANT_BE_EMPTY_OR_WHITESPACE = 3710;
exports.ER_SRS_ORGANIZATION_CANT_BE_EMPTY_OR_WHITESPACE = 3711;
exports.ER_SRS_ID_ALREADY_EXISTS = 3712;
exports.ER_WARN_SRS_ID_ALREADY_EXISTS = 3713;
exports.ER_CANT_MODIFY_SRID_0 = 3714;
exports.ER_WARN_RESERVED_SRID_RANGE = 3715;
exports.ER_CANT_MODIFY_SRS_USED_BY_COLUMN = 3716;
exports.ER_SRS_INVALID_CHARACTER_IN_ATTRIBUTE = 3717;
exports.ER_SRS_ATTRIBUTE_STRING_TOO_LONG = 3718;
exports.ER_DEPRECATED_UTF8_ALIAS = 3719;
exports.ER_DEPRECATED_NATIONAL = 3720;
exports.ER_INVALID_DEFAULT_UTF8MB4_COLLATION = 3721;
exports.ER_UNABLE_TO_COLLECT_LOG_STATUS = 3722;
exports.ER_RESERVED_TABLESPACE_NAME = 3723;
exports.ER_UNABLE_TO_SET_OPTION = 3724;
exports.ER_REPLICA_POSSIBLY_DIVERGED_AFTER_DDL = 3725;
exports.ER_SRS_NOT_GEOGRAPHIC = 3726;
exports.ER_POLYGON_TOO_LARGE = 3727;
exports.ER_SPATIAL_UNIQUE_INDEX = 3728;
exports.ER_INDEX_TYPE_NOT_SUPPORTED_FOR_SPATIAL_INDEX = 3729;
exports.ER_FK_CANNOT_DROP_PARENT = 3730;
exports.ER_GEOMETRY_PARAM_LONGITUDE_OUT_OF_RANGE = 3731;
exports.ER_GEOMETRY_PARAM_LATITUDE_OUT_OF_RANGE = 3732;
exports.ER_FK_CANNOT_USE_VIRTUAL_COLUMN = 3733;
exports.ER_FK_NO_COLUMN_PARENT = 3734;
exports.ER_CANT_SET_ERROR_SUPPRESSION_LIST = 3735;
exports.ER_SRS_GEOGCS_INVALID_AXES = 3736;
exports.ER_SRS_INVALID_SEMI_MAJOR_AXIS = 3737;
exports.ER_SRS_INVALID_INVERSE_FLATTENING = 3738;
exports.ER_SRS_INVALID_ANGULAR_UNIT = 3739;
exports.ER_SRS_INVALID_PRIME_MERIDIAN = 3740;
exports.ER_TRANSFORM_SOURCE_SRS_NOT_SUPPORTED = 3741;
exports.ER_TRANSFORM_TARGET_SRS_NOT_SUPPORTED = 3742;
exports.ER_TRANSFORM_SOURCE_SRS_MISSING_TOWGS84 = 3743;
exports.ER_TRANSFORM_TARGET_SRS_MISSING_TOWGS84 = 3744;
exports.ER_TEMP_TABLE_PREVENTS_SWITCH_SESSION_BINLOG_FORMAT = 3745;
exports.ER_TEMP_TABLE_PREVENTS_SWITCH_GLOBAL_BINLOG_FORMAT = 3746;
exports.ER_RUNNING_APPLIER_PREVENTS_SWITCH_GLOBAL_BINLOG_FORMAT = 3747;
exports.ER_CLIENT_GTID_UNSAFE_CREATE_DROP_TEMP_TABLE_IN_TRX_IN_SBR = 3748;
exports.ER_XA_CANT_CREATE_MDL_BACKUP = 3749;
exports.ER_TABLE_WITHOUT_PK = 3750;
exports.ER_WARN_DATA_TRUNCATED_FUNCTIONAL_INDEX = 3751;
exports.ER_WARN_DATA_OUT_OF_RANGE_FUNCTIONAL_INDEX = 3752;
exports.ER_FUNCTIONAL_INDEX_ON_JSON_OR_GEOMETRY_FUNCTION = 3753;
exports.ER_FUNCTIONAL_INDEX_REF_AUTO_INCREMENT = 3754;
exports.ER_CANNOT_DROP_COLUMN_FUNCTIONAL_INDEX = 3755;
exports.ER_FUNCTIONAL_INDEX_PRIMARY_KEY = 3756;
exports.ER_FUNCTIONAL_INDEX_ON_LOB = 3757;
exports.ER_FUNCTIONAL_INDEX_FUNCTION_IS_NOT_ALLOWED = 3758;
exports.ER_FULLTEXT_FUNCTIONAL_INDEX = 3759;
exports.ER_SPATIAL_FUNCTIONAL_INDEX = 3760;
exports.ER_WRONG_KEY_COLUMN_FUNCTIONAL_INDEX = 3761;
exports.ER_FUNCTIONAL_INDEX_ON_FIELD = 3762;
exports.ER_GENERATED_COLUMN_NAMED_FUNCTION_IS_NOT_ALLOWED = 3763;
exports.ER_GENERATED_COLUMN_ROW_VALUE = 3764;
exports.ER_GENERATED_COLUMN_VARIABLES = 3765;
exports.ER_DEPENDENT_BY_DEFAULT_GENERATED_VALUE = 3766;
exports.ER_DEFAULT_VAL_GENERATED_NON_PRIOR = 3767;
exports.ER_DEFAULT_VAL_GENERATED_REF_AUTO_INC = 3768;
exports.ER_DEFAULT_VAL_GENERATED_FUNCTION_IS_NOT_ALLOWED = 3769;
exports.ER_DEFAULT_VAL_GENERATED_NAMED_FUNCTION_IS_NOT_ALLOWED = 3770;
exports.ER_DEFAULT_VAL_GENERATED_ROW_VALUE = 3771;
exports.ER_DEFAULT_VAL_GENERATED_VARIABLES = 3772;
exports.ER_DEFAULT_AS_VAL_GENERATED = 3773;
exports.ER_UNSUPPORTED_ACTION_ON_DEFAULT_VAL_GENERATED = 3774;
exports.ER_GTID_UNSAFE_ALTER_ADD_COL_WITH_DEFAULT_EXPRESSION = 3775;
exports.ER_FK_CANNOT_CHANGE_ENGINE = 3776;
exports.ER_WARN_DEPRECATED_USER_SET_EXPR = 3777;
exports.ER_WARN_DEPRECATED_UTF8MB3_COLLATION = 3778;
exports.ER_WARN_DEPRECATED_NESTED_COMMENT_SYNTAX = 3779;
exports.ER_FK_INCOMPATIBLE_COLUMNS = 3780;
exports.ER_GR_HOLD_WAIT_TIMEOUT = 3781;
exports.ER_GR_HOLD_KILLED = 3782;
exports.ER_GR_HOLD_MEMBER_STATUS_ERROR = 3783;
exports.ER_RPL_ENCRYPTION_FAILED_TO_FETCH_KEY = 3784;
exports.ER_RPL_ENCRYPTION_KEY_NOT_FOUND = 3785;
exports.ER_RPL_ENCRYPTION_KEYRING_INVALID_KEY = 3786;
exports.ER_RPL_ENCRYPTION_HEADER_ERROR = 3787;
exports.ER_RPL_ENCRYPTION_FAILED_TO_ROTATE_LOGS = 3788;
exports.ER_RPL_ENCRYPTION_KEY_EXISTS_UNEXPECTED = 3789;
exports.ER_RPL_ENCRYPTION_FAILED_TO_GENERATE_KEY = 3790;
exports.ER_RPL_ENCRYPTION_FAILED_TO_STORE_KEY = 3791;
exports.ER_RPL_ENCRYPTION_FAILED_TO_REMOVE_KEY = 3792;
exports.ER_RPL_ENCRYPTION_UNABLE_TO_CHANGE_OPTION = 3793;
exports.ER_RPL_ENCRYPTION_MASTER_KEY_RECOVERY_FAILED = 3794;
exports.ER_SLOW_LOG_MODE_IGNORED_WHEN_NOT_LOGGING_TO_FILE = 3795;
exports.ER_GRP_TRX_CONSISTENCY_NOT_ALLOWED = 3796;
exports.ER_GRP_TRX_CONSISTENCY_BEFORE = 3797;
exports.ER_GRP_TRX_CONSISTENCY_AFTER_ON_TRX_BEGIN = 3798;
exports.ER_GRP_TRX_CONSISTENCY_BEGIN_NOT_ALLOWED = 3799;
exports.ER_FUNCTIONAL_INDEX_ROW_VALUE_IS_NOT_ALLOWED = 3800;
exports.ER_RPL_ENCRYPTION_FAILED_TO_ENCRYPT = 3801;
exports.ER_PAGE_TRACKING_NOT_STARTED = 3802;
exports.ER_PAGE_TRACKING_RANGE_NOT_TRACKED = 3803;
exports.ER_PAGE_TRACKING_CANNOT_PURGE = 3804;
exports.ER_RPL_ENCRYPTION_CANNOT_ROTATE_BINLOG_MASTER_KEY = 3805;
exports.ER_BINLOG_MASTER_KEY_RECOVERY_OUT_OF_COMBINATION = 3806;
exports.ER_BINLOG_MASTER_KEY_ROTATION_FAIL_TO_OPERATE_KEY = 3807;
exports.ER_BINLOG_MASTER_KEY_ROTATION_FAIL_TO_ROTATE_LOGS = 3808;
exports.ER_BINLOG_MASTER_KEY_ROTATION_FAIL_TO_REENCRYPT_LOG = 3809;
exports.ER_BINLOG_MASTER_KEY_ROTATION_FAIL_TO_CLEANUP_UNUSED_KEYS = 3810;
exports.ER_BINLOG_MASTER_KEY_ROTATION_FAIL_TO_CLEANUP_AUX_KEY = 3811;
exports.ER_NON_BOOLEAN_EXPR_FOR_CHECK_CONSTRAINT = 3812;
exports.ER_COLUMN_CHECK_CONSTRAINT_REFERENCES_OTHER_COLUMN = 3813;
exports.ER_CHECK_CONSTRAINT_NAMED_FUNCTION_IS_NOT_ALLOWED = 3814;
exports.ER_CHECK_CONSTRAINT_FUNCTION_IS_NOT_ALLOWED = 3815;
exports.ER_CHECK_CONSTRAINT_VARIABLES = 3816;
exports.ER_CHECK_CONSTRAINT_ROW_VALUE = 3817;
exports.ER_CHECK_CONSTRAINT_REFERS_AUTO_INCREMENT_COLUMN = 3818;
exports.ER_CHECK_CONSTRAINT_VIOLATED = 3819;
exports.ER_CHECK_CONSTRAINT_REFERS_UNKNOWN_COLUMN = 3820;
exports.ER_CHECK_CONSTRAINT_NOT_FOUND = 3821;
exports.ER_CHECK_CONSTRAINT_DUP_NAME = 3822;
exports.ER_CHECK_CONSTRAINT_CLAUSE_USING_FK_REFER_ACTION_COLUMN = 3823;
exports.WARN_UNENCRYPTED_TABLE_IN_ENCRYPTED_DB = 3824;
exports.ER_INVALID_ENCRYPTION_REQUEST = 3825;
exports.ER_CANNOT_SET_TABLE_ENCRYPTION = 3826;
exports.ER_CANNOT_SET_DATABASE_ENCRYPTION = 3827;
exports.ER_CANNOT_SET_TABLESPACE_ENCRYPTION = 3828;
exports.ER_TABLESPACE_CANNOT_BE_ENCRYPTED = 3829;
exports.ER_TABLESPACE_CANNOT_BE_DECRYPTED = 3830;
exports.ER_TABLESPACE_TYPE_UNKNOWN = 3831;
exports.ER_TARGET_TABLESPACE_UNENCRYPTED = 3832;
exports.ER_CANNOT_USE_ENCRYPTION_CLAUSE = 3833;
exports.ER_INVALID_MULTIPLE_CLAUSES = 3834;
exports.ER_UNSUPPORTED_USE_OF_GRANT_AS = 3835;
exports.ER_UKNOWN_AUTH_ID_OR_ACCESS_DENIED_FOR_GRANT_AS = 3836;
exports.ER_DEPENDENT_BY_FUNCTIONAL_INDEX = 3837;
exports.ER_PLUGIN_NOT_EARLY = 3838;
exports.ER_INNODB_REDO_LOG_ARCHIVE_START_SUBDIR_PATH = 3839;
exports.ER_INNODB_REDO_LOG_ARCHIVE_START_TIMEOUT = 3840;
exports.ER_INNODB_REDO_LOG_ARCHIVE_DIRS_INVALID = 3841;
exports.ER_INNODB_REDO_LOG_ARCHIVE_LABEL_NOT_FOUND = 3842;
exports.ER_INNODB_REDO_LOG_ARCHIVE_DIR_EMPTY = 3843;
exports.ER_INNODB_REDO_LOG_ARCHIVE_NO_SUCH_DIR = 3844;
exports.ER_INNODB_REDO_LOG_ARCHIVE_DIR_CLASH = 3845;
exports.ER_INNODB_REDO_LOG_ARCHIVE_DIR_PERMISSIONS = 3846;
exports.ER_INNODB_REDO_LOG_ARCHIVE_FILE_CREATE = 3847;
exports.ER_INNODB_REDO_LOG_ARCHIVE_ACTIVE = 3848;
exports.ER_INNODB_REDO_LOG_ARCHIVE_INACTIVE = 3849;
exports.ER_INNODB_REDO_LOG_ARCHIVE_FAILED = 3850;
exports.ER_INNODB_REDO_LOG_ARCHIVE_SESSION = 3851;
exports.ER_STD_REGEX_ERROR = 3852;
exports.ER_INVALID_JSON_TYPE = 3853;
exports.ER_CANNOT_CONVERT_STRING = 3854;
exports.ER_DEPENDENT_BY_PARTITION_FUNC = 3855;
exports.ER_WARN_DEPRECATED_FLOAT_AUTO_INCREMENT = 3856;
exports.ER_RPL_CANT_STOP_REPLICA_WHILE_LOCKED_BACKUP = 3857;
exports.ER_WARN_DEPRECATED_FLOAT_DIGITS = 3858;
exports.ER_WARN_DEPRECATED_FLOAT_UNSIGNED = 3859;
exports.ER_WARN_DEPRECATED_INTEGER_DISPLAY_WIDTH = 3860;
exports.ER_WARN_DEPRECATED_ZEROFILL = 3861;
exports.ER_CLONE_DONOR = 3862;
exports.ER_CLONE_PROTOCOL = 3863;
exports.ER_CLONE_DONOR_VERSION = 3864;
exports.ER_CLONE_OS = 3865;
exports.ER_CLONE_PLATFORM = 3866;
exports.ER_CLONE_CHARSET = 3867;
exports.ER_CLONE_CONFIG = 3868;
exports.ER_CLONE_SYS_CONFIG = 3869;
exports.ER_CLONE_PLUGIN_MATCH = 3870;
exports.ER_CLONE_LOOPBACK = 3871;
exports.ER_CLONE_ENCRYPTION = 3872;
exports.ER_CLONE_DISK_SPACE = 3873;
exports.ER_CLONE_IN_PROGRESS = 3874;
exports.ER_CLONE_DISALLOWED = 3875;
exports.ER_CANNOT_GRANT_ROLES_TO_ANONYMOUS_USER = 3876;
exports.ER_SECONDARY_ENGINE_PLUGIN = 3877;
exports.ER_SECOND_PASSWORD_CANNOT_BE_EMPTY = 3878;
exports.ER_DB_ACCESS_DENIED = 3879;
exports.ER_DA_AUTH_ID_WITH_SYSTEM_USER_PRIV_IN_MANDATORY_ROLES = 3880;
exports.ER_DA_RPL_GTID_TABLE_CANNOT_OPEN = 3881;
exports.ER_GEOMETRY_IN_UNKNOWN_LENGTH_UNIT = 3882;
exports.ER_DA_PLUGIN_INSTALL_ERROR = 3883;
exports.ER_NO_SESSION_TEMP = 3884;
exports.ER_DA_UNKNOWN_ERROR_NUMBER = 3885;
exports.ER_COLUMN_CHANGE_SIZE = 3886;
exports.ER_REGEXP_INVALID_CAPTURE_GROUP_NAME = 3887;
exports.ER_DA_SSL_LIBRARY_ERROR = 3888;
exports.ER_SECONDARY_ENGINE = 3889;
exports.ER_SECONDARY_ENGINE_DDL = 3890;
exports.ER_INCORRECT_CURRENT_PASSWORD = 3891;
exports.ER_MISSING_CURRENT_PASSWORD = 3892;
exports.ER_CURRENT_PASSWORD_NOT_REQUIRED = 3893;
exports.ER_PASSWORD_CANNOT_BE_RETAINED_ON_PLUGIN_CHANGE = 3894;
exports.ER_CURRENT_PASSWORD_CANNOT_BE_RETAINED = 3895;
exports.ER_PARTIAL_REVOKES_EXIST = 3896;
exports.ER_CANNOT_GRANT_SYSTEM_PRIV_TO_MANDATORY_ROLE = 3897;
exports.ER_XA_REPLICATION_FILTERS = 3898;
exports.ER_UNSUPPORTED_SQL_MODE = 3899;
exports.ER_REGEXP_INVALID_FLAG = 3900;
exports.ER_PARTIAL_REVOKE_AND_DB_GRANT_BOTH_EXISTS = 3901;
exports.ER_UNIT_NOT_FOUND = 3902;
exports.ER_INVALID_JSON_VALUE_FOR_FUNC_INDEX = 3903;
exports.ER_JSON_VALUE_OUT_OF_RANGE_FOR_FUNC_INDEX = 3904;
exports.ER_EXCEEDED_MV_KEYS_NUM = 3905;
exports.ER_EXCEEDED_MV_KEYS_SPACE = 3906;
exports.ER_FUNCTIONAL_INDEX_DATA_IS_TOO_LONG = 3907;
exports.ER_WRONG_MVI_VALUE = 3908;
exports.ER_WARN_FUNC_INDEX_NOT_APPLICABLE = 3909;
exports.ER_GRP_RPL_UDF_ERROR = 3910;
exports.ER_UPDATE_GTID_PURGED_WITH_GR = 3911;
exports.ER_GROUPING_ON_TIMESTAMP_IN_DST = 3912;
exports.ER_TABLE_NAME_CAUSES_TOO_LONG_PATH = 3913;
exports.ER_AUDIT_LOG_INSUFFICIENT_PRIVILEGE = 3914;
exports.ER_AUDIT_LOG_PASSWORD_HAS_BEEN_COPIED = 3915;
exports.ER_DA_GRP_RPL_STARTED_AUTO_REJOIN = 3916;
exports.ER_SYSVAR_CHANGE_DURING_QUERY = 3917;
exports.ER_GLOBSTAT_CHANGE_DURING_QUERY = 3918;
exports.ER_GRP_RPL_MESSAGE_SERVICE_INIT_FAILURE = 3919;
exports.ER_CHANGE_SOURCE_WRONG_COMPRESSION_ALGORITHM_CLIENT = 3920;
exports.ER_CHANGE_SOURCE_WRONG_COMPRESSION_LEVEL_CLIENT = 3921;
exports.ER_WRONG_COMPRESSION_ALGORITHM_CLIENT = 3922;
exports.ER_WRONG_COMPRESSION_LEVEL_CLIENT = 3923;
exports.ER_CHANGE_SOURCE_WRONG_COMPRESSION_ALGORITHM_LIST_CLIENT = 3924;
exports.ER_CLIENT_PRIVILEGE_CHECKS_USER_CANNOT_BE_ANONYMOUS = 3925;
exports.ER_CLIENT_PRIVILEGE_CHECKS_USER_DOES_NOT_EXIST = 3926;
exports.ER_CLIENT_PRIVILEGE_CHECKS_USER_CORRUPT = 3927;
exports.ER_CLIENT_PRIVILEGE_CHECKS_USER_NEEDS_RPL_APPLIER_PRIV = 3928;
exports.ER_WARN_DA_PRIVILEGE_NOT_REGISTERED = 3929;
exports.ER_CLIENT_KEYRING_UDF_KEY_INVALID = 3930;
exports.ER_CLIENT_KEYRING_UDF_KEY_TYPE_INVALID = 3931;
exports.ER_CLIENT_KEYRING_UDF_KEY_TOO_LONG = 3932;
exports.ER_CLIENT_KEYRING_UDF_KEY_TYPE_TOO_LONG = 3933;
exports.ER_JSON_SCHEMA_VALIDATION_ERROR_WITH_DETAILED_REPORT = 3934;
exports.ER_DA_UDF_INVALID_CHARSET_SPECIFIED = 3935;
exports.ER_DA_UDF_INVALID_CHARSET = 3936;
exports.ER_DA_UDF_INVALID_COLLATION = 3937;
exports.ER_DA_UDF_INVALID_EXTENSION_ARGUMENT_TYPE = 3938;
exports.ER_MULTIPLE_CONSTRAINTS_WITH_SAME_NAME = 3939;
exports.ER_CONSTRAINT_NOT_FOUND = 3940;
exports.ER_ALTER_CONSTRAINT_ENFORCEMENT_NOT_SUPPORTED = 3941;
exports.ER_TABLE_VALUE_CONSTRUCTOR_MUST_HAVE_COLUMNS = 3942;
exports.ER_TABLE_VALUE_CONSTRUCTOR_CANNOT_HAVE_DEFAULT = 3943;
exports.ER_CLIENT_QUERY_FAILURE_INVALID_NON_ROW_FORMAT = 3944;
exports.ER_REQUIRE_ROW_FORMAT_INVALID_VALUE = 3945;
exports.ER_FAILED_TO_DETERMINE_IF_ROLE_IS_MANDATORY = 3946;
exports.ER_FAILED_TO_FETCH_MANDATORY_ROLE_LIST = 3947;
exports.ER_CLIENT_LOCAL_FILES_DISABLED = 3948;
exports.ER_IMP_INCOMPATIBLE_CFG_VERSION = 3949;
exports.ER_DA_OOM = 3950;
exports.ER_DA_UDF_INVALID_ARGUMENT_TO_SET_CHARSET = 3951;
exports.ER_DA_UDF_INVALID_RETURN_TYPE_TO_SET_CHARSET = 3952;
exports.ER_MULTIPLE_INTO_CLAUSES = 3953;
exports.ER_MISPLACED_INTO = 3954;
exports.ER_USER_ACCESS_DENIED_FOR_USER_ACCOUNT_BLOCKED_BY_PASSWORD_LOCK = 3955;
exports.ER_WARN_DEPRECATED_YEAR_UNSIGNED = 3956;
exports.ER_CLONE_NETWORK_PACKET = 3957;
exports.ER_SDI_OPERATION_FAILED_MISSING_RECORD = 3958;
exports.ER_DEPENDENT_BY_CHECK_CONSTRAINT = 3959;
exports.ER_GRP_OPERATION_NOT_ALLOWED_GR_MUST_STOP = 3960;
exports.ER_WARN_DEPRECATED_JSON_TABLE_ON_ERROR_ON_EMPTY = 3961;
exports.ER_WARN_DEPRECATED_INNER_INTO = 3962;
exports.ER_WARN_DEPRECATED_VALUES_FUNCTION_ALWAYS_NULL = 3963;
exports.ER_WARN_DEPRECATED_SQL_CALC_FOUND_ROWS = 3964;
exports.ER_WARN_DEPRECATED_FOUND_ROWS = 3965;
exports.ER_MISSING_JSON_VALUE = 3966;
exports.ER_MULTIPLE_JSON_VALUES = 3967;
exports.ER_HOSTNAME_TOO_LONG = 3968;
exports.ER_WARN_CLIENT_DEPRECATED_PARTITION_PREFIX_KEY = 3969;
exports.ER_GROUP_REPLICATION_USER_EMPTY_MSG = 3970;
exports.ER_GROUP_REPLICATION_USER_MANDATORY_MSG = 3971;
exports.ER_GROUP_REPLICATION_PASSWORD_LENGTH = 3972;
exports.ER_SUBQUERY_TRANSFORM_REJECTED = 3973;
exports.ER_DA_GRP_RPL_RECOVERY_ENDPOINT_FORMAT = 3974;
exports.ER_DA_GRP_RPL_RECOVERY_ENDPOINT_INVALID = 3975;
exports.ER_WRONG_VALUE_FOR_VAR_PLUS_ACTIONABLE_PART = 3976;
exports.ER_STATEMENT_NOT_ALLOWED_AFTER_START_TRANSACTION = 3977;
exports.ER_FOREIGN_KEY_WITH_ATOMIC_CREATE_SELECT = 3978;
exports.ER_NOT_ALLOWED_WITH_START_TRANSACTION = 3979;
exports.ER_INVALID_JSON_ATTRIBUTE = 3980;
exports.ER_ENGINE_ATTRIBUTE_NOT_SUPPORTED = 3981;
exports.ER_INVALID_USER_ATTRIBUTE_JSON = 3982;
exports.ER_INNODB_REDO_DISABLED = 3983;
exports.ER_INNODB_REDO_ARCHIVING_ENABLED = 3984;
exports.ER_MDL_OUT_OF_RESOURCES = 3985;
exports.ER_IMPLICIT_COMPARISON_FOR_JSON = 3986;
exports.ER_FUNCTION_DOES_NOT_SUPPORT_CHARACTER_SET = 3987;
exports.ER_IMPOSSIBLE_STRING_CONVERSION = 3988;
exports.ER_SCHEMA_READ_ONLY = 3989;
exports.ER_RPL_ASYNC_RECONNECT_GTID_MODE_OFF = 3990;
exports.ER_RPL_ASYNC_RECONNECT_AUTO_POSITION_OFF = 3991;
exports.ER_DISABLE_GTID_MODE_REQUIRES_ASYNC_RECONNECT_OFF = 3992;
exports.ER_DISABLE_AUTO_POSITION_REQUIRES_ASYNC_RECONNECT_OFF = 3993;
exports.ER_INVALID_PARAMETER_USE = 3994;
exports.ER_CHARACTER_SET_MISMATCH = 3995;
exports.ER_WARN_VAR_VALUE_CHANGE_NOT_SUPPORTED = 3996;
exports.ER_INVALID_TIME_ZONE_INTERVAL = 3997;
exports.ER_INVALID_CAST = 3998;
exports.ER_HYPERGRAPH_NOT_SUPPORTED_YET = 3999;
exports.ER_WARN_HYPERGRAPH_EXPERIMENTAL = 4000;
exports.ER_DA_NO_ERROR_LOG_PARSER_CONFIGURED = 4001;
exports.ER_DA_ERROR_LOG_TABLE_DISABLED = 4002;
exports.ER_DA_ERROR_LOG_MULTIPLE_FILTERS = 4003;
exports.ER_DA_CANT_OPEN_ERROR_LOG = 4004;
exports.ER_USER_REFERENCED_AS_DEFINER = 4005;
exports.ER_CANNOT_USER_REFERENCED_AS_DEFINER = 4006;
exports.ER_REGEX_NUMBER_TOO_BIG = 4007;
exports.ER_SPVAR_NONINTEGER_TYPE = 4008;
exports.WARN_UNSUPPORTED_ACL_TABLES_READ = 4009;
exports.ER_BINLOG_UNSAFE_ACL_TABLE_READ_IN_DML_DDL = 4010;
exports.ER_STOP_REPLICA_MONITOR_IO_THREAD_TIMEOUT = 4011;
exports.ER_STARTING_REPLICA_MONITOR_IO_THREAD = 4012;
exports.ER_CANT_USE_ANONYMOUS_TO_GTID_WITH_GTID_MODE_NOT_ON = 4013;
exports.ER_CANT_COMBINE_ANONYMOUS_TO_GTID_AND_AUTOPOSITION = 4014;
exports.ER_ASSIGN_GTIDS_TO_ANONYMOUS_TRANSACTIONS_REQUIRES_GTID_MODE_ON = 4015;
exports.ER_SQL_REPLICA_SKIP_COUNTER_USED_WITH_GTID_MODE_ON = 4016;
exports.ER_USING_ASSIGN_GTIDS_TO_ANONYMOUS_TRANSACTIONS_AS_LOCAL_OR_UUID = 4017;
exports.ER_CANT_SET_ANONYMOUS_TO_GTID_AND_WAIT_UNTIL_SQL_THD_AFTER_GTIDS = 4018;
exports.ER_CANT_SET_SQL_AFTER_OR_BEFORE_GTIDS_WITH_ANONYMOUS_TO_GTID = 4019;
exports.ER_ANONYMOUS_TO_GTID_UUID_SAME_AS_GROUP_NAME = 4020;
exports.ER_CANT_USE_SAME_UUID_AS_GROUP_NAME = 4021;
exports.ER_GRP_RPL_RECOVERY_CHANNEL_STILL_RUNNING = 4022;
exports.ER_INNODB_INVALID_AUTOEXTEND_SIZE_VALUE = 4023;
exports.ER_INNODB_INCOMPATIBLE_WITH_TABLESPACE = 4024;
exports.ER_INNODB_AUTOEXTEND_SIZE_OUT_OF_RANGE = 4025;
exports.ER_CANNOT_USE_AUTOEXTEND_SIZE_CLAUSE = 4026;
exports.ER_ROLE_GRANTED_TO_ITSELF = 4027;
exports.ER_TABLE_MUST_HAVE_A_VISIBLE_COLUMN = 4028;
exports.ER_INNODB_COMPRESSION_FAILURE = 4029;
exports.ER_WARN_ASYNC_CONN_FAILOVER_NETWORK_NAMESPACE = 4030;
exports.ER_CLIENT_INTERACTION_TIMEOUT = 4031;
exports.ER_INVALID_CAST_TO_GEOMETRY = 4032;
exports.ER_INVALID_CAST_POLYGON_RING_DIRECTION = 4033;
exports.ER_GIS_DIFFERENT_SRIDS_AGGREGATION = 4034;
exports.ER_RELOAD_KEYRING_FAILURE = 4035;
exports.ER_SDI_GET_KEYS_INVALID_TABLESPACE = 4036;
exports.ER_CHANGE_RPL_SRC_WRONG_COMPRESSION_ALGORITHM_SIZE = 4037;
exports.ER_WARN_DEPRECATED_TLS_VERSION_FOR_CHANNEL_CLI = 4038;
exports.ER_CANT_USE_SAME_UUID_AS_VIEW_CHANGE_UUID = 4039;
exports.ER_ANONYMOUS_TO_GTID_UUID_SAME_AS_VIEW_CHANGE_UUID = 4040;
exports.ER_GRP_RPL_VIEW_CHANGE_UUID_FAIL_GET_VARIABLE = 4041;
exports.ER_WARN_ADUIT_LOG_MAX_SIZE_AND_PRUNE_SECONDS = 4042;
exports.ER_WARN_ADUIT_LOG_MAX_SIZE_CLOSE_TO_ROTATE_ON_SIZE = 4043;
exports.ER_KERBEROS_CREATE_USER = 4044;
exports.ER_INSTALL_PLUGIN_CONFLICT_CLIENT = 4045;
exports.ER_DA_ERROR_LOG_COMPONENT_FLUSH_FAILED = 4046;
exports.ER_WARN_SQL_AFTER_MTS_GAPS_GAP_NOT_CALCULATED = 4047;
exports.ER_INVALID_ASSIGNMENT_TARGET = 4048;
exports.ER_OPERATION_NOT_ALLOWED_ON_GR_SECONDARY = 4049;
exports.ER_GRP_RPL_FAILOVER_CHANNEL_STATUS_PROPAGATION = 4050;
exports.ER_WARN_AUDIT_LOG_FORMAT_UNIX_TIMESTAMP_ONLY_WHEN_JSON = 4051;
exports.ER_INVALID_MFA_PLUGIN_SPECIFIED = 4052;
exports.ER_IDENTIFIED_BY_UNSUPPORTED = 4053;
exports.ER_INVALID_PLUGIN_FOR_REGISTRATION = 4054;
exports.ER_PLUGIN_REQUIRES_REGISTRATION = 4055;
exports.ER_MFA_METHOD_EXISTS = 4056;
exports.ER_MFA_METHOD_NOT_EXISTS = 4057;
exports.ER_AUTHENTICATION_POLICY_MISMATCH = 4058;
exports.ER_PLUGIN_REGISTRATION_DONE = 4059;
exports.ER_INVALID_USER_FOR_REGISTRATION = 4060;
exports.ER_USER_REGISTRATION_FAILED = 4061;
exports.ER_MFA_METHODS_INVALID_ORDER = 4062;
exports.ER_MFA_METHODS_IDENTICAL = 4063;
exports.ER_INVALID_MFA_OPERATIONS_FOR_PASSWORDLESS_USER = 4064;
exports.ER_CHANGE_REPLICATION_SOURCE_NO_OPTIONS_FOR_GTID_ONLY = 4065;
exports.ER_CHANGE_REP_SOURCE_CANT_DISABLE_REQ_ROW_FORMAT_WITH_GTID_ONLY = 4066;
exports.ER_CHANGE_REP_SOURCE_CANT_DISABLE_AUTO_POSITION_WITH_GTID_ONLY = 4067;
exports.ER_CHANGE_REP_SOURCE_CANT_DISABLE_GTID_ONLY_WITHOUT_POSITIONS = 4068;
exports.ER_CHANGE_REP_SOURCE_CANT_DISABLE_AUTO_POS_WITHOUT_POSITIONS = 4069;
exports.ER_CHANGE_REP_SOURCE_GR_CHANNEL_WITH_GTID_MODE_NOT_ON = 4070;
exports.ER_CANT_USE_GTID_ONLY_WITH_GTID_MODE_NOT_ON = 4071;
exports.ER_WARN_C_DISABLE_GTID_ONLY_WITH_SOURCE_AUTO_POS_INVALID_POS = 4072;
exports.ER_DA_SSL_FIPS_MODE_ERROR = 4073;
exports.ER_VALUE_OUT_OF_RANGE = 4074;
exports.ER_FULLTEXT_WITH_ROLLUP = 4075;
exports.ER_REGEXP_MISSING_RESOURCE = 4076;
exports.ER_WARN_REGEXP_USING_DEFAULT = 4077;
exports.ER_REGEXP_MISSING_FILE = 4078;
exports.ER_WARN_DEPRECATED_COLLATION = 4079;
exports.ER_CONCURRENT_PROCEDURE_USAGE = 4080;
exports.ER_DA_GLOBAL_CONN_LIMIT = 4081;
exports.ER_DA_CONN_LIMIT = 4082;
exports.ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_COLUMN_TYPE_INSTANT = 4083;
exports.ER_WARN_SF_UDF_NAME_COLLISION = 4084;
exports.ER_CANNOT_PURGE_BINLOG_WITH_BACKUP_LOCK = 4085;
exports.ER_TOO_MANY_WINDOWS = 4086;
exports.ER_MYSQLBACKUP_CLIENT_MSG = 4087;
exports.ER_COMMENT_CONTAINS_INVALID_STRING = 4088;
exports.ER_DEFINITION_CONTAINS_INVALID_STRING = 4089;
exports.ER_CANT_EXECUTE_COMMAND_WITH_ASSIGNED_GTID_NEXT = 4090;
exports.ER_XA_TEMP_TABLE = 4091;
exports.ER_INNODB_MAX_ROW_VERSION = 4092;
exports.ER_INNODB_INSTANT_ADD_NOT_SUPPORTED_MAX_SIZE = 4093;
exports.ER_OPERATION_NOT_ALLOWED_WHILE_PRIMARY_CHANGE_IS_RUNNING = 4094;
exports.ER_WARN_DEPRECATED_DATETIME_DELIMITER = 4095;
exports.ER_WARN_DEPRECATED_SUPERFLUOUS_DELIMITER = 4096;
exports.ER_CANNOT_PERSIST_SENSITIVE_VARIABLES = 4097;
exports.ER_WARN_CANNOT_SECURELY_PERSIST_SENSITIVE_VARIABLES = 4098;
exports.ER_WARN_TRG_ALREADY_EXISTS = 4099;
exports.ER_IF_NOT_EXISTS_UNSUPPORTED_TRG_EXISTS_ON_DIFFERENT_TABLE = 4100;
exports.ER_IF_NOT_EXISTS_UNSUPPORTED_UDF_NATIVE_FCT_NAME_COLLISION = 4101;
exports.ER_SET_PASSWORD_AUTH_PLUGIN_ERROR = 4102;
exports.ER_REDUCED_DBLWR_FILE_CORRUPTED = 4103;
exports.ER_REDUCED_DBLWR_PAGE_FOUND = 4104;
exports.ER_SRS_INVALID_LATITUDE_OF_ORIGIN = 4105;
exports.ER_SRS_INVALID_LONGITUDE_OF_ORIGIN = 4106;
exports.ER_SRS_UNUSED_PROJ_PARAMETER_PRESENT = 4107;
exports.ER_GIPK_COLUMN_EXISTS = 4108;
exports.ER_GIPK_FAILED_AUTOINC_COLUMN_EXISTS = 4109;
exports.ER_GIPK_COLUMN_ALTER_NOT_ALLOWED = 4110;
exports.ER_DROP_PK_COLUMN_TO_DROP_GIPK = 4111;
exports.ER_CREATE_SELECT_WITH_GIPK_DISALLOWED_IN_SBR = 4112;
exports.ER_DA_EXPIRE_LOGS_DAYS_IGNORED = 4113;
exports.ER_CTE_RECURSIVE_NOT_UNION = 4114;
exports.ER_COMMAND_BACKEND_FAILED_TO_FETCH_SECURITY_CTX = 4115;
exports.ER_COMMAND_SERVICE_BACKEND_FAILED = 4116;
exports.ER_CLIENT_FILE_PRIVILEGE_FOR_REPLICATION_CHECKS = 4117;
exports.ER_GROUP_REPLICATION_FORCE_MEMBERS_COMMAND_FAILURE = 4118;
exports.ER_WARN_DEPRECATED_IDENT = 4119;
exports.ER_INTERSECT_ALL_MAX_DUPLICATES_EXCEEDED = 4120;
exports.ER_TP_QUERY_THRS_PER_GRP_EXCEEDS_TXN_THR_LIMIT = 4121;
exports.ER_BAD_TIMESTAMP_FORMAT = 4122;
exports.ER_SHAPE_PRIDICTION_UDF = 4123;
exports.ER_SRS_INVALID_HEIGHT = 4124;
exports.ER_SRS_INVALID_SCALING = 4125;
exports.ER_SRS_INVALID_ZONE_WIDTH = 4126;
exports.ER_SRS_INVALID_LATITUDE_POLAR_STERE_VAR_A = 4127;
exports.ER_WARN_DEPRECATED_CLIENT_NO_SCHEMA_OPTION = 4128;
exports.ER_TABLE_NOT_EMPTY = 4129;
exports.ER_TABLE_NO_PRIMARY_KEY = 4130;
exports.ER_TABLE_IN_SHARED_TABLESPACE = 4131;
exports.ER_INDEX_OTHER_THAN_PK = 4132;
exports.ER_LOAD_BULK_DATA_UNSORTED = 4133;
exports.ER_BULK_EXECUTOR_ERROR = 4134;
exports.ER_BULK_READER_LIBCURL_INIT_FAILED = 4135;
exports.ER_BULK_READER_LIBCURL_ERROR = 4136;
exports.ER_BULK_READER_SERVER_ERROR = 4137;
exports.ER_BULK_READER_COMMUNICATION_ERROR = 4138;
exports.ER_BULK_LOAD_DATA_FAILED = 4139;
exports.ER_BULK_LOADER_COLUMN_TOO_BIG_FOR_LEFTOVER_BUFFER = 4140;
exports.ER_BULK_LOADER_COMPONENT_ERROR = 4141;
exports.ER_BULK_LOADER_FILE_CONTAINS_LESS_LINES_THAN_IGNORE_CLAUSE = 4142;
exports.ER_BULK_PARSER_MISSING_ENCLOSED_BY = 4143;
exports.ER_BULK_PARSER_ROW_BUFFER_MAX_TOTAL_COLS_EXCEEDED = 4144;
exports.ER_BULK_PARSER_COPY_BUFFER_SIZE_EXCEEDED = 4145;
exports.ER_BULK_PARSER_UNEXPECTED_END_OF_INPUT = 4146;
exports.ER_BULK_PARSER_UNEXPECTED_ROW_TERMINATOR = 4147;
exports.ER_BULK_PARSER_UNEXPECTED_CHAR_AFTER_ENDING_ENCLOSED_BY = 4148;
exports.ER_BULK_PARSER_UNEXPECTED_CHAR_AFTER_NULL_ESCAPE = 4149;
exports.ER_BULK_PARSER_UNEXPECTED_CHAR_AFTER_COLUMN_TERMINATOR = 4150;
exports.ER_BULK_PARSER_INCOMPLETE_ESCAPE_SEQUENCE = 4151;
exports.ER_LOAD_BULK_DATA_FAILED = 4152;
exports.ER_LOAD_BULK_DATA_WRONG_VALUE_FOR_FIELD = 4153;
exports.ER_LOAD_BULK_DATA_WARN_NULL_TO_NOTNULL = 4154;
exports.ER_REQUIRE_TABLE_PRIMARY_KEY_CHECK_GENERATE_WITH_GR = 4155;
exports.ER_CANT_CHANGE_SYS_VAR_IN_READ_ONLY_MODE = 4156;
exports.ER_INNODB_INSTANT_ADD_DROP_NOT_SUPPORTED_MAX_SIZE = 4157;
exports.ER_INNODB_INSTANT_ADD_NOT_SUPPORTED_MAX_FIELDS = 4158;
exports.ER_CANT_SET_PERSISTED = 4159;
exports.ER_INSTALL_COMPONENT_SET_NULL_VALUE = 4160;
exports.ER_INSTALL_COMPONENT_SET_UNUSED_VALUE = 4161;
exports.ER_WARN_DEPRECATED_USER_DEFINED_COLLATIONS = 4162;

// Lookup-by-number table
exports[1] = 'EE_CANTCREATEFILE';
exports[2] = 'EE_READ';
exports[3] = 'EE_WRITE';
exports[4] = 'EE_BADCLOSE';
exports[5] = 'EE_OUTOFMEMORY';
exports[6] = 'EE_DELETE';
exports[7] = 'EE_LINK';
exports[9] = 'EE_EOFERR';
exports[10] = 'EE_CANTLOCK';
exports[11] = 'EE_CANTUNLOCK';
exports[12] = 'EE_DIR';
exports[13] = 'EE_STAT';
exports[14] = 'EE_CANT_CHSIZE';
exports[15] = 'EE_CANT_OPEN_STREAM';
exports[16] = 'EE_GETWD';
exports[17] = 'EE_SETWD';
exports[18] = 'EE_LINK_WARNING';
exports[19] = 'EE_OPEN_WARNING';
exports[20] = 'EE_DISK_FULL';
exports[21] = 'EE_CANT_MKDIR';
exports[22] = 'EE_UNKNOWN_CHARSET';
exports[23] = 'EE_OUT_OF_FILERESOURCES';
exports[24] = 'EE_CANT_READLINK';
exports[25] = 'EE_CANT_SYMLINK';
exports[26] = 'EE_REALPATH';
exports[27] = 'EE_SYNC';
exports[28] = 'EE_UNKNOWN_COLLATION';
exports[29] = 'EE_FILENOTFOUND';
exports[30] = 'EE_FILE_NOT_CLOSED';
exports[31] = 'EE_CHANGE_OWNERSHIP';
exports[32] = 'EE_CHANGE_PERMISSIONS';
exports[33] = 'EE_CANT_SEEK';
exports[34] = 'EE_CAPACITY_EXCEEDED';
exports[35] = 'EE_DISK_FULL_WITH_RETRY_MSG';
exports[36] = 'EE_FAILED_TO_CREATE_TIMER';
exports[37] = 'EE_FAILED_TO_DELETE_TIMER';
exports[38] = 'EE_FAILED_TO_CREATE_TIMER_QUEUE';
exports[39] = 'EE_FAILED_TO_START_TIMER_NOTIFY_THREAD';
exports[40] = 'EE_FAILED_TO_CREATE_TIMER_NOTIFY_THREAD_INTERRUPT_EVENT';
exports[41] = 'EE_EXITING_TIMER_NOTIFY_THREAD';
exports[42] = 'EE_WIN_LIBRARY_LOAD_FAILED';
exports[43] = 'EE_WIN_RUN_TIME_ERROR_CHECK';
exports[44] = 'EE_FAILED_TO_DETERMINE_LARGE_PAGE_SIZE';
exports[45] = 'EE_FAILED_TO_KILL_ALL_THREADS';
exports[46] = 'EE_FAILED_TO_CREATE_IO_COMPLETION_PORT';
exports[47] = 'EE_FAILED_TO_OPEN_DEFAULTS_FILE';
exports[48] = 'EE_FAILED_TO_HANDLE_DEFAULTS_FILE';
exports[49] = 'EE_WRONG_DIRECTIVE_IN_CONFIG_FILE';
exports[50] = 'EE_SKIPPING_DIRECTIVE_DUE_TO_MAX_INCLUDE_RECURSION';
exports[51] = 'EE_INCORRECT_GRP_DEFINITION_IN_CONFIG_FILE';
exports[52] = 'EE_OPTION_WITHOUT_GRP_IN_CONFIG_FILE';
exports[53] = 'EE_CONFIG_FILE_PERMISSION_ERROR';
exports[54] = 'EE_IGNORE_WORLD_WRITABLE_CONFIG_FILE';
exports[55] = 'EE_USING_DISABLED_OPTION';
exports[56] = 'EE_USING_DISABLED_SHORT_OPTION';
exports[57] = 'EE_USING_PASSWORD_ON_CLI_IS_INSECURE';
exports[58] = 'EE_UNKNOWN_SUFFIX_FOR_VARIABLE';
exports[59] = 'EE_SSL_ERROR_FROM_FILE';
exports[60] = 'EE_SSL_ERROR';
exports[61] = 'EE_NET_SEND_ERROR_IN_BOOTSTRAP';
exports[62] = 'EE_PACKETS_OUT_OF_ORDER';
exports[63] = 'EE_UNKNOWN_PROTOCOL_OPTION';
exports[64] = 'EE_FAILED_TO_LOCATE_SERVER_PUBLIC_KEY';
exports[65] = 'EE_PUBLIC_KEY_NOT_IN_PEM_FORMAT';
exports[66] = 'EE_DEBUG_INFO';
exports[67] = 'EE_UNKNOWN_VARIABLE';
exports[68] = 'EE_UNKNOWN_OPTION';
exports[69] = 'EE_UNKNOWN_SHORT_OPTION';
exports[70] = 'EE_OPTION_WITHOUT_ARGUMENT';
exports[71] = 'EE_OPTION_REQUIRES_ARGUMENT';
exports[72] = 'EE_SHORT_OPTION_REQUIRES_ARGUMENT';
exports[73] = 'EE_OPTION_IGNORED_DUE_TO_INVALID_VALUE';
exports[74] = 'EE_OPTION_WITH_EMPTY_VALUE';
exports[75] = 'EE_FAILED_TO_ASSIGN_MAX_VALUE_TO_OPTION';
exports[76] = 'EE_INCORRECT_BOOLEAN_VALUE_FOR_OPTION';
exports[77] = 'EE_FAILED_TO_SET_OPTION_VALUE';
exports[78] = 'EE_INCORRECT_INT_VALUE_FOR_OPTION';
exports[79] = 'EE_INCORRECT_UINT_VALUE_FOR_OPTION';
exports[80] = 'EE_ADJUSTED_SIGNED_VALUE_FOR_OPTION';
exports[81] = 'EE_ADJUSTED_UNSIGNED_VALUE_FOR_OPTION';
exports[82] = 'EE_ADJUSTED_ULONGLONG_VALUE_FOR_OPTION';
exports[83] = 'EE_ADJUSTED_DOUBLE_VALUE_FOR_OPTION';
exports[84] = 'EE_INVALID_DECIMAL_VALUE_FOR_OPTION';
exports[85] = 'EE_COLLATION_PARSER_ERROR';
exports[86] = 'EE_FAILED_TO_RESET_BEFORE_PRIMARY_IGNORABLE_CHAR';
exports[87] = 'EE_FAILED_TO_RESET_BEFORE_TERTIARY_IGNORABLE_CHAR';
exports[88] = 'EE_SHIFT_CHAR_OUT_OF_RANGE';
exports[89] = 'EE_RESET_CHAR_OUT_OF_RANGE';
exports[90] = 'EE_UNKNOWN_LDML_TAG';
exports[91] = 'EE_FAILED_TO_RESET_BEFORE_SECONDARY_IGNORABLE_CHAR';
exports[92] = 'EE_FAILED_PROCESSING_DIRECTIVE';
exports[93] = 'EE_PTHREAD_KILL_FAILED';
exports[120] = 'HA_ERR_KEY_NOT_FOUND';
exports[121] = 'HA_ERR_FOUND_DUPP_KEY';
exports[122] = 'HA_ERR_INTERNAL_ERROR';
exports[123] = 'HA_ERR_RECORD_CHANGED';
exports[124] = 'HA_ERR_WRONG_INDEX';
exports[125] = 'HA_ERR_ROLLED_BACK';
exports[126] = 'HA_ERR_CRASHED';
exports[127] = 'HA_ERR_WRONG_IN_RECORD';
exports[128] = 'HA_ERR_OUT_OF_MEM';
exports[130] = 'HA_ERR_NOT_A_TABLE';
exports[131] = 'HA_ERR_WRONG_COMMAND';
exports[132] = 'HA_ERR_OLD_FILE';
exports[133] = 'HA_ERR_NO_ACTIVE_RECORD';
exports[134] = 'HA_ERR_RECORD_DELETED';
exports[135] = 'HA_ERR_RECORD_FILE_FULL';
exports[136] = 'HA_ERR_INDEX_FILE_FULL';
exports[137] = 'HA_ERR_END_OF_FILE';
exports[138] = 'HA_ERR_UNSUPPORTED';
exports[139] = 'HA_ERR_TOO_BIG_ROW';
exports[140] = 'HA_WRONG_CREATE_OPTION';
exports[141] = 'HA_ERR_FOUND_DUPP_UNIQUE';
exports[142] = 'HA_ERR_UNKNOWN_CHARSET';
exports[143] = 'HA_ERR_WRONG_MRG_TABLE_DEF';
exports[144] = 'HA_ERR_CRASHED_ON_REPAIR';
exports[145] = 'HA_ERR_CRASHED_ON_USAGE';
exports[146] = 'HA_ERR_LOCK_WAIT_TIMEOUT';
exports[147] = 'HA_ERR_LOCK_TABLE_FULL';
exports[148] = 'HA_ERR_READ_ONLY_TRANSACTION';
exports[149] = 'HA_ERR_LOCK_DEADLOCK';
exports[150] = 'HA_ERR_CANNOT_ADD_FOREIGN';
exports[151] = 'HA_ERR_NO_REFERENCED_ROW';
exports[152] = 'HA_ERR_ROW_IS_REFERENCED';
exports[153] = 'HA_ERR_NO_SAVEPOINT';
exports[154] = 'HA_ERR_NON_UNIQUE_BLOCK_SIZE';
exports[155] = 'HA_ERR_NO_SUCH_TABLE';
exports[156] = 'HA_ERR_TABLE_EXIST';
exports[157] = 'HA_ERR_NO_CONNECTION';
exports[158] = 'HA_ERR_NULL_IN_SPATIAL';
exports[159] = 'HA_ERR_TABLE_DEF_CHANGED';
exports[160] = 'HA_ERR_NO_PARTITION_FOUND';
exports[161] = 'HA_ERR_RBR_LOGGING_FAILED';
exports[162] = 'HA_ERR_DROP_INDEX_FK';
exports[163] = 'HA_ERR_FOREIGN_DUPLICATE_KEY';
exports[164] = 'HA_ERR_TABLE_NEEDS_UPGRADE';
exports[165] = 'HA_ERR_TABLE_READONLY';
exports[166] = 'HA_ERR_AUTOINC_READ_FAILED';
exports[167] = 'HA_ERR_AUTOINC_ERANGE';
exports[168] = 'HA_ERR_GENERIC';
exports[169] = 'HA_ERR_RECORD_IS_THE_SAME';
exports[170] = 'HA_ERR_LOGGING_IMPOSSIBLE';
exports[171] = 'HA_ERR_CORRUPT_EVENT';
exports[172] = 'HA_ERR_NEW_FILE';
exports[173] = 'HA_ERR_ROWS_EVENT_APPLY';
exports[174] = 'HA_ERR_INITIALIZATION';
exports[175] = 'HA_ERR_FILE_TOO_SHORT';
exports[176] = 'HA_ERR_WRONG_CRC';
exports[177] = 'HA_ERR_TOO_MANY_CONCURRENT_TRXS';
exports[178] = 'HA_ERR_NOT_IN_LOCK_PARTITIONS';
exports[179] = 'HA_ERR_INDEX_COL_TOO_LONG';
exports[180] = 'HA_ERR_INDEX_CORRUPT';
exports[181] = 'HA_ERR_UNDO_REC_TOO_BIG';
exports[182] = 'HA_FTS_INVALID_DOCID';
exports[183] = 'HA_ERR_TABLE_IN_FK_CHECK';
exports[184] = 'HA_ERR_TABLESPACE_EXISTS';
exports[185] = 'HA_ERR_TOO_MANY_FIELDS';
exports[186] = 'HA_ERR_ROW_IN_WRONG_PARTITION';
exports[187] = 'HA_ERR_INNODB_READ_ONLY';
exports[188] = 'HA_ERR_FTS_EXCEED_RESULT_CACHE_LIMIT';
exports[189] = 'HA_ERR_TEMP_FILE_WRITE_FAILURE';
exports[190] = 'HA_ERR_INNODB_FORCED_RECOVERY';
exports[191] = 'HA_ERR_FTS_TOO_MANY_WORDS_IN_PHRASE';
exports[192] = 'HA_ERR_FK_DEPTH_EXCEEDED';
exports[193] = 'HA_MISSING_CREATE_OPTION';
exports[194] = 'HA_ERR_SE_OUT_OF_MEMORY';
exports[195] = 'HA_ERR_TABLE_CORRUPT';
exports[196] = 'HA_ERR_QUERY_INTERRUPTED';
exports[197] = 'HA_ERR_TABLESPACE_MISSING';
exports[198] = 'HA_ERR_TABLESPACE_IS_NOT_EMPTY';
exports[199] = 'HA_ERR_WRONG_FILE_NAME';
exports[200] = 'HA_ERR_NOT_ALLOWED_COMMAND';
exports[201] = 'HA_ERR_COMPUTE_FAILED';
exports[202] = 'HA_ERR_ROW_FORMAT_CHANGED';
exports[203] = 'HA_ERR_NO_WAIT_LOCK';
exports[204] = 'HA_ERR_DISK_FULL_NOWAIT';
exports[205] = 'HA_ERR_NO_SESSION_TEMP';
exports[206] = 'HA_ERR_WRONG_TABLE_NAME';
exports[207] = 'HA_ERR_TOO_LONG_PATH';
exports[208] = 'HA_ERR_SAMPLING_INIT_FAILED';
exports[209] = 'HA_ERR_FTS_TOO_MANY_NESTED_EXP';
exports[1000] = 'ER_HASHCHK';
exports[1001] = 'ER_NISAMCHK';
exports[1002] = 'ER_NO';
exports[1003] = 'ER_YES';
exports[1004] = 'ER_CANT_CREATE_FILE';
exports[1005] = 'ER_CANT_CREATE_TABLE';
exports[1006] = 'ER_CANT_CREATE_DB';
exports[1007] = 'ER_DB_CREATE_EXISTS';
exports[1008] = 'ER_DB_DROP_EXISTS';
exports[1009] = 'ER_DB_DROP_DELETE';
exports[1010] = 'ER_DB_DROP_RMDIR';
exports[1011] = 'ER_CANT_DELETE_FILE';
exports[1012] = 'ER_CANT_FIND_SYSTEM_REC';
exports[1013] = 'ER_CANT_GET_STAT';
exports[1014] = 'ER_CANT_GET_WD';
exports[1015] = 'ER_CANT_LOCK';
exports[1016] = 'ER_CANT_OPEN_FILE';
exports[1017] = 'ER_FILE_NOT_FOUND';
exports[1018] = 'ER_CANT_READ_DIR';
exports[1019] = 'ER_CANT_SET_WD';
exports[1020] = 'ER_CHECKREAD';
exports[1021] = 'ER_DISK_FULL';
exports[1022] = 'ER_DUP_KEY';
exports[1023] = 'ER_ERROR_ON_CLOSE';
exports[1024] = 'ER_ERROR_ON_READ';
exports[1025] = 'ER_ERROR_ON_RENAME';
exports[1026] = 'ER_ERROR_ON_WRITE';
exports[1027] = 'ER_FILE_USED';
exports[1028] = 'ER_FILSORT_ABORT';
exports[1029] = 'ER_FORM_NOT_FOUND';
exports[1030] = 'ER_GET_ERRNO';
exports[1031] = 'ER_ILLEGAL_HA';
exports[1032] = 'ER_KEY_NOT_FOUND';
exports[1033] = 'ER_NOT_FORM_FILE';
exports[1034] = 'ER_NOT_KEYFILE';
exports[1035] = 'ER_OLD_KEYFILE';
exports[1036] = 'ER_OPEN_AS_READONLY';
exports[1037] = 'ER_OUTOFMEMORY';
exports[1038] = 'ER_OUT_OF_SORTMEMORY';
exports[1039] = 'ER_UNEXPECTED_EOF';
exports[1040] = 'ER_CON_COUNT_ERROR';
exports[1041] = 'ER_OUT_OF_RESOURCES';
exports[1042] = 'ER_BAD_HOST_ERROR';
exports[1043] = 'ER_HANDSHAKE_ERROR';
exports[1044] = 'ER_DBACCESS_DENIED_ERROR';
exports[1045] = 'ER_ACCESS_DENIED_ERROR';
exports[1046] = 'ER_NO_DB_ERROR';
exports[1047] = 'ER_UNKNOWN_COM_ERROR';
exports[1048] = 'ER_BAD_NULL_ERROR';
exports[1049] = 'ER_BAD_DB_ERROR';
exports[1050] = 'ER_TABLE_EXISTS_ERROR';
exports[1051] = 'ER_BAD_TABLE_ERROR';
exports[1052] = 'ER_NON_UNIQ_ERROR';
exports[1053] = 'ER_SERVER_SHUTDOWN';
exports[1054] = 'ER_BAD_FIELD_ERROR';
exports[1055] = 'ER_WRONG_FIELD_WITH_GROUP';
exports[1056] = 'ER_WRONG_GROUP_FIELD';
exports[1057] = 'ER_WRONG_SUM_SELECT';
exports[1058] = 'ER_WRONG_VALUE_COUNT';
exports[1059] = 'ER_TOO_LONG_IDENT';
exports[1060] = 'ER_DUP_FIELDNAME';
exports[1061] = 'ER_DUP_KEYNAME';
exports[1062] = 'ER_DUP_ENTRY';
exports[1063] = 'ER_WRONG_FIELD_SPEC';
exports[1064] = 'ER_PARSE_ERROR';
exports[1065] = 'ER_EMPTY_QUERY';
exports[1066] = 'ER_NONUNIQ_TABLE';
exports[1067] = 'ER_INVALID_DEFAULT';
exports[1068] = 'ER_MULTIPLE_PRI_KEY';
exports[1069] = 'ER_TOO_MANY_KEYS';
exports[1070] = 'ER_TOO_MANY_KEY_PARTS';
exports[1071] = 'ER_TOO_LONG_KEY';
exports[1072] = 'ER_KEY_COLUMN_DOES_NOT_EXITS';
exports[1073] = 'ER_BLOB_USED_AS_KEY';
exports[1074] = 'ER_TOO_BIG_FIELDLENGTH';
exports[1075] = 'ER_WRONG_AUTO_KEY';
exports[1076] = 'ER_READY';
exports[1077] = 'ER_NORMAL_SHUTDOWN';
exports[1078] = 'ER_GOT_SIGNAL';
exports[1079] = 'ER_SHUTDOWN_COMPLETE';
exports[1080] = 'ER_FORCING_CLOSE';
exports[1081] = 'ER_IPSOCK_ERROR';
exports[1082] = 'ER_NO_SUCH_INDEX';
exports[1083] = 'ER_WRONG_FIELD_TERMINATORS';
exports[1084] = 'ER_BLOBS_AND_NO_TERMINATED';
exports[1085] = 'ER_TEXTFILE_NOT_READABLE';
exports[1086] = 'ER_FILE_EXISTS_ERROR';
exports[1087] = 'ER_LOAD_INFO';
exports[1088] = 'ER_ALTER_INFO';
exports[1089] = 'ER_WRONG_SUB_KEY';
exports[1090] = 'ER_CANT_REMOVE_ALL_FIELDS';
exports[1091] = 'ER_CANT_DROP_FIELD_OR_KEY';
exports[1092] = 'ER_INSERT_INFO';
exports[1093] = 'ER_UPDATE_TABLE_USED';
exports[1094] = 'ER_NO_SUCH_THREAD';
exports[1095] = 'ER_KILL_DENIED_ERROR';
exports[1096] = 'ER_NO_TABLES_USED';
exports[1097] = 'ER_TOO_BIG_SET';
exports[1098] = 'ER_NO_UNIQUE_LOGFILE';
exports[1099] = 'ER_TABLE_NOT_LOCKED_FOR_WRITE';
exports[1100] = 'ER_TABLE_NOT_LOCKED';
exports[1101] = 'ER_BLOB_CANT_HAVE_DEFAULT';
exports[1102] = 'ER_WRONG_DB_NAME';
exports[1103] = 'ER_WRONG_TABLE_NAME';
exports[1104] = 'ER_TOO_BIG_SELECT';
exports[1105] = 'ER_UNKNOWN_ERROR';
exports[1106] = 'ER_UNKNOWN_PROCEDURE';
exports[1107] = 'ER_WRONG_PARAMCOUNT_TO_PROCEDURE';
exports[1108] = 'ER_WRONG_PARAMETERS_TO_PROCEDURE';
exports[1109] = 'ER_UNKNOWN_TABLE';
exports[1110] = 'ER_FIELD_SPECIFIED_TWICE';
exports[1111] = 'ER_INVALID_GROUP_FUNC_USE';
exports[1112] = 'ER_UNSUPPORTED_EXTENSION';
exports[1113] = 'ER_TABLE_MUST_HAVE_COLUMNS';
exports[1114] = 'ER_RECORD_FILE_FULL';
exports[1115] = 'ER_UNKNOWN_CHARACTER_SET';
exports[1116] = 'ER_TOO_MANY_TABLES';
exports[1117] = 'ER_TOO_MANY_FIELDS';
exports[1118] = 'ER_TOO_BIG_ROWSIZE';
exports[1119] = 'ER_STACK_OVERRUN';
exports[1120] = 'ER_WRONG_OUTER_JOIN';
exports[1121] = 'ER_NULL_COLUMN_IN_INDEX';
exports[1122] = 'ER_CANT_FIND_UDF';
exports[1123] = 'ER_CANT_INITIALIZE_UDF';
exports[1124] = 'ER_UDF_NO_PATHS';
exports[1125] = 'ER_UDF_EXISTS';
exports[1126] = 'ER_CANT_OPEN_LIBRARY';
exports[1127] = 'ER_CANT_FIND_DL_ENTRY';
exports[1128] = 'ER_FUNCTION_NOT_DEFINED';
exports[1129] = 'ER_HOST_IS_BLOCKED';
exports[1130] = 'ER_HOST_NOT_PRIVILEGED';
exports[1131] = 'ER_PASSWORD_ANONYMOUS_USER';
exports[1132] = 'ER_PASSWORD_NOT_ALLOWED';
exports[1133] = 'ER_PASSWORD_NO_MATCH';
exports[1134] = 'ER_UPDATE_INFO';
exports[1135] = 'ER_CANT_CREATE_THREAD';
exports[1136] = 'ER_WRONG_VALUE_COUNT_ON_ROW';
exports[1137] = 'ER_CANT_REOPEN_TABLE';
exports[1138] = 'ER_INVALID_USE_OF_NULL';
exports[1139] = 'ER_REGEXP_ERROR';
exports[1140] = 'ER_MIX_OF_GROUP_FUNC_AND_FIELDS';
exports[1141] = 'ER_NONEXISTING_GRANT';
exports[1142] = 'ER_TABLEACCESS_DENIED_ERROR';
exports[1143] = 'ER_COLUMNACCESS_DENIED_ERROR';
exports[1144] = 'ER_ILLEGAL_GRANT_FOR_TABLE';
exports[1145] = 'ER_GRANT_WRONG_HOST_OR_USER';
exports[1146] = 'ER_NO_SUCH_TABLE';
exports[1147] = 'ER_NONEXISTING_TABLE_GRANT';
exports[1148] = 'ER_NOT_ALLOWED_COMMAND';
exports[1149] = 'ER_SYNTAX_ERROR';
exports[1150] = 'ER_UNUSED1';
exports[1151] = 'ER_UNUSED2';
exports[1152] = 'ER_ABORTING_CONNECTION';
exports[1153] = 'ER_NET_PACKET_TOO_LARGE';
exports[1154] = 'ER_NET_READ_ERROR_FROM_PIPE';
exports[1155] = 'ER_NET_FCNTL_ERROR';
exports[1156] = 'ER_NET_PACKETS_OUT_OF_ORDER';
exports[1157] = 'ER_NET_UNCOMPRESS_ERROR';
exports[1158] = 'ER_NET_READ_ERROR';
exports[1159] = 'ER_NET_READ_INTERRUPTED';
exports[1160] = 'ER_NET_ERROR_ON_WRITE';
exports[1161] = 'ER_NET_WRITE_INTERRUPTED';
exports[1162] = 'ER_TOO_LONG_STRING';
exports[1163] = 'ER_TABLE_CANT_HANDLE_BLOB';
exports[1164] = 'ER_TABLE_CANT_HANDLE_AUTO_INCREMENT';
exports[1165] = 'ER_UNUSED3';
exports[1166] = 'ER_WRONG_COLUMN_NAME';
exports[1167] = 'ER_WRONG_KEY_COLUMN';
exports[1168] = 'ER_WRONG_MRG_TABLE';
exports[1169] = 'ER_DUP_UNIQUE';
exports[1170] = 'ER_BLOB_KEY_WITHOUT_LENGTH';
exports[1171] = 'ER_PRIMARY_CANT_HAVE_NULL';
exports[1172] = 'ER_TOO_MANY_ROWS';
exports[1173] = 'ER_REQUIRES_PRIMARY_KEY';
exports[1174] = 'ER_NO_RAID_COMPILED';
exports[1175] = 'ER_UPDATE_WITHOUT_KEY_IN_SAFE_MODE';
exports[1176] = 'ER_KEY_DOES_NOT_EXITS';
exports[1177] = 'ER_CHECK_NO_SUCH_TABLE';
exports[1178] = 'ER_CHECK_NOT_IMPLEMENTED';
exports[1179] = 'ER_CANT_DO_THIS_DURING_AN_TRANSACTION';
exports[1180] = 'ER_ERROR_DURING_COMMIT';
exports[1181] = 'ER_ERROR_DURING_ROLLBACK';
exports[1182] = 'ER_ERROR_DURING_FLUSH_LOGS';
exports[1183] = 'ER_ERROR_DURING_CHECKPOINT';
exports[1184] = 'ER_NEW_ABORTING_CONNECTION';
exports[1185] = 'ER_DUMP_NOT_IMPLEMENTED';
exports[1186] = 'ER_FLUSH_MASTER_BINLOG_CLOSED';
exports[1187] = 'ER_INDEX_REBUILD';
exports[1188] = 'ER_SOURCE';
exports[1189] = 'ER_SOURCE_NET_READ';
exports[1190] = 'ER_SOURCE_NET_WRITE';
exports[1191] = 'ER_FT_MATCHING_KEY_NOT_FOUND';
exports[1192] = 'ER_LOCK_OR_ACTIVE_TRANSACTION';
exports[1193] = 'ER_UNKNOWN_SYSTEM_VARIABLE';
exports[1194] = 'ER_CRASHED_ON_USAGE';
exports[1195] = 'ER_CRASHED_ON_REPAIR';
exports[1196] = 'ER_WARNING_NOT_COMPLETE_ROLLBACK';
exports[1197] = 'ER_TRANS_CACHE_FULL';
exports[1198] = 'ER_SLAVE_MUST_STOP';
exports[1199] = 'ER_REPLICA_NOT_RUNNING';
exports[1200] = 'ER_BAD_REPLICA';
exports[1201] = 'ER_CONNECTION_METADATA';
exports[1202] = 'ER_REPLICA_THREAD';
exports[1203] = 'ER_TOO_MANY_USER_CONNECTIONS';
exports[1204] = 'ER_SET_CONSTANTS_ONLY';
exports[1205] = 'ER_LOCK_WAIT_TIMEOUT';
exports[1206] = 'ER_LOCK_TABLE_FULL';
exports[1207] = 'ER_READ_ONLY_TRANSACTION';
exports[1208] = 'ER_DROP_DB_WITH_READ_LOCK';
exports[1209] = 'ER_CREATE_DB_WITH_READ_LOCK';
exports[1210] = 'ER_WRONG_ARGUMENTS';
exports[1211] = 'ER_NO_PERMISSION_TO_CREATE_USER';
exports[1212] = 'ER_UNION_TABLES_IN_DIFFERENT_DIR';
exports[1213] = 'ER_LOCK_DEADLOCK';
exports[1214] = 'ER_TABLE_CANT_HANDLE_FT';
exports[1215] = 'ER_CANNOT_ADD_FOREIGN';
exports[1216] = 'ER_NO_REFERENCED_ROW';
exports[1217] = 'ER_ROW_IS_REFERENCED';
exports[1218] = 'ER_CONNECT_TO_SOURCE';
exports[1219] = 'ER_QUERY_ON_MASTER';
exports[1220] = 'ER_ERROR_WHEN_EXECUTING_COMMAND';
exports[1221] = 'ER_WRONG_USAGE';
exports[1222] = 'ER_WRONG_NUMBER_OF_COLUMNS_IN_SELECT';
exports[1223] = 'ER_CANT_UPDATE_WITH_READLOCK';
exports[1224] = 'ER_MIXING_NOT_ALLOWED';
exports[1225] = 'ER_DUP_ARGUMENT';
exports[1226] = 'ER_USER_LIMIT_REACHED';
exports[1227] = 'ER_SPECIFIC_ACCESS_DENIED_ERROR';
exports[1228] = 'ER_LOCAL_VARIABLE';
exports[1229] = 'ER_GLOBAL_VARIABLE';
exports[1230] = 'ER_NO_DEFAULT';
exports[1231] = 'ER_WRONG_VALUE_FOR_VAR';
exports[1232] = 'ER_WRONG_TYPE_FOR_VAR';
exports[1233] = 'ER_VAR_CANT_BE_READ';
exports[1234] = 'ER_CANT_USE_OPTION_HERE';
exports[1235] = 'ER_NOT_SUPPORTED_YET';
exports[1236] = 'ER_SOURCE_FATAL_ERROR_READING_BINLOG';
exports[1237] = 'ER_REPLICA_IGNORED_TABLE';
exports[1238] = 'ER_INCORRECT_GLOBAL_LOCAL_VAR';
exports[1239] = 'ER_WRONG_FK_DEF';
exports[1240] = 'ER_KEY_REF_DO_NOT_MATCH_TABLE_REF';
exports[1241] = 'ER_OPERAND_COLUMNS';
exports[1242] = 'ER_SUBQUERY_NO_1_ROW';
exports[1243] = 'ER_UNKNOWN_STMT_HANDLER';
exports[1244] = 'ER_CORRUPT_HELP_DB';
exports[1245] = 'ER_CYCLIC_REFERENCE';
exports[1246] = 'ER_AUTO_CONVERT';
exports[1247] = 'ER_ILLEGAL_REFERENCE';
exports[1248] = 'ER_DERIVED_MUST_HAVE_ALIAS';
exports[1249] = 'ER_SELECT_REDUCED';
exports[1250] = 'ER_TABLENAME_NOT_ALLOWED_HERE';
exports[1251] = 'ER_NOT_SUPPORTED_AUTH_MODE';
exports[1252] = 'ER_SPATIAL_CANT_HAVE_NULL';
exports[1253] = 'ER_COLLATION_CHARSET_MISMATCH';
exports[1254] = 'ER_SLAVE_WAS_RUNNING';
exports[1255] = 'ER_SLAVE_WAS_NOT_RUNNING';
exports[1256] = 'ER_TOO_BIG_FOR_UNCOMPRESS';
exports[1257] = 'ER_ZLIB_Z_MEM_ERROR';
exports[1258] = 'ER_ZLIB_Z_BUF_ERROR';
exports[1259] = 'ER_ZLIB_Z_DATA_ERROR';
exports[1260] = 'ER_CUT_VALUE_GROUP_CONCAT';
exports[1261] = 'ER_WARN_TOO_FEW_RECORDS';
exports[1262] = 'ER_WARN_TOO_MANY_RECORDS';
exports[1263] = 'ER_WARN_NULL_TO_NOTNULL';
exports[1264] = 'ER_WARN_DATA_OUT_OF_RANGE';
exports[1265] = 'WARN_DATA_TRUNCATED';
exports[1266] = 'ER_WARN_USING_OTHER_HANDLER';
exports[1267] = 'ER_CANT_AGGREGATE_2COLLATIONS';
exports[1268] = 'ER_DROP_USER';
exports[1269] = 'ER_REVOKE_GRANTS';
exports[1270] = 'ER_CANT_AGGREGATE_3COLLATIONS';
exports[1271] = 'ER_CANT_AGGREGATE_NCOLLATIONS';
exports[1272] = 'ER_VARIABLE_IS_NOT_STRUCT';
exports[1273] = 'ER_UNKNOWN_COLLATION';
exports[1274] = 'ER_REPLICA_IGNORED_SSL_PARAMS';
exports[1275] = 'ER_SERVER_IS_IN_SECURE_AUTH_MODE';
exports[1276] = 'ER_WARN_FIELD_RESOLVED';
exports[1277] = 'ER_BAD_REPLICA_UNTIL_COND';
exports[1278] = 'ER_MISSING_SKIP_REPLICA';
exports[1279] = 'ER_UNTIL_COND_IGNORED';
exports[1280] = 'ER_WRONG_NAME_FOR_INDEX';
exports[1281] = 'ER_WRONG_NAME_FOR_CATALOG';
exports[1282] = 'ER_WARN_QC_RESIZE';
exports[1283] = 'ER_BAD_FT_COLUMN';
exports[1284] = 'ER_UNKNOWN_KEY_CACHE';
exports[1285] = 'ER_WARN_HOSTNAME_WONT_WORK';
exports[1286] = 'ER_UNKNOWN_STORAGE_ENGINE';
exports[1287] = 'ER_WARN_DEPRECATED_SYNTAX';
exports[1288] = 'ER_NON_UPDATABLE_TABLE';
exports[1289] = 'ER_FEATURE_DISABLED';
exports[1290] = 'ER_OPTION_PREVENTS_STATEMENT';
exports[1291] = 'ER_DUPLICATED_VALUE_IN_TYPE';
exports[1292] = 'ER_TRUNCATED_WRONG_VALUE';
exports[1293] = 'ER_TOO_MUCH_AUTO_TIMESTAMP_COLS';
exports[1294] = 'ER_INVALID_ON_UPDATE';
exports[1295] = 'ER_UNSUPPORTED_PS';
exports[1296] = 'ER_GET_ERRMSG';
exports[1297] = 'ER_GET_TEMPORARY_ERRMSG';
exports[1298] = 'ER_UNKNOWN_TIME_ZONE';
exports[1299] = 'ER_WARN_INVALID_TIMESTAMP';
exports[1300] = 'ER_INVALID_CHARACTER_STRING';
exports[1301] = 'ER_WARN_ALLOWED_PACKET_OVERFLOWED';
exports[1302] = 'ER_CONFLICTING_DECLARATIONS';
exports[1303] = 'ER_SP_NO_RECURSIVE_CREATE';
exports[1304] = 'ER_SP_ALREADY_EXISTS';
exports[1305] = 'ER_SP_DOES_NOT_EXIST';
exports[1306] = 'ER_SP_DROP_FAILED';
exports[1307] = 'ER_SP_STORE_FAILED';
exports[1308] = 'ER_SP_LILABEL_MISMATCH';
exports[1309] = 'ER_SP_LABEL_REDEFINE';
exports[1310] = 'ER_SP_LABEL_MISMATCH';
exports[1311] = 'ER_SP_UNINIT_VAR';
exports[1312] = 'ER_SP_BADSELECT';
exports[1313] = 'ER_SP_BADRETURN';
exports[1314] = 'ER_SP_BADSTATEMENT';
exports[1315] = 'ER_UPDATE_LOG_DEPRECATED_IGNORED';
exports[1316] = 'ER_UPDATE_LOG_DEPRECATED_TRANSLATED';
exports[1317] = 'ER_QUERY_INTERRUPTED';
exports[1318] = 'ER_SP_WRONG_NO_OF_ARGS';
exports[1319] = 'ER_SP_COND_MISMATCH';
exports[1320] = 'ER_SP_NORETURN';
exports[1321] = 'ER_SP_NORETURNEND';
exports[1322] = 'ER_SP_BAD_CURSOR_QUERY';
exports[1323] = 'ER_SP_BAD_CURSOR_SELECT';
exports[1324] = 'ER_SP_CURSOR_MISMATCH';
exports[1325] = 'ER_SP_CURSOR_ALREADY_OPEN';
exports[1326] = 'ER_SP_CURSOR_NOT_OPEN';
exports[1327] = 'ER_SP_UNDECLARED_VAR';
exports[1328] = 'ER_SP_WRONG_NO_OF_FETCH_ARGS';
exports[1329] = 'ER_SP_FETCH_NO_DATA';
exports[1330] = 'ER_SP_DUP_PARAM';
exports[1331] = 'ER_SP_DUP_VAR';
exports[1332] = 'ER_SP_DUP_COND';
exports[1333] = 'ER_SP_DUP_CURS';
exports[1334] = 'ER_SP_CANT_ALTER';
exports[1335] = 'ER_SP_SUBSELECT_NYI';
exports[1336] = 'ER_STMT_NOT_ALLOWED_IN_SF_OR_TRG';
exports[1337] = 'ER_SP_VARCOND_AFTER_CURSHNDLR';
exports[1338] = 'ER_SP_CURSOR_AFTER_HANDLER';
exports[1339] = 'ER_SP_CASE_NOT_FOUND';
exports[1340] = 'ER_FPARSER_TOO_BIG_FILE';
exports[1341] = 'ER_FPARSER_BAD_HEADER';
exports[1342] = 'ER_FPARSER_EOF_IN_COMMENT';
exports[1343] = 'ER_FPARSER_ERROR_IN_PARAMETER';
exports[1344] = 'ER_FPARSER_EOF_IN_UNKNOWN_PARAMETER';
exports[1345] = 'ER_VIEW_NO_EXPLAIN';
exports[1346] = 'ER_FRM_UNKNOWN_TYPE';
exports[1347] = 'ER_WRONG_OBJECT';
exports[1348] = 'ER_NONUPDATEABLE_COLUMN';
exports[1349] = 'ER_VIEW_SELECT_DERIVED';
exports[1350] = 'ER_VIEW_SELECT_CLAUSE';
exports[1351] = 'ER_VIEW_SELECT_VARIABLE';
exports[1352] = 'ER_VIEW_SELECT_TMPTABLE';
exports[1353] = 'ER_VIEW_WRONG_LIST';
exports[1354] = 'ER_WARN_VIEW_MERGE';
exports[1355] = 'ER_WARN_VIEW_WITHOUT_KEY';
exports[1356] = 'ER_VIEW_INVALID';
exports[1357] = 'ER_SP_NO_DROP_SP';
exports[1358] = 'ER_SP_GOTO_IN_HNDLR';
exports[1359] = 'ER_TRG_ALREADY_EXISTS';
exports[1360] = 'ER_TRG_DOES_NOT_EXIST';
exports[1361] = 'ER_TRG_ON_VIEW_OR_TEMP_TABLE';
exports[1362] = 'ER_TRG_CANT_CHANGE_ROW';
exports[1363] = 'ER_TRG_NO_SUCH_ROW_IN_TRG';
exports[1364] = 'ER_NO_DEFAULT_FOR_FIELD';
exports[1365] = 'ER_DIVISION_BY_ZERO';
exports[1366] = 'ER_TRUNCATED_WRONG_VALUE_FOR_FIELD';
exports[1367] = 'ER_ILLEGAL_VALUE_FOR_TYPE';
exports[1368] = 'ER_VIEW_NONUPD_CHECK';
exports[1369] = 'ER_VIEW_CHECK_FAILED';
exports[1370] = 'ER_PROCACCESS_DENIED_ERROR';
exports[1371] = 'ER_RELAY_LOG_FAIL';
exports[1372] = 'ER_PASSWD_LENGTH';
exports[1373] = 'ER_UNKNOWN_TARGET_BINLOG';
exports[1374] = 'ER_IO_ERR_LOG_INDEX_READ';
exports[1375] = 'ER_BINLOG_PURGE_PROHIBITED';
exports[1376] = 'ER_FSEEK_FAIL';
exports[1377] = 'ER_BINLOG_PURGE_FATAL_ERR';
exports[1378] = 'ER_LOG_IN_USE';
exports[1379] = 'ER_LOG_PURGE_UNKNOWN_ERR';
exports[1380] = 'ER_RELAY_LOG_INIT';
exports[1381] = 'ER_NO_BINARY_LOGGING';
exports[1382] = 'ER_RESERVED_SYNTAX';
exports[1383] = 'ER_WSAS_FAILED';
exports[1384] = 'ER_DIFF_GROUPS_PROC';
exports[1385] = 'ER_NO_GROUP_FOR_PROC';
exports[1386] = 'ER_ORDER_WITH_PROC';
exports[1387] = 'ER_LOGGING_PROHIBIT_CHANGING_OF';
exports[1388] = 'ER_NO_FILE_MAPPING';
exports[1389] = 'ER_WRONG_MAGIC';
exports[1390] = 'ER_PS_MANY_PARAM';
exports[1391] = 'ER_KEY_PART_0';
exports[1392] = 'ER_VIEW_CHECKSUM';
exports[1393] = 'ER_VIEW_MULTIUPDATE';
exports[1394] = 'ER_VIEW_NO_INSERT_FIELD_LIST';
exports[1395] = 'ER_VIEW_DELETE_MERGE_VIEW';
exports[1396] = 'ER_CANNOT_USER';
exports[1397] = 'ER_XAER_NOTA';
exports[1398] = 'ER_XAER_INVAL';
exports[1399] = 'ER_XAER_RMFAIL';
exports[1400] = 'ER_XAER_OUTSIDE';
exports[1401] = 'ER_XAER_RMERR';
exports[1402] = 'ER_XA_RBROLLBACK';
exports[1403] = 'ER_NONEXISTING_PROC_GRANT';
exports[1404] = 'ER_PROC_AUTO_GRANT_FAIL';
exports[1405] = 'ER_PROC_AUTO_REVOKE_FAIL';
exports[1406] = 'ER_DATA_TOO_LONG';
exports[1407] = 'ER_SP_BAD_SQLSTATE';
exports[1408] = 'ER_STARTUP';
exports[1409] = 'ER_LOAD_FROM_FIXED_SIZE_ROWS_TO_VAR';
exports[1410] = 'ER_CANT_CREATE_USER_WITH_GRANT';
exports[1411] = 'ER_WRONG_VALUE_FOR_TYPE';
exports[1412] = 'ER_TABLE_DEF_CHANGED';
exports[1413] = 'ER_SP_DUP_HANDLER';
exports[1414] = 'ER_SP_NOT_VAR_ARG';
exports[1415] = 'ER_SP_NO_RETSET';
exports[1416] = 'ER_CANT_CREATE_GEOMETRY_OBJECT';
exports[1417] = 'ER_FAILED_ROUTINE_BREAK_BINLOG';
exports[1418] = 'ER_BINLOG_UNSAFE_ROUTINE';
exports[1419] = 'ER_BINLOG_CREATE_ROUTINE_NEED_SUPER';
exports[1420] = 'ER_EXEC_STMT_WITH_OPEN_CURSOR';
exports[1421] = 'ER_STMT_HAS_NO_OPEN_CURSOR';
exports[1422] = 'ER_COMMIT_NOT_ALLOWED_IN_SF_OR_TRG';
exports[1423] = 'ER_NO_DEFAULT_FOR_VIEW_FIELD';
exports[1424] = 'ER_SP_NO_RECURSION';
exports[1425] = 'ER_TOO_BIG_SCALE';
exports[1426] = 'ER_TOO_BIG_PRECISION';
exports[1427] = 'ER_M_BIGGER_THAN_D';
exports[1428] = 'ER_WRONG_LOCK_OF_SYSTEM_TABLE';
exports[1429] = 'ER_CONNECT_TO_FOREIGN_DATA_SOURCE';
exports[1430] = 'ER_QUERY_ON_FOREIGN_DATA_SOURCE';
exports[1431] = 'ER_FOREIGN_DATA_SOURCE_DOESNT_EXIST';
exports[1432] = 'ER_FOREIGN_DATA_STRING_INVALID_CANT_CREATE';
exports[1433] = 'ER_FOREIGN_DATA_STRING_INVALID';
exports[1434] = 'ER_CANT_CREATE_FEDERATED_TABLE';
exports[1435] = 'ER_TRG_IN_WRONG_SCHEMA';
exports[1436] = 'ER_STACK_OVERRUN_NEED_MORE';
exports[1437] = 'ER_TOO_LONG_BODY';
exports[1438] = 'ER_WARN_CANT_DROP_DEFAULT_KEYCACHE';
exports[1439] = 'ER_TOO_BIG_DISPLAYWIDTH';
exports[1440] = 'ER_XAER_DUPID';
exports[1441] = 'ER_DATETIME_FUNCTION_OVERFLOW';
exports[1442] = 'ER_CANT_UPDATE_USED_TABLE_IN_SF_OR_TRG';
exports[1443] = 'ER_VIEW_PREVENT_UPDATE';
exports[1444] = 'ER_PS_NO_RECURSION';
exports[1445] = 'ER_SP_CANT_SET_AUTOCOMMIT';
exports[1446] = 'ER_MALFORMED_DEFINER';
exports[1447] = 'ER_VIEW_FRM_NO_USER';
exports[1448] = 'ER_VIEW_OTHER_USER';
exports[1449] = 'ER_NO_SUCH_USER';
exports[1450] = 'ER_FORBID_SCHEMA_CHANGE';
exports[1451] = 'ER_ROW_IS_REFERENCED_2';
exports[1452] = 'ER_NO_REFERENCED_ROW_2';
exports[1453] = 'ER_SP_BAD_VAR_SHADOW';
exports[1454] = 'ER_TRG_NO_DEFINER';
exports[1455] = 'ER_OLD_FILE_FORMAT';
exports[1456] = 'ER_SP_RECURSION_LIMIT';
exports[1457] = 'ER_SP_PROC_TABLE_CORRUPT';
exports[1458] = 'ER_SP_WRONG_NAME';
exports[1459] = 'ER_TABLE_NEEDS_UPGRADE';
exports[1460] = 'ER_SP_NO_AGGREGATE';
exports[1461] = 'ER_MAX_PREPARED_STMT_COUNT_REACHED';
exports[1462] = 'ER_VIEW_RECURSIVE';
exports[1463] = 'ER_NON_GROUPING_FIELD_USED';
exports[1464] = 'ER_TABLE_CANT_HANDLE_SPKEYS';
exports[1465] = 'ER_NO_TRIGGERS_ON_SYSTEM_SCHEMA';
exports[1466] = 'ER_REMOVED_SPACES';
exports[1467] = 'ER_AUTOINC_READ_FAILED';
exports[1468] = 'ER_USERNAME';
exports[1469] = 'ER_HOSTNAME';
exports[1470] = 'ER_WRONG_STRING_LENGTH';
exports[1471] = 'ER_NON_INSERTABLE_TABLE';
exports[1472] = 'ER_ADMIN_WRONG_MRG_TABLE';
exports[1473] = 'ER_TOO_HIGH_LEVEL_OF_NESTING_FOR_SELECT';
exports[1474] = 'ER_NAME_BECOMES_EMPTY';
exports[1475] = 'ER_AMBIGUOUS_FIELD_TERM';
exports[1476] = 'ER_FOREIGN_SERVER_EXISTS';
exports[1477] = 'ER_FOREIGN_SERVER_DOESNT_EXIST';
exports[1478] = 'ER_ILLEGAL_HA_CREATE_OPTION';
exports[1479] = 'ER_PARTITION_REQUIRES_VALUES_ERROR';
exports[1480] = 'ER_PARTITION_WRONG_VALUES_ERROR';
exports[1481] = 'ER_PARTITION_MAXVALUE_ERROR';
exports[1482] = 'ER_PARTITION_SUBPARTITION_ERROR';
exports[1483] = 'ER_PARTITION_SUBPART_MIX_ERROR';
exports[1484] = 'ER_PARTITION_WRONG_NO_PART_ERROR';
exports[1485] = 'ER_PARTITION_WRONG_NO_SUBPART_ERROR';
exports[1486] = 'ER_WRONG_EXPR_IN_PARTITION_FUNC_ERROR';
exports[1487] = 'ER_NO_CONST_EXPR_IN_RANGE_OR_LIST_ERROR';
exports[1488] = 'ER_FIELD_NOT_FOUND_PART_ERROR';
exports[1489] = 'ER_LIST_OF_FIELDS_ONLY_IN_HASH_ERROR';
exports[1490] = 'ER_INCONSISTENT_PARTITION_INFO_ERROR';
exports[1491] = 'ER_PARTITION_FUNC_NOT_ALLOWED_ERROR';
exports[1492] = 'ER_PARTITIONS_MUST_BE_DEFINED_ERROR';
exports[1493] = 'ER_RANGE_NOT_INCREASING_ERROR';
exports[1494] = 'ER_INCONSISTENT_TYPE_OF_FUNCTIONS_ERROR';
exports[1495] = 'ER_MULTIPLE_DEF_CONST_IN_LIST_PART_ERROR';
exports[1496] = 'ER_PARTITION_ENTRY_ERROR';
exports[1497] = 'ER_MIX_HANDLER_ERROR';
exports[1498] = 'ER_PARTITION_NOT_DEFINED_ERROR';
exports[1499] = 'ER_TOO_MANY_PARTITIONS_ERROR';
exports[1500] = 'ER_SUBPARTITION_ERROR';
exports[1501] = 'ER_CANT_CREATE_HANDLER_FILE';
exports[1502] = 'ER_BLOB_FIELD_IN_PART_FUNC_ERROR';
exports[1503] = 'ER_UNIQUE_KEY_NEED_ALL_FIELDS_IN_PF';
exports[1504] = 'ER_NO_PARTS_ERROR';
exports[1505] = 'ER_PARTITION_MGMT_ON_NONPARTITIONED';
exports[1506] = 'ER_FOREIGN_KEY_ON_PARTITIONED';
exports[1507] = 'ER_DROP_PARTITION_NON_EXISTENT';
exports[1508] = 'ER_DROP_LAST_PARTITION';
exports[1509] = 'ER_COALESCE_ONLY_ON_HASH_PARTITION';
exports[1510] = 'ER_REORG_HASH_ONLY_ON_SAME_NO';
exports[1511] = 'ER_REORG_NO_PARAM_ERROR';
exports[1512] = 'ER_ONLY_ON_RANGE_LIST_PARTITION';
exports[1513] = 'ER_ADD_PARTITION_SUBPART_ERROR';
exports[1514] = 'ER_ADD_PARTITION_NO_NEW_PARTITION';
exports[1515] = 'ER_COALESCE_PARTITION_NO_PARTITION';
exports[1516] = 'ER_REORG_PARTITION_NOT_EXIST';
exports[1517] = 'ER_SAME_NAME_PARTITION';
exports[1518] = 'ER_NO_BINLOG_ERROR';
exports[1519] = 'ER_CONSECUTIVE_REORG_PARTITIONS';
exports[1520] = 'ER_REORG_OUTSIDE_RANGE';
exports[1521] = 'ER_PARTITION_FUNCTION_FAILURE';
exports[1522] = 'ER_PART_STATE_ERROR';
exports[1523] = 'ER_LIMITED_PART_RANGE';
exports[1524] = 'ER_PLUGIN_IS_NOT_LOADED';
exports[1525] = 'ER_WRONG_VALUE';
exports[1526] = 'ER_NO_PARTITION_FOR_GIVEN_VALUE';
exports[1527] = 'ER_FILEGROUP_OPTION_ONLY_ONCE';
exports[1528] = 'ER_CREATE_FILEGROUP_FAILED';
exports[1529] = 'ER_DROP_FILEGROUP_FAILED';
exports[1530] = 'ER_TABLESPACE_AUTO_EXTEND_ERROR';
exports[1531] = 'ER_WRONG_SIZE_NUMBER';
exports[1532] = 'ER_SIZE_OVERFLOW_ERROR';
exports[1533] = 'ER_ALTER_FILEGROUP_FAILED';
exports[1534] = 'ER_BINLOG_ROW_LOGGING_FAILED';
exports[1535] = 'ER_BINLOG_ROW_WRONG_TABLE_DEF';
exports[1536] = 'ER_BINLOG_ROW_RBR_TO_SBR';
exports[1537] = 'ER_EVENT_ALREADY_EXISTS';
exports[1538] = 'ER_EVENT_STORE_FAILED';
exports[1539] = 'ER_EVENT_DOES_NOT_EXIST';
exports[1540] = 'ER_EVENT_CANT_ALTER';
exports[1541] = 'ER_EVENT_DROP_FAILED';
exports[1542] = 'ER_EVENT_INTERVAL_NOT_POSITIVE_OR_TOO_BIG';
exports[1543] = 'ER_EVENT_ENDS_BEFORE_STARTS';
exports[1544] = 'ER_EVENT_EXEC_TIME_IN_THE_PAST';
exports[1545] = 'ER_EVENT_OPEN_TABLE_FAILED';
exports[1546] = 'ER_EVENT_NEITHER_M_EXPR_NOR_M_AT';
exports[1547] = 'ER_COL_COUNT_DOESNT_MATCH_CORRUPTED';
exports[1548] = 'ER_CANNOT_LOAD_FROM_TABLE';
exports[1549] = 'ER_EVENT_CANNOT_DELETE';
exports[1550] = 'ER_EVENT_COMPILE_ERROR';
exports[1551] = 'ER_EVENT_SAME_NAME';
exports[1552] = 'ER_EVENT_DATA_TOO_LONG';
exports[1553] = 'ER_DROP_INDEX_FK';
exports[1554] = 'ER_WARN_DEPRECATED_SYNTAX_WITH_VER';
exports[1555] = 'ER_CANT_WRITE_LOCK_LOG_TABLE';
exports[1556] = 'ER_CANT_LOCK_LOG_TABLE';
exports[1557] = 'ER_FOREIGN_DUPLICATE_KEY';
exports[1558] = 'ER_COL_COUNT_DOESNT_MATCH_PLEASE_UPDATE';
exports[1559] = 'ER_TEMP_TABLE_PREVENTS_SWITCH_OUT_OF_RBR';
exports[1560] = 'ER_STORED_FUNCTION_PREVENTS_SWITCH_BINLOG_FORMAT';
exports[1561] = 'ER_NDB_CANT_SWITCH_BINLOG_FORMAT';
exports[1562] = 'ER_PARTITION_NO_TEMPORARY';
exports[1563] = 'ER_PARTITION_CONST_DOMAIN_ERROR';
exports[1564] = 'ER_PARTITION_FUNCTION_IS_NOT_ALLOWED';
exports[1565] = 'ER_DDL_LOG_ERROR';
exports[1566] = 'ER_NULL_IN_VALUES_LESS_THAN';
exports[1567] = 'ER_WRONG_PARTITION_NAME';
exports[1568] = 'ER_CANT_CHANGE_TX_CHARACTERISTICS';
exports[1569] = 'ER_DUP_ENTRY_AUTOINCREMENT_CASE';
exports[1570] = 'ER_EVENT_MODIFY_QUEUE_ERROR';
exports[1571] = 'ER_EVENT_SET_VAR_ERROR';
exports[1572] = 'ER_PARTITION_MERGE_ERROR';
exports[1573] = 'ER_CANT_ACTIVATE_LOG';
exports[1574] = 'ER_RBR_NOT_AVAILABLE';
exports[1575] = 'ER_BASE64_DECODE_ERROR';
exports[1576] = 'ER_EVENT_RECURSION_FORBIDDEN';
exports[1577] = 'ER_EVENTS_DB_ERROR';
exports[1578] = 'ER_ONLY_INTEGERS_ALLOWED';
exports[1579] = 'ER_UNSUPORTED_LOG_ENGINE';
exports[1580] = 'ER_BAD_LOG_STATEMENT';
exports[1581] = 'ER_CANT_RENAME_LOG_TABLE';
exports[1582] = 'ER_WRONG_PARAMCOUNT_TO_NATIVE_FCT';
exports[1583] = 'ER_WRONG_PARAMETERS_TO_NATIVE_FCT';
exports[1584] = 'ER_WRONG_PARAMETERS_TO_STORED_FCT';
exports[1585] = 'ER_NATIVE_FCT_NAME_COLLISION';
exports[1586] = 'ER_DUP_ENTRY_WITH_KEY_NAME';
exports[1587] = 'ER_BINLOG_PURGE_EMFILE';
exports[1588] = 'ER_EVENT_CANNOT_CREATE_IN_THE_PAST';
exports[1589] = 'ER_EVENT_CANNOT_ALTER_IN_THE_PAST';
exports[1590] = 'ER_SLAVE_INCIDENT';
exports[1591] = 'ER_NO_PARTITION_FOR_GIVEN_VALUE_SILENT';
exports[1592] = 'ER_BINLOG_UNSAFE_STATEMENT';
exports[1593] = 'ER_BINLOG_FATAL_ERROR';
exports[1594] = 'ER_SLAVE_RELAY_LOG_READ_FAILURE';
exports[1595] = 'ER_SLAVE_RELAY_LOG_WRITE_FAILURE';
exports[1596] = 'ER_SLAVE_CREATE_EVENT_FAILURE';
exports[1597] = 'ER_SLAVE_MASTER_COM_FAILURE';
exports[1598] = 'ER_BINLOG_LOGGING_IMPOSSIBLE';
exports[1599] = 'ER_VIEW_NO_CREATION_CTX';
exports[1600] = 'ER_VIEW_INVALID_CREATION_CTX';
exports[1601] = 'ER_SR_INVALID_CREATION_CTX';
exports[1602] = 'ER_TRG_CORRUPTED_FILE';
exports[1603] = 'ER_TRG_NO_CREATION_CTX';
exports[1604] = 'ER_TRG_INVALID_CREATION_CTX';
exports[1605] = 'ER_EVENT_INVALID_CREATION_CTX';
exports[1606] = 'ER_TRG_CANT_OPEN_TABLE';
exports[1607] = 'ER_CANT_CREATE_SROUTINE';
exports[1608] = 'ER_NEVER_USED';
exports[1609] = 'ER_NO_FORMAT_DESCRIPTION_EVENT_BEFORE_BINLOG_STATEMENT';
exports[1610] = 'ER_REPLICA_CORRUPT_EVENT';
exports[1611] = 'ER_LOAD_DATA_INVALID_COLUMN';
exports[1612] = 'ER_LOG_PURGE_NO_FILE';
exports[1613] = 'ER_XA_RBTIMEOUT';
exports[1614] = 'ER_XA_RBDEADLOCK';
exports[1615] = 'ER_NEED_REPREPARE';
exports[1616] = 'ER_DELAYED_NOT_SUPPORTED';
exports[1617] = 'WARN_NO_CONNECTION_METADATA';
exports[1618] = 'WARN_OPTION_IGNORED';
exports[1619] = 'ER_PLUGIN_DELETE_BUILTIN';
exports[1620] = 'WARN_PLUGIN_BUSY';
exports[1621] = 'ER_VARIABLE_IS_READONLY';
exports[1622] = 'ER_WARN_ENGINE_TRANSACTION_ROLLBACK';
exports[1623] = 'ER_SLAVE_HEARTBEAT_FAILURE';
exports[1624] = 'ER_REPLICA_HEARTBEAT_VALUE_OUT_OF_RANGE';
exports[1625] = 'ER_NDB_REPLICATION_SCHEMA_ERROR';
exports[1626] = 'ER_CONFLICT_FN_PARSE_ERROR';
exports[1627] = 'ER_EXCEPTIONS_WRITE_ERROR';
exports[1628] = 'ER_TOO_LONG_TABLE_COMMENT';
exports[1629] = 'ER_TOO_LONG_FIELD_COMMENT';
exports[1630] = 'ER_FUNC_INEXISTENT_NAME_COLLISION';
exports[1631] = 'ER_DATABASE_NAME';
exports[1632] = 'ER_TABLE_NAME';
exports[1633] = 'ER_PARTITION_NAME';
exports[1634] = 'ER_SUBPARTITION_NAME';
exports[1635] = 'ER_TEMPORARY_NAME';
exports[1636] = 'ER_RENAMED_NAME';
exports[1637] = 'ER_TOO_MANY_CONCURRENT_TRXS';
exports[1638] = 'WARN_NON_ASCII_SEPARATOR_NOT_IMPLEMENTED';
exports[1639] = 'ER_DEBUG_SYNC_TIMEOUT';
exports[1640] = 'ER_DEBUG_SYNC_HIT_LIMIT';
exports[1641] = 'ER_DUP_SIGNAL_SET';
exports[1642] = 'ER_SIGNAL_WARN';
exports[1643] = 'ER_SIGNAL_NOT_FOUND';
exports[1644] = 'ER_SIGNAL_EXCEPTION';
exports[1645] = 'ER_RESIGNAL_WITHOUT_ACTIVE_HANDLER';
exports[1646] = 'ER_SIGNAL_BAD_CONDITION_TYPE';
exports[1647] = 'WARN_COND_ITEM_TRUNCATED';
exports[1648] = 'ER_COND_ITEM_TOO_LONG';
exports[1649] = 'ER_UNKNOWN_LOCALE';
exports[1650] = 'ER_REPLICA_IGNORE_SERVER_IDS';
exports[1651] = 'ER_QUERY_CACHE_DISABLED';
exports[1652] = 'ER_SAME_NAME_PARTITION_FIELD';
exports[1653] = 'ER_PARTITION_COLUMN_LIST_ERROR';
exports[1654] = 'ER_WRONG_TYPE_COLUMN_VALUE_ERROR';
exports[1655] = 'ER_TOO_MANY_PARTITION_FUNC_FIELDS_ERROR';
exports[1656] = 'ER_MAXVALUE_IN_VALUES_IN';
exports[1657] = 'ER_TOO_MANY_VALUES_ERROR';
exports[1658] = 'ER_ROW_SINGLE_PARTITION_FIELD_ERROR';
exports[1659] = 'ER_FIELD_TYPE_NOT_ALLOWED_AS_PARTITION_FIELD';
exports[1660] = 'ER_PARTITION_FIELDS_TOO_LONG';
exports[1661] = 'ER_BINLOG_ROW_ENGINE_AND_STMT_ENGINE';
exports[1662] = 'ER_BINLOG_ROW_MODE_AND_STMT_ENGINE';
exports[1663] = 'ER_BINLOG_UNSAFE_AND_STMT_ENGINE';
exports[1664] = 'ER_BINLOG_ROW_INJECTION_AND_STMT_ENGINE';
exports[1665] = 'ER_BINLOG_STMT_MODE_AND_ROW_ENGINE';
exports[1666] = 'ER_BINLOG_ROW_INJECTION_AND_STMT_MODE';
exports[1667] = 'ER_BINLOG_MULTIPLE_ENGINES_AND_SELF_LOGGING_ENGINE';
exports[1668] = 'ER_BINLOG_UNSAFE_LIMIT';
exports[1669] = 'ER_UNUSED4';
exports[1670] = 'ER_BINLOG_UNSAFE_SYSTEM_TABLE';
exports[1671] = 'ER_BINLOG_UNSAFE_AUTOINC_COLUMNS';
exports[1672] = 'ER_BINLOG_UNSAFE_UDF';
exports[1673] = 'ER_BINLOG_UNSAFE_SYSTEM_VARIABLE';
exports[1674] = 'ER_BINLOG_UNSAFE_SYSTEM_FUNCTION';
exports[1675] = 'ER_BINLOG_UNSAFE_NONTRANS_AFTER_TRANS';
exports[1676] = 'ER_MESSAGE_AND_STATEMENT';
exports[1677] = 'ER_SLAVE_CONVERSION_FAILED';
exports[1678] = 'ER_REPLICA_CANT_CREATE_CONVERSION';
exports[1679] = 'ER_INSIDE_TRANSACTION_PREVENTS_SWITCH_BINLOG_FORMAT';
exports[1680] = 'ER_PATH_LENGTH';
exports[1681] = 'ER_WARN_DEPRECATED_SYNTAX_NO_REPLACEMENT';
exports[1682] = 'ER_WRONG_NATIVE_TABLE_STRUCTURE';
exports[1683] = 'ER_WRONG_PERFSCHEMA_USAGE';
exports[1684] = 'ER_WARN_I_S_SKIPPED_TABLE';
exports[1685] = 'ER_INSIDE_TRANSACTION_PREVENTS_SWITCH_BINLOG_DIRECT';
exports[1686] = 'ER_STORED_FUNCTION_PREVENTS_SWITCH_BINLOG_DIRECT';
exports[1687] = 'ER_SPATIAL_MUST_HAVE_GEOM_COL';
exports[1688] = 'ER_TOO_LONG_INDEX_COMMENT';
exports[1689] = 'ER_LOCK_ABORTED';
exports[1690] = 'ER_DATA_OUT_OF_RANGE';
exports[1691] = 'ER_WRONG_SPVAR_TYPE_IN_LIMIT';
exports[1692] = 'ER_BINLOG_UNSAFE_MULTIPLE_ENGINES_AND_SELF_LOGGING_ENGINE';
exports[1693] = 'ER_BINLOG_UNSAFE_MIXED_STATEMENT';
exports[1694] = 'ER_INSIDE_TRANSACTION_PREVENTS_SWITCH_SQL_LOG_BIN';
exports[1695] = 'ER_STORED_FUNCTION_PREVENTS_SWITCH_SQL_LOG_BIN';
exports[1696] = 'ER_FAILED_READ_FROM_PAR_FILE';
exports[1697] = 'ER_VALUES_IS_NOT_INT_TYPE_ERROR';
exports[1698] = 'ER_ACCESS_DENIED_NO_PASSWORD_ERROR';
exports[1699] = 'ER_SET_PASSWORD_AUTH_PLUGIN';
exports[1700] = 'ER_GRANT_PLUGIN_USER_EXISTS';
exports[1701] = 'ER_TRUNCATE_ILLEGAL_FK';
exports[1702] = 'ER_PLUGIN_IS_PERMANENT';
exports[1703] = 'ER_REPLICA_HEARTBEAT_VALUE_OUT_OF_RANGE_MIN';
exports[1704] = 'ER_REPLICA_HEARTBEAT_VALUE_OUT_OF_RANGE_MAX';
exports[1705] = 'ER_STMT_CACHE_FULL';
exports[1706] = 'ER_MULTI_UPDATE_KEY_CONFLICT';
exports[1707] = 'ER_TABLE_NEEDS_REBUILD';
exports[1708] = 'WARN_OPTION_BELOW_LIMIT';
exports[1709] = 'ER_INDEX_COLUMN_TOO_LONG';
exports[1710] = 'ER_ERROR_IN_TRIGGER_BODY';
exports[1711] = 'ER_ERROR_IN_UNKNOWN_TRIGGER_BODY';
exports[1712] = 'ER_INDEX_CORRUPT';
exports[1713] = 'ER_UNDO_RECORD_TOO_BIG';
exports[1714] = 'ER_BINLOG_UNSAFE_INSERT_IGNORE_SELECT';
exports[1715] = 'ER_BINLOG_UNSAFE_INSERT_SELECT_UPDATE';
exports[1716] = 'ER_BINLOG_UNSAFE_REPLACE_SELECT';
exports[1717] = 'ER_BINLOG_UNSAFE_CREATE_IGNORE_SELECT';
exports[1718] = 'ER_BINLOG_UNSAFE_CREATE_REPLACE_SELECT';
exports[1719] = 'ER_BINLOG_UNSAFE_UPDATE_IGNORE';
exports[1720] = 'ER_PLUGIN_NO_UNINSTALL';
exports[1721] = 'ER_PLUGIN_NO_INSTALL';
exports[1722] = 'ER_BINLOG_UNSAFE_WRITE_AUTOINC_SELECT';
exports[1723] = 'ER_BINLOG_UNSAFE_CREATE_SELECT_AUTOINC';
exports[1724] = 'ER_BINLOG_UNSAFE_INSERT_TWO_KEYS';
exports[1725] = 'ER_TABLE_IN_FK_CHECK';
exports[1726] = 'ER_UNSUPPORTED_ENGINE';
exports[1727] = 'ER_BINLOG_UNSAFE_AUTOINC_NOT_FIRST';
exports[1728] = 'ER_CANNOT_LOAD_FROM_TABLE_V2';
exports[1729] = 'ER_SOURCE_DELAY_VALUE_OUT_OF_RANGE';
exports[1730] = 'ER_ONLY_FD_AND_RBR_EVENTS_ALLOWED_IN_BINLOG_STATEMENT';
exports[1731] = 'ER_PARTITION_EXCHANGE_DIFFERENT_OPTION';
exports[1732] = 'ER_PARTITION_EXCHANGE_PART_TABLE';
exports[1733] = 'ER_PARTITION_EXCHANGE_TEMP_TABLE';
exports[1734] = 'ER_PARTITION_INSTEAD_OF_SUBPARTITION';
exports[1735] = 'ER_UNKNOWN_PARTITION';
exports[1736] = 'ER_TABLES_DIFFERENT_METADATA';
exports[1737] = 'ER_ROW_DOES_NOT_MATCH_PARTITION';
exports[1738] = 'ER_BINLOG_CACHE_SIZE_GREATER_THAN_MAX';
exports[1739] = 'ER_WARN_INDEX_NOT_APPLICABLE';
exports[1740] = 'ER_PARTITION_EXCHANGE_FOREIGN_KEY';
exports[1741] = 'ER_NO_SUCH_KEY_VALUE';
exports[1742] = 'ER_RPL_INFO_DATA_TOO_LONG';
exports[1743] = 'ER_NETWORK_READ_EVENT_CHECKSUM_FAILURE';
exports[1744] = 'ER_BINLOG_READ_EVENT_CHECKSUM_FAILURE';
exports[1745] = 'ER_BINLOG_STMT_CACHE_SIZE_GREATER_THAN_MAX';
exports[1746] = 'ER_CANT_UPDATE_TABLE_IN_CREATE_TABLE_SELECT';
exports[1747] = 'ER_PARTITION_CLAUSE_ON_NONPARTITIONED';
exports[1748] = 'ER_ROW_DOES_NOT_MATCH_GIVEN_PARTITION_SET';
exports[1749] = 'ER_NO_SUCH_PARTITION';
exports[1750] = 'ER_CHANGE_RPL_INFO_REPOSITORY_FAILURE';
exports[1751] = 'ER_WARNING_NOT_COMPLETE_ROLLBACK_WITH_CREATED_TEMP_TABLE';
exports[1752] = 'ER_WARNING_NOT_COMPLETE_ROLLBACK_WITH_DROPPED_TEMP_TABLE';
exports[1753] = 'ER_MTA_FEATURE_IS_NOT_SUPPORTED';
exports[1754] = 'ER_MTA_UPDATED_DBS_GREATER_MAX';
exports[1755] = 'ER_MTA_CANT_PARALLEL';
exports[1756] = 'ER_MTA_INCONSISTENT_DATA';
exports[1757] = 'ER_FULLTEXT_NOT_SUPPORTED_WITH_PARTITIONING';
exports[1758] = 'ER_DA_INVALID_CONDITION_NUMBER';
exports[1759] = 'ER_INSECURE_PLAIN_TEXT';
exports[1760] = 'ER_INSECURE_CHANGE_SOURCE';
exports[1761] = 'ER_FOREIGN_DUPLICATE_KEY_WITH_CHILD_INFO';
exports[1762] = 'ER_FOREIGN_DUPLICATE_KEY_WITHOUT_CHILD_INFO';
exports[1763] = 'ER_SQLTHREAD_WITH_SECURE_REPLICA';
exports[1764] = 'ER_TABLE_HAS_NO_FT';
exports[1765] = 'ER_VARIABLE_NOT_SETTABLE_IN_SF_OR_TRIGGER';
exports[1766] = 'ER_VARIABLE_NOT_SETTABLE_IN_TRANSACTION';
exports[1767] = 'ER_GTID_NEXT_IS_NOT_IN_GTID_NEXT_LIST';
exports[1768] = 'ER_CANT_CHANGE_GTID_NEXT_IN_TRANSACTION';
exports[1769] = 'ER_SET_STATEMENT_CANNOT_INVOKE_FUNCTION';
exports[1770] = 'ER_GTID_NEXT_CANT_BE_AUTOMATIC_IF_GTID_NEXT_LIST_IS_NON_NULL';
exports[1771] = 'ER_SKIPPING_LOGGED_TRANSACTION';
exports[1772] = 'ER_MALFORMED_GTID_SET_SPECIFICATION';
exports[1773] = 'ER_MALFORMED_GTID_SET_ENCODING';
exports[1774] = 'ER_MALFORMED_GTID_SPECIFICATION';
exports[1775] = 'ER_GNO_EXHAUSTED';
exports[1776] = 'ER_BAD_REPLICA_AUTO_POSITION';
exports[1777] = 'ER_AUTO_POSITION_REQUIRES_GTID_MODE_NOT_OFF';
exports[1778] = 'ER_CANT_DO_IMPLICIT_COMMIT_IN_TRX_WHEN_GTID_NEXT_IS_SET';
exports[1779] = 'ER_GTID_MODE_ON_REQUIRES_ENFORCE_GTID_CONSISTENCY_ON';
exports[1780] = 'ER_GTID_MODE_REQUIRES_BINLOG';
exports[1781] = 'ER_CANT_SET_GTID_NEXT_TO_GTID_WHEN_GTID_MODE_IS_OFF';
exports[1782] = 'ER_CANT_SET_GTID_NEXT_TO_ANONYMOUS_WHEN_GTID_MODE_IS_ON';
exports[1783] = 'ER_CANT_SET_GTID_NEXT_LIST_TO_NON_NULL_WHEN_GTID_MODE_IS_OFF';
exports[1784] = 'ER_FOUND_GTID_EVENT_WHEN_GTID_MODE_IS_OFF';
exports[1785] = 'ER_GTID_UNSAFE_NON_TRANSACTIONAL_TABLE';
exports[1786] = 'ER_GTID_UNSAFE_CREATE_SELECT';
exports[1787] = 'ER_GTID_UNSAFE_CREATE_DROP_TEMP_TABLE_IN_TRANSACTION';
exports[1788] = 'ER_GTID_MODE_CAN_ONLY_CHANGE_ONE_STEP_AT_A_TIME';
exports[1789] = 'ER_SOURCE_HAS_PURGED_REQUIRED_GTIDS';
exports[1790] = 'ER_CANT_SET_GTID_NEXT_WHEN_OWNING_GTID';
exports[1791] = 'ER_UNKNOWN_EXPLAIN_FORMAT';
exports[1792] = 'ER_CANT_EXECUTE_IN_READ_ONLY_TRANSACTION';
exports[1793] = 'ER_TOO_LONG_TABLE_PARTITION_COMMENT';
exports[1794] = 'ER_REPLICA_CONFIGURATION';
exports[1795] = 'ER_INNODB_FT_LIMIT';
exports[1796] = 'ER_INNODB_NO_FT_TEMP_TABLE';
exports[1797] = 'ER_INNODB_FT_WRONG_DOCID_COLUMN';
exports[1798] = 'ER_INNODB_FT_WRONG_DOCID_INDEX';
exports[1799] = 'ER_INNODB_ONLINE_LOG_TOO_BIG';
exports[1800] = 'ER_UNKNOWN_ALTER_ALGORITHM';
exports[1801] = 'ER_UNKNOWN_ALTER_LOCK';
exports[1802] = 'ER_MTA_CHANGE_SOURCE_CANT_RUN_WITH_GAPS';
exports[1803] = 'ER_MTA_RECOVERY_FAILURE';
exports[1804] = 'ER_MTA_RESET_WORKERS';
exports[1805] = 'ER_COL_COUNT_DOESNT_MATCH_CORRUPTED_V2';
exports[1806] = 'ER_REPLICA_SILENT_RETRY_TRANSACTION';
exports[1807] = 'ER_DISCARD_FK_CHECKS_RUNNING';
exports[1808] = 'ER_TABLE_SCHEMA_MISMATCH';
exports[1809] = 'ER_TABLE_IN_SYSTEM_TABLESPACE';
exports[1810] = 'ER_IO_READ_ERROR';
exports[1811] = 'ER_IO_WRITE_ERROR';
exports[1812] = 'ER_TABLESPACE_MISSING';
exports[1813] = 'ER_TABLESPACE_EXISTS';
exports[1814] = 'ER_TABLESPACE_DISCARDED';
exports[1815] = 'ER_INTERNAL_ERROR';
exports[1816] = 'ER_INNODB_IMPORT_ERROR';
exports[1817] = 'ER_INNODB_INDEX_CORRUPT';
exports[1818] = 'ER_INVALID_YEAR_COLUMN_LENGTH';
exports[1819] = 'ER_NOT_VALID_PASSWORD';
exports[1820] = 'ER_MUST_CHANGE_PASSWORD';
exports[1821] = 'ER_FK_NO_INDEX_CHILD';
exports[1822] = 'ER_FK_NO_INDEX_PARENT';
exports[1823] = 'ER_FK_FAIL_ADD_SYSTEM';
exports[1824] = 'ER_FK_CANNOT_OPEN_PARENT';
exports[1825] = 'ER_FK_INCORRECT_OPTION';
exports[1826] = 'ER_FK_DUP_NAME';
exports[1827] = 'ER_PASSWORD_FORMAT';
exports[1828] = 'ER_FK_COLUMN_CANNOT_DROP';
exports[1829] = 'ER_FK_COLUMN_CANNOT_DROP_CHILD';
exports[1830] = 'ER_FK_COLUMN_NOT_NULL';
exports[1831] = 'ER_DUP_INDEX';
exports[1832] = 'ER_FK_COLUMN_CANNOT_CHANGE';
exports[1833] = 'ER_FK_COLUMN_CANNOT_CHANGE_CHILD';
exports[1834] = 'ER_UNUSED5';
exports[1835] = 'ER_MALFORMED_PACKET';
exports[1836] = 'ER_READ_ONLY_MODE';
exports[1837] = 'ER_GTID_NEXT_TYPE_UNDEFINED_GTID';
exports[1838] = 'ER_VARIABLE_NOT_SETTABLE_IN_SP';
exports[1839] = 'ER_CANT_SET_GTID_PURGED_WHEN_GTID_MODE_IS_OFF';
exports[1840] = 'ER_CANT_SET_GTID_PURGED_WHEN_GTID_EXECUTED_IS_NOT_EMPTY';
exports[1841] = 'ER_CANT_SET_GTID_PURGED_WHEN_OWNED_GTIDS_IS_NOT_EMPTY';
exports[1842] = 'ER_GTID_PURGED_WAS_CHANGED';
exports[1843] = 'ER_GTID_EXECUTED_WAS_CHANGED';
exports[1844] = 'ER_BINLOG_STMT_MODE_AND_NO_REPL_TABLES';
exports[1845] = 'ER_ALTER_OPERATION_NOT_SUPPORTED';
exports[1846] = 'ER_ALTER_OPERATION_NOT_SUPPORTED_REASON';
exports[1847] = 'ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_COPY';
exports[1848] = 'ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_PARTITION';
exports[1849] = 'ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_FK_RENAME';
exports[1850] = 'ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_COLUMN_TYPE';
exports[1851] = 'ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_FK_CHECK';
exports[1852] = 'ER_UNUSED6';
exports[1853] = 'ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_NOPK';
exports[1854] = 'ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_AUTOINC';
exports[1855] = 'ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_HIDDEN_FTS';
exports[1856] = 'ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_CHANGE_FTS';
exports[1857] = 'ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_FTS';
exports[1858] = 'ER_SQL_REPLICA_SKIP_COUNTER_NOT_SETTABLE_IN_GTID_MODE';
exports[1859] = 'ER_DUP_UNKNOWN_IN_INDEX';
exports[1860] = 'ER_IDENT_CAUSES_TOO_LONG_PATH';
exports[1861] = 'ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_NOT_NULL';
exports[1862] = 'ER_MUST_CHANGE_PASSWORD_LOGIN';
exports[1863] = 'ER_ROW_IN_WRONG_PARTITION';
exports[1864] = 'ER_MTA_EVENT_BIGGER_PENDING_JOBS_SIZE_MAX';
exports[1865] = 'ER_INNODB_NO_FT_USES_PARSER';
exports[1866] = 'ER_BINLOG_LOGICAL_CORRUPTION';
exports[1867] = 'ER_WARN_PURGE_LOG_IN_USE';
exports[1868] = 'ER_WARN_PURGE_LOG_IS_ACTIVE';
exports[1869] = 'ER_AUTO_INCREMENT_CONFLICT';
exports[1870] = 'WARN_ON_BLOCKHOLE_IN_RBR';
exports[1871] = 'ER_REPLICA_CM_INIT_REPOSITORY';
exports[1872] = 'ER_REPLICA_AM_INIT_REPOSITORY';
exports[1873] = 'ER_ACCESS_DENIED_CHANGE_USER_ERROR';
exports[1874] = 'ER_INNODB_READ_ONLY';
exports[1875] = 'ER_STOP_REPLICA_SQL_THREAD_TIMEOUT';
exports[1876] = 'ER_STOP_REPLICA_IO_THREAD_TIMEOUT';
exports[1877] = 'ER_TABLE_CORRUPT';
exports[1878] = 'ER_TEMP_FILE_WRITE_FAILURE';
exports[1879] = 'ER_INNODB_FT_AUX_NOT_HEX_ID';
exports[1880] = 'ER_OLD_TEMPORALS_UPGRADED';
exports[1881] = 'ER_INNODB_FORCED_RECOVERY';
exports[1882] = 'ER_AES_INVALID_IV';
exports[1883] = 'ER_PLUGIN_CANNOT_BE_UNINSTALLED';
exports[1884] = 'ER_GTID_UNSAFE_BINLOG_SPLITTABLE_STATEMENT_AND_ASSIGNED_GTID';
exports[1885] = 'ER_REPLICA_HAS_MORE_GTIDS_THAN_SOURCE';
exports[1886] = 'ER_MISSING_KEY';
exports[1887] = 'WARN_NAMED_PIPE_ACCESS_EVERYONE';
exports[3000] = 'ER_FILE_CORRUPT';
exports[3001] = 'ER_ERROR_ON_SOURCE';
exports[3002] = 'ER_INCONSISTENT_ERROR';
exports[3003] = 'ER_STORAGE_ENGINE_NOT_LOADED';
exports[3004] = 'ER_GET_STACKED_DA_WITHOUT_ACTIVE_HANDLER';
exports[3005] = 'ER_WARN_LEGACY_SYNTAX_CONVERTED';
exports[3006] = 'ER_BINLOG_UNSAFE_FULLTEXT_PLUGIN';
exports[3007] = 'ER_CANNOT_DISCARD_TEMPORARY_TABLE';
exports[3008] = 'ER_FK_DEPTH_EXCEEDED';
exports[3009] = 'ER_COL_COUNT_DOESNT_MATCH_PLEASE_UPDATE_V2';
exports[3010] = 'ER_WARN_TRIGGER_DOESNT_HAVE_CREATED';
exports[3011] = 'ER_REFERENCED_TRG_DOES_NOT_EXIST';
exports[3012] = 'ER_EXPLAIN_NOT_SUPPORTED';
exports[3013] = 'ER_INVALID_FIELD_SIZE';
exports[3014] = 'ER_MISSING_HA_CREATE_OPTION';
exports[3015] = 'ER_ENGINE_OUT_OF_MEMORY';
exports[3016] = 'ER_PASSWORD_EXPIRE_ANONYMOUS_USER';
exports[3017] = 'ER_REPLICA_SQL_THREAD_MUST_STOP';
exports[3018] = 'ER_NO_FT_MATERIALIZED_SUBQUERY';
exports[3019] = 'ER_INNODB_UNDO_LOG_FULL';
exports[3020] = 'ER_INVALID_ARGUMENT_FOR_LOGARITHM';
exports[3021] = 'ER_REPLICA_CHANNEL_IO_THREAD_MUST_STOP';
exports[3022] = 'ER_WARN_OPEN_TEMP_TABLES_MUST_BE_ZERO';
exports[3023] = 'ER_WARN_ONLY_SOURCE_LOG_FILE_NO_POS';
exports[3024] = 'ER_QUERY_TIMEOUT';
exports[3025] = 'ER_NON_RO_SELECT_DISABLE_TIMER';
exports[3026] = 'ER_DUP_LIST_ENTRY';
exports[3027] = 'ER_SQL_MODE_NO_EFFECT';
exports[3028] = 'ER_AGGREGATE_ORDER_FOR_UNION';
exports[3029] = 'ER_AGGREGATE_ORDER_NON_AGG_QUERY';
exports[3030] = 'ER_REPLICA_WORKER_STOPPED_PREVIOUS_THD_ERROR';
exports[3031] = 'ER_DONT_SUPPORT_REPLICA_PRESERVE_COMMIT_ORDER';
exports[3032] = 'ER_SERVER_OFFLINE_MODE';
exports[3033] = 'ER_GIS_DIFFERENT_SRIDS';
exports[3034] = 'ER_GIS_UNSUPPORTED_ARGUMENT';
exports[3035] = 'ER_GIS_UNKNOWN_ERROR';
exports[3036] = 'ER_GIS_UNKNOWN_EXCEPTION';
exports[3037] = 'ER_GIS_INVALID_DATA';
exports[3038] = 'ER_BOOST_GEOMETRY_EMPTY_INPUT_EXCEPTION';
exports[3039] = 'ER_BOOST_GEOMETRY_CENTROID_EXCEPTION';
exports[3040] = 'ER_BOOST_GEOMETRY_OVERLAY_INVALID_INPUT_EXCEPTION';
exports[3041] = 'ER_BOOST_GEOMETRY_TURN_INFO_EXCEPTION';
exports[3042] = 'ER_BOOST_GEOMETRY_SELF_INTERSECTION_POINT_EXCEPTION';
exports[3043] = 'ER_BOOST_GEOMETRY_UNKNOWN_EXCEPTION';
exports[3044] = 'ER_STD_BAD_ALLOC_ERROR';
exports[3045] = 'ER_STD_DOMAIN_ERROR';
exports[3046] = 'ER_STD_LENGTH_ERROR';
exports[3047] = 'ER_STD_INVALID_ARGUMENT';
exports[3048] = 'ER_STD_OUT_OF_RANGE_ERROR';
exports[3049] = 'ER_STD_OVERFLOW_ERROR';
exports[3050] = 'ER_STD_RANGE_ERROR';
exports[3051] = 'ER_STD_UNDERFLOW_ERROR';
exports[3052] = 'ER_STD_LOGIC_ERROR';
exports[3053] = 'ER_STD_RUNTIME_ERROR';
exports[3054] = 'ER_STD_UNKNOWN_EXCEPTION';
exports[3055] = 'ER_GIS_DATA_WRONG_ENDIANESS';
exports[3056] = 'ER_CHANGE_SOURCE_PASSWORD_LENGTH';
exports[3057] = 'ER_USER_LOCK_WRONG_NAME';
exports[3058] = 'ER_USER_LOCK_DEADLOCK';
exports[3059] = 'ER_REPLACE_INACCESSIBLE_ROWS';
exports[3060] = 'ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_GIS';
exports[3061] = 'ER_ILLEGAL_USER_VAR';
exports[3062] = 'ER_GTID_MODE_OFF';
exports[3063] = 'ER_UNSUPPORTED_BY_REPLICATION_THREAD';
exports[3064] = 'ER_INCORRECT_TYPE';
exports[3065] = 'ER_FIELD_IN_ORDER_NOT_SELECT';
exports[3066] = 'ER_AGGREGATE_IN_ORDER_NOT_SELECT';
exports[3067] = 'ER_INVALID_RPL_WILD_TABLE_FILTER_PATTERN';
exports[3068] = 'ER_NET_OK_PACKET_TOO_LARGE';
exports[3069] = 'ER_INVALID_JSON_DATA';
exports[3070] = 'ER_INVALID_GEOJSON_MISSING_MEMBER';
exports[3071] = 'ER_INVALID_GEOJSON_WRONG_TYPE';
exports[3072] = 'ER_INVALID_GEOJSON_UNSPECIFIED';
exports[3073] = 'ER_DIMENSION_UNSUPPORTED';
exports[3074] = 'ER_REPLICA_CHANNEL_DOES_NOT_EXIST';
exports[3075] = 'ER_SLAVE_MULTIPLE_CHANNELS_HOST_PORT';
exports[3076] = 'ER_REPLICA_CHANNEL_NAME_INVALID_OR_TOO_LONG';
exports[3077] = 'ER_REPLICA_NEW_CHANNEL_WRONG_REPOSITORY';
exports[3078] = 'ER_SLAVE_CHANNEL_DELETE';
exports[3079] = 'ER_REPLICA_MULTIPLE_CHANNELS_CMD';
exports[3080] = 'ER_REPLICA_MAX_CHANNELS_EXCEEDED';
exports[3081] = 'ER_REPLICA_CHANNEL_MUST_STOP';
exports[3082] = 'ER_REPLICA_CHANNEL_NOT_RUNNING';
exports[3083] = 'ER_REPLICA_CHANNEL_WAS_RUNNING';
exports[3084] = 'ER_REPLICA_CHANNEL_WAS_NOT_RUNNING';
exports[3085] = 'ER_REPLICA_CHANNEL_SQL_THREAD_MUST_STOP';
exports[3086] = 'ER_REPLICA_CHANNEL_SQL_SKIP_COUNTER';
exports[3087] = 'ER_WRONG_FIELD_WITH_GROUP_V2';
exports[3088] = 'ER_MIX_OF_GROUP_FUNC_AND_FIELDS_V2';
exports[3089] = 'ER_WARN_DEPRECATED_SYSVAR_UPDATE';
exports[3090] = 'ER_WARN_DEPRECATED_SQLMODE';
exports[3091] = 'ER_CANNOT_LOG_PARTIAL_DROP_DATABASE_WITH_GTID';
exports[3092] = 'ER_GROUP_REPLICATION_CONFIGURATION';
exports[3093] = 'ER_GROUP_REPLICATION_RUNNING';
exports[3094] = 'ER_GROUP_REPLICATION_APPLIER_INIT_ERROR';
exports[3095] = 'ER_GROUP_REPLICATION_STOP_APPLIER_THREAD_TIMEOUT';
exports[3096] = 'ER_GROUP_REPLICATION_COMMUNICATION_LAYER_SESSION_ERROR';
exports[3097] = 'ER_GROUP_REPLICATION_COMMUNICATION_LAYER_JOIN_ERROR';
exports[3098] = 'ER_BEFORE_DML_VALIDATION_ERROR';
exports[3099] = 'ER_PREVENTS_VARIABLE_WITHOUT_RBR';
exports[3100] = 'ER_RUN_HOOK_ERROR';
exports[3101] = 'ER_TRANSACTION_ROLLBACK_DURING_COMMIT';
exports[3102] = 'ER_GENERATED_COLUMN_FUNCTION_IS_NOT_ALLOWED';
exports[3103] = 'ER_UNSUPPORTED_ALTER_INPLACE_ON_VIRTUAL_COLUMN';
exports[3104] = 'ER_WRONG_FK_OPTION_FOR_GENERATED_COLUMN';
exports[3105] = 'ER_NON_DEFAULT_VALUE_FOR_GENERATED_COLUMN';
exports[3106] = 'ER_UNSUPPORTED_ACTION_ON_GENERATED_COLUMN';
exports[3107] = 'ER_GENERATED_COLUMN_NON_PRIOR';
exports[3108] = 'ER_DEPENDENT_BY_GENERATED_COLUMN';
exports[3109] = 'ER_GENERATED_COLUMN_REF_AUTO_INC';
exports[3110] = 'ER_FEATURE_NOT_AVAILABLE';
exports[3111] = 'ER_CANT_SET_GTID_MODE';
exports[3112] = 'ER_CANT_USE_AUTO_POSITION_WITH_GTID_MODE_OFF';
exports[3113] = 'ER_CANT_REPLICATE_ANONYMOUS_WITH_AUTO_POSITION';
exports[3114] = 'ER_CANT_REPLICATE_ANONYMOUS_WITH_GTID_MODE_ON';
exports[3115] = 'ER_CANT_REPLICATE_GTID_WITH_GTID_MODE_OFF';
exports[3116] =
  'ER_CANT_ENFORCE_GTID_CONSISTENCY_WITH_ONGOING_GTID_VIOLATING_TX';
exports[3117] =
  'ER_ENFORCE_GTID_CONSISTENCY_WARN_WITH_ONGOING_GTID_VIOLATING_TX';
exports[3118] = 'ER_ACCOUNT_HAS_BEEN_LOCKED';
exports[3119] = 'ER_WRONG_TABLESPACE_NAME';
exports[3120] = 'ER_TABLESPACE_IS_NOT_EMPTY';
exports[3121] = 'ER_WRONG_FILE_NAME';
exports[3122] = 'ER_BOOST_GEOMETRY_INCONSISTENT_TURNS_EXCEPTION';
exports[3123] = 'ER_WARN_OPTIMIZER_HINT_SYNTAX_ERROR';
exports[3124] = 'ER_WARN_BAD_MAX_EXECUTION_TIME';
exports[3125] = 'ER_WARN_UNSUPPORTED_MAX_EXECUTION_TIME';
exports[3126] = 'ER_WARN_CONFLICTING_HINT';
exports[3127] = 'ER_WARN_UNKNOWN_QB_NAME';
exports[3128] = 'ER_UNRESOLVED_HINT_NAME';
exports[3129] = 'ER_WARN_ON_MODIFYING_GTID_EXECUTED_TABLE';
exports[3130] = 'ER_PLUGGABLE_PROTOCOL_COMMAND_NOT_SUPPORTED';
exports[3131] = 'ER_LOCKING_SERVICE_WRONG_NAME';
exports[3132] = 'ER_LOCKING_SERVICE_DEADLOCK';
exports[3133] = 'ER_LOCKING_SERVICE_TIMEOUT';
exports[3134] = 'ER_GIS_MAX_POINTS_IN_GEOMETRY_OVERFLOWED';
exports[3135] = 'ER_SQL_MODE_MERGED';
exports[3136] = 'ER_VTOKEN_PLUGIN_TOKEN_MISMATCH';
exports[3137] = 'ER_VTOKEN_PLUGIN_TOKEN_NOT_FOUND';
exports[3138] = 'ER_CANT_SET_VARIABLE_WHEN_OWNING_GTID';
exports[3139] = 'ER_REPLICA_CHANNEL_OPERATION_NOT_ALLOWED';
exports[3140] = 'ER_INVALID_JSON_TEXT';
exports[3141] = 'ER_INVALID_JSON_TEXT_IN_PARAM';
exports[3142] = 'ER_INVALID_JSON_BINARY_DATA';
exports[3143] = 'ER_INVALID_JSON_PATH';
exports[3144] = 'ER_INVALID_JSON_CHARSET';
exports[3145] = 'ER_INVALID_JSON_CHARSET_IN_FUNCTION';
exports[3146] = 'ER_INVALID_TYPE_FOR_JSON';
exports[3147] = 'ER_INVALID_CAST_TO_JSON';
exports[3148] = 'ER_INVALID_JSON_PATH_CHARSET';
exports[3149] = 'ER_INVALID_JSON_PATH_WILDCARD';
exports[3150] = 'ER_JSON_VALUE_TOO_BIG';
exports[3151] = 'ER_JSON_KEY_TOO_BIG';
exports[3152] = 'ER_JSON_USED_AS_KEY';
exports[3153] = 'ER_JSON_VACUOUS_PATH';
exports[3154] = 'ER_JSON_BAD_ONE_OR_ALL_ARG';
exports[3155] = 'ER_NUMERIC_JSON_VALUE_OUT_OF_RANGE';
exports[3156] = 'ER_INVALID_JSON_VALUE_FOR_CAST';
exports[3157] = 'ER_JSON_DOCUMENT_TOO_DEEP';
exports[3158] = 'ER_JSON_DOCUMENT_NULL_KEY';
exports[3159] = 'ER_SECURE_TRANSPORT_REQUIRED';
exports[3160] = 'ER_NO_SECURE_TRANSPORTS_CONFIGURED';
exports[3161] = 'ER_DISABLED_STORAGE_ENGINE';
exports[3162] = 'ER_USER_DOES_NOT_EXIST';
exports[3163] = 'ER_USER_ALREADY_EXISTS';
exports[3164] = 'ER_AUDIT_API_ABORT';
exports[3165] = 'ER_INVALID_JSON_PATH_ARRAY_CELL';
exports[3166] = 'ER_BUFPOOL_RESIZE_INPROGRESS';
exports[3167] = 'ER_FEATURE_DISABLED_SEE_DOC';
exports[3168] = 'ER_SERVER_ISNT_AVAILABLE';
exports[3169] = 'ER_SESSION_WAS_KILLED';
exports[3170] = 'ER_CAPACITY_EXCEEDED';
exports[3171] = 'ER_CAPACITY_EXCEEDED_IN_RANGE_OPTIMIZER';
exports[3172] = 'ER_TABLE_NEEDS_UPG_PART';
exports[3173] = 'ER_CANT_WAIT_FOR_EXECUTED_GTID_SET_WHILE_OWNING_A_GTID';
exports[3174] = 'ER_CANNOT_ADD_FOREIGN_BASE_COL_VIRTUAL';
exports[3175] = 'ER_CANNOT_CREATE_VIRTUAL_INDEX_CONSTRAINT';
exports[3176] = 'ER_ERROR_ON_MODIFYING_GTID_EXECUTED_TABLE';
exports[3177] = 'ER_LOCK_REFUSED_BY_ENGINE';
exports[3178] = 'ER_UNSUPPORTED_ALTER_ONLINE_ON_VIRTUAL_COLUMN';
exports[3179] = 'ER_MASTER_KEY_ROTATION_NOT_SUPPORTED_BY_SE';
exports[3180] = 'ER_MASTER_KEY_ROTATION_ERROR_BY_SE';
exports[3181] = 'ER_MASTER_KEY_ROTATION_BINLOG_FAILED';
exports[3182] = 'ER_MASTER_KEY_ROTATION_SE_UNAVAILABLE';
exports[3183] = 'ER_TABLESPACE_CANNOT_ENCRYPT';
exports[3184] = 'ER_INVALID_ENCRYPTION_OPTION';
exports[3185] = 'ER_CANNOT_FIND_KEY_IN_KEYRING';
exports[3186] = 'ER_CAPACITY_EXCEEDED_IN_PARSER';
exports[3187] = 'ER_UNSUPPORTED_ALTER_ENCRYPTION_INPLACE';
exports[3188] = 'ER_KEYRING_UDF_KEYRING_SERVICE_ERROR';
exports[3189] = 'ER_USER_COLUMN_OLD_LENGTH';
exports[3190] = 'ER_CANT_RESET_SOURCE';
exports[3191] = 'ER_GROUP_REPLICATION_MAX_GROUP_SIZE';
exports[3192] = 'ER_CANNOT_ADD_FOREIGN_BASE_COL_STORED';
exports[3193] = 'ER_TABLE_REFERENCED';
exports[3194] = 'ER_PARTITION_ENGINE_DEPRECATED_FOR_TABLE';
exports[3195] = 'ER_WARN_USING_GEOMFROMWKB_TO_SET_SRID_ZERO';
exports[3196] = 'ER_WARN_USING_GEOMFROMWKB_TO_SET_SRID';
exports[3197] = 'ER_XA_RETRY';
exports[3198] = 'ER_KEYRING_AWS_UDF_AWS_KMS_ERROR';
exports[3199] = 'ER_BINLOG_UNSAFE_XA';
exports[3200] = 'ER_UDF_ERROR';
exports[3201] = 'ER_KEYRING_MIGRATION_FAILURE';
exports[3202] = 'ER_KEYRING_ACCESS_DENIED_ERROR';
exports[3203] = 'ER_KEYRING_MIGRATION_STATUS';
exports[3204] = 'ER_PLUGIN_FAILED_TO_OPEN_TABLES';
exports[3205] = 'ER_PLUGIN_FAILED_TO_OPEN_TABLE';
exports[3206] = 'ER_AUDIT_LOG_NO_KEYRING_PLUGIN_INSTALLED';
exports[3207] = 'ER_AUDIT_LOG_ENCRYPTION_PASSWORD_HAS_NOT_BEEN_SET';
exports[3208] = 'ER_AUDIT_LOG_COULD_NOT_CREATE_AES_KEY';
exports[3209] = 'ER_AUDIT_LOG_ENCRYPTION_PASSWORD_CANNOT_BE_FETCHED';
exports[3210] = 'ER_AUDIT_LOG_JSON_FILTERING_NOT_ENABLED';
exports[3211] = 'ER_AUDIT_LOG_UDF_INSUFFICIENT_PRIVILEGE';
exports[3212] = 'ER_AUDIT_LOG_SUPER_PRIVILEGE_REQUIRED';
exports[3213] = 'ER_COULD_NOT_REINITIALIZE_AUDIT_LOG_FILTERS';
exports[3214] = 'ER_AUDIT_LOG_UDF_INVALID_ARGUMENT_TYPE';
exports[3215] = 'ER_AUDIT_LOG_UDF_INVALID_ARGUMENT_COUNT';
exports[3216] = 'ER_AUDIT_LOG_HAS_NOT_BEEN_INSTALLED';
exports[3217] = 'ER_AUDIT_LOG_UDF_READ_INVALID_MAX_ARRAY_LENGTH_ARG_TYPE';
exports[3218] = 'ER_AUDIT_LOG_UDF_READ_INVALID_MAX_ARRAY_LENGTH_ARG_VALUE';
exports[3219] = 'ER_AUDIT_LOG_JSON_FILTER_PARSING_ERROR';
exports[3220] = 'ER_AUDIT_LOG_JSON_FILTER_NAME_CANNOT_BE_EMPTY';
exports[3221] = 'ER_AUDIT_LOG_JSON_USER_NAME_CANNOT_BE_EMPTY';
exports[3222] = 'ER_AUDIT_LOG_JSON_FILTER_DOES_NOT_EXISTS';
exports[3223] = 'ER_AUDIT_LOG_USER_FIRST_CHARACTER_MUST_BE_ALPHANUMERIC';
exports[3224] = 'ER_AUDIT_LOG_USER_NAME_INVALID_CHARACTER';
exports[3225] = 'ER_AUDIT_LOG_HOST_NAME_INVALID_CHARACTER';
exports[3226] = 'WARN_DEPRECATED_MAXDB_SQL_MODE_FOR_TIMESTAMP';
exports[3227] = 'ER_XA_REPLICATION_FILTERS';
exports[3228] = 'ER_CANT_OPEN_ERROR_LOG';
exports[3229] = 'ER_GROUPING_ON_TIMESTAMP_IN_DST';
exports[3230] = 'ER_CANT_START_SERVER_NAMED_PIPE';
exports[3231] = 'ER_WRITE_SET_EXCEEDS_LIMIT';
exports[3232] = 'ER_DEPRECATED_TLS_VERSION_SESSION_57';
exports[3233] = 'ER_WARN_DEPRECATED_TLS_VERSION_57';
exports[3234] = 'ER_WARN_WRONG_NATIVE_TABLE_STRUCTURE';
exports[3235] = 'ER_AES_INVALID_KDF_NAME';
exports[3236] = 'ER_AES_INVALID_KDF_ITERATIONS';
exports[3237] = 'WARN_AES_KEY_SIZE';
exports[3238] = 'ER_AES_INVALID_KDF_OPTION_SIZE';
exports[3500] = 'ER_UNSUPPORT_COMPRESSED_TEMPORARY_TABLE';
exports[3501] = 'ER_ACL_OPERATION_FAILED';
exports[3502] = 'ER_UNSUPPORTED_INDEX_ALGORITHM';
exports[3503] = 'ER_NO_SUCH_DB';
exports[3504] = 'ER_TOO_BIG_ENUM';
exports[3505] = 'ER_TOO_LONG_SET_ENUM_VALUE';
exports[3506] = 'ER_INVALID_DD_OBJECT';
exports[3507] = 'ER_UPDATING_DD_TABLE';
exports[3508] = 'ER_INVALID_DD_OBJECT_ID';
exports[3509] = 'ER_INVALID_DD_OBJECT_NAME';
exports[3510] = 'ER_TABLESPACE_MISSING_WITH_NAME';
exports[3511] = 'ER_TOO_LONG_ROUTINE_COMMENT';
exports[3512] = 'ER_SP_LOAD_FAILED';
exports[3513] = 'ER_INVALID_BITWISE_OPERANDS_SIZE';
exports[3514] = 'ER_INVALID_BITWISE_AGGREGATE_OPERANDS_SIZE';
exports[3515] = 'ER_WARN_UNSUPPORTED_HINT';
exports[3516] = 'ER_UNEXPECTED_GEOMETRY_TYPE';
exports[3517] = 'ER_SRS_PARSE_ERROR';
exports[3518] = 'ER_SRS_PROJ_PARAMETER_MISSING';
exports[3519] = 'ER_WARN_SRS_NOT_FOUND';
exports[3520] = 'ER_SRS_NOT_CARTESIAN';
exports[3521] = 'ER_SRS_NOT_CARTESIAN_UNDEFINED';
exports[3522] = 'ER_PK_INDEX_CANT_BE_INVISIBLE';
exports[3523] = 'ER_UNKNOWN_AUTHID';
exports[3524] = 'ER_FAILED_ROLE_GRANT';
exports[3525] = 'ER_OPEN_ROLE_TABLES';
exports[3526] = 'ER_FAILED_DEFAULT_ROLES';
exports[3527] = 'ER_COMPONENTS_NO_SCHEME';
exports[3528] = 'ER_COMPONENTS_NO_SCHEME_SERVICE';
exports[3529] = 'ER_COMPONENTS_CANT_LOAD';
exports[3530] = 'ER_ROLE_NOT_GRANTED';
exports[3531] = 'ER_FAILED_REVOKE_ROLE';
exports[3532] = 'ER_RENAME_ROLE';
exports[3533] = 'ER_COMPONENTS_CANT_ACQUIRE_SERVICE_IMPLEMENTATION';
exports[3534] = 'ER_COMPONENTS_CANT_SATISFY_DEPENDENCY';
exports[3535] = 'ER_COMPONENTS_LOAD_CANT_REGISTER_SERVICE_IMPLEMENTATION';
exports[3536] = 'ER_COMPONENTS_LOAD_CANT_INITIALIZE';
exports[3537] = 'ER_COMPONENTS_UNLOAD_NOT_LOADED';
exports[3538] = 'ER_COMPONENTS_UNLOAD_CANT_DEINITIALIZE';
exports[3539] = 'ER_COMPONENTS_CANT_RELEASE_SERVICE';
exports[3540] = 'ER_COMPONENTS_UNLOAD_CANT_UNREGISTER_SERVICE';
exports[3541] = 'ER_COMPONENTS_CANT_UNLOAD';
exports[3542] = 'ER_WARN_UNLOAD_THE_NOT_PERSISTED';
exports[3543] = 'ER_COMPONENT_TABLE_INCORRECT';
exports[3544] = 'ER_COMPONENT_MANIPULATE_ROW_FAILED';
exports[3545] = 'ER_COMPONENTS_UNLOAD_DUPLICATE_IN_GROUP';
exports[3546] = 'ER_CANT_SET_GTID_PURGED_DUE_SETS_CONSTRAINTS';
exports[3547] = 'ER_CANNOT_LOCK_USER_MANAGEMENT_CACHES';
exports[3548] = 'ER_SRS_NOT_FOUND';
exports[3549] = 'ER_VARIABLE_NOT_PERSISTED';
exports[3550] = 'ER_IS_QUERY_INVALID_CLAUSE';
exports[3551] = 'ER_UNABLE_TO_STORE_STATISTICS';
exports[3552] = 'ER_NO_SYSTEM_SCHEMA_ACCESS';
exports[3553] = 'ER_NO_SYSTEM_TABLESPACE_ACCESS';
exports[3554] = 'ER_NO_SYSTEM_TABLE_ACCESS';
exports[3555] = 'ER_NO_SYSTEM_TABLE_ACCESS_FOR_DICTIONARY_TABLE';
exports[3556] = 'ER_NO_SYSTEM_TABLE_ACCESS_FOR_SYSTEM_TABLE';
exports[3557] = 'ER_NO_SYSTEM_TABLE_ACCESS_FOR_TABLE';
exports[3558] = 'ER_INVALID_OPTION_KEY';
exports[3559] = 'ER_INVALID_OPTION_VALUE';
exports[3560] = 'ER_INVALID_OPTION_KEY_VALUE_PAIR';
exports[3561] = 'ER_INVALID_OPTION_START_CHARACTER';
exports[3562] = 'ER_INVALID_OPTION_END_CHARACTER';
exports[3563] = 'ER_INVALID_OPTION_CHARACTERS';
exports[3564] = 'ER_DUPLICATE_OPTION_KEY';
exports[3565] = 'ER_WARN_SRS_NOT_FOUND_AXIS_ORDER';
exports[3566] = 'ER_NO_ACCESS_TO_NATIVE_FCT';
exports[3567] = 'ER_RESET_SOURCE_TO_VALUE_OUT_OF_RANGE';
exports[3568] = 'ER_UNRESOLVED_TABLE_LOCK';
exports[3569] = 'ER_DUPLICATE_TABLE_LOCK';
exports[3570] = 'ER_BINLOG_UNSAFE_SKIP_LOCKED';
exports[3571] = 'ER_BINLOG_UNSAFE_NOWAIT';
exports[3572] = 'ER_LOCK_NOWAIT';
exports[3573] = 'ER_CTE_RECURSIVE_REQUIRES_UNION';
exports[3574] = 'ER_CTE_RECURSIVE_REQUIRES_NONRECURSIVE_FIRST';
exports[3575] = 'ER_CTE_RECURSIVE_FORBIDS_AGGREGATION';
exports[3576] = 'ER_CTE_RECURSIVE_FORBIDDEN_JOIN_ORDER';
exports[3577] = 'ER_CTE_RECURSIVE_REQUIRES_SINGLE_REFERENCE';
exports[3578] = 'ER_SWITCH_TMP_ENGINE';
exports[3579] = 'ER_WINDOW_NO_SUCH_WINDOW';
exports[3580] = 'ER_WINDOW_CIRCULARITY_IN_WINDOW_GRAPH';
exports[3581] = 'ER_WINDOW_NO_CHILD_PARTITIONING';
exports[3582] = 'ER_WINDOW_NO_INHERIT_FRAME';
exports[3583] = 'ER_WINDOW_NO_REDEFINE_ORDER_BY';
exports[3584] = 'ER_WINDOW_FRAME_START_ILLEGAL';
exports[3585] = 'ER_WINDOW_FRAME_END_ILLEGAL';
exports[3586] = 'ER_WINDOW_FRAME_ILLEGAL';
exports[3587] = 'ER_WINDOW_RANGE_FRAME_ORDER_TYPE';
exports[3588] = 'ER_WINDOW_RANGE_FRAME_TEMPORAL_TYPE';
exports[3589] = 'ER_WINDOW_RANGE_FRAME_NUMERIC_TYPE';
exports[3590] = 'ER_WINDOW_RANGE_BOUND_NOT_CONSTANT';
exports[3591] = 'ER_WINDOW_DUPLICATE_NAME';
exports[3592] = 'ER_WINDOW_ILLEGAL_ORDER_BY';
exports[3593] = 'ER_WINDOW_INVALID_WINDOW_FUNC_USE';
exports[3594] = 'ER_WINDOW_INVALID_WINDOW_FUNC_ALIAS_USE';
exports[3595] = 'ER_WINDOW_NESTED_WINDOW_FUNC_USE_IN_WINDOW_SPEC';
exports[3596] = 'ER_WINDOW_ROWS_INTERVAL_USE';
exports[3597] = 'ER_WINDOW_NO_GROUP_ORDER';
exports[3598] = 'ER_WINDOW_EXPLAIN_JSON';
exports[3599] = 'ER_WINDOW_FUNCTION_IGNORES_FRAME';
exports[3600] = 'ER_WL9236_NOW';
exports[3601] = 'ER_INVALID_NO_OF_ARGS';
exports[3602] = 'ER_FIELD_IN_GROUPING_NOT_GROUP_BY';
exports[3603] = 'ER_TOO_LONG_TABLESPACE_COMMENT';
exports[3604] = 'ER_ENGINE_CANT_DROP_TABLE';
exports[3605] = 'ER_ENGINE_CANT_DROP_MISSING_TABLE';
exports[3606] = 'ER_TABLESPACE_DUP_FILENAME';
exports[3607] = 'ER_DB_DROP_RMDIR2';
exports[3608] = 'ER_IMP_NO_FILES_MATCHED';
exports[3609] = 'ER_IMP_SCHEMA_DOES_NOT_EXIST';
exports[3610] = 'ER_IMP_TABLE_ALREADY_EXISTS';
exports[3611] = 'ER_IMP_INCOMPATIBLE_MYSQLD_VERSION';
exports[3612] = 'ER_IMP_INCOMPATIBLE_DD_VERSION';
exports[3613] = 'ER_IMP_INCOMPATIBLE_SDI_VERSION';
exports[3614] = 'ER_WARN_INVALID_HINT';
exports[3615] = 'ER_VAR_DOES_NOT_EXIST';
exports[3616] = 'ER_LONGITUDE_OUT_OF_RANGE';
exports[3617] = 'ER_LATITUDE_OUT_OF_RANGE';
exports[3618] = 'ER_NOT_IMPLEMENTED_FOR_GEOGRAPHIC_SRS';
exports[3619] = 'ER_ILLEGAL_PRIVILEGE_LEVEL';
exports[3620] = 'ER_NO_SYSTEM_VIEW_ACCESS';
exports[3621] = 'ER_COMPONENT_FILTER_FLABBERGASTED';
exports[3622] = 'ER_PART_EXPR_TOO_LONG';
exports[3623] = 'ER_UDF_DROP_DYNAMICALLY_REGISTERED';
exports[3624] = 'ER_UNABLE_TO_STORE_COLUMN_STATISTICS';
exports[3625] = 'ER_UNABLE_TO_UPDATE_COLUMN_STATISTICS';
exports[3626] = 'ER_UNABLE_TO_DROP_COLUMN_STATISTICS';
exports[3627] = 'ER_UNABLE_TO_BUILD_HISTOGRAM';
exports[3628] = 'ER_MANDATORY_ROLE';
exports[3629] = 'ER_MISSING_TABLESPACE_FILE';
exports[3630] = 'ER_PERSIST_ONLY_ACCESS_DENIED_ERROR';
exports[3631] = 'ER_CMD_NEED_SUPER';
exports[3632] = 'ER_PATH_IN_DATADIR';
exports[3633] = 'ER_CLONE_DDL_IN_PROGRESS';
exports[3634] = 'ER_CLONE_TOO_MANY_CONCURRENT_CLONES';
exports[3635] = 'ER_APPLIER_LOG_EVENT_VALIDATION_ERROR';
exports[3636] = 'ER_CTE_MAX_RECURSION_DEPTH';
exports[3637] = 'ER_NOT_HINT_UPDATABLE_VARIABLE';
exports[3638] = 'ER_CREDENTIALS_CONTRADICT_TO_HISTORY';
exports[3639] = 'ER_WARNING_PASSWORD_HISTORY_CLAUSES_VOID';
exports[3640] = 'ER_CLIENT_DOES_NOT_SUPPORT';
exports[3641] = 'ER_I_S_SKIPPED_TABLESPACE';
exports[3642] = 'ER_TABLESPACE_ENGINE_MISMATCH';
exports[3643] = 'ER_WRONG_SRID_FOR_COLUMN';
exports[3644] = 'ER_CANNOT_ALTER_SRID_DUE_TO_INDEX';
exports[3645] = 'ER_WARN_BINLOG_PARTIAL_UPDATES_DISABLED';
exports[3646] = 'ER_WARN_BINLOG_V1_ROW_EVENTS_DISABLED';
exports[3647] = 'ER_WARN_BINLOG_PARTIAL_UPDATES_SUGGESTS_PARTIAL_IMAGES';
exports[3648] = 'ER_COULD_NOT_APPLY_JSON_DIFF';
exports[3649] = 'ER_CORRUPTED_JSON_DIFF';
exports[3650] = 'ER_RESOURCE_GROUP_EXISTS';
exports[3651] = 'ER_RESOURCE_GROUP_NOT_EXISTS';
exports[3652] = 'ER_INVALID_VCPU_ID';
exports[3653] = 'ER_INVALID_VCPU_RANGE';
exports[3654] = 'ER_INVALID_THREAD_PRIORITY';
exports[3655] = 'ER_DISALLOWED_OPERATION';
exports[3656] = 'ER_RESOURCE_GROUP_BUSY';
exports[3657] = 'ER_RESOURCE_GROUP_DISABLED';
exports[3658] = 'ER_FEATURE_UNSUPPORTED';
exports[3659] = 'ER_ATTRIBUTE_IGNORED';
exports[3660] = 'ER_INVALID_THREAD_ID';
exports[3661] = 'ER_RESOURCE_GROUP_BIND_FAILED';
exports[3662] = 'ER_INVALID_USE_OF_FORCE_OPTION';
exports[3663] = 'ER_GROUP_REPLICATION_COMMAND_FAILURE';
exports[3664] = 'ER_SDI_OPERATION_FAILED';
exports[3665] = 'ER_MISSING_JSON_TABLE_VALUE';
exports[3666] = 'ER_WRONG_JSON_TABLE_VALUE';
exports[3667] = 'ER_TF_MUST_HAVE_ALIAS';
exports[3668] = 'ER_TF_FORBIDDEN_JOIN_TYPE';
exports[3669] = 'ER_JT_VALUE_OUT_OF_RANGE';
exports[3670] = 'ER_JT_MAX_NESTED_PATH';
exports[3671] = 'ER_PASSWORD_EXPIRATION_NOT_SUPPORTED_BY_AUTH_METHOD';
exports[3672] = 'ER_INVALID_GEOJSON_CRS_NOT_TOP_LEVEL';
exports[3673] = 'ER_BAD_NULL_ERROR_NOT_IGNORED';
exports[3674] = 'WARN_USELESS_SPATIAL_INDEX';
exports[3675] = 'ER_DISK_FULL_NOWAIT';
exports[3676] = 'ER_PARSE_ERROR_IN_DIGEST_FN';
exports[3677] = 'ER_UNDISCLOSED_PARSE_ERROR_IN_DIGEST_FN';
exports[3678] = 'ER_SCHEMA_DIR_EXISTS';
exports[3679] = 'ER_SCHEMA_DIR_MISSING';
exports[3680] = 'ER_SCHEMA_DIR_CREATE_FAILED';
exports[3681] = 'ER_SCHEMA_DIR_UNKNOWN';
exports[3682] = 'ER_ONLY_IMPLEMENTED_FOR_SRID_0_AND_4326';
exports[3683] = 'ER_BINLOG_EXPIRE_LOG_DAYS_AND_SECS_USED_TOGETHER';
exports[3684] = 'ER_REGEXP_BUFFER_OVERFLOW';
exports[3685] = 'ER_REGEXP_ILLEGAL_ARGUMENT';
exports[3686] = 'ER_REGEXP_INDEX_OUTOFBOUNDS_ERROR';
exports[3687] = 'ER_REGEXP_INTERNAL_ERROR';
exports[3688] = 'ER_REGEXP_RULE_SYNTAX';
exports[3689] = 'ER_REGEXP_BAD_ESCAPE_SEQUENCE';
exports[3690] = 'ER_REGEXP_UNIMPLEMENTED';
exports[3691] = 'ER_REGEXP_MISMATCHED_PAREN';
exports[3692] = 'ER_REGEXP_BAD_INTERVAL';
exports[3693] = 'ER_REGEXP_MAX_LT_MIN';
exports[3694] = 'ER_REGEXP_INVALID_BACK_REF';
exports[3695] = 'ER_REGEXP_LOOK_BEHIND_LIMIT';
exports[3696] = 'ER_REGEXP_MISSING_CLOSE_BRACKET';
exports[3697] = 'ER_REGEXP_INVALID_RANGE';
exports[3698] = 'ER_REGEXP_STACK_OVERFLOW';
exports[3699] = 'ER_REGEXP_TIME_OUT';
exports[3700] = 'ER_REGEXP_PATTERN_TOO_BIG';
exports[3701] = 'ER_CANT_SET_ERROR_LOG_SERVICE';
exports[3702] = 'ER_EMPTY_PIPELINE_FOR_ERROR_LOG_SERVICE';
exports[3703] = 'ER_COMPONENT_FILTER_DIAGNOSTICS';
exports[3704] = 'ER_NOT_IMPLEMENTED_FOR_CARTESIAN_SRS';
exports[3705] = 'ER_NOT_IMPLEMENTED_FOR_PROJECTED_SRS';
exports[3706] = 'ER_NONPOSITIVE_RADIUS';
exports[3707] = 'ER_RESTART_SERVER_FAILED';
exports[3708] = 'ER_SRS_MISSING_MANDATORY_ATTRIBUTE';
exports[3709] = 'ER_SRS_MULTIPLE_ATTRIBUTE_DEFINITIONS';
exports[3710] = 'ER_SRS_NAME_CANT_BE_EMPTY_OR_WHITESPACE';
exports[3711] = 'ER_SRS_ORGANIZATION_CANT_BE_EMPTY_OR_WHITESPACE';
exports[3712] = 'ER_SRS_ID_ALREADY_EXISTS';
exports[3713] = 'ER_WARN_SRS_ID_ALREADY_EXISTS';
exports[3714] = 'ER_CANT_MODIFY_SRID_0';
exports[3715] = 'ER_WARN_RESERVED_SRID_RANGE';
exports[3716] = 'ER_CANT_MODIFY_SRS_USED_BY_COLUMN';
exports[3717] = 'ER_SRS_INVALID_CHARACTER_IN_ATTRIBUTE';
exports[3718] = 'ER_SRS_ATTRIBUTE_STRING_TOO_LONG';
exports[3719] = 'ER_DEPRECATED_UTF8_ALIAS';
exports[3720] = 'ER_DEPRECATED_NATIONAL';
exports[3721] = 'ER_INVALID_DEFAULT_UTF8MB4_COLLATION';
exports[3722] = 'ER_UNABLE_TO_COLLECT_LOG_STATUS';
exports[3723] = 'ER_RESERVED_TABLESPACE_NAME';
exports[3724] = 'ER_UNABLE_TO_SET_OPTION';
exports[3725] = 'ER_REPLICA_POSSIBLY_DIVERGED_AFTER_DDL';
exports[3726] = 'ER_SRS_NOT_GEOGRAPHIC';
exports[3727] = 'ER_POLYGON_TOO_LARGE';
exports[3728] = 'ER_SPATIAL_UNIQUE_INDEX';
exports[3729] = 'ER_INDEX_TYPE_NOT_SUPPORTED_FOR_SPATIAL_INDEX';
exports[3730] = 'ER_FK_CANNOT_DROP_PARENT';
exports[3731] = 'ER_GEOMETRY_PARAM_LONGITUDE_OUT_OF_RANGE';
exports[3732] = 'ER_GEOMETRY_PARAM_LATITUDE_OUT_OF_RANGE';
exports[3733] = 'ER_FK_CANNOT_USE_VIRTUAL_COLUMN';
exports[3734] = 'ER_FK_NO_COLUMN_PARENT';
exports[3735] = 'ER_CANT_SET_ERROR_SUPPRESSION_LIST';
exports[3736] = 'ER_SRS_GEOGCS_INVALID_AXES';
exports[3737] = 'ER_SRS_INVALID_SEMI_MAJOR_AXIS';
exports[3738] = 'ER_SRS_INVALID_INVERSE_FLATTENING';
exports[3739] = 'ER_SRS_INVALID_ANGULAR_UNIT';
exports[3740] = 'ER_SRS_INVALID_PRIME_MERIDIAN';
exports[3741] = 'ER_TRANSFORM_SOURCE_SRS_NOT_SUPPORTED';
exports[3742] = 'ER_TRANSFORM_TARGET_SRS_NOT_SUPPORTED';
exports[3743] = 'ER_TRANSFORM_SOURCE_SRS_MISSING_TOWGS84';
exports[3744] = 'ER_TRANSFORM_TARGET_SRS_MISSING_TOWGS84';
exports[3745] = 'ER_TEMP_TABLE_PREVENTS_SWITCH_SESSION_BINLOG_FORMAT';
exports[3746] = 'ER_TEMP_TABLE_PREVENTS_SWITCH_GLOBAL_BINLOG_FORMAT';
exports[3747] = 'ER_RUNNING_APPLIER_PREVENTS_SWITCH_GLOBAL_BINLOG_FORMAT';
exports[3748] = 'ER_CLIENT_GTID_UNSAFE_CREATE_DROP_TEMP_TABLE_IN_TRX_IN_SBR';
exports[3749] = 'ER_XA_CANT_CREATE_MDL_BACKUP';
exports[3750] = 'ER_TABLE_WITHOUT_PK';
exports[3751] = 'ER_WARN_DATA_TRUNCATED_FUNCTIONAL_INDEX';
exports[3752] = 'ER_WARN_DATA_OUT_OF_RANGE_FUNCTIONAL_INDEX';
exports[3753] = 'ER_FUNCTIONAL_INDEX_ON_JSON_OR_GEOMETRY_FUNCTION';
exports[3754] = 'ER_FUNCTIONAL_INDEX_REF_AUTO_INCREMENT';
exports[3755] = 'ER_CANNOT_DROP_COLUMN_FUNCTIONAL_INDEX';
exports[3756] = 'ER_FUNCTIONAL_INDEX_PRIMARY_KEY';
exports[3757] = 'ER_FUNCTIONAL_INDEX_ON_LOB';
exports[3758] = 'ER_FUNCTIONAL_INDEX_FUNCTION_IS_NOT_ALLOWED';
exports[3759] = 'ER_FULLTEXT_FUNCTIONAL_INDEX';
exports[3760] = 'ER_SPATIAL_FUNCTIONAL_INDEX';
exports[3761] = 'ER_WRONG_KEY_COLUMN_FUNCTIONAL_INDEX';
exports[3762] = 'ER_FUNCTIONAL_INDEX_ON_FIELD';
exports[3763] = 'ER_GENERATED_COLUMN_NAMED_FUNCTION_IS_NOT_ALLOWED';
exports[3764] = 'ER_GENERATED_COLUMN_ROW_VALUE';
exports[3765] = 'ER_GENERATED_COLUMN_VARIABLES';
exports[3766] = 'ER_DEPENDENT_BY_DEFAULT_GENERATED_VALUE';
exports[3767] = 'ER_DEFAULT_VAL_GENERATED_NON_PRIOR';
exports[3768] = 'ER_DEFAULT_VAL_GENERATED_REF_AUTO_INC';
exports[3769] = 'ER_DEFAULT_VAL_GENERATED_FUNCTION_IS_NOT_ALLOWED';
exports[3770] = 'ER_DEFAULT_VAL_GENERATED_NAMED_FUNCTION_IS_NOT_ALLOWED';
exports[3771] = 'ER_DEFAULT_VAL_GENERATED_ROW_VALUE';
exports[3772] = 'ER_DEFAULT_VAL_GENERATED_VARIABLES';
exports[3773] = 'ER_DEFAULT_AS_VAL_GENERATED';
exports[3774] = 'ER_UNSUPPORTED_ACTION_ON_DEFAULT_VAL_GENERATED';
exports[3775] = 'ER_GTID_UNSAFE_ALTER_ADD_COL_WITH_DEFAULT_EXPRESSION';
exports[3776] = 'ER_FK_CANNOT_CHANGE_ENGINE';
exports[3777] = 'ER_WARN_DEPRECATED_USER_SET_EXPR';
exports[3778] = 'ER_WARN_DEPRECATED_UTF8MB3_COLLATION';
exports[3779] = 'ER_WARN_DEPRECATED_NESTED_COMMENT_SYNTAX';
exports[3780] = 'ER_FK_INCOMPATIBLE_COLUMNS';
exports[3781] = 'ER_GR_HOLD_WAIT_TIMEOUT';
exports[3782] = 'ER_GR_HOLD_KILLED';
exports[3783] = 'ER_GR_HOLD_MEMBER_STATUS_ERROR';
exports[3784] = 'ER_RPL_ENCRYPTION_FAILED_TO_FETCH_KEY';
exports[3785] = 'ER_RPL_ENCRYPTION_KEY_NOT_FOUND';
exports[3786] = 'ER_RPL_ENCRYPTION_KEYRING_INVALID_KEY';
exports[3787] = 'ER_RPL_ENCRYPTION_HEADER_ERROR';
exports[3788] = 'ER_RPL_ENCRYPTION_FAILED_TO_ROTATE_LOGS';
exports[3789] = 'ER_RPL_ENCRYPTION_KEY_EXISTS_UNEXPECTED';
exports[3790] = 'ER_RPL_ENCRYPTION_FAILED_TO_GENERATE_KEY';
exports[3791] = 'ER_RPL_ENCRYPTION_FAILED_TO_STORE_KEY';
exports[3792] = 'ER_RPL_ENCRYPTION_FAILED_TO_REMOVE_KEY';
exports[3793] = 'ER_RPL_ENCRYPTION_UNABLE_TO_CHANGE_OPTION';
exports[3794] = 'ER_RPL_ENCRYPTION_MASTER_KEY_RECOVERY_FAILED';
exports[3795] = 'ER_SLOW_LOG_MODE_IGNORED_WHEN_NOT_LOGGING_TO_FILE';
exports[3796] = 'ER_GRP_TRX_CONSISTENCY_NOT_ALLOWED';
exports[3797] = 'ER_GRP_TRX_CONSISTENCY_BEFORE';
exports[3798] = 'ER_GRP_TRX_CONSISTENCY_AFTER_ON_TRX_BEGIN';
exports[3799] = 'ER_GRP_TRX_CONSISTENCY_BEGIN_NOT_ALLOWED';
exports[3800] = 'ER_FUNCTIONAL_INDEX_ROW_VALUE_IS_NOT_ALLOWED';
exports[3801] = 'ER_RPL_ENCRYPTION_FAILED_TO_ENCRYPT';
exports[3802] = 'ER_PAGE_TRACKING_NOT_STARTED';
exports[3803] = 'ER_PAGE_TRACKING_RANGE_NOT_TRACKED';
exports[3804] = 'ER_PAGE_TRACKING_CANNOT_PURGE';
exports[3805] = 'ER_RPL_ENCRYPTION_CANNOT_ROTATE_BINLOG_MASTER_KEY';
exports[3806] = 'ER_BINLOG_MASTER_KEY_RECOVERY_OUT_OF_COMBINATION';
exports[3807] = 'ER_BINLOG_MASTER_KEY_ROTATION_FAIL_TO_OPERATE_KEY';
exports[3808] = 'ER_BINLOG_MASTER_KEY_ROTATION_FAIL_TO_ROTATE_LOGS';
exports[3809] = 'ER_BINLOG_MASTER_KEY_ROTATION_FAIL_TO_REENCRYPT_LOG';
exports[3810] = 'ER_BINLOG_MASTER_KEY_ROTATION_FAIL_TO_CLEANUP_UNUSED_KEYS';
exports[3811] = 'ER_BINLOG_MASTER_KEY_ROTATION_FAIL_TO_CLEANUP_AUX_KEY';
exports[3812] = 'ER_NON_BOOLEAN_EXPR_FOR_CHECK_CONSTRAINT';
exports[3813] = 'ER_COLUMN_CHECK_CONSTRAINT_REFERENCES_OTHER_COLUMN';
exports[3814] = 'ER_CHECK_CONSTRAINT_NAMED_FUNCTION_IS_NOT_ALLOWED';
exports[3815] = 'ER_CHECK_CONSTRAINT_FUNCTION_IS_NOT_ALLOWED';
exports[3816] = 'ER_CHECK_CONSTRAINT_VARIABLES';
exports[3817] = 'ER_CHECK_CONSTRAINT_ROW_VALUE';
exports[3818] = 'ER_CHECK_CONSTRAINT_REFERS_AUTO_INCREMENT_COLUMN';
exports[3819] = 'ER_CHECK_CONSTRAINT_VIOLATED';
exports[3820] = 'ER_CHECK_CONSTRAINT_REFERS_UNKNOWN_COLUMN';
exports[3821] = 'ER_CHECK_CONSTRAINT_NOT_FOUND';
exports[3822] = 'ER_CHECK_CONSTRAINT_DUP_NAME';
exports[3823] = 'ER_CHECK_CONSTRAINT_CLAUSE_USING_FK_REFER_ACTION_COLUMN';
exports[3824] = 'WARN_UNENCRYPTED_TABLE_IN_ENCRYPTED_DB';
exports[3825] = 'ER_INVALID_ENCRYPTION_REQUEST';
exports[3826] = 'ER_CANNOT_SET_TABLE_ENCRYPTION';
exports[3827] = 'ER_CANNOT_SET_DATABASE_ENCRYPTION';
exports[3828] = 'ER_CANNOT_SET_TABLESPACE_ENCRYPTION';
exports[3829] = 'ER_TABLESPACE_CANNOT_BE_ENCRYPTED';
exports[3830] = 'ER_TABLESPACE_CANNOT_BE_DECRYPTED';
exports[3831] = 'ER_TABLESPACE_TYPE_UNKNOWN';
exports[3832] = 'ER_TARGET_TABLESPACE_UNENCRYPTED';
exports[3833] = 'ER_CANNOT_USE_ENCRYPTION_CLAUSE';
exports[3834] = 'ER_INVALID_MULTIPLE_CLAUSES';
exports[3835] = 'ER_UNSUPPORTED_USE_OF_GRANT_AS';
exports[3836] = 'ER_UKNOWN_AUTH_ID_OR_ACCESS_DENIED_FOR_GRANT_AS';
exports[3837] = 'ER_DEPENDENT_BY_FUNCTIONAL_INDEX';
exports[3838] = 'ER_PLUGIN_NOT_EARLY';
exports[3839] = 'ER_INNODB_REDO_LOG_ARCHIVE_START_SUBDIR_PATH';
exports[3840] = 'ER_INNODB_REDO_LOG_ARCHIVE_START_TIMEOUT';
exports[3841] = 'ER_INNODB_REDO_LOG_ARCHIVE_DIRS_INVALID';
exports[3842] = 'ER_INNODB_REDO_LOG_ARCHIVE_LABEL_NOT_FOUND';
exports[3843] = 'ER_INNODB_REDO_LOG_ARCHIVE_DIR_EMPTY';
exports[3844] = 'ER_INNODB_REDO_LOG_ARCHIVE_NO_SUCH_DIR';
exports[3845] = 'ER_INNODB_REDO_LOG_ARCHIVE_DIR_CLASH';
exports[3846] = 'ER_INNODB_REDO_LOG_ARCHIVE_DIR_PERMISSIONS';
exports[3847] = 'ER_INNODB_REDO_LOG_ARCHIVE_FILE_CREATE';
exports[3848] = 'ER_INNODB_REDO_LOG_ARCHIVE_ACTIVE';
exports[3849] = 'ER_INNODB_REDO_LOG_ARCHIVE_INACTIVE';
exports[3850] = 'ER_INNODB_REDO_LOG_ARCHIVE_FAILED';
exports[3851] = 'ER_INNODB_REDO_LOG_ARCHIVE_SESSION';
exports[3852] = 'ER_STD_REGEX_ERROR';
exports[3853] = 'ER_INVALID_JSON_TYPE';
exports[3854] = 'ER_CANNOT_CONVERT_STRING';
exports[3855] = 'ER_DEPENDENT_BY_PARTITION_FUNC';
exports[3856] = 'ER_WARN_DEPRECATED_FLOAT_AUTO_INCREMENT';
exports[3857] = 'ER_RPL_CANT_STOP_REPLICA_WHILE_LOCKED_BACKUP';
exports[3858] = 'ER_WARN_DEPRECATED_FLOAT_DIGITS';
exports[3859] = 'ER_WARN_DEPRECATED_FLOAT_UNSIGNED';
exports[3860] = 'ER_WARN_DEPRECATED_INTEGER_DISPLAY_WIDTH';
exports[3861] = 'ER_WARN_DEPRECATED_ZEROFILL';
exports[3862] = 'ER_CLONE_DONOR';
exports[3863] = 'ER_CLONE_PROTOCOL';
exports[3864] = 'ER_CLONE_DONOR_VERSION';
exports[3865] = 'ER_CLONE_OS';
exports[3866] = 'ER_CLONE_PLATFORM';
exports[3867] = 'ER_CLONE_CHARSET';
exports[3868] = 'ER_CLONE_CONFIG';
exports[3869] = 'ER_CLONE_SYS_CONFIG';
exports[3870] = 'ER_CLONE_PLUGIN_MATCH';
exports[3871] = 'ER_CLONE_LOOPBACK';
exports[3872] = 'ER_CLONE_ENCRYPTION';
exports[3873] = 'ER_CLONE_DISK_SPACE';
exports[3874] = 'ER_CLONE_IN_PROGRESS';
exports[3875] = 'ER_CLONE_DISALLOWED';
exports[3876] = 'ER_CANNOT_GRANT_ROLES_TO_ANONYMOUS_USER';
exports[3877] = 'ER_SECONDARY_ENGINE_PLUGIN';
exports[3878] = 'ER_SECOND_PASSWORD_CANNOT_BE_EMPTY';
exports[3879] = 'ER_DB_ACCESS_DENIED';
exports[3880] = 'ER_DA_AUTH_ID_WITH_SYSTEM_USER_PRIV_IN_MANDATORY_ROLES';
exports[3881] = 'ER_DA_RPL_GTID_TABLE_CANNOT_OPEN';
exports[3882] = 'ER_GEOMETRY_IN_UNKNOWN_LENGTH_UNIT';
exports[3883] = 'ER_DA_PLUGIN_INSTALL_ERROR';
exports[3884] = 'ER_NO_SESSION_TEMP';
exports[3885] = 'ER_DA_UNKNOWN_ERROR_NUMBER';
exports[3886] = 'ER_COLUMN_CHANGE_SIZE';
exports[3887] = 'ER_REGEXP_INVALID_CAPTURE_GROUP_NAME';
exports[3888] = 'ER_DA_SSL_LIBRARY_ERROR';
exports[3889] = 'ER_SECONDARY_ENGINE';
exports[3890] = 'ER_SECONDARY_ENGINE_DDL';
exports[3891] = 'ER_INCORRECT_CURRENT_PASSWORD';
exports[3892] = 'ER_MISSING_CURRENT_PASSWORD';
exports[3893] = 'ER_CURRENT_PASSWORD_NOT_REQUIRED';
exports[3894] = 'ER_PASSWORD_CANNOT_BE_RETAINED_ON_PLUGIN_CHANGE';
exports[3895] = 'ER_CURRENT_PASSWORD_CANNOT_BE_RETAINED';
exports[3896] = 'ER_PARTIAL_REVOKES_EXIST';
exports[3897] = 'ER_CANNOT_GRANT_SYSTEM_PRIV_TO_MANDATORY_ROLE';
exports[3898] = 'ER_XA_REPLICATION_FILTERS';
exports[3899] = 'ER_UNSUPPORTED_SQL_MODE';
exports[3900] = 'ER_REGEXP_INVALID_FLAG';
exports[3901] = 'ER_PARTIAL_REVOKE_AND_DB_GRANT_BOTH_EXISTS';
exports[3902] = 'ER_UNIT_NOT_FOUND';
exports[3903] = 'ER_INVALID_JSON_VALUE_FOR_FUNC_INDEX';
exports[3904] = 'ER_JSON_VALUE_OUT_OF_RANGE_FOR_FUNC_INDEX';
exports[3905] = 'ER_EXCEEDED_MV_KEYS_NUM';
exports[3906] = 'ER_EXCEEDED_MV_KEYS_SPACE';
exports[3907] = 'ER_FUNCTIONAL_INDEX_DATA_IS_TOO_LONG';
exports[3908] = 'ER_WRONG_MVI_VALUE';
exports[3909] = 'ER_WARN_FUNC_INDEX_NOT_APPLICABLE';
exports[3910] = 'ER_GRP_RPL_UDF_ERROR';
exports[3911] = 'ER_UPDATE_GTID_PURGED_WITH_GR';
exports[3912] = 'ER_GROUPING_ON_TIMESTAMP_IN_DST';
exports[3913] = 'ER_TABLE_NAME_CAUSES_TOO_LONG_PATH';
exports[3914] = 'ER_AUDIT_LOG_INSUFFICIENT_PRIVILEGE';
exports[3915] = 'ER_AUDIT_LOG_PASSWORD_HAS_BEEN_COPIED';
exports[3916] = 'ER_DA_GRP_RPL_STARTED_AUTO_REJOIN';
exports[3917] = 'ER_SYSVAR_CHANGE_DURING_QUERY';
exports[3918] = 'ER_GLOBSTAT_CHANGE_DURING_QUERY';
exports[3919] = 'ER_GRP_RPL_MESSAGE_SERVICE_INIT_FAILURE';
exports[3920] = 'ER_CHANGE_SOURCE_WRONG_COMPRESSION_ALGORITHM_CLIENT';
exports[3921] = 'ER_CHANGE_SOURCE_WRONG_COMPRESSION_LEVEL_CLIENT';
exports[3922] = 'ER_WRONG_COMPRESSION_ALGORITHM_CLIENT';
exports[3923] = 'ER_WRONG_COMPRESSION_LEVEL_CLIENT';
exports[3924] = 'ER_CHANGE_SOURCE_WRONG_COMPRESSION_ALGORITHM_LIST_CLIENT';
exports[3925] = 'ER_CLIENT_PRIVILEGE_CHECKS_USER_CANNOT_BE_ANONYMOUS';
exports[3926] = 'ER_CLIENT_PRIVILEGE_CHECKS_USER_DOES_NOT_EXIST';
exports[3927] = 'ER_CLIENT_PRIVILEGE_CHECKS_USER_CORRUPT';
exports[3928] = 'ER_CLIENT_PRIVILEGE_CHECKS_USER_NEEDS_RPL_APPLIER_PRIV';
exports[3929] = 'ER_WARN_DA_PRIVILEGE_NOT_REGISTERED';
exports[3930] = 'ER_CLIENT_KEYRING_UDF_KEY_INVALID';
exports[3931] = 'ER_CLIENT_KEYRING_UDF_KEY_TYPE_INVALID';
exports[3932] = 'ER_CLIENT_KEYRING_UDF_KEY_TOO_LONG';
exports[3933] = 'ER_CLIENT_KEYRING_UDF_KEY_TYPE_TOO_LONG';
exports[3934] = 'ER_JSON_SCHEMA_VALIDATION_ERROR_WITH_DETAILED_REPORT';
exports[3935] = 'ER_DA_UDF_INVALID_CHARSET_SPECIFIED';
exports[3936] = 'ER_DA_UDF_INVALID_CHARSET';
exports[3937] = 'ER_DA_UDF_INVALID_COLLATION';
exports[3938] = 'ER_DA_UDF_INVALID_EXTENSION_ARGUMENT_TYPE';
exports[3939] = 'ER_MULTIPLE_CONSTRAINTS_WITH_SAME_NAME';
exports[3940] = 'ER_CONSTRAINT_NOT_FOUND';
exports[3941] = 'ER_ALTER_CONSTRAINT_ENFORCEMENT_NOT_SUPPORTED';
exports[3942] = 'ER_TABLE_VALUE_CONSTRUCTOR_MUST_HAVE_COLUMNS';
exports[3943] = 'ER_TABLE_VALUE_CONSTRUCTOR_CANNOT_HAVE_DEFAULT';
exports[3944] = 'ER_CLIENT_QUERY_FAILURE_INVALID_NON_ROW_FORMAT';
exports[3945] = 'ER_REQUIRE_ROW_FORMAT_INVALID_VALUE';
exports[3946] = 'ER_FAILED_TO_DETERMINE_IF_ROLE_IS_MANDATORY';
exports[3947] = 'ER_FAILED_TO_FETCH_MANDATORY_ROLE_LIST';
exports[3948] = 'ER_CLIENT_LOCAL_FILES_DISABLED';
exports[3949] = 'ER_IMP_INCOMPATIBLE_CFG_VERSION';
exports[3950] = 'ER_DA_OOM';
exports[3951] = 'ER_DA_UDF_INVALID_ARGUMENT_TO_SET_CHARSET';
exports[3952] = 'ER_DA_UDF_INVALID_RETURN_TYPE_TO_SET_CHARSET';
exports[3953] = 'ER_MULTIPLE_INTO_CLAUSES';
exports[3954] = 'ER_MISPLACED_INTO';
exports[3955] =
  'ER_USER_ACCESS_DENIED_FOR_USER_ACCOUNT_BLOCKED_BY_PASSWORD_LOCK';
exports[3956] = 'ER_WARN_DEPRECATED_YEAR_UNSIGNED';
exports[3957] = 'ER_CLONE_NETWORK_PACKET';
exports[3958] = 'ER_SDI_OPERATION_FAILED_MISSING_RECORD';
exports[3959] = 'ER_DEPENDENT_BY_CHECK_CONSTRAINT';
exports[3960] = 'ER_GRP_OPERATION_NOT_ALLOWED_GR_MUST_STOP';
exports[3961] = 'ER_WARN_DEPRECATED_JSON_TABLE_ON_ERROR_ON_EMPTY';
exports[3962] = 'ER_WARN_DEPRECATED_INNER_INTO';
exports[3963] = 'ER_WARN_DEPRECATED_VALUES_FUNCTION_ALWAYS_NULL';
exports[3964] = 'ER_WARN_DEPRECATED_SQL_CALC_FOUND_ROWS';
exports[3965] = 'ER_WARN_DEPRECATED_FOUND_ROWS';
exports[3966] = 'ER_MISSING_JSON_VALUE';
exports[3967] = 'ER_MULTIPLE_JSON_VALUES';
exports[3968] = 'ER_HOSTNAME_TOO_LONG';
exports[3969] = 'ER_WARN_CLIENT_DEPRECATED_PARTITION_PREFIX_KEY';
exports[3970] = 'ER_GROUP_REPLICATION_USER_EMPTY_MSG';
exports[3971] = 'ER_GROUP_REPLICATION_USER_MANDATORY_MSG';
exports[3972] = 'ER_GROUP_REPLICATION_PASSWORD_LENGTH';
exports[3973] = 'ER_SUBQUERY_TRANSFORM_REJECTED';
exports[3974] = 'ER_DA_GRP_RPL_RECOVERY_ENDPOINT_FORMAT';
exports[3975] = 'ER_DA_GRP_RPL_RECOVERY_ENDPOINT_INVALID';
exports[3976] = 'ER_WRONG_VALUE_FOR_VAR_PLUS_ACTIONABLE_PART';
exports[3977] = 'ER_STATEMENT_NOT_ALLOWED_AFTER_START_TRANSACTION';
exports[3978] = 'ER_FOREIGN_KEY_WITH_ATOMIC_CREATE_SELECT';
exports[3979] = 'ER_NOT_ALLOWED_WITH_START_TRANSACTION';
exports[3980] = 'ER_INVALID_JSON_ATTRIBUTE';
exports[3981] = 'ER_ENGINE_ATTRIBUTE_NOT_SUPPORTED';
exports[3982] = 'ER_INVALID_USER_ATTRIBUTE_JSON';
exports[3983] = 'ER_INNODB_REDO_DISABLED';
exports[3984] = 'ER_INNODB_REDO_ARCHIVING_ENABLED';
exports[3985] = 'ER_MDL_OUT_OF_RESOURCES';
exports[3986] = 'ER_IMPLICIT_COMPARISON_FOR_JSON';
exports[3987] = 'ER_FUNCTION_DOES_NOT_SUPPORT_CHARACTER_SET';
exports[3988] = 'ER_IMPOSSIBLE_STRING_CONVERSION';
exports[3989] = 'ER_SCHEMA_READ_ONLY';
exports[3990] = 'ER_RPL_ASYNC_RECONNECT_GTID_MODE_OFF';
exports[3991] = 'ER_RPL_ASYNC_RECONNECT_AUTO_POSITION_OFF';
exports[3992] = 'ER_DISABLE_GTID_MODE_REQUIRES_ASYNC_RECONNECT_OFF';
exports[3993] = 'ER_DISABLE_AUTO_POSITION_REQUIRES_ASYNC_RECONNECT_OFF';
exports[3994] = 'ER_INVALID_PARAMETER_USE';
exports[3995] = 'ER_CHARACTER_SET_MISMATCH';
exports[3996] = 'ER_WARN_VAR_VALUE_CHANGE_NOT_SUPPORTED';
exports[3997] = 'ER_INVALID_TIME_ZONE_INTERVAL';
exports[3998] = 'ER_INVALID_CAST';
exports[3999] = 'ER_HYPERGRAPH_NOT_SUPPORTED_YET';
exports[4000] = 'ER_WARN_HYPERGRAPH_EXPERIMENTAL';
exports[4001] = 'ER_DA_NO_ERROR_LOG_PARSER_CONFIGURED';
exports[4002] = 'ER_DA_ERROR_LOG_TABLE_DISABLED';
exports[4003] = 'ER_DA_ERROR_LOG_MULTIPLE_FILTERS';
exports[4004] = 'ER_DA_CANT_OPEN_ERROR_LOG';
exports[4005] = 'ER_USER_REFERENCED_AS_DEFINER';
exports[4006] = 'ER_CANNOT_USER_REFERENCED_AS_DEFINER';
exports[4007] = 'ER_REGEX_NUMBER_TOO_BIG';
exports[4008] = 'ER_SPVAR_NONINTEGER_TYPE';
exports[4009] = 'WARN_UNSUPPORTED_ACL_TABLES_READ';
exports[4010] = 'ER_BINLOG_UNSAFE_ACL_TABLE_READ_IN_DML_DDL';
exports[4011] = 'ER_STOP_REPLICA_MONITOR_IO_THREAD_TIMEOUT';
exports[4012] = 'ER_STARTING_REPLICA_MONITOR_IO_THREAD';
exports[4013] = 'ER_CANT_USE_ANONYMOUS_TO_GTID_WITH_GTID_MODE_NOT_ON';
exports[4014] = 'ER_CANT_COMBINE_ANONYMOUS_TO_GTID_AND_AUTOPOSITION';
exports[4015] =
  'ER_ASSIGN_GTIDS_TO_ANONYMOUS_TRANSACTIONS_REQUIRES_GTID_MODE_ON';
exports[4016] = 'ER_SQL_REPLICA_SKIP_COUNTER_USED_WITH_GTID_MODE_ON';
exports[4017] =
  'ER_USING_ASSIGN_GTIDS_TO_ANONYMOUS_TRANSACTIONS_AS_LOCAL_OR_UUID';
exports[4018] =
  'ER_CANT_SET_ANONYMOUS_TO_GTID_AND_WAIT_UNTIL_SQL_THD_AFTER_GTIDS';
exports[4019] = 'ER_CANT_SET_SQL_AFTER_OR_BEFORE_GTIDS_WITH_ANONYMOUS_TO_GTID';
exports[4020] = 'ER_ANONYMOUS_TO_GTID_UUID_SAME_AS_GROUP_NAME';
exports[4021] = 'ER_CANT_USE_SAME_UUID_AS_GROUP_NAME';
exports[4022] = 'ER_GRP_RPL_RECOVERY_CHANNEL_STILL_RUNNING';
exports[4023] = 'ER_INNODB_INVALID_AUTOEXTEND_SIZE_VALUE';
exports[4024] = 'ER_INNODB_INCOMPATIBLE_WITH_TABLESPACE';
exports[4025] = 'ER_INNODB_AUTOEXTEND_SIZE_OUT_OF_RANGE';
exports[4026] = 'ER_CANNOT_USE_AUTOEXTEND_SIZE_CLAUSE';
exports[4027] = 'ER_ROLE_GRANTED_TO_ITSELF';
exports[4028] = 'ER_TABLE_MUST_HAVE_A_VISIBLE_COLUMN';
exports[4029] = 'ER_INNODB_COMPRESSION_FAILURE';
exports[4030] = 'ER_WARN_ASYNC_CONN_FAILOVER_NETWORK_NAMESPACE';
exports[4031] = 'ER_CLIENT_INTERACTION_TIMEOUT';
exports[4032] = 'ER_INVALID_CAST_TO_GEOMETRY';
exports[4033] = 'ER_INVALID_CAST_POLYGON_RING_DIRECTION';
exports[4034] = 'ER_GIS_DIFFERENT_SRIDS_AGGREGATION';
exports[4035] = 'ER_RELOAD_KEYRING_FAILURE';
exports[4036] = 'ER_SDI_GET_KEYS_INVALID_TABLESPACE';
exports[4037] = 'ER_CHANGE_RPL_SRC_WRONG_COMPRESSION_ALGORITHM_SIZE';
exports[4038] = 'ER_WARN_DEPRECATED_TLS_VERSION_FOR_CHANNEL_CLI';
exports[4039] = 'ER_CANT_USE_SAME_UUID_AS_VIEW_CHANGE_UUID';
exports[4040] = 'ER_ANONYMOUS_TO_GTID_UUID_SAME_AS_VIEW_CHANGE_UUID';
exports[4041] = 'ER_GRP_RPL_VIEW_CHANGE_UUID_FAIL_GET_VARIABLE';
exports[4042] = 'ER_WARN_ADUIT_LOG_MAX_SIZE_AND_PRUNE_SECONDS';
exports[4043] = 'ER_WARN_ADUIT_LOG_MAX_SIZE_CLOSE_TO_ROTATE_ON_SIZE';
exports[4044] = 'ER_KERBEROS_CREATE_USER';
exports[4045] = 'ER_INSTALL_PLUGIN_CONFLICT_CLIENT';
exports[4046] = 'ER_DA_ERROR_LOG_COMPONENT_FLUSH_FAILED';
exports[4047] = 'ER_WARN_SQL_AFTER_MTS_GAPS_GAP_NOT_CALCULATED';
exports[4048] = 'ER_INVALID_ASSIGNMENT_TARGET';
exports[4049] = 'ER_OPERATION_NOT_ALLOWED_ON_GR_SECONDARY';
exports[4050] = 'ER_GRP_RPL_FAILOVER_CHANNEL_STATUS_PROPAGATION';
exports[4051] = 'ER_WARN_AUDIT_LOG_FORMAT_UNIX_TIMESTAMP_ONLY_WHEN_JSON';
exports[4052] = 'ER_INVALID_MFA_PLUGIN_SPECIFIED';
exports[4053] = 'ER_IDENTIFIED_BY_UNSUPPORTED';
exports[4054] = 'ER_INVALID_PLUGIN_FOR_REGISTRATION';
exports[4055] = 'ER_PLUGIN_REQUIRES_REGISTRATION';
exports[4056] = 'ER_MFA_METHOD_EXISTS';
exports[4057] = 'ER_MFA_METHOD_NOT_EXISTS';
exports[4058] = 'ER_AUTHENTICATION_POLICY_MISMATCH';
exports[4059] = 'ER_PLUGIN_REGISTRATION_DONE';
exports[4060] = 'ER_INVALID_USER_FOR_REGISTRATION';
exports[4061] = 'ER_USER_REGISTRATION_FAILED';
exports[4062] = 'ER_MFA_METHODS_INVALID_ORDER';
exports[4063] = 'ER_MFA_METHODS_IDENTICAL';
exports[4064] = 'ER_INVALID_MFA_OPERATIONS_FOR_PASSWORDLESS_USER';
exports[4065] = 'ER_CHANGE_REPLICATION_SOURCE_NO_OPTIONS_FOR_GTID_ONLY';
exports[4066] =
  'ER_CHANGE_REP_SOURCE_CANT_DISABLE_REQ_ROW_FORMAT_WITH_GTID_ONLY';
exports[4067] =
  'ER_CHANGE_REP_SOURCE_CANT_DISABLE_AUTO_POSITION_WITH_GTID_ONLY';
exports[4068] = 'ER_CHANGE_REP_SOURCE_CANT_DISABLE_GTID_ONLY_WITHOUT_POSITIONS';
exports[4069] = 'ER_CHANGE_REP_SOURCE_CANT_DISABLE_AUTO_POS_WITHOUT_POSITIONS';
exports[4070] = 'ER_CHANGE_REP_SOURCE_GR_CHANNEL_WITH_GTID_MODE_NOT_ON';
exports[4071] = 'ER_CANT_USE_GTID_ONLY_WITH_GTID_MODE_NOT_ON';
exports[4072] = 'ER_WARN_C_DISABLE_GTID_ONLY_WITH_SOURCE_AUTO_POS_INVALID_POS';
exports[4073] = 'ER_DA_SSL_FIPS_MODE_ERROR';
exports[4074] = 'ER_VALUE_OUT_OF_RANGE';
exports[4075] = 'ER_FULLTEXT_WITH_ROLLUP';
exports[4076] = 'ER_REGEXP_MISSING_RESOURCE';
exports[4077] = 'ER_WARN_REGEXP_USING_DEFAULT';
exports[4078] = 'ER_REGEXP_MISSING_FILE';
exports[4079] = 'ER_WARN_DEPRECATED_COLLATION';
exports[4080] = 'ER_CONCURRENT_PROCEDURE_USAGE';
exports[4081] = 'ER_DA_GLOBAL_CONN_LIMIT';
exports[4082] = 'ER_DA_CONN_LIMIT';
exports[4083] = 'ER_ALTER_OPERATION_NOT_SUPPORTED_REASON_COLUMN_TYPE_INSTANT';
exports[4084] = 'ER_WARN_SF_UDF_NAME_COLLISION';
exports[4085] = 'ER_CANNOT_PURGE_BINLOG_WITH_BACKUP_LOCK';
exports[4086] = 'ER_TOO_MANY_WINDOWS';
exports[4087] = 'ER_MYSQLBACKUP_CLIENT_MSG';
exports[4088] = 'ER_COMMENT_CONTAINS_INVALID_STRING';
exports[4089] = 'ER_DEFINITION_CONTAINS_INVALID_STRING';
exports[4090] = 'ER_CANT_EXECUTE_COMMAND_WITH_ASSIGNED_GTID_NEXT';
exports[4091] = 'ER_XA_TEMP_TABLE';
exports[4092] = 'ER_INNODB_MAX_ROW_VERSION';
exports[4093] = 'ER_INNODB_INSTANT_ADD_NOT_SUPPORTED_MAX_SIZE';
exports[4094] = 'ER_OPERATION_NOT_ALLOWED_WHILE_PRIMARY_CHANGE_IS_RUNNING';
exports[4095] = 'ER_WARN_DEPRECATED_DATETIME_DELIMITER';
exports[4096] = 'ER_WARN_DEPRECATED_SUPERFLUOUS_DELIMITER';
exports[4097] = 'ER_CANNOT_PERSIST_SENSITIVE_VARIABLES';
exports[4098] = 'ER_WARN_CANNOT_SECURELY_PERSIST_SENSITIVE_VARIABLES';
exports[4099] = 'ER_WARN_TRG_ALREADY_EXISTS';
exports[4100] = 'ER_IF_NOT_EXISTS_UNSUPPORTED_TRG_EXISTS_ON_DIFFERENT_TABLE';
exports[4101] = 'ER_IF_NOT_EXISTS_UNSUPPORTED_UDF_NATIVE_FCT_NAME_COLLISION';
exports[4102] = 'ER_SET_PASSWORD_AUTH_PLUGIN_ERROR';
exports[4103] = 'ER_REDUCED_DBLWR_FILE_CORRUPTED';
exports[4104] = 'ER_REDUCED_DBLWR_PAGE_FOUND';
exports[4105] = 'ER_SRS_INVALID_LATITUDE_OF_ORIGIN';
exports[4106] = 'ER_SRS_INVALID_LONGITUDE_OF_ORIGIN';
exports[4107] = 'ER_SRS_UNUSED_PROJ_PARAMETER_PRESENT';
exports[4108] = 'ER_GIPK_COLUMN_EXISTS';
exports[4109] = 'ER_GIPK_FAILED_AUTOINC_COLUMN_EXISTS';
exports[4110] = 'ER_GIPK_COLUMN_ALTER_NOT_ALLOWED';
exports[4111] = 'ER_DROP_PK_COLUMN_TO_DROP_GIPK';
exports[4112] = 'ER_CREATE_SELECT_WITH_GIPK_DISALLOWED_IN_SBR';
exports[4113] = 'ER_DA_EXPIRE_LOGS_DAYS_IGNORED';
exports[4114] = 'ER_CTE_RECURSIVE_NOT_UNION';
exports[4115] = 'ER_COMMAND_BACKEND_FAILED_TO_FETCH_SECURITY_CTX';
exports[4116] = 'ER_COMMAND_SERVICE_BACKEND_FAILED';
exports[4117] = 'ER_CLIENT_FILE_PRIVILEGE_FOR_REPLICATION_CHECKS';
exports[4118] = 'ER_GROUP_REPLICATION_FORCE_MEMBERS_COMMAND_FAILURE';
exports[4119] = 'ER_WARN_DEPRECATED_IDENT';
exports[4120] = 'ER_INTERSECT_ALL_MAX_DUPLICATES_EXCEEDED';
exports[4121] = 'ER_TP_QUERY_THRS_PER_GRP_EXCEEDS_TXN_THR_LIMIT';
exports[4122] = 'ER_BAD_TIMESTAMP_FORMAT';
exports[4123] = 'ER_SHAPE_PRIDICTION_UDF';
exports[4124] = 'ER_SRS_INVALID_HEIGHT';
exports[4125] = 'ER_SRS_INVALID_SCALING';
exports[4126] = 'ER_SRS_INVALID_ZONE_WIDTH';
exports[4127] = 'ER_SRS_INVALID_LATITUDE_POLAR_STERE_VAR_A';
exports[4128] = 'ER_WARN_DEPRECATED_CLIENT_NO_SCHEMA_OPTION';
exports[4129] = 'ER_TABLE_NOT_EMPTY';
exports[4130] = 'ER_TABLE_NO_PRIMARY_KEY';
exports[4131] = 'ER_TABLE_IN_SHARED_TABLESPACE';
exports[4132] = 'ER_INDEX_OTHER_THAN_PK';
exports[4133] = 'ER_LOAD_BULK_DATA_UNSORTED';
exports[4134] = 'ER_BULK_EXECUTOR_ERROR';
exports[4135] = 'ER_BULK_READER_LIBCURL_INIT_FAILED';
exports[4136] = 'ER_BULK_READER_LIBCURL_ERROR';
exports[4137] = 'ER_BULK_READER_SERVER_ERROR';
exports[4138] = 'ER_BULK_READER_COMMUNICATION_ERROR';
exports[4139] = 'ER_BULK_LOAD_DATA_FAILED';
exports[4140] = 'ER_BULK_LOADER_COLUMN_TOO_BIG_FOR_LEFTOVER_BUFFER';
exports[4141] = 'ER_BULK_LOADER_COMPONENT_ERROR';
exports[4142] = 'ER_BULK_LOADER_FILE_CONTAINS_LESS_LINES_THAN_IGNORE_CLAUSE';
exports[4143] = 'ER_BULK_PARSER_MISSING_ENCLOSED_BY';
exports[4144] = 'ER_BULK_PARSER_ROW_BUFFER_MAX_TOTAL_COLS_EXCEEDED';
exports[4145] = 'ER_BULK_PARSER_COPY_BUFFER_SIZE_EXCEEDED';
exports[4146] = 'ER_BULK_PARSER_UNEXPECTED_END_OF_INPUT';
exports[4147] = 'ER_BULK_PARSER_UNEXPECTED_ROW_TERMINATOR';
exports[4148] = 'ER_BULK_PARSER_UNEXPECTED_CHAR_AFTER_ENDING_ENCLOSED_BY';
exports[4149] = 'ER_BULK_PARSER_UNEXPECTED_CHAR_AFTER_NULL_ESCAPE';
exports[4150] = 'ER_BULK_PARSER_UNEXPECTED_CHAR_AFTER_COLUMN_TERMINATOR';
exports[4151] = 'ER_BULK_PARSER_INCOMPLETE_ESCAPE_SEQUENCE';
exports[4152] = 'ER_LOAD_BULK_DATA_FAILED';
exports[4153] = 'ER_LOAD_BULK_DATA_WRONG_VALUE_FOR_FIELD';
exports[4154] = 'ER_LOAD_BULK_DATA_WARN_NULL_TO_NOTNULL';
exports[4155] = 'ER_REQUIRE_TABLE_PRIMARY_KEY_CHECK_GENERATE_WITH_GR';
exports[4156] = 'ER_CANT_CHANGE_SYS_VAR_IN_READ_ONLY_MODE';
exports[4157] = 'ER_INNODB_INSTANT_ADD_DROP_NOT_SUPPORTED_MAX_SIZE';
exports[4158] = 'ER_INNODB_INSTANT_ADD_NOT_SUPPORTED_MAX_FIELDS';
exports[4159] = 'ER_CANT_SET_PERSISTED';
exports[4160] = 'ER_INSTALL_COMPONENT_SET_NULL_VALUE';
exports[4161] = 'ER_INSTALL_COMPONENT_SET_UNUSED_VALUE';
exports[4162] = 'ER_WARN_DEPRECATED_USER_DEFINED_COLLATIONS';
</file>

<file path="lib/constants/field_flags.js">
'use strict';

// Manually extracted from mysql-5.5.23/include/mysql_com.h
exports.NOT_NULL = 1; /* Field can't be NULL */
exports.PRI_KEY = 2; /* Field is part of a primary key */
exports.UNIQUE_KEY = 4; /* Field is part of a unique key */
exports.MULTIPLE_KEY = 8; /* Field is part of a key */
exports.BLOB = 16; /* Field is a blob */
exports.UNSIGNED = 32; /* Field is unsigned */
exports.ZEROFILL = 64; /* Field is zerofill */
exports.BINARY = 128; /* Field is binary   */

/* The following are only sent to new clients */
exports.ENUM = 256; /* field is an enum */
exports.AUTO_INCREMENT = 512; /* field is a autoincrement field */
exports.TIMESTAMP = 1024; /* Field is a timestamp */
exports.SET = 2048; /* field is a set */
exports.NO_DEFAULT_VALUE = 4096; /* Field doesn't have default value */
exports.ON_UPDATE_NOW = 8192; /* Field is set to NOW on UPDATE */
exports.NUM = 32768; /* Field is num (for clients) */
</file>

<file path="lib/constants/server_status.js">
'use strict';

// Manually extracted from mysql-5.5.23/include/mysql_com.h

/**
  Is raised when a multi-statement transaction
  has been started, either explicitly, by means
  of BEGIN or COMMIT AND CHAIN, or
  implicitly, by the first transactional
  statement, when autocommit=off.
*/
exports.SERVER_STATUS_IN_TRANS = 1;
exports.SERVER_STATUS_AUTOCOMMIT = 2; /* Server in auto_commit mode */
exports.SERVER_MORE_RESULTS_EXISTS = 8; /* Multi query - next query exists */
exports.SERVER_QUERY_NO_GOOD_INDEX_USED = 16;
exports.SERVER_QUERY_NO_INDEX_USED = 32;
/**
  The server was able to fulfill the clients request and opened a
  read-only non-scrollable cursor for a query. This flag comes
  in reply to COM_STMT_EXECUTE and COM_STMT_FETCH commands.
*/
exports.SERVER_STATUS_CURSOR_EXISTS = 64;
/**
  This flag is sent when a read-only cursor is exhausted, in reply to
  COM_STMT_FETCH command.
*/
exports.SERVER_STATUS_LAST_ROW_SENT = 128;
exports.SERVER_STATUS_DB_DROPPED = 256; /* A database was dropped */
exports.SERVER_STATUS_NO_BACKSLASH_ESCAPES = 512;
/**
  Sent to the client if after a prepared statement reprepare
  we discovered that the new statement returns a different
  number of result set columns.
*/
exports.SERVER_STATUS_METADATA_CHANGED = 1024;
exports.SERVER_QUERY_WAS_SLOW = 2048;

/**
  To mark ResultSet containing output parameter values.
*/
exports.SERVER_PS_OUT_PARAMS = 4096;

exports.SERVER_STATUS_IN_TRANS_READONLY = 0x2000; // in a read-only transaction
exports.SERVER_SESSION_STATE_CHANGED = 0x4000;
</file>

<file path="lib/constants/session_track.js">
'use strict';

exports.SYSTEM_VARIABLES = 0;
exports.SCHEMA = 1;
exports.STATE_CHANGE = 2;
exports.STATE_GTIDS = 3;
exports.TRANSACTION_CHARACTERISTICS = 4;
exports.TRANSACTION_STATE = 5;

exports.FIRST_KEY = exports.SYSTEM_VARIABLES;
exports.LAST_KEY = exports.TRANSACTION_STATE;
</file>

<file path="lib/constants/ssl_profiles.js">
'use strict';

const awsCaBundle = require('aws-ssl-profiles');

/**
 * @deprecated
 * Please, use [**aws-ssl-profiles**](https://github.com/mysqljs/aws-ssl-profiles).
 */
exports['Amazon RDS'] = {
  ca: awsCaBundle.ca,
};
</file>

<file path="lib/constants/types.js">
'use strict';

module.exports = {
  0x00: 'DECIMAL', // aka DECIMAL
  0x01: 'TINY', // aka TINYINT, 1 byte
  0x02: 'SHORT', // aka SMALLINT, 2 bytes
  0x03: 'LONG', // aka INT, 4 bytes
  0x04: 'FLOAT', // aka FLOAT, 4-8 bytes
  0x05: 'DOUBLE', // aka DOUBLE, 8 bytes
  0x06: 'NULL', // NULL (used for prepared statements, I think)
  0x07: 'TIMESTAMP', // aka TIMESTAMP
  0x08: 'LONGLONG', // aka BIGINT, 8 bytes
  0x09: 'INT24', // aka MEDIUMINT, 3 bytes
  0x0a: 'DATE', // aka DATE
  0x0b: 'TIME', // aka TIME
  0x0c: 'DATETIME', // aka DATETIME
  0x0d: 'YEAR', // aka YEAR, 1 byte (don't ask)
  0x0e: 'NEWDATE', // aka ?
  0x0f: 'VARCHAR', // aka VARCHAR (?)
  0x10: 'BIT', // aka BIT, 1-8 byte
  0xf5: 'JSON',
  0xf6: 'NEWDECIMAL', // aka DECIMAL
  0xf7: 'ENUM', // aka ENUM
  0xf8: 'SET', // aka SET
  0xf9: 'TINY_BLOB', // aka TINYBLOB, TINYTEXT
  0xfa: 'MEDIUM_BLOB', // aka MEDIUMBLOB, MEDIUMTEXT
  0xfb: 'LONG_BLOB', // aka LONGBLOG, LONGTEXT
  0xfc: 'BLOB', // aka BLOB, TEXT
  0xfd: 'VAR_STRING', // aka VARCHAR, VARBINARY
  0xfe: 'STRING', // aka CHAR, BINARY
  0xff: 'GEOMETRY', // aka GEOMETRY
};

// Manually extracted from mysql-5.5.23/include/mysql_com.h
// some more info here: http://dev.mysql.com/doc/refman/5.5/en/c-api-prepared-statement-type-codes.html
module.exports.DECIMAL = 0x00; // aka DECIMAL (http://dev.mysql.com/doc/refman/5.0/en/precision-math-decimal-changes.html)
module.exports.TINY = 0x01; // aka TINYINT, 1 byte
module.exports.SHORT = 0x02; // aka SMALLINT, 2 bytes
module.exports.LONG = 0x03; // aka INT, 4 bytes
module.exports.FLOAT = 0x04; // aka FLOAT, 4-8 bytes
module.exports.DOUBLE = 0x05; // aka DOUBLE, 8 bytes
module.exports.NULL = 0x06; // NULL (used for prepared statements, I think)
module.exports.TIMESTAMP = 0x07; // aka TIMESTAMP
module.exports.LONGLONG = 0x08; // aka BIGINT, 8 bytes
module.exports.INT24 = 0x09; // aka MEDIUMINT, 3 bytes
module.exports.DATE = 0x0a; // aka DATE
module.exports.TIME = 0x0b; // aka TIME
module.exports.DATETIME = 0x0c; // aka DATETIME
module.exports.YEAR = 0x0d; // aka YEAR, 1 byte (don't ask)
module.exports.NEWDATE = 0x0e; // aka ?
module.exports.VARCHAR = 0x0f; // aka VARCHAR (?)
module.exports.BIT = 0x10; // aka BIT, 1-8 byte
module.exports.VECTOR = 0xf2;
module.exports.JSON = 0xf5;
module.exports.NEWDECIMAL = 0xf6; // aka DECIMAL
module.exports.ENUM = 0xf7; // aka ENUM
module.exports.SET = 0xf8; // aka SET
module.exports.TINY_BLOB = 0xf9; // aka TINYBLOB, TINYTEXT
module.exports.MEDIUM_BLOB = 0xfa; // aka MEDIUMBLOB, MEDIUMTEXT
module.exports.LONG_BLOB = 0xfb; // aka LONGBLOG, LONGTEXT
module.exports.BLOB = 0xfc; // aka BLOB, TEXT
module.exports.VAR_STRING = 0xfd; // aka VARCHAR, VARBINARY
module.exports.STRING = 0xfe; // aka CHAR, BINARY
module.exports.GEOMETRY = 0xff; // aka GEOMETRY
</file>

<file path="lib/create_connection.js">
'use strict';

const Connection = require('./connection.js');
const ConnectionConfig = require('./connection_config.js');

function createConnection(opts) {
  return new Connection({ config: new ConnectionConfig(opts) });
}

module.exports = createConnection;
</file>

<file path="lib/create_pool_cluster.js">
'use strict';

const PoolCluster = require('./pool_cluster.js');

function createPoolCluster(config) {
  return new PoolCluster(config);
}

module.exports = createPoolCluster;
</file>

<file path="lib/create_pool.js">
'use strict';

const Pool = require('./pool.js');
const PoolConfig = require('./pool_config.js');

function createPool(config) {
  return new Pool({ config: new PoolConfig(config) });
}

module.exports = createPool;
</file>

<file path="lib/helpers.js">
'use strict';

/*

  this seems to be not only shorter, but faster than
  string.replace(/\\/g, '\\\\').
            replace(/\u0008/g, '\\b').
            replace(/\t/g, '\\t').
            replace(/\n/g, '\\n').
            replace(/\f/g, '\\f').
            replace(/\r/g, '\\r').
            replace(/'/g, '\\\'').
            replace(/"/g, '\\"');
  or string.replace(/[\-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&")
  see http://jsperf.com/string-escape-regexp-vs-json-stringify
  */
function srcEscape(str) {
  return JSON.stringify({
    [str]: 1,
  }).slice(1, -3);
}

exports.srcEscape = srcEscape;

let highlightFn;
let cardinalRecommended = false;
try {
  // the purpose of this is to prevent projects using Webpack from displaying a warning during runtime if cardinal is not a dependency
  const REQUIRE_TERMINATOR = '';
  highlightFn = require(`cardinal${REQUIRE_TERMINATOR}`).highlight;
} catch (err) {
  highlightFn = (text) => {
    if (!cardinalRecommended) {
      // eslint-disable-next-line no-console
      console.log('For nicer debug output consider install cardinal@^2.0.0');
      cardinalRecommended = true;
    }
    return text;
  };
}

/**
 * Prints debug message with code frame, will try to use `cardinal` if available.
 */
function printDebugWithCode(msg, code) {
  // eslint-disable-next-line no-console
  console.log(`\n\n${msg}:\n`);
  // eslint-disable-next-line no-console
  console.log(`${highlightFn(code)}\n`);
}

exports.printDebugWithCode = printDebugWithCode;

/**
 * checks whether the `type` is in the `list`
 */
function typeMatch(type, list, Types) {
  if (Array.isArray(list)) {
    return list.some((t) => type === Types[t]);
  }

  return !!list;
}

exports.typeMatch = typeMatch;

const privateObjectProps = new Set([
  '__defineGetter__',
  '__defineSetter__',
  '__lookupGetter__',
  '__lookupSetter__',
  '__proto__',
]);

exports.privateObjectProps = privateObjectProps;

const fieldEscape = (field, isEval = true) => {
  if (privateObjectProps.has(field)) {
    throw new Error(
      `The field name (${field}) can't be the same as an object's private property.`
    );
  }

  return isEval ? srcEscape(field) : field;
};
exports.fieldEscape = fieldEscape;
</file>

<file path="lib/packet_parser.js">
'use strict';

const Packet = require('./packets/packet.js');

const MAX_PACKET_LENGTH = 16777215;

function readPacketLength(b, off) {
  const b0 = b[off];
  const b1 = b[off + 1];
  const b2 = b[off + 2];
  if (b1 + b2 === 0) {
    return b0;
  }
  return b0 + (b1 << 8) + (b2 << 16);
}

class PacketParser {
  constructor(onPacket, packetHeaderLength) {
    // 4 for normal packets, 7 for comprssed protocol packets
    if (typeof packetHeaderLength === 'undefined') {
      packetHeaderLength = 4;
    }
    // array of last payload chunks
    // only used when current payload is not complete
    this.buffer = [];
    // total length of chunks on buffer
    this.bufferLength = 0;
    this.packetHeaderLength = packetHeaderLength;
    // incomplete header state: number of header bytes received
    this.headerLen = 0;
    // expected payload length
    this.length = 0;
    this.largePacketParts = [];
    this.firstPacketSequenceId = 0;
    this.onPacket = onPacket;
    this.execute = PacketParser.prototype.executeStart;
    this._flushLargePacket =
      packetHeaderLength === 7
        ? this._flushLargePacket7
        : this._flushLargePacket4;
  }

  _flushLargePacket4() {
    const numPackets = this.largePacketParts.length;
    this.largePacketParts.unshift(Buffer.from([0, 0, 0, 0])); // insert header
    const body = Buffer.concat(this.largePacketParts);
    const packet = new Packet(this.firstPacketSequenceId, body, 0, body.length);
    this.largePacketParts.length = 0;
    packet.numPackets = numPackets;
    this.onPacket(packet);
  }

  _flushLargePacket7() {
    const numPackets = this.largePacketParts.length;
    this.largePacketParts.unshift(Buffer.from([0, 0, 0, 0, 0, 0, 0])); // insert header
    const body = Buffer.concat(this.largePacketParts);
    this.largePacketParts.length = 0;
    const packet = new Packet(this.firstPacketSequenceId, body, 0, body.length);
    packet.numPackets = numPackets;
    this.onPacket(packet);
  }

  executeStart(chunk) {
    let start = 0;
    const end = chunk.length;
    while (end - start >= 3) {
      this.length = readPacketLength(chunk, start);
      if (end - start >= this.length + this.packetHeaderLength) {
        // at least one full packet
        const sequenceId = chunk[start + 3];
        if (
          this.length < MAX_PACKET_LENGTH &&
          this.largePacketParts.length === 0
        ) {
          this.onPacket(
            new Packet(
              sequenceId,
              chunk,
              start,
              start + this.packetHeaderLength + this.length
            )
          );
        } else {
          // first large packet - remember it's id
          if (this.largePacketParts.length === 0) {
            this.firstPacketSequenceId = sequenceId;
          }
          this.largePacketParts.push(
            chunk.slice(
              start + this.packetHeaderLength,
              start + this.packetHeaderLength + this.length
            )
          );
          if (this.length < MAX_PACKET_LENGTH) {
            this._flushLargePacket();
          }
        }
        start += this.packetHeaderLength + this.length;
      } else {
        // payload is incomplete
        this.buffer = [chunk.slice(start + 3, end)];
        this.bufferLength = end - start - 3;
        this.execute = PacketParser.prototype.executePayload;
        return;
      }
    }
    if (end - start > 0) {
      // there is start of length header, but it's not full 3 bytes
      this.headerLen = end - start; // 1 or 2 bytes
      this.length = chunk[start];
      if (this.headerLen === 2) {
        this.length = chunk[start] + (chunk[start + 1] << 8);
        this.execute = PacketParser.prototype.executeHeader3;
      } else {
        this.execute = PacketParser.prototype.executeHeader2;
      }
    }
  }

  executePayload(chunk) {
    let start = 0;
    const end = chunk.length;
    const remainingPayload =
      this.length - this.bufferLength + this.packetHeaderLength - 3;
    if (end - start >= remainingPayload) {
      // last chunk for payload
      const payload = Buffer.allocUnsafe(this.length + this.packetHeaderLength);
      let offset = 3;
      for (let i = 0; i < this.buffer.length; ++i) {
        this.buffer[i].copy(payload, offset);
        offset += this.buffer[i].length;
      }
      chunk.copy(payload, offset, start, start + remainingPayload);
      const sequenceId = payload[3];
      if (
        this.length < MAX_PACKET_LENGTH &&
        this.largePacketParts.length === 0
      ) {
        this.onPacket(
          new Packet(
            sequenceId,
            payload,
            0,
            this.length + this.packetHeaderLength
          )
        );
      } else {
        // first large packet - remember it's id
        if (this.largePacketParts.length === 0) {
          this.firstPacketSequenceId = sequenceId;
        }
        this.largePacketParts.push(
          payload.slice(
            this.packetHeaderLength,
            this.packetHeaderLength + this.length
          )
        );
        if (this.length < MAX_PACKET_LENGTH) {
          this._flushLargePacket();
        }
      }
      this.buffer = [];
      this.bufferLength = 0;
      this.execute = PacketParser.prototype.executeStart;
      start += remainingPayload;
      if (end - start > 0) {
        return this.execute(chunk.slice(start, end));
      }
    } else {
      this.buffer.push(chunk);
      this.bufferLength += chunk.length;
    }
    return null;
  }

  executeHeader2(chunk) {
    this.length += chunk[0] << 8;
    if (chunk.length > 1) {
      this.length += chunk[1] << 16;
      this.execute = PacketParser.prototype.executePayload;
      return this.executePayload(chunk.slice(2));
    }
    this.execute = PacketParser.prototype.executeHeader3;

    return null;
  }

  executeHeader3(chunk) {
    this.length += chunk[0] << 16;
    this.execute = PacketParser.prototype.executePayload;
    return this.executePayload(chunk.slice(1));
  }
}

module.exports = PacketParser;
</file>

<file path="lib/packets/auth_next_factor.js">
// Copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const Packet = require('../packets/packet');

class AuthNextFactor {
  constructor(opts) {
    this.pluginName = opts.pluginName;
    this.pluginData = opts.pluginData;
  }

  toPacket(encoding) {
    const length = 6 + this.pluginName.length + this.pluginData.length;
    const buffer = Buffer.allocUnsafe(length);
    const packet = new Packet(0, buffer, 0, length);
    packet.offset = 4;
    packet.writeInt8(0x02);
    packet.writeNullTerminatedString(this.pluginName, encoding);
    packet.writeBuffer(this.pluginData);
    return packet;
  }

  static fromPacket(packet, encoding) {
    packet.readInt8(); // marker
    const name = packet.readNullTerminatedString(encoding);
    const data = packet.readBuffer();
    return new AuthNextFactor({
      pluginName: name,
      pluginData: data,
    });
  }
}

module.exports = AuthNextFactor;
</file>

<file path="lib/packets/auth_switch_request_more_data.js">
'use strict';

// http://dev.mysql.com/doc/internals/en/connection-phase-packets.html#packet-Protocol::AuthSwitchRequest

const Packet = require('../packets/packet');

class AuthSwitchRequestMoreData {
  constructor(data) {
    this.data = data;
  }

  toPacket() {
    const length = 5 + this.data.length;
    const buffer = Buffer.allocUnsafe(length);
    const packet = new Packet(0, buffer, 0, length);
    packet.offset = 4;
    packet.writeInt8(0x01);
    packet.writeBuffer(this.data);
    return packet;
  }

  static fromPacket(packet) {
    packet.readInt8(); // marker
    const data = packet.readBuffer();
    return new AuthSwitchRequestMoreData(data);
  }

  static verifyMarker(packet) {
    return packet.peekByte() === 0x01;
  }
}

module.exports = AuthSwitchRequestMoreData;
</file>

<file path="lib/packets/auth_switch_request.js">
'use strict';

// http://dev.mysql.com/doc/internals/en/connection-phase-packets.html#packet-Protocol::AuthSwitchRequest

const Packet = require('../packets/packet');

class AuthSwitchRequest {
  constructor(opts) {
    this.pluginName = opts.pluginName;
    this.pluginData = opts.pluginData;
  }

  toPacket() {
    const length = 6 + this.pluginName.length + this.pluginData.length;
    const buffer = Buffer.allocUnsafe(length);
    const packet = new Packet(0, buffer, 0, length);
    packet.offset = 4;
    packet.writeInt8(0xfe);
    // TODO: use server encoding
    packet.writeNullTerminatedString(this.pluginName, 'cesu8');
    packet.writeBuffer(this.pluginData);
    return packet;
  }

  static fromPacket(packet) {
    packet.readInt8(); // marker
    // assert marker == 0xfe?
    // TODO: use server encoding
    const name = packet.readNullTerminatedString('cesu8');
    const data = packet.readBuffer();
    return new AuthSwitchRequest({
      pluginName: name,
      pluginData: data,
    });
  }
}

module.exports = AuthSwitchRequest;
</file>

<file path="lib/packets/auth_switch_response.js">
'use strict';

// http://dev.mysql.com/doc/internals/en/connection-phase-packets.html#packet-Protocol::AuthSwitchRequest

const Packet = require('../packets/packet');

class AuthSwitchResponse {
  constructor(data) {
    if (!Buffer.isBuffer(data)) {
      data = Buffer.from(data);
    }
    this.data = data;
  }

  toPacket() {
    const length = 4 + this.data.length;
    const buffer = Buffer.allocUnsafe(length);
    const packet = new Packet(0, buffer, 0, length);
    packet.offset = 4;
    packet.writeBuffer(this.data);
    return packet;
  }

  static fromPacket(packet) {
    const data = packet.readBuffer();
    return new AuthSwitchResponse(data);
  }
}

module.exports = AuthSwitchResponse;
</file>

<file path="lib/packets/binary_row.js">
'use strict';

const Types = require('../constants/types');
const Packet = require('../packets/packet');

const binaryReader = new Array(256);

class BinaryRow {
  constructor(columns) {
    this.columns = columns || [];
  }

  static toPacket(columns, encoding) {
    // throw new Error('Not implemented');
    const sequenceId = 0; // TODO remove, this is calculated now in connecton
    let length = 0;
    columns.forEach((val) => {
      if (val === null || typeof val === 'undefined') {
        ++length;
        return;
      }
      length += Packet.lengthCodedStringLength(val.toString(10), encoding);
    });

    length = length + 2;

    const buffer = Buffer.allocUnsafe(length + 4);
    const packet = new Packet(sequenceId, buffer, 0, length + 4);
    packet.offset = 4;

    packet.writeInt8(0);

    let bitmap = 0;
    let bitValue = 1;
    columns.forEach((parameter) => {
      if (parameter.type === Types.NULL) {
        bitmap += bitValue;
      }
      bitValue *= 2;
      if (bitValue === 256) {
        packet.writeInt8(bitmap);
        bitmap = 0;
        bitValue = 1;
      }
    });
    if (bitValue !== 1) {
      packet.writeInt8(bitmap);
    }

    columns.forEach((val) => {
      if (val === null) {
        packet.writeNull();
        return;
      }
      if (typeof val === 'undefined') {
        packet.writeInt8(0);
        return;
      }
      packet.writeLengthCodedString(val.toString(10), encoding);
    });
    return packet;
  }

  // TODO: complete list of types...
  static fromPacket(fields, packet) {
    const columns = new Array(fields.length);
    packet.readInt8(); // TODO check it's 0
    const nullBitmapLength = Math.floor((fields.length + 7 + 2) / 8);
    // TODO: read and interpret null bitmap
    packet.skip(nullBitmapLength);
    for (let i = 0; i < columns.length; ++i) {
      columns[i] = binaryReader[fields[i].columnType].apply(packet);
    }
    return new BinaryRow(columns);
  }
}

// TODO: replace with constants.MYSQL_TYPE_*
binaryReader[Types.DECIMAL] = Packet.prototype.readLengthCodedString;
binaryReader[1] = Packet.prototype.readInt8; // tiny
binaryReader[2] = Packet.prototype.readInt16; // short
binaryReader[3] = Packet.prototype.readInt32; // long
binaryReader[4] = Packet.prototype.readFloat; // float
binaryReader[5] = Packet.prototype.readDouble; // double
binaryReader[6] = Packet.prototype.assertInvalid; // null, should be skipped vie null bitmap
binaryReader[7] = Packet.prototype.readTimestamp; // timestamp, http://dev.mysql.com/doc/internals/en/prepared-statements.html#packet-ProtocolBinary::MYSQL_TYPE_TIMESTAMP
binaryReader[8] = Packet.prototype.readInt64; // long long
binaryReader[9] = Packet.prototype.readInt32; // int24
binaryReader[10] = Packet.prototype.readTimestamp; // date
binaryReader[11] = Packet.prototype.readTime; // time, http://dev.mysql.com/doc/internals/en/prepared-statements.html#packet-ProtocolBinary::MYSQL_TYPE_TIME
binaryReader[12] = Packet.prototype.readDateTime; // datetime, http://dev.mysql.com/doc/internals/en/prepared-statements.html#packet-ProtocolBinary::MYSQL_TYPE_DATETIME
binaryReader[13] = Packet.prototype.readInt16; // year
binaryReader[Types.VAR_STRING] = Packet.prototype.readLengthCodedString; // var string

module.exports = BinaryRow;
</file>

<file path="lib/packets/binlog_dump.js">
'use strict';

// http://dev.mysql.com/doc/internals/en/com-binlog-dump.html#packet-COM_BINLOG_DUMP

const Packet = require('../packets/packet');
const CommandCodes = require('../constants/commands');

// TODO: add flag to constants
// 0x01 - BINLOG_DUMP_NON_BLOCK
// send EOF instead of blocking
class BinlogDump {
  constructor(opts) {
    this.binlogPos = opts.binlogPos || 0;
    this.serverId = opts.serverId || 0;
    this.flags = opts.flags || 0;
    this.filename = opts.filename || '';
  }

  toPacket() {
    const length = 15 + Buffer.byteLength(this.filename, 'utf8'); // TODO: should be ascii?
    const buffer = Buffer.allocUnsafe(length);
    const packet = new Packet(0, buffer, 0, length);
    packet.offset = 4;
    packet.writeInt8(CommandCodes.BINLOG_DUMP);
    packet.writeInt32(this.binlogPos);
    packet.writeInt16(this.flags);
    packet.writeInt32(this.serverId);
    packet.writeString(this.filename);
    return packet;
  }
}

module.exports = BinlogDump;
</file>

<file path="lib/packets/binlog_query_statusvars.js">
'use strict';

// http://dev.mysql.com/doc/internals/en/query-event.html

const keys = {
  FLAGS2: 0,
  SQL_MODE: 1,
  CATALOG: 2,
  AUTO_INCREMENT: 3,
  CHARSET: 4,
  TIME_ZONE: 5,
  CATALOG_NZ: 6,
  LC_TIME_NAMES: 7,
  CHARSET_DATABASE: 8,
  TABLE_MAP_FOR_UPDATE: 9,
  MASTER_DATA_WRITTEN: 10,
  INVOKERS: 11,
  UPDATED_DB_NAMES: 12,
  MICROSECONDS: 3,
};

module.exports = function parseStatusVars(buffer) {
  const result = {};
  let offset = 0;
  let key, length, prevOffset;
  while (offset < buffer.length) {
    key = buffer[offset++];
    switch (key) {
      case keys.FLAGS2:
        result.flags = buffer.readUInt32LE(offset);
        offset += 4;
        break;
      case keys.SQL_MODE:
        // value is 8 bytes, but all dcumented flags are in first 4 bytes
        result.sqlMode = buffer.readUInt32LE(offset);
        offset += 8;
        break;
      case keys.CATALOG:
        length = buffer[offset++];
        result.catalog = buffer.toString('utf8', offset, offset + length);
        offset += length + 1; // null byte after string
        break;
      case keys.CHARSET:
        result.clientCharset = buffer.readUInt16LE(offset);
        result.connectionCollation = buffer.readUInt16LE(offset + 2);
        result.serverCharset = buffer.readUInt16LE(offset + 4);
        offset += 6;
        break;
      case keys.TIME_ZONE:
        length = buffer[offset++];
        result.timeZone = buffer.toString('utf8', offset, offset + length);
        offset += length; // no null byte
        break;
      case keys.CATALOG_NZ:
        length = buffer[offset++];
        result.catalogNz = buffer.toString('utf8', offset, offset + length);
        offset += length; // no null byte
        break;
      case keys.LC_TIME_NAMES:
        result.lcTimeNames = buffer.readUInt16LE(offset);
        offset += 2;
        break;
      case keys.CHARSET_DATABASE:
        result.schemaCharset = buffer.readUInt16LE(offset);
        offset += 2;
        break;
      case keys.TABLE_MAP_FOR_UPDATE:
        result.mapForUpdate1 = buffer.readUInt32LE(offset);
        result.mapForUpdate2 = buffer.readUInt32LE(offset + 4);
        offset += 8;
        break;
      case keys.MASTER_DATA_WRITTEN:
        result.masterDataWritten = buffer.readUInt32LE(offset);
        offset += 4;
        break;
      case keys.INVOKERS:
        length = buffer[offset++];
        result.invokerUsername = buffer.toString(
          'utf8',
          offset,
          offset + length
        );
        offset += length;
        length = buffer[offset++];
        result.invokerHostname = buffer.toString(
          'utf8',
          offset,
          offset + length
        );
        offset += length;
        break;
      case keys.UPDATED_DB_NAMES:
        length = buffer[offset++];
        // length - number of null-terminated strings
        result.updatedDBs = []; // we'll store them as array here
        for (; length; --length) {
          prevOffset = offset;
          // fast forward to null terminating byte
          while (buffer[offset++] && offset < buffer.length) {
            // empty body, everything inside while condition
          }
          result.updatedDBs.push(
            buffer.toString('utf8', prevOffset, offset - 1)
          );
        }
        break;
      case keys.MICROSECONDS:
        result.microseconds =
          // REVIEW: INVALID UNKNOWN VARIABLE!
          buffer.readInt16LE(offset) + (buffer[offset + 2] << 16);
        offset += 3;
    }
  }
  return result;
};
</file>

<file path="lib/packets/change_user.js">
'use strict';

const CommandCode = require('../constants/commands.js');
const ClientConstants = require('../constants/client.js');
const Packet = require('../packets/packet.js');
const auth41 = require('../auth_41.js');
const CharsetToEncoding = require('../constants/charset_encodings.js');

// https://dev.mysql.com/doc/internals/en/com-change-user.html#packet-COM_CHANGE_USER
class ChangeUser {
  constructor(opts) {
    this.flags = opts.flags;
    this.user = opts.user || '';
    this.database = opts.database || '';
    this.password = opts.password || '';
    this.passwordSha1 = opts.passwordSha1;
    this.authPluginData1 = opts.authPluginData1;
    this.authPluginData2 = opts.authPluginData2;
    this.connectAttributes = opts.connectAttrinutes || {};
    let authToken;
    if (this.passwordSha1) {
      authToken = auth41.calculateTokenFromPasswordSha(
        this.passwordSha1,
        this.authPluginData1,
        this.authPluginData2
      );
    } else {
      authToken = auth41.calculateToken(
        this.password,
        this.authPluginData1,
        this.authPluginData2
      );
    }
    this.authToken = authToken;
    this.charsetNumber = opts.charsetNumber;
  }

  // TODO
  // ChangeUser.fromPacket = function(packet)
  // };
  serializeToBuffer(buffer) {
    const isSet = (flag) => this.flags & ClientConstants[flag];
    const packet = new Packet(0, buffer, 0, buffer.length);
    packet.offset = 4;
    const encoding = CharsetToEncoding[this.charsetNumber];
    packet.writeInt8(CommandCode.CHANGE_USER);
    packet.writeNullTerminatedString(this.user, encoding);
    if (isSet('SECURE_CONNECTION')) {
      packet.writeInt8(this.authToken.length);
      packet.writeBuffer(this.authToken);
    } else {
      packet.writeBuffer(this.authToken);
      packet.writeInt8(0);
    }
    packet.writeNullTerminatedString(this.database, encoding);
    packet.writeInt16(this.charsetNumber);
    if (isSet('PLUGIN_AUTH')) {
      // TODO: read this from parameters
      packet.writeNullTerminatedString('mysql_native_password', 'latin1');
    }
    if (isSet('CONNECT_ATTRS')) {
      const connectAttributes = this.connectAttributes;
      const attrNames = Object.keys(connectAttributes);
      let keysLength = 0;
      for (let k = 0; k < attrNames.length; ++k) {
        keysLength += Packet.lengthCodedStringLength(attrNames[k], encoding);
        keysLength += Packet.lengthCodedStringLength(
          connectAttributes[attrNames[k]],
          encoding
        );
      }
      packet.writeLengthCodedNumber(keysLength);
      for (let k = 0; k < attrNames.length; ++k) {
        packet.writeLengthCodedString(attrNames[k], encoding);
        packet.writeLengthCodedString(
          connectAttributes[attrNames[k]],
          encoding
        );
      }
    }
    return packet;
  }

  toPacket() {
    if (typeof this.user !== 'string') {
      throw new Error('"user" connection config property must be a string');
    }
    if (typeof this.database !== 'string') {
      throw new Error('"database" connection config property must be a string');
    }
    // dry run: calculate resulting packet length
    const p = this.serializeToBuffer(Packet.MockBuffer());
    return this.serializeToBuffer(Buffer.allocUnsafe(p.offset));
  }
}

module.exports = ChangeUser;
</file>

<file path="lib/packets/close_statement.js">
'use strict';

const Packet = require('../packets/packet');
const CommandCodes = require('../constants/commands');

class CloseStatement {
  constructor(id) {
    this.id = id;
  }

  // note: no response sent back
  toPacket() {
    const packet = new Packet(0, Buffer.allocUnsafe(9), 0, 9);
    packet.offset = 4;
    packet.writeInt8(CommandCodes.STMT_CLOSE);
    packet.writeInt32(this.id);
    return packet;
  }
}

module.exports = CloseStatement;
</file>

<file path="lib/packets/column_definition.js">
'use strict';

const Packet = require('../packets/packet');
const StringParser = require('../parsers/string');
const CharsetToEncoding = require('../constants/charset_encodings.js');

const fields = ['catalog', 'schema', 'table', 'orgTable', 'name', 'orgName'];

// creating JS string is relatively expensive (compared to
// reading few bytes from buffer) because all string properties
// except for name are unlikely to be used we postpone
// string conversion until property access
//
// TODO: watch for integration benchmarks (one with real network buffer)
// there could be bad side effect as keeping reference to a buffer makes it
// sit in the memory longer (usually until final .query() callback)
// Latest v8 perform much better in regard to bufferer -> string conversion,
// at some point of time this optimisation might become unnecessary
// see https://github.com/sidorares/node-mysql2/pull/137
//
class ColumnDefinition {
  constructor(packet, clientEncoding) {
    this._buf = packet.buffer;
    this._clientEncoding = clientEncoding;
    this._catalogLength = packet.readLengthCodedNumber();
    this._catalogStart = packet.offset;
    packet.offset += this._catalogLength;
    this._schemaLength = packet.readLengthCodedNumber();
    this._schemaStart = packet.offset;
    packet.offset += this._schemaLength;
    this._tableLength = packet.readLengthCodedNumber();
    this._tableStart = packet.offset;
    packet.offset += this._tableLength;
    this._orgTableLength = packet.readLengthCodedNumber();
    this._orgTableStart = packet.offset;
    packet.offset += this._orgTableLength;
    // name is always used, don't make it lazy
    const _nameLength = packet.readLengthCodedNumber();
    const _nameStart = packet.offset;
    packet.offset += _nameLength;
    this._orgNameLength = packet.readLengthCodedNumber();
    this._orgNameStart = packet.offset;
    packet.offset += this._orgNameLength;
    packet.skip(1); //  length of the following fields (always 0x0c)
    this.characterSet = packet.readInt16();
    this.encoding = CharsetToEncoding[this.characterSet];
    this.name = StringParser.decode(
      this._buf,
      this.encoding === 'binary' ? this._clientEncoding : this.encoding,
      _nameStart,
      _nameStart + _nameLength
    );
    this.columnLength = packet.readInt32();
    this.columnType = packet.readInt8();
    this.type = this.columnType;
    this.flags = packet.readInt16();
    this.decimals = packet.readInt8();
  }

  inspect() {
    return {
      catalog: this.catalog,
      schema: this.schema,
      name: this.name,
      orgName: this.orgName,
      table: this.table,
      orgTable: this.orgTable,
      characterSet: this.characterSet,
      encoding: this.encoding,
      columnLength: this.columnLength,
      type: this.columnType,
      flags: this.flags,
      decimals: this.decimals,
    };
  }

  [Symbol.for('nodejs.util.inspect.custom')](depth, inspectOptions, inspect) {
    const Types = require('../constants/types.js');
    const typeNames = [];
    for (const t in Types) {
      typeNames[Types[t]] = t;
    }
    const fiedFlags = require('../constants/field_flags.js');
    const flagNames = [];
    // TODO: respect inspectOptions.showHidden
    //const inspectFlags = inspectOptions.showHidden ? this.flags : this.flags & ~fiedFlags.PRI_KEY;
    const inspectFlags = this.flags;
    for (const f in fiedFlags) {
      if (inspectFlags & fiedFlags[f]) {
        if (f === 'PRI_KEY') {
          flagNames.push('PRIMARY KEY');
        } else if (f === 'NOT_NULL') {
          flagNames.push('NOT NULL');
        } else if (f === 'BINARY') {
          // ignore flag for now
        } else if (f === 'MULTIPLE_KEY') {
          // not sure if that should be part of inspection.
          // in the schema usually this is part of index definition
          // example: UNIQUE KEY `my_uniq_id` (`id_box_elements`,`id_router`)
          // note that only first column has MULTIPLE_KEY flag set in this case
          // so there is no good way of knowing that this is part of index just
          // by looking at indifidual field flags
        } else if (f === 'NO_DEFAULT_VALUE') {
          // almost the same as NOT_NULL?
        } else if (f === 'BLOB') {
          // included in the type
        } else if (f === 'UNSIGNED') {
          // this should be first after type
        } else if (f === 'TIMESTAMP') {
          // timestamp flag is redundant for inspection - already included in type
        } else if (f === 'ON_UPDATE_NOW') {
          flagNames.push('ON UPDATE CURRENT_TIMESTAMP');
        } else {
          flagNames.push(f);
        }
      }
    }

    if (depth > 1) {
      return inspect({
        ...this.inspect(),
        typeName: typeNames[this.columnType],
        flags: flagNames,
      });
    }

    const isUnsigned = this.flags & fiedFlags.UNSIGNED;

    let typeName = typeNames[this.columnType];
    if (typeName === 'BLOB') {
      // TODO: check for non-utf8mb4 encoding
      if (this.columnLength === 4294967295) {
        typeName = 'LONGTEXT';
      } else if (this.columnLength === 67108860) {
        typeName = 'MEDIUMTEXT';
      } else if (this.columnLength === 262140) {
        typeName = 'TEXT';
      } else if (this.columnLength === 1020) {
        // 255*4
        typeName = 'TINYTEXT';
      } else {
        typeName = `BLOB(${this.columnLength})`;
      }
    } else if (typeName === 'VAR_STRING') {
      // TODO: check for non-utf8mb4 encoding
      typeName = `VARCHAR(${Math.ceil(this.columnLength / 4)})`;
    } else if (typeName === 'TINY') {
      if (
        (this.columnLength === 3 && isUnsigned) ||
        (this.columnLength === 4 && !isUnsigned)
      ) {
        typeName = 'TINYINT';
      } else {
        typeName = `TINYINT(${this.columnLength})`;
      }
    } else if (typeName === 'LONGLONG') {
      if (this.columnLength === 20) {
        typeName = 'BIGINT';
      } else {
        typeName = `BIGINT(${this.columnLength})`;
      }
    } else if (typeName === 'SHORT') {
      if (isUnsigned && this.columnLength === 5) {
        typeName = 'SMALLINT';
      } else if (!isUnsigned && this.columnLength === 6) {
        typeName = 'SMALLINT';
      } else {
        typeName = `SMALLINT(${this.columnLength})`;
      }
    } else if (typeName === 'LONG') {
      if (isUnsigned && this.columnLength === 10) {
        typeName = 'INT';
      } else if (!isUnsigned && this.columnLength === 11) {
        typeName = 'INT';
      } else {
        typeName = `INT(${this.columnLength})`;
      }
    } else if (typeName === 'INT24') {
      if (isUnsigned && this.columnLength === 8) {
        typeName = 'MEDIUMINT';
      } else if (!isUnsigned && this.columnLength === 9) {
        typeName = 'MEDIUMINT';
      } else {
        typeName = `MEDIUMINT(${this.columnLength})`;
      }
    } else if (typeName === 'DOUBLE') {
      // DOUBLE without modifiers is reported as DOUBLE(22, 31)
      if (this.columnLength === 22 && this.decimals === 31) {
        typeName = 'DOUBLE';
      } else {
        typeName = `DOUBLE(${this.columnLength},${this.decimals})`;
      }
    } else if (typeName === 'FLOAT') {
      // FLOAT without modifiers is reported as FLOAT(12, 31)
      if (this.columnLength === 12 && this.decimals === 31) {
        typeName = 'FLOAT';
      } else {
        typeName = `FLOAT(${this.columnLength},${this.decimals})`;
      }
    } else if (typeName === 'NEWDECIMAL') {
      if (this.columnLength === 11 && this.decimals === 0) {
        typeName = 'DECIMAL';
      } else if (this.decimals === 0) {
        // not sure why, but DECIMAL(13) is reported as DECIMAL(14, 0)
        // and DECIMAL(13, 9) is reported as NEWDECIMAL(15, 9)
        if (isUnsigned) {
          typeName = `DECIMAL(${this.columnLength})`;
        } else {
          typeName = `DECIMAL(${this.columnLength - 1})`;
        }
      } else {
        typeName = `DECIMAL(${this.columnLength - 2},${this.decimals})`;
      }
    } else {
      typeName = `${typeNames[this.columnType]}(${this.columnLength})`;
    }

    if (isUnsigned) {
      typeName += ' UNSIGNED';
    }

    // TODO respect colors option
    return `\`${this.name}\` ${[typeName, ...flagNames].join(' ')}`;
  }

  static toPacket(column, sequenceId) {
    let length = 17; // = 4 padding + 1 + 12 for the rest
    fields.forEach((field) => {
      length += Packet.lengthCodedStringLength(
        column[field],
        CharsetToEncoding[column.characterSet]
      );
    });
    const buffer = Buffer.allocUnsafe(length);

    const packet = new Packet(sequenceId, buffer, 0, length);
    function writeField(name) {
      packet.writeLengthCodedString(
        column[name],
        CharsetToEncoding[column.characterSet]
      );
    }
    packet.offset = 4;
    fields.forEach(writeField);
    packet.writeInt8(0x0c);
    packet.writeInt16(column.characterSet);
    packet.writeInt32(column.columnLength);
    packet.writeInt8(column.columnType);
    packet.writeInt16(column.flags);
    packet.writeInt8(column.decimals);
    packet.writeInt16(0); // filler
    return packet;
  }

  // node-mysql compatibility: alias "db" to "schema"
  get db() {
    return this.schema;
  }
}

const addString = function (name) {
  Object.defineProperty(ColumnDefinition.prototype, name, {
    get: function () {
      const start = this[`_${name}Start`];
      const end = start + this[`_${name}Length`];
      const val = StringParser.decode(
        this._buf,
        this.encoding === 'binary' ? this._clientEncoding : this.encoding,
        start,
        end
      );

      Object.defineProperty(this, name, {
        value: val,
        writable: false,
        configurable: false,
        enumerable: false,
      });

      return val;
    },
  });
};

addString('catalog');
addString('schema');
addString('table');
addString('orgTable');
addString('orgName');

module.exports = ColumnDefinition;
</file>

<file path="lib/packets/execute.js">
'use strict';

const CursorType = require('../constants/cursor');
const CommandCodes = require('../constants/commands');
const Types = require('../constants/types');
const Packet = require('../packets/packet');
const CharsetToEncoding = require('../constants/charset_encodings.js');

function isJSON(value) {
  return (
    Array.isArray(value) ||
    value.constructor === Object ||
    (typeof value.toJSON === 'function' && !Buffer.isBuffer(value))
  );
}

/**
 * Converts a value to an object describing type, String/Buffer representation and length
 * @param {*} value
 */
function toParameter(value, encoding, timezone) {
  let type = Types.VAR_STRING;
  let length;
  let writer = function (value) {
    // eslint-disable-next-line no-invalid-this
    return Packet.prototype.writeLengthCodedString.call(this, value, encoding);
  };
  if (value !== null) {
    switch (typeof value) {
      case 'undefined':
        throw new TypeError('Bind parameters must not contain undefined');

      case 'number':
        type = Types.DOUBLE;
        length = 8;
        writer = Packet.prototype.writeDouble;
        break;

      case 'boolean':
        value = value | 0;
        type = Types.TINY;
        length = 1;
        writer = Packet.prototype.writeInt8;
        break;

      case 'object':
        if (Object.prototype.toString.call(value) === '[object Date]') {
          type = Types.DATETIME;
          length = 12;
          writer = function (value) {
            // eslint-disable-next-line no-invalid-this
            return Packet.prototype.writeDate.call(this, value, timezone);
          };
        } else if (isJSON(value)) {
          value = JSON.stringify(value);
          type = Types.JSON;
        } else if (Buffer.isBuffer(value)) {
          length = Packet.lengthCodedNumberLength(value.length) + value.length;
          writer = Packet.prototype.writeLengthCodedBuffer;
        }
        break;

      default:
        value = value.toString();
    }
  } else {
    value = '';
    type = Types.NULL;
  }
  if (!length) {
    length = Packet.lengthCodedStringLength(value, encoding);
  }
  return { value, type, length, writer };
}

class Execute {
  constructor(id, parameters, charsetNumber, timezone) {
    this.id = id;
    this.parameters = parameters;
    this.encoding = CharsetToEncoding[charsetNumber];
    this.timezone = timezone;
  }

  static fromPacket(packet, encoding) {
    const stmtId = packet.readInt32();
    const flags = packet.readInt8();
    const iterationCount = packet.readInt32();

    let i = packet.offset;
    while (i < packet.end - 1) {
      if (
        (packet.buffer[i + 1] === Types.VAR_STRING ||
          packet.buffer[i + 1] === Types.NULL ||
          packet.buffer[i + 1] === Types.DOUBLE ||
          packet.buffer[i + 1] === Types.TINY ||
          packet.buffer[i + 1] === Types.DATETIME ||
          packet.buffer[i + 1] === Types.JSON) &&
        packet.buffer[i] === 1 &&
        packet.buffer[i + 2] === 0
      ) {
        break;
      } else {
        packet.readInt8();
      }
      i++;
    }

    const types = [];

    for (let i = packet.offset + 1; i < packet.end - 1; i++) {
      if (
        (packet.buffer[i] === Types.VAR_STRING ||
          packet.buffer[i] === Types.NULL ||
          packet.buffer[i] === Types.DOUBLE ||
          packet.buffer[i] === Types.TINY ||
          packet.buffer[i] === Types.DATETIME ||
          packet.buffer[i] === Types.JSON) &&
        packet.buffer[i + 1] === 0
      ) {
        types.push(packet.buffer[i]);
        packet.skip(2);
      }
    }

    packet.skip(1);

    const values = [];
    for (let i = 0; i < types.length; i++) {
      if (types[i] === Types.VAR_STRING) {
        values.push(packet.readLengthCodedString(encoding));
      } else if (types[i] === Types.DOUBLE) {
        values.push(packet.readDouble());
      } else if (types[i] === Types.TINY) {
        values.push(packet.readInt8());
      } else if (types[i] === Types.DATETIME) {
        values.push(packet.readDateTime());
      } else if (types[i] === Types.JSON) {
        values.push(JSON.parse(packet.readLengthCodedString(encoding)));
      }
      if (types[i] === Types.NULL) {
        values.push(null);
      }
    }

    return { stmtId, flags, iterationCount, values };
  }

  toPacket() {
    // TODO: don't try to calculate packet length in advance, allocate some big buffer in advance (header + 256 bytes?)
    // and copy + reallocate if not enough
    // 0 + 4 - length, seqId
    // 4 + 1 - COM_EXECUTE
    // 5 + 4 - stmtId
    // 9 + 1 - flags
    // 10 + 4 - iteration-count (always 1)
    let length = 14;
    let parameters;
    if (this.parameters && this.parameters.length > 0) {
      length += Math.floor((this.parameters.length + 7) / 8);
      length += 1; // new-params-bound-flag
      length += 2 * this.parameters.length; // type byte for each parameter if new-params-bound-flag is set
      parameters = this.parameters.map((value) =>
        toParameter(value, this.encoding, this.timezone)
      );
      length += parameters.reduce(
        (accumulator, parameter) => accumulator + parameter.length,
        0
      );
    }
    const buffer = Buffer.allocUnsafe(length);
    const packet = new Packet(0, buffer, 0, length);
    packet.offset = 4;
    packet.writeInt8(CommandCodes.STMT_EXECUTE);
    packet.writeInt32(this.id);
    packet.writeInt8(CursorType.NO_CURSOR); // flags
    packet.writeInt32(1); // iteration-count, always 1
    if (parameters) {
      let bitmap = 0;
      let bitValue = 1;
      parameters.forEach((parameter) => {
        if (parameter.type === Types.NULL) {
          bitmap += bitValue;
        }
        bitValue *= 2;
        if (bitValue === 256) {
          packet.writeInt8(bitmap);
          bitmap = 0;
          bitValue = 1;
        }
      });
      if (bitValue !== 1) {
        packet.writeInt8(bitmap);
      }
      // TODO: explain meaning of the flag
      // afaik, if set n*2 bytes with type of parameter are sent before parameters
      // if not, previous execution types are used (TODO prooflink)
      packet.writeInt8(1); // new-params-bound-flag
      // Write parameter types
      parameters.forEach((parameter) => {
        packet.writeInt8(parameter.type); // field type
        packet.writeInt8(0); // parameter flag
      });
      // Write parameter values
      parameters.forEach((parameter) => {
        if (parameter.type !== Types.NULL) {
          parameter.writer.call(packet, parameter.value);
        }
      });
    }
    return packet;
  }
}

module.exports = Execute;
</file>

<file path="lib/packets/handshake_response.js">
'use strict';

const ClientConstants = require('../constants/client.js');
const CharsetToEncoding = require('../constants/charset_encodings.js');
const Packet = require('../packets/packet.js');

const auth41 = require('../auth_41.js');

class HandshakeResponse {
  constructor(handshake) {
    this.user = handshake.user || '';
    this.database = handshake.database || '';
    this.password = handshake.password || '';
    this.passwordSha1 = handshake.passwordSha1;
    this.authPluginData1 = handshake.authPluginData1;
    this.authPluginData2 = handshake.authPluginData2;
    this.compress = handshake.compress;
    this.clientFlags = handshake.flags;
    // TODO: pre-4.1 auth support
    let authToken;
    if (this.passwordSha1) {
      authToken = auth41.calculateTokenFromPasswordSha(
        this.passwordSha1,
        this.authPluginData1,
        this.authPluginData2
      );
    } else {
      authToken = auth41.calculateToken(
        this.password,
        this.authPluginData1,
        this.authPluginData2
      );
    }
    this.authToken = authToken;
    this.charsetNumber = handshake.charsetNumber;
    this.encoding = CharsetToEncoding[handshake.charsetNumber];
    this.connectAttributes = handshake.connectAttributes;
  }

  serializeResponse(buffer) {
    const isSet = (flag) => this.clientFlags & ClientConstants[flag];
    const packet = new Packet(0, buffer, 0, buffer.length);
    packet.offset = 4;
    packet.writeInt32(this.clientFlags);
    packet.writeInt32(0); // max packet size. todo: move to config
    packet.writeInt8(this.charsetNumber);
    packet.skip(23);
    const encoding = this.encoding;
    packet.writeNullTerminatedString(this.user, encoding);
    let k;
    if (isSet('PLUGIN_AUTH_LENENC_CLIENT_DATA')) {
      packet.writeLengthCodedNumber(this.authToken.length);
      packet.writeBuffer(this.authToken);
    } else if (isSet('SECURE_CONNECTION')) {
      packet.writeInt8(this.authToken.length);
      packet.writeBuffer(this.authToken);
    } else {
      packet.writeBuffer(this.authToken);
      packet.writeInt8(0);
    }
    if (isSet('CONNECT_WITH_DB')) {
      packet.writeNullTerminatedString(this.database, encoding);
    }
    if (isSet('PLUGIN_AUTH')) {
      // TODO: pass from config
      packet.writeNullTerminatedString('mysql_native_password', 'latin1');
    }
    if (isSet('CONNECT_ATTRS')) {
      const connectAttributes = this.connectAttributes || {};
      const attrNames = Object.keys(connectAttributes);
      let keysLength = 0;
      for (k = 0; k < attrNames.length; ++k) {
        keysLength += Packet.lengthCodedStringLength(attrNames[k], encoding);
        keysLength += Packet.lengthCodedStringLength(
          connectAttributes[attrNames[k]],
          encoding
        );
      }
      packet.writeLengthCodedNumber(keysLength);
      for (k = 0; k < attrNames.length; ++k) {
        packet.writeLengthCodedString(attrNames[k], encoding);
        packet.writeLengthCodedString(
          connectAttributes[attrNames[k]],
          encoding
        );
      }
    }
    return packet;
  }

  toPacket() {
    if (typeof this.user !== 'string') {
      throw new Error('"user" connection config property must be a string');
    }
    if (typeof this.database !== 'string') {
      throw new Error('"database" connection config property must be a string');
    }
    // dry run: calculate resulting packet length
    const p = this.serializeResponse(Packet.MockBuffer());
    return this.serializeResponse(Buffer.alloc(p.offset));
  }
  static fromPacket(packet) {
    const args = {};
    args.clientFlags = packet.readInt32();
    function isSet(flag) {
      return args.clientFlags & ClientConstants[flag];
    }
    args.maxPacketSize = packet.readInt32();
    args.charsetNumber = packet.readInt8();
    const encoding = CharsetToEncoding[args.charsetNumber];
    args.encoding = encoding;
    packet.skip(23);
    args.user = packet.readNullTerminatedString(encoding);
    let authTokenLength;
    if (isSet('PLUGIN_AUTH_LENENC_CLIENT_DATA')) {
      authTokenLength = packet.readLengthCodedNumber(encoding);
      args.authToken = packet.readBuffer(authTokenLength);
    } else if (isSet('SECURE_CONNECTION')) {
      authTokenLength = packet.readInt8();
      args.authToken = packet.readBuffer(authTokenLength);
    } else {
      args.authToken = packet.readNullTerminatedString(encoding);
    }
    if (isSet('CONNECT_WITH_DB')) {
      args.database = packet.readNullTerminatedString(encoding);
    }
    if (isSet('PLUGIN_AUTH')) {
      args.authPluginName = packet.readNullTerminatedString(encoding);
    }
    if (isSet('CONNECT_ATTRS')) {
      const keysLength = packet.readLengthCodedNumber(encoding);
      const keysEnd = packet.offset + keysLength;
      const attrs = {};
      while (packet.offset < keysEnd) {
        attrs[packet.readLengthCodedString(encoding)] =
          packet.readLengthCodedString(encoding);
      }
      args.connectAttributes = attrs;
    }
    return args;
  }
}

module.exports = HandshakeResponse;
</file>

<file path="lib/packets/handshake.js">
'use strict';

const Packet = require('../packets/packet');
const ClientConstants = require('../constants/client.js');

// https://dev.mysql.com/doc/internals/en/connection-phase-packets.html#packet-Protocol::Handshake

class Handshake {
  constructor(args) {
    this.protocolVersion = args.protocolVersion;
    this.serverVersion = args.serverVersion;
    this.capabilityFlags = args.capabilityFlags;
    this.connectionId = args.connectionId;
    this.authPluginData1 = args.authPluginData1;
    this.authPluginData2 = args.authPluginData2;
    this.characterSet = args.characterSet;
    this.statusFlags = args.statusFlags;
    this.authPluginName = args.authPluginName;
  }

  setScrambleData(cb) {
    require('crypto').randomBytes(20, (err, data) => {
      if (err) {
        cb(err);
        return;
      }
      this.authPluginData1 = data.slice(0, 8);
      this.authPluginData2 = data.slice(8, 20);
      cb();
    });
  }

  toPacket(sequenceId) {
    const length = 68 + Buffer.byteLength(this.serverVersion, 'utf8');
    const buffer = Buffer.alloc(length + 4, 0); // zero fill, 10 bytes filler later needs to contain zeros
    const packet = new Packet(sequenceId, buffer, 0, length + 4);
    packet.offset = 4;
    packet.writeInt8(this.protocolVersion);
    packet.writeString(this.serverVersion, 'cesu8');
    packet.writeInt8(0);
    packet.writeInt32(this.connectionId);
    packet.writeBuffer(this.authPluginData1);
    packet.writeInt8(0);
    const capabilityFlagsBuffer = Buffer.allocUnsafe(4);
    capabilityFlagsBuffer.writeUInt32LE(this.capabilityFlags, 0);
    packet.writeBuffer(capabilityFlagsBuffer.slice(0, 2));
    packet.writeInt8(this.characterSet);
    packet.writeInt16(this.statusFlags);
    packet.writeBuffer(capabilityFlagsBuffer.slice(2, 4));
    packet.writeInt8(21); // authPluginDataLength
    packet.skip(10);
    packet.writeBuffer(this.authPluginData2);
    packet.writeInt8(0);
    packet.writeString('mysql_native_password', 'latin1');
    packet.writeInt8(0);
    return packet;
  }

  static fromPacket(packet) {
    const args = {};
    args.protocolVersion = packet.readInt8();
    args.serverVersion = packet.readNullTerminatedString('cesu8');
    args.connectionId = packet.readInt32();
    args.authPluginData1 = packet.readBuffer(8);
    packet.skip(1);
    const capabilityFlagsBuffer = Buffer.allocUnsafe(4);
    capabilityFlagsBuffer[0] = packet.readInt8();
    capabilityFlagsBuffer[1] = packet.readInt8();
    if (packet.haveMoreData()) {
      args.characterSet = packet.readInt8();
      args.statusFlags = packet.readInt16();
      // upper 2 bytes
      capabilityFlagsBuffer[2] = packet.readInt8();
      capabilityFlagsBuffer[3] = packet.readInt8();
      args.capabilityFlags = capabilityFlagsBuffer.readUInt32LE(0);
      if (args.capabilityFlags & ClientConstants.PLUGIN_AUTH) {
        args.authPluginDataLength = packet.readInt8();
      } else {
        args.authPluginDataLength = 0;
        packet.skip(1);
      }
      packet.skip(10);
    } else {
      args.capabilityFlags = capabilityFlagsBuffer.readUInt16LE(0);
    }

    const isSecureConnection =
      args.capabilityFlags & ClientConstants.SECURE_CONNECTION;
    if (isSecureConnection) {
      const authPluginDataLength = args.authPluginDataLength;
      if (authPluginDataLength === 0) {
        // for Secure Password Authentication
        args.authPluginDataLength = 20;
        args.authPluginData2 = packet.readBuffer(12);
        packet.skip(1);
      } else {
        // length > 0
        // for Custom Auth Plugin (PLUGIN_AUTH)
        const len = Math.max(13, authPluginDataLength - 8);
        args.authPluginData2 = packet.readBuffer(len);
      }
    }

    if (args.capabilityFlags & ClientConstants.PLUGIN_AUTH) {
      args.authPluginName = packet.readNullTerminatedString('ascii');
    }

    return new Handshake(args);
  }
}

module.exports = Handshake;
</file>

<file path="lib/packets/index.js">
// This file was modified by Oracle on June 1, 2021.
// A utility method was introduced to generate an Error instance from a
// binary server packet.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

// This file was modified by Oracle on September 21, 2021.
// The new AuthNextFactor packet is now available.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const process = require('process');

const AuthNextFactor = require('./auth_next_factor');
const AuthSwitchRequest = require('./auth_switch_request');
const AuthSwitchRequestMoreData = require('./auth_switch_request_more_data');
const AuthSwitchResponse = require('./auth_switch_response');
const BinaryRow = require('./binary_row');
const BinlogDump = require('./binlog_dump');
const ChangeUser = require('./change_user');
const CloseStatement = require('./close_statement');
const ColumnDefinition = require('./column_definition');
const Execute = require('./execute');
const Handshake = require('./handshake');
const HandshakeResponse = require('./handshake_response');
const PrepareStatement = require('./prepare_statement');
const PreparedStatementHeader = require('./prepared_statement_header');
const Query = require('./query');
const RegisterSlave = require('./register_slave');
const ResultSetHeader = require('./resultset_header');
const SSLRequest = require('./ssl_request');
const TextRow = require('./text_row');

const ctorMap = {
  AuthNextFactor,
  AuthSwitchRequest,
  AuthSwitchRequestMoreData,
  AuthSwitchResponse,
  BinaryRow,
  BinlogDump,
  ChangeUser,
  CloseStatement,
  ColumnDefinition,
  Execute,
  Handshake,
  HandshakeResponse,
  PrepareStatement,
  PreparedStatementHeader,
  Query,
  RegisterSlave,
  ResultSetHeader,
  SSLRequest,
  TextRow,
};
Object.entries(ctorMap).forEach(([name, ctor]) => {
  module.exports[name] = ctor;
  // monkey-patch it to include name if debug is on
  if (process.env.NODE_DEBUG) {
    if (ctor.prototype.toPacket) {
      const old = ctor.prototype.toPacket;
      ctor.prototype.toPacket = function () {
        const p = old.call(this);
        p._name = name;
        return p;
      };
    }
  }
});

// simple packets:
const Packet = require('./packet');
exports.Packet = Packet;

class OK {
  static toPacket(args, encoding) {
    args = args || {};
    const affectedRows = args.affectedRows || 0;
    const insertId = args.insertId || 0;
    const serverStatus = args.serverStatus || 0;
    const warningCount = args.warningCount || 0;
    const message = args.message || '';

    let length = 9 + Packet.lengthCodedNumberLength(affectedRows);
    length += Packet.lengthCodedNumberLength(insertId);

    const buffer = Buffer.allocUnsafe(length);
    const packet = new Packet(0, buffer, 0, length);
    packet.offset = 4;
    packet.writeInt8(0);
    packet.writeLengthCodedNumber(affectedRows);
    packet.writeLengthCodedNumber(insertId);
    packet.writeInt16(serverStatus);
    packet.writeInt16(warningCount);
    packet.writeString(message, encoding);
    packet._name = 'OK';
    return packet;
  }
}

exports.OK = OK;

// warnings, statusFlags
class EOF {
  static toPacket(warnings, statusFlags) {
    if (typeof warnings === 'undefined') {
      warnings = 0;
    }
    if (typeof statusFlags === 'undefined') {
      statusFlags = 0;
    }
    const packet = new Packet(0, Buffer.allocUnsafe(9), 0, 9);
    packet.offset = 4;
    packet.writeInt8(0xfe);
    packet.writeInt16(warnings);
    packet.writeInt16(statusFlags);
    packet._name = 'EOF';
    return packet;
  }
}

exports.EOF = EOF;

class Error {
  static toPacket(args, encoding) {
    const length = 13 + Buffer.byteLength(args.message, 'utf8');
    const packet = new Packet(0, Buffer.allocUnsafe(length), 0, length);
    packet.offset = 4;
    packet.writeInt8(0xff);
    packet.writeInt16(args.code);
    // TODO: sql state parameter
    packet.writeString('#_____', encoding);
    packet.writeString(args.message, encoding);
    packet._name = 'Error';
    return packet;
  }

  static fromPacket(packet) {
    packet.readInt8(); // marker
    const code = packet.readInt16();
    packet.readString(1, 'ascii'); // sql state marker
    // The SQL state of the ERR_Packet which is always 5 bytes long.
    // https://dev.mysql.com/doc/dev/mysql-server/8.0.11/page_protocol_basic_dt_strings.html#sect_protocol_basic_dt_string_fix
    packet.readString(5, 'ascii'); // sql state (ignore for now)
    const message = packet.readNullTerminatedString('utf8');
    const error = new Error();
    error.message = message;
    error.code = code;
    return error;
  }
}

exports.Error = Error;
</file>

<file path="lib/packets/packet.js">
// This file was modified by Oracle on June 1, 2021.
// A comment describing some changes in the strict default SQL mode regarding
// non-standard dates was introduced.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const ErrorCodeToName = require('../constants/errors.js');
const NativeBuffer = require('buffer').Buffer;
const Long = require('long');
const StringParser = require('../parsers/string.js');
const Types = require('../constants/types.js');
const INVALID_DATE = new Date(NaN);

// this is nearly duplicate of previous function so generated code is not slower
// due to "if (dateStrings)" branching
const pad = '000000000000';
function leftPad(num, value) {
  const s = value.toString();
  // if we don't need to pad
  if (s.length >= num) {
    return s;
  }
  return (pad + s).slice(-num);
}

// The whole reason parse* function below exist
// is because String creation is relatively expensive (at least with V8), and if we have
// a buffer with "12345" content ideally we would like to bypass intermediate
// "12345" string creation and directly build 12345 number out of
// <Buffer 31 32 33 34 35> data.
// In my benchmarks the difference is ~25M 8-digit numbers per second vs
// 4.5 M using Number(packet.readLengthCodedString())
// not used when size is close to max precision as series of *10 accumulate error
// and approximate result mihgt be diffreent from (approximate as well) Number(bigNumStringValue))
// In the futire node version if speed difference is smaller parse* functions might be removed
// don't consider them as Packet public API

const minus = '-'.charCodeAt(0);
const plus = '+'.charCodeAt(0);

// TODO: handle E notation
const dot = '.'.charCodeAt(0);
const exponent = 'e'.charCodeAt(0);
const exponentCapital = 'E'.charCodeAt(0);

class Packet {
  constructor(id, buffer, start, end) {
    // hot path, enable checks when testing only
    // if (!Buffer.isBuffer(buffer) || typeof start == 'undefined' || typeof end == 'undefined')
    //  throw new Error('invalid packet');
    this.sequenceId = id;
    this.numPackets = 1;
    this.buffer = buffer;
    this.start = start;
    this.offset = start + 4;
    this.end = end;
  }

  // ==============================
  // readers
  // ==============================
  reset() {
    this.offset = this.start + 4;
  }

  length() {
    return this.end - this.start;
  }

  slice() {
    return this.buffer.slice(this.start, this.end);
  }

  dump() {
    // eslint-disable-next-line no-console
    console.log(
      [this.buffer.asciiSlice(this.start, this.end)],
      this.buffer.slice(this.start, this.end),
      this.length(),
      this.sequenceId
    );
  }

  haveMoreData() {
    return this.end > this.offset;
  }

  skip(num) {
    this.offset += num;
  }

  readInt8() {
    return this.buffer[this.offset++];
  }

  readInt16() {
    this.offset += 2;
    return this.buffer.readUInt16LE(this.offset - 2);
  }

  readInt24() {
    return this.readInt16() + (this.readInt8() << 16);
  }

  readInt32() {
    this.offset += 4;
    return this.buffer.readUInt32LE(this.offset - 4);
  }

  readSInt8() {
    return this.buffer.readInt8(this.offset++);
  }

  readSInt16() {
    this.offset += 2;
    return this.buffer.readInt16LE(this.offset - 2);
  }

  readSInt32() {
    this.offset += 4;
    return this.buffer.readInt32LE(this.offset - 4);
  }

  readInt64JSNumber() {
    const word0 = this.readInt32();
    const word1 = this.readInt32();
    const l = new Long(word0, word1, true);
    return l.toNumber();
  }

  readSInt64JSNumber() {
    const word0 = this.readInt32();
    const word1 = this.readInt32();
    if (!(word1 & 0x80000000)) {
      return word0 + 0x100000000 * word1;
    }
    const l = new Long(word0, word1, false);
    return l.toNumber();
  }

  readInt64String() {
    const word0 = this.readInt32();
    const word1 = this.readInt32();
    const res = new Long(word0, word1, true);
    return res.toString();
  }

  readSInt64String() {
    const word0 = this.readInt32();
    const word1 = this.readInt32();
    const res = new Long(word0, word1, false);
    return res.toString();
  }

  readInt64() {
    const word0 = this.readInt32();
    const word1 = this.readInt32();
    let res = new Long(word0, word1, true);
    const resNumber = res.toNumber();
    const resString = res.toString();
    res = resNumber.toString() === resString ? resNumber : resString;
    return res;
  }

  readSInt64() {
    const word0 = this.readInt32();
    const word1 = this.readInt32();
    let res = new Long(word0, word1, false);
    const resNumber = res.toNumber();
    const resString = res.toString();
    res = resNumber.toString() === resString ? resNumber : resString;
    return res;
  }

  isEOF() {
    return this.buffer[this.offset] === 0xfe && this.length() < 13;
  }

  eofStatusFlags() {
    return this.buffer.readInt16LE(this.offset + 3);
  }

  eofWarningCount() {
    return this.buffer.readInt16LE(this.offset + 1);
  }

  readLengthCodedNumber(bigNumberStrings, signed) {
    const byte1 = this.buffer[this.offset++];
    if (byte1 < 251) {
      return byte1;
    }
    return this.readLengthCodedNumberExt(byte1, bigNumberStrings, signed);
  }

  readLengthCodedNumberSigned(bigNumberStrings) {
    return this.readLengthCodedNumber(bigNumberStrings, true);
  }

  readLengthCodedNumberExt(tag, bigNumberStrings, signed) {
    let word0, word1;
    let res;
    if (tag === 0xfb) {
      return null;
    }
    if (tag === 0xfc) {
      return this.readInt8() + (this.readInt8() << 8);
    }
    if (tag === 0xfd) {
      return this.readInt8() + (this.readInt8() << 8) + (this.readInt8() << 16);
    }
    if (tag === 0xfe) {
      // TODO: check version
      // Up to MySQL 3.22, 0xfe was followed by a 4-byte integer.
      word0 = this.readInt32();
      word1 = this.readInt32();
      if (word1 === 0) {
        return word0; // don't convert to float if possible
      }
      if (word1 < 2097152) {
        // max exact float point int, 2^52 / 2^32
        return word1 * 0x100000000 + word0;
      }
      res = new Long(word0, word1, !signed); // Long need unsigned
      const resNumber = res.toNumber();
      const resString = res.toString();
      res = resNumber.toString() === resString ? resNumber : resString;
      return bigNumberStrings ? resString : res;
    }
    // eslint-disable-next-line no-console
    console.trace();
    throw new Error(`Should not reach here: ${tag}`);
  }

  readFloat() {
    const res = this.buffer.readFloatLE(this.offset);
    this.offset += 4;
    return res;
  }

  readDouble() {
    const res = this.buffer.readDoubleLE(this.offset);
    this.offset += 8;
    return res;
  }

  readBuffer(len) {
    if (typeof len === 'undefined') {
      len = this.end - this.offset;
    }
    this.offset += len;
    return this.buffer.slice(this.offset - len, this.offset);
  }

  // DATE, DATETIME and TIMESTAMP
  readDateTime(timezone) {
    if (!timezone || timezone === 'Z' || timezone === 'local') {
      const length = this.readInt8();
      if (length === 0xfb) {
        return null;
      }
      let y = 0;
      let m = 0;
      let d = 0;
      let H = 0;
      let M = 0;
      let S = 0;
      let ms = 0;
      if (length > 3) {
        y = this.readInt16();
        m = this.readInt8();
        d = this.readInt8();
      }
      if (length > 6) {
        H = this.readInt8();
        M = this.readInt8();
        S = this.readInt8();
      }
      if (length > 10) {
        ms = this.readInt32() / 1000;
      }
      // NO_ZERO_DATE mode and NO_ZERO_IN_DATE mode are part of the strict
      // default SQL mode used by MySQL 8.0. This means that non-standard
      // dates like '0000-00-00' become NULL. For older versions and other
      // possible MySQL flavours we still need to account for the
      // non-standard behaviour.
      if (y + m + d + H + M + S + ms === 0) {
        return INVALID_DATE;
      }
      if (timezone === 'Z') {
        return new Date(Date.UTC(y, m - 1, d, H, M, S, ms));
      }
      return new Date(y, m - 1, d, H, M, S, ms);
    }
    let str = this.readDateTimeString(6, 'T', null);
    if (str.length === 10) {
      str += 'T00:00:00';
    }
    return new Date(str + timezone);
  }

  readDateTimeString(decimals, timeSep, columnType) {
    const length = this.readInt8();
    let y = 0;
    let m = 0;
    let d = 0;
    let H = 0;
    let M = 0;
    let S = 0;
    let ms = 0;
    let str;
    if (length > 3) {
      y = this.readInt16();
      m = this.readInt8();
      d = this.readInt8();
      str = [leftPad(4, y), leftPad(2, m), leftPad(2, d)].join('-');
    }
    if (length > 6) {
      H = this.readInt8();
      M = this.readInt8();
      S = this.readInt8();
      str += `${timeSep || ' '}${[
        leftPad(2, H),
        leftPad(2, M),
        leftPad(2, S),
      ].join(':')}`;
    } else if (columnType === Types.DATETIME) {
      str += ' 00:00:00';
    }
    if (length > 10) {
      ms = this.readInt32();
      str += '.';
      if (decimals) {
        ms = leftPad(6, ms);
        if (ms.length > decimals) {
          ms = ms.substring(0, decimals); // rounding is done at the MySQL side, only 0 are here
        }
      }
      str += ms;
    }
    return str;
  }

  // TIME - value as a string, Can be negative
  readTimeString(convertTtoMs) {
    const length = this.readInt8();
    if (length === 0) {
      return '00:00:00';
    }
    const sign = this.readInt8() ? -1 : 1; // 'isNegative' flag byte
    let d = 0;
    let H = 0;
    let M = 0;
    let S = 0;
    let ms = 0;
    if (length > 6) {
      d = this.readInt32();
      H = this.readInt8();
      M = this.readInt8();
      S = this.readInt8();
    }
    if (length > 10) {
      ms = this.readInt32();
    }
    if (convertTtoMs) {
      H += d * 24;
      M += H * 60;
      S += M * 60;
      ms += S * 1000;
      ms *= sign;
      return ms;
    }
    // Format follows mySQL TIME format ([-][h]hh:mm:ss[.u[u[u[u[u[u]]]]]])
    // For positive times below 24 hours, this makes it equal to ISO 8601 times
    return (
      (sign === -1 ? '-' : '') +
      [leftPad(2, d * 24 + H), leftPad(2, M), leftPad(2, S)].join(':') +
      (ms ? `.${ms}`.replace(/0+$/, '') : '')
    );
  }

  readLengthCodedString(encoding) {
    const len = this.readLengthCodedNumber();
    // TODO: check manually first byte here to avoid polymorphic return type?
    if (len === null) {
      return null;
    }
    this.offset += len;
    // TODO: Use characterSetCode to get proper encoding
    // https://github.com/sidorares/node-mysql2/pull/374
    return StringParser.decode(
      this.buffer,
      encoding,
      this.offset - len,
      this.offset
    );
  }

  readLengthCodedBuffer() {
    const len = this.readLengthCodedNumber();
    if (len === null) {
      return null;
    }
    return this.readBuffer(len);
  }

  readNullTerminatedString(encoding) {
    const start = this.offset;
    let end = this.offset;
    while (this.buffer[end]) {
      end = end + 1; // TODO: handle OOB check
    }
    this.offset = end + 1;
    return StringParser.decode(this.buffer, encoding, start, end);
  }

  // TODO reuse?
  readString(len, encoding) {
    if (typeof len === 'string' && typeof encoding === 'undefined') {
      encoding = len;
      len = undefined;
    }
    if (typeof len === 'undefined') {
      len = this.end - this.offset;
    }
    this.offset += len;
    return StringParser.decode(
      this.buffer,
      encoding,
      this.offset - len,
      this.offset
    );
  }

  parseInt(len, supportBigNumbers) {
    if (len === null) {
      return null;
    }
    if (len >= 14 && !supportBigNumbers) {
      const s = this.buffer.toString('ascii', this.offset, this.offset + len);
      this.offset += len;
      return Number(s);
    }
    let result = 0;
    const start = this.offset;
    const end = this.offset + len;
    let sign = 1;
    if (len === 0) {
      return 0; // TODO: assert? exception?
    }
    if (this.buffer[this.offset] === minus) {
      this.offset++;
      sign = -1;
    }
    // max precise int is 9007199254740992
    let str;
    const numDigits = end - this.offset;
    if (supportBigNumbers) {
      if (numDigits >= 15) {
        str = this.readString(end - this.offset, 'binary');
        result = parseInt(str, 10);
        if (result.toString() === str) {
          return sign * result;
        }
        return sign === -1 ? `-${str}` : str;
      }
      if (numDigits > 16) {
        str = this.readString(end - this.offset);
        return sign === -1 ? `-${str}` : str;
      }
    }
    if (this.buffer[this.offset] === plus) {
      this.offset++; // just ignore
    }
    while (this.offset < end) {
      result *= 10;
      result += this.buffer[this.offset] - 48;
      this.offset++;
    }
    const num = result * sign;
    if (!supportBigNumbers) {
      return num;
    }
    str = this.buffer.toString('ascii', start, end);
    if (num.toString() === str) {
      return num;
    }
    return str;
  }

  // note that if value of inputNumberAsString is bigger than MAX_SAFE_INTEGER
  // ( or smaller than MIN_SAFE_INTEGER ) the parseIntNoBigCheck result might be
  // different from what you would get from Number(inputNumberAsString)
  // String(parseIntNoBigCheck) <> String(Number(inputNumberAsString)) <> inputNumberAsString
  parseIntNoBigCheck(len) {
    if (len === null) {
      return null;
    }
    let result = 0;
    const end = this.offset + len;
    let sign = 1;
    if (len === 0) {
      return 0; // TODO: assert? exception?
    }
    if (this.buffer[this.offset] === minus) {
      this.offset++;
      sign = -1;
    }
    if (this.buffer[this.offset] === plus) {
      this.offset++; // just ignore
    }
    while (this.offset < end) {
      result *= 10;
      result += this.buffer[this.offset] - 48;
      this.offset++;
    }
    return result * sign;
  }

  // copy-paste from https://github.com/mysqljs/mysql/blob/master/lib/protocol/Parser.js
  parseGeometryValue() {
    const buffer = this.readLengthCodedBuffer();
    let offset = 4;
    if (buffer === null || !buffer.length) {
      return null;
    }
    function parseGeometry() {
      let x, y, i, j, numPoints, line;
      let result = null;
      const byteOrder = buffer.readUInt8(offset);
      offset += 1;
      const wkbType = byteOrder
        ? buffer.readUInt32LE(offset)
        : buffer.readUInt32BE(offset);
      offset += 4;
      switch (wkbType) {
        case 1: // WKBPoint
          x = byteOrder
            ? buffer.readDoubleLE(offset)
            : buffer.readDoubleBE(offset);
          offset += 8;
          y = byteOrder
            ? buffer.readDoubleLE(offset)
            : buffer.readDoubleBE(offset);
          offset += 8;
          result = { x: x, y: y };
          break;
        case 2: // WKBLineString
          numPoints = byteOrder
            ? buffer.readUInt32LE(offset)
            : buffer.readUInt32BE(offset);
          offset += 4;
          result = [];
          for (i = numPoints; i > 0; i--) {
            x = byteOrder
              ? buffer.readDoubleLE(offset)
              : buffer.readDoubleBE(offset);
            offset += 8;
            y = byteOrder
              ? buffer.readDoubleLE(offset)
              : buffer.readDoubleBE(offset);
            offset += 8;
            result.push({ x: x, y: y });
          }
          break;
        case 3: // WKBPolygon
          // eslint-disable-next-line no-case-declarations
          const numRings = byteOrder
            ? buffer.readUInt32LE(offset)
            : buffer.readUInt32BE(offset);
          offset += 4;
          result = [];
          for (i = numRings; i > 0; i--) {
            numPoints = byteOrder
              ? buffer.readUInt32LE(offset)
              : buffer.readUInt32BE(offset);
            offset += 4;
            line = [];
            for (j = numPoints; j > 0; j--) {
              x = byteOrder
                ? buffer.readDoubleLE(offset)
                : buffer.readDoubleBE(offset);
              offset += 8;
              y = byteOrder
                ? buffer.readDoubleLE(offset)
                : buffer.readDoubleBE(offset);
              offset += 8;
              line.push({ x: x, y: y });
            }
            result.push(line);
          }
          break;
        case 4: // WKBMultiPoint
        case 5: // WKBMultiLineString
        case 6: // WKBMultiPolygon
        case 7: // WKBGeometryCollection
          // eslint-disable-next-line no-case-declarations
          const num = byteOrder
            ? buffer.readUInt32LE(offset)
            : buffer.readUInt32BE(offset);
          offset += 4;
          result = [];
          for (i = num; i > 0; i--) {
            result.push(parseGeometry());
          }
          break;
      }
      return result;
    }
    return parseGeometry();
  }

  parseVector() {
    const bufLen = this.readLengthCodedNumber();
    const vectorEnd = this.offset + bufLen;
    const result = [];
    while (this.offset < vectorEnd && this.offset < this.end) {
      result.push(this.readFloat());
    }
    return result;
  }

  parseDate(timezone) {
    const strLen = this.readLengthCodedNumber();
    if (strLen === null) {
      return null;
    }
    if (strLen !== 10) {
      // we expect only YYYY-MM-DD here.
      // if for some reason it's not the case return invalid date
      return new Date(NaN);
    }
    const y = this.parseInt(4);
    this.offset++; // -
    const m = this.parseInt(2);
    this.offset++; // -
    const d = this.parseInt(2);
    if (!timezone || timezone === 'local') {
      return new Date(y, m - 1, d);
    }
    if (timezone === 'Z') {
      return new Date(Date.UTC(y, m - 1, d));
    }
    return new Date(
      `${leftPad(4, y)}-${leftPad(2, m)}-${leftPad(2, d)}T00:00:00${timezone}`
    );
  }

  parseDateTime(timezone) {
    const str = this.readLengthCodedString('binary');
    if (str === null) {
      return null;
    }
    if (!timezone || timezone === 'local') {
      return new Date(str);
    }
    return new Date(`${str}${timezone}`);
  }

  parseFloat(len) {
    if (len === null) {
      return null;
    }
    let result = 0;
    const end = this.offset + len;
    let factor = 1;
    let pastDot = false;
    let charCode = 0;
    if (len === 0) {
      return 0; // TODO: assert? exception?
    }
    if (this.buffer[this.offset] === minus) {
      this.offset++;
      factor = -1;
    }
    if (this.buffer[this.offset] === plus) {
      this.offset++; // just ignore
    }
    while (this.offset < end) {
      charCode = this.buffer[this.offset];
      if (charCode === dot) {
        pastDot = true;
        this.offset++;
      } else if (charCode === exponent || charCode === exponentCapital) {
        this.offset++;
        const exponentValue = this.parseInt(end - this.offset);
        return (result / factor) * Math.pow(10, exponentValue);
      } else {
        result *= 10;
        result += this.buffer[this.offset] - 48;
        this.offset++;
        if (pastDot) {
          factor = factor * 10;
        }
      }
    }
    return result / factor;
  }

  parseLengthCodedIntNoBigCheck() {
    return this.parseIntNoBigCheck(this.readLengthCodedNumber());
  }

  parseLengthCodedInt(supportBigNumbers) {
    return this.parseInt(this.readLengthCodedNumber(), supportBigNumbers);
  }

  parseLengthCodedIntString() {
    return this.readLengthCodedString('binary');
  }

  parseLengthCodedFloat() {
    return this.parseFloat(this.readLengthCodedNumber());
  }

  peekByte() {
    return this.buffer[this.offset];
  }

  // OxFE is often used as "Alt" flag - not ok, not error.
  // For example, it's first byte of AuthSwitchRequest
  isAlt() {
    return this.peekByte() === 0xfe;
  }

  isError() {
    return this.peekByte() === 0xff;
  }

  asError(encoding) {
    this.reset();
    this.readInt8(); // fieldCount
    const errorCode = this.readInt16();
    let sqlState = '';
    if (this.buffer[this.offset] === 0x23) {
      this.skip(1);
      sqlState = this.readBuffer(5).toString();
    }
    const message = this.readString(undefined, encoding);
    const err = new Error(message);
    err.code = ErrorCodeToName[errorCode];
    err.errno = errorCode;
    err.sqlState = sqlState;
    err.sqlMessage = message;
    return err;
  }

  writeInt32(n) {
    this.buffer.writeUInt32LE(n, this.offset);
    this.offset += 4;
  }

  writeInt24(n) {
    this.writeInt8(n & 0xff);
    this.writeInt16(n >> 8);
  }

  writeInt16(n) {
    this.buffer.writeUInt16LE(n, this.offset);
    this.offset += 2;
  }

  writeInt8(n) {
    this.buffer.writeUInt8(n, this.offset);
    this.offset++;
  }

  writeDouble(n) {
    this.buffer.writeDoubleLE(n, this.offset);
    this.offset += 8;
  }

  writeBuffer(b) {
    b.copy(this.buffer, this.offset);
    this.offset += b.length;
  }

  writeNull() {
    this.buffer[this.offset] = 0xfb;
    this.offset++;
  }

  // TODO: refactor following three?
  writeNullTerminatedString(s, encoding) {
    const buf = StringParser.encode(s, encoding);
    this.buffer.length && buf.copy(this.buffer, this.offset);
    this.offset += buf.length;
    this.writeInt8(0);
  }

  writeString(s, encoding) {
    if (s === null) {
      this.writeInt8(0xfb);
      return;
    }
    if (s.length === 0) {
      return;
    }
    // const bytes = Buffer.byteLength(s, 'utf8');
    // this.buffer.write(s, this.offset, bytes, 'utf8');
    // this.offset += bytes;
    const buf = StringParser.encode(s, encoding);
    this.buffer.length && buf.copy(this.buffer, this.offset);
    this.offset += buf.length;
  }

  writeLengthCodedString(s, encoding) {
    const buf = StringParser.encode(s, encoding);
    this.writeLengthCodedNumber(buf.length);
    this.buffer.length && buf.copy(this.buffer, this.offset);
    this.offset += buf.length;
  }

  writeLengthCodedBuffer(b) {
    this.writeLengthCodedNumber(b.length);
    b.copy(this.buffer, this.offset);
    this.offset += b.length;
  }

  writeLengthCodedNumber(n) {
    if (n < 0xfb) {
      return this.writeInt8(n);
    }
    if (n < 0xffff) {
      this.writeInt8(0xfc);
      return this.writeInt16(n);
    }
    if (n < 0xffffff) {
      this.writeInt8(0xfd);
      return this.writeInt24(n);
    }
    if (n === null) {
      return this.writeInt8(0xfb);
    }
    // TODO: check that n is out of int precision
    this.writeInt8(0xfe);
    this.buffer.writeUInt32LE(n, this.offset);
    this.offset += 4;
    this.buffer.writeUInt32LE(n >> 32, this.offset);
    this.offset += 4;
    return this.offset;
  }

  writeDate(d, timezone) {
    this.buffer.writeUInt8(11, this.offset);
    if (!timezone || timezone === 'local') {
      this.buffer.writeUInt16LE(d.getFullYear(), this.offset + 1);
      this.buffer.writeUInt8(d.getMonth() + 1, this.offset + 3);
      this.buffer.writeUInt8(d.getDate(), this.offset + 4);
      this.buffer.writeUInt8(d.getHours(), this.offset + 5);
      this.buffer.writeUInt8(d.getMinutes(), this.offset + 6);
      this.buffer.writeUInt8(d.getSeconds(), this.offset + 7);
      this.buffer.writeUInt32LE(d.getMilliseconds() * 1000, this.offset + 8);
    } else {
      if (timezone !== 'Z') {
        const offset =
          (timezone[0] === '-' ? -1 : 1) *
          (parseInt(timezone.substring(1, 3), 10) * 60 +
            parseInt(timezone.substring(4), 10));
        if (offset !== 0) {
          d = new Date(d.getTime() + 60000 * offset);
        }
      }
      this.buffer.writeUInt16LE(d.getUTCFullYear(), this.offset + 1);
      this.buffer.writeUInt8(d.getUTCMonth() + 1, this.offset + 3);
      this.buffer.writeUInt8(d.getUTCDate(), this.offset + 4);
      this.buffer.writeUInt8(d.getUTCHours(), this.offset + 5);
      this.buffer.writeUInt8(d.getUTCMinutes(), this.offset + 6);
      this.buffer.writeUInt8(d.getUTCSeconds(), this.offset + 7);
      this.buffer.writeUInt32LE(d.getUTCMilliseconds() * 1000, this.offset + 8);
    }
    this.offset += 12;
  }

  writeHeader(sequenceId) {
    const offset = this.offset;
    this.offset = 0;
    this.writeInt24(this.buffer.length - 4);
    this.writeInt8(sequenceId);
    this.offset = offset;
  }

  clone() {
    return new Packet(this.sequenceId, this.buffer, this.start, this.end);
  }

  type() {
    if (this.isEOF()) {
      return 'EOF';
    }
    if (this.isError()) {
      return 'Error';
    }
    if (this.buffer[this.offset] === 0) {
      return 'maybeOK'; // could be other packet types as well
    }
    return '';
  }

  static lengthCodedNumberLength(n) {
    if (n < 0xfb) {
      return 1;
    }
    if (n < 0xffff) {
      return 3;
    }
    if (n < 0xffffff) {
      return 5;
    }
    return 9;
  }

  static lengthCodedStringLength(str, encoding) {
    const buf = StringParser.encode(str, encoding);
    const slen = buf.length;
    return Packet.lengthCodedNumberLength(slen) + slen;
  }

  static MockBuffer() {
    const noop = function () {};
    const res = Buffer.alloc(0);
    for (const op in NativeBuffer.prototype) {
      if (typeof res[op] === 'function') {
        res[op] = noop;
      }
    }
    return res;
  }
}

module.exports = Packet;
</file>

<file path="lib/packets/prepare_statement.js">
'use strict';

const Packet = require('../packets/packet');
const CommandCodes = require('../constants/commands');
const StringParser = require('../parsers/string.js');
const CharsetToEncoding = require('../constants/charset_encodings.js');

class PrepareStatement {
  constructor(sql, charsetNumber) {
    this.query = sql;
    this.charsetNumber = charsetNumber;
    this.encoding = CharsetToEncoding[charsetNumber];
  }

  toPacket() {
    const buf = StringParser.encode(this.query, this.encoding);
    const length = 5 + buf.length;
    const buffer = Buffer.allocUnsafe(length);
    const packet = new Packet(0, buffer, 0, length);
    packet.offset = 4;
    packet.writeInt8(CommandCodes.STMT_PREPARE);
    packet.writeBuffer(buf);
    return packet;
  }
}

module.exports = PrepareStatement;
</file>

<file path="lib/packets/prepared_statement_header.js">
'use strict';

class PreparedStatementHeader {
  constructor(packet) {
    packet.skip(1); // should be 0
    this.id = packet.readInt32();
    this.fieldCount = packet.readInt16();
    this.parameterCount = packet.readInt16();
    packet.skip(1); // should be 0
    this.warningCount = packet.readInt16();
  }
}

// TODO: toPacket

module.exports = PreparedStatementHeader;
</file>

<file path="lib/packets/query.js">
'use strict';

const Packet = require('../packets/packet.js');
const CommandCode = require('../constants/commands.js');
const StringParser = require('../parsers/string.js');
const CharsetToEncoding = require('../constants/charset_encodings.js');

class Query {
  constructor(sql, charsetNumber) {
    this.query = sql;
    this.charsetNumber = charsetNumber;
    this.encoding = CharsetToEncoding[charsetNumber];
  }

  toPacket() {
    const buf = StringParser.encode(this.query, this.encoding);
    const length = 5 + buf.length;
    const buffer = Buffer.allocUnsafe(length);
    const packet = new Packet(0, buffer, 0, length);
    packet.offset = 4;
    packet.writeInt8(CommandCode.QUERY);
    packet.writeBuffer(buf);
    return packet;
  }
}

module.exports = Query;
</file>

<file path="lib/packets/register_slave.js">
'use strict';

// http://dev.mysql.com/doc/internals/en/com-register-slave.html
// note that documentation is incorrect, for example command code is actually 0x15 but documented as 0x14

const Packet = require('../packets/packet');
const CommandCodes = require('../constants/commands');

class RegisterSlave {
  constructor(opts) {
    this.serverId = opts.serverId || 0;
    this.slaveHostname = opts.slaveHostname || '';
    this.slaveUser = opts.slaveUser || '';
    this.slavePassword = opts.slavePassword || '';
    this.slavePort = opts.slavePort || 0;
    this.replicationRank = opts.replicationRank || 0;
    this.masterId = opts.masterId || 0;
  }

  toPacket() {
    const length =
      15 + // TODO: should be ascii?
      Buffer.byteLength(this.slaveHostname, 'utf8') +
      Buffer.byteLength(this.slaveUser, 'utf8') +
      Buffer.byteLength(this.slavePassword, 'utf8') +
      3 +
      4;
    const buffer = Buffer.allocUnsafe(length);
    const packet = new Packet(0, buffer, 0, length);
    packet.offset = 4;
    packet.writeInt8(CommandCodes.REGISTER_SLAVE);
    packet.writeInt32(this.serverId);
    packet.writeInt8(Buffer.byteLength(this.slaveHostname, 'utf8'));
    packet.writeString(this.slaveHostname);
    packet.writeInt8(Buffer.byteLength(this.slaveUser, 'utf8'));
    packet.writeString(this.slaveUser);
    packet.writeInt8(Buffer.byteLength(this.slavePassword, 'utf8'));
    packet.writeString(this.slavePassword);
    packet.writeInt16(this.slavePort);
    packet.writeInt32(this.replicationRank);
    packet.writeInt32(this.masterId);
    return packet;
  }
}

module.exports = RegisterSlave;
</file>

<file path="lib/packets/resultset_header.js">
'use strict';

// TODO: rename to OK packet
// https://dev.mysql.com/doc/internals/en/packet-OK_Packet.html

const Packet = require('./packet.js');
const ClientConstants = require('../constants/client.js');
const ServerSatusFlags = require('../constants/server_status.js');

const EncodingToCharset = require('../constants/encoding_charset.js');
const sessionInfoTypes = require('../constants/session_track.js');

class ResultSetHeader {
  constructor(packet, connection) {
    const bigNumberStrings = connection.config.bigNumberStrings;
    const encoding = connection.serverEncoding;
    const flags = connection._handshakePacket.capabilityFlags;
    const isSet = function (flag) {
      return flags & ClientConstants[flag];
    };
    if (packet.buffer[packet.offset] !== 0) {
      this.fieldCount = packet.readLengthCodedNumber();
      if (this.fieldCount === null) {
        this.infileName = packet.readString(undefined, encoding);
      }
      return;
    }
    this.fieldCount = packet.readInt8(); // skip OK byte
    this.affectedRows = packet.readLengthCodedNumber(bigNumberStrings);
    this.insertId = packet.readLengthCodedNumberSigned(bigNumberStrings);
    this.info = '';
    if (isSet('PROTOCOL_41')) {
      this.serverStatus = packet.readInt16();
      this.warningStatus = packet.readInt16();
    } else if (isSet('TRANSACTIONS')) {
      this.serverStatus = packet.readInt16();
    }
    let stateChanges = null;
    if (isSet('SESSION_TRACK') && packet.offset < packet.end) {
      this.info = packet.readLengthCodedString(encoding);

      if (this.serverStatus && ServerSatusFlags.SERVER_SESSION_STATE_CHANGED) {
        // session change info record - see
        // https://dev.mysql.com/doc/internals/en/packet-OK_Packet.html#cs-sect-packet-ok-sessioninfo
        let len =
          packet.offset < packet.end ? packet.readLengthCodedNumber() : 0;
        const end = packet.offset + len;
        let type, key, stateEnd;
        if (len > 0) {
          stateChanges = {
            systemVariables: {},
            schema: null,
            gtids: [],
            trackStateChange: null,
          };
        }
        while (packet.offset < end) {
          type = packet.readInt8();
          len = packet.readLengthCodedNumber();
          stateEnd = packet.offset + len;
          if (type === sessionInfoTypes.SYSTEM_VARIABLES) {
            key = packet.readLengthCodedString(encoding);
            const val = packet.readLengthCodedString(encoding);
            stateChanges.systemVariables[key] = val;
            if (key === 'character_set_client') {
              const charsetNumber = EncodingToCharset[val];
              // TODO - better api for driver users to handle unknown encodings?
              // maybe custom coverter in the config?
              // For now just ignore character_set_client command if there is
              // no known mapping from reported encoding to a charset code
              if (typeof charsetNumber !== 'undefined') {
                connection.config.charsetNumber = charsetNumber;
              }
            }
          } else if (type === sessionInfoTypes.SCHEMA) {
            key = packet.readLengthCodedString(encoding);
            stateChanges.schema = key;
          } else if (type === sessionInfoTypes.STATE_CHANGE) {
            stateChanges.trackStateChange =
              packet.readLengthCodedString(encoding);
          } else if (type === sessionInfoTypes.STATE_GTIDS) {
            // TODO: find if the first length coded string means anything. Usually comes as empty
            // eslint-disable-next-line no-unused-vars
            const _unknownString = packet.readLengthCodedString(encoding);
            const gtid = packet.readLengthCodedString(encoding);
            stateChanges.gtids = gtid.split(',');
          } else {
            // unsupported session track type. For now just ignore
          }
          packet.offset = stateEnd;
        }
      }
    } else {
      this.info = packet.readString(undefined, encoding);
    }
    if (stateChanges) {
      this.stateChanges = stateChanges;
    }
    const m = this.info.match(/\schanged:\s*(\d+)/i);
    if (m !== null) {
      this.changedRows = parseInt(m[1], 10);
    } else {
      this.changedRows = 0;
    }
  }

  // TODO: should be consistent instance member, but it's just easier here to have just function
  static toPacket(fieldCount, insertId) {
    let length = 4 + Packet.lengthCodedNumberLength(fieldCount);
    if (typeof insertId !== 'undefined') {
      length += Packet.lengthCodedNumberLength(insertId);
    }
    const buffer = Buffer.allocUnsafe(length);
    const packet = new Packet(0, buffer, 0, length);
    packet.offset = 4;
    packet.writeLengthCodedNumber(fieldCount);
    if (typeof insertId !== 'undefined') {
      packet.writeLengthCodedNumber(insertId);
    }
    return packet;
  }
}

module.exports = ResultSetHeader;
</file>

<file path="lib/packets/ssl_request.js">
'use strict';

const ClientConstants = require('../constants/client');
const Packet = require('../packets/packet');

class SSLRequest {
  constructor(flags, charset) {
    this.clientFlags = flags | ClientConstants.SSL;
    this.charset = charset;
  }

  toPacket() {
    const length = 36;
    const buffer = Buffer.allocUnsafe(length);
    const packet = new Packet(0, buffer, 0, length);
    buffer.fill(0);
    packet.offset = 4;
    packet.writeInt32(this.clientFlags);
    packet.writeInt32(0); // max packet size. todo: move to config
    packet.writeInt8(this.charset);
    return packet;
  }
}

module.exports = SSLRequest;
</file>

<file path="lib/packets/text_row.js">
'use strict';

const Packet = require('../packets/packet');

class TextRow {
  constructor(columns) {
    this.columns = columns || [];
  }

  static fromPacket(packet) {
    // packet.reset(); // set offset to starting point?
    const columns = [];
    while (packet.haveMoreData()) {
      columns.push(packet.readLengthCodedString());
    }
    return new TextRow(columns);
  }

  static toPacket(columns, encoding) {
    const sequenceId = 0; // TODO remove, this is calculated now in connecton
    let length = 0;
    columns.forEach((val) => {
      if (val === null || typeof val === 'undefined') {
        ++length;
        return;
      }
      length += Packet.lengthCodedStringLength(val.toString(10), encoding);
    });
    const buffer = Buffer.allocUnsafe(length + 4);
    const packet = new Packet(sequenceId, buffer, 0, length + 4);
    packet.offset = 4;
    columns.forEach((val) => {
      if (val === null) {
        packet.writeNull();
        return;
      }
      if (typeof val === 'undefined') {
        packet.writeInt8(0);
        return;
      }
      packet.writeLengthCodedString(val.toString(10), encoding);
    });
    return packet;
  }
}

module.exports = TextRow;
</file>

<file path="lib/parsers/binary_parser.js">
'use strict';

const FieldFlags = require('../constants/field_flags.js');
const Charsets = require('../constants/charsets.js');
const Types = require('../constants/types.js');
const helpers = require('../helpers');
const genFunc = require('generate-function');
const parserCache = require('./parser_cache.js');
const typeNames = [];
for (const t in Types) {
  typeNames[Types[t]] = t;
}

function readCodeFor(field, config, options, fieldNum) {
  const supportBigNumbers = Boolean(
    options.supportBigNumbers || config.supportBigNumbers
  );
  const bigNumberStrings = Boolean(
    options.bigNumberStrings || config.bigNumberStrings
  );
  const timezone = options.timezone || config.timezone;
  const dateStrings = options.dateStrings || config.dateStrings;
  const unsigned = field.flags & FieldFlags.UNSIGNED;
  switch (field.columnType) {
    case Types.TINY:
      return unsigned ? 'packet.readInt8();' : 'packet.readSInt8();';
    case Types.SHORT:
      return unsigned ? 'packet.readInt16();' : 'packet.readSInt16();';
    case Types.LONG:
    case Types.INT24: // in binary protocol int24 is encoded in 4 bytes int32
      return unsigned ? 'packet.readInt32();' : 'packet.readSInt32();';
    case Types.YEAR:
      return 'packet.readInt16()';
    case Types.FLOAT:
      return 'packet.readFloat();';
    case Types.DOUBLE:
      return 'packet.readDouble();';
    case Types.NULL:
      return 'null;';
    case Types.DATE:
    case Types.DATETIME:
    case Types.TIMESTAMP:
    case Types.NEWDATE:
      if (helpers.typeMatch(field.columnType, dateStrings, Types)) {
        return `packet.readDateTimeString(${parseInt(field.decimals, 10)}, ${null}, ${field.columnType});`;
      }
      return `packet.readDateTime(${helpers.srcEscape(timezone)});`;
    case Types.TIME:
      return 'packet.readTimeString()';
    case Types.DECIMAL:
    case Types.NEWDECIMAL:
      if (config.decimalNumbers) {
        return 'packet.parseLengthCodedFloat();';
      }
      return 'packet.readLengthCodedString("ascii");';
    case Types.GEOMETRY:
      return 'packet.parseGeometryValue();';
    case Types.VECTOR:
      return 'packet.parseVector()';
    case Types.JSON:
      // Since for JSON columns mysql always returns charset 63 (BINARY),
      // we have to handle it according to JSON specs and use "utf8",
      // see https://github.com/sidorares/node-mysql2/issues/409
      return config.jsonStrings
        ? 'packet.readLengthCodedString("utf8")'
        : 'JSON.parse(packet.readLengthCodedString("utf8"));';
    case Types.LONGLONG:
      if (!supportBigNumbers) {
        return unsigned
          ? 'packet.readInt64JSNumber();'
          : 'packet.readSInt64JSNumber();';
      }
      if (bigNumberStrings) {
        return unsigned
          ? 'packet.readInt64String();'
          : 'packet.readSInt64String();';
      }
      return unsigned ? 'packet.readInt64();' : 'packet.readSInt64();';

    default:
      if (field.characterSet === Charsets.BINARY) {
        return 'packet.readLengthCodedBuffer();';
      }
      return `packet.readLengthCodedString(fields[${fieldNum}].encoding)`;
  }
}

function compile(fields, options, config) {
  const parserFn = genFunc();
  const nullBitmapLength = Math.floor((fields.length + 7 + 2) / 8);

  function wrap(field, packet) {
    return {
      type: typeNames[field.columnType],
      length: field.columnLength,
      db: field.schema,
      table: field.table,
      name: field.name,
      string: function (encoding = field.encoding) {
        if (field.columnType === Types.JSON && encoding === field.encoding) {
          // Since for JSON columns mysql always returns charset 63 (BINARY),
          // we have to handle it according to JSON specs and use "utf8",
          // see https://github.com/sidorares/node-mysql2/issues/1661
          console.warn(
            `typeCast: JSON column "${field.name}" is interpreted as BINARY by default, recommended to manually set utf8 encoding: \`field.string("utf8")\``
          );
        }

        if (
          [Types.DATETIME, Types.NEWDATE, Types.TIMESTAMP, Types.DATE].includes(
            field.columnType
          )
        ) {
          return packet.readDateTimeString(parseInt(field.decimals, 10));
        }

        if (field.columnType === Types.TINY) {
          const unsigned = field.flags & FieldFlags.UNSIGNED;

          return String(unsigned ? packet.readInt8() : packet.readSInt8());
        }

        if (field.columnType === Types.TIME) {
          return packet.readTimeString();
        }

        return packet.readLengthCodedString(encoding);
      },
      buffer: function () {
        return packet.readLengthCodedBuffer();
      },
      geometry: function () {
        return packet.parseGeometryValue();
      },
    };
  }

  parserFn('(function(){');
  parserFn('return class BinaryRow {');
  parserFn('constructor() {');
  parserFn('}');

  parserFn('next(packet, fields, options) {');
  if (options.rowsAsArray) {
    parserFn(`const result = new Array(${fields.length});`);
  } else {
    parserFn('const result = {};');
  }

  // Global typeCast
  if (
    typeof config.typeCast === 'function' &&
    typeof options.typeCast !== 'function'
  ) {
    options.typeCast = config.typeCast;
  }

  parserFn('packet.readInt8();'); // status byte
  for (let i = 0; i < nullBitmapLength; ++i) {
    parserFn(`const nullBitmaskByte${i} = packet.readInt8();`);
  }

  let lvalue = '';
  let currentFieldNullBit = 4;
  let nullByteIndex = 0;
  let fieldName = '';
  let tableName = '';

  for (let i = 0; i < fields.length; i++) {
    fieldName = helpers.fieldEscape(fields[i].name);
    // parserFn(`// ${fieldName}: ${typeNames[fields[i].columnType]}`);

    if (typeof options.nestTables === 'string') {
      lvalue = `result[${helpers.fieldEscape(fields[i].table + options.nestTables + fields[i].name)}]`;
    } else if (options.nestTables === true) {
      tableName = helpers.fieldEscape(fields[i].table);

      parserFn(`if (!result[${tableName}]) result[${tableName}] = {};`);
      lvalue = `result[${tableName}][${fieldName}]`;
    } else if (options.rowsAsArray) {
      lvalue = `result[${i.toString(10)}]`;
    } else {
      lvalue = `result[${fieldName}]`;
    }

    parserFn(`if (nullBitmaskByte${nullByteIndex} & ${currentFieldNullBit}) `);
    parserFn(`${lvalue} = null;`);
    parserFn('else {');

    if (options.typeCast === false) {
      parserFn(`${lvalue} = packet.readLengthCodedBuffer();`);
    } else {
      const fieldWrapperVar = `fieldWrapper${i}`;
      parserFn(`const ${fieldWrapperVar} = wrap(fields[${i}], packet);`);
      const readCode = readCodeFor(fields[i], config, options, i);

      if (typeof options.typeCast === 'function') {
        parserFn(
          `${lvalue} = options.typeCast(${fieldWrapperVar}, function() { return ${readCode} });`
        );
      } else {
        parserFn(`${lvalue} = ${readCode};`);
      }
    }
    parserFn('}');

    currentFieldNullBit *= 2;
    if (currentFieldNullBit === 0x100) {
      currentFieldNullBit = 1;
      nullByteIndex++;
    }
  }

  parserFn('return result;');
  parserFn('}');
  parserFn('};')('})()');

  if (config.debug) {
    helpers.printDebugWithCode(
      'Compiled binary protocol row parser',
      parserFn.toString()
    );
  }
  return parserFn.toFunction({ wrap });
}

function getBinaryParser(fields, options, config) {
  return parserCache.getParser('binary', fields, options, config, compile);
}

module.exports = getBinaryParser;
</file>

<file path="lib/parsers/parser_cache.js">
'use strict';

const { createLRU } = require('lru.min');

const parserCache = createLRU({
  max: 15000,
});

function keyFromFields(type, fields, options, config) {
  const res = [
    type,
    typeof options.nestTables,
    options.nestTables,
    Boolean(options.rowsAsArray),
    Boolean(options.supportBigNumbers || config.supportBigNumbers),
    Boolean(options.bigNumberStrings || config.bigNumberStrings),
    typeof options.typeCast,
    options.timezone || config.timezone,
    Boolean(options.decimalNumbers),
    options.dateStrings,
  ];

  for (let i = 0; i < fields.length; ++i) {
    const field = fields[i];

    res.push([
      field.name,
      field.columnType,
      field.length,
      field.schema,
      field.table,
      field.flags,
      field.characterSet,
    ]);
  }

  return JSON.stringify(res, null, 0);
}

function getParser(type, fields, options, config, compiler) {
  const key = keyFromFields(type, fields, options, config);
  let parser = parserCache.get(key);

  if (parser) {
    return parser;
  }

  parser = compiler(fields, options, config);
  parserCache.set(key, parser);
  return parser;
}

function setMaxCache(max) {
  parserCache.resize(max);
}

function clearCache() {
  parserCache.clear();
}

module.exports = {
  getParser: getParser,
  setMaxCache: setMaxCache,
  clearCache: clearCache,
  _keyFromFields: keyFromFields,
};
</file>

<file path="lib/parsers/static_binary_parser.js">
'use strict';

const FieldFlags = require('../constants/field_flags.js');
const Charsets = require('../constants/charsets.js');
const Types = require('../constants/types.js');
const helpers = require('../helpers');

const typeNames = [];
for (const t in Types) {
  typeNames[Types[t]] = t;
}

function getBinaryParser(fields, _options, config) {
  function readCode(field, config, options, fieldNum, packet) {
    const supportBigNumbers = Boolean(
      options.supportBigNumbers || config.supportBigNumbers
    );
    const bigNumberStrings = Boolean(
      options.bigNumberStrings || config.bigNumberStrings
    );
    const timezone = options.timezone || config.timezone;
    const dateStrings = options.dateStrings || config.dateStrings;
    const unsigned = field.flags & FieldFlags.UNSIGNED;

    switch (field.columnType) {
      case Types.TINY:
        return unsigned ? packet.readInt8() : packet.readSInt8();
      case Types.SHORT:
        return unsigned ? packet.readInt16() : packet.readSInt16();
      case Types.LONG:
      case Types.INT24: // in binary protocol int24 is encoded in 4 bytes int32
        return unsigned ? packet.readInt32() : packet.readSInt32();
      case Types.YEAR:
        return packet.readInt16();
      case Types.FLOAT:
        return packet.readFloat();
      case Types.DOUBLE:
        return packet.readDouble();
      case Types.NULL:
        return null;
      case Types.DATE:
      case Types.DATETIME:
      case Types.TIMESTAMP:
      case Types.NEWDATE:
        return helpers.typeMatch(field.columnType, dateStrings, Types)
          ? packet.readDateTimeString(
              parseInt(field.decimals, 10),
              null,
              field.columnType
            )
          : packet.readDateTime(timezone);
      case Types.TIME:
        return packet.readTimeString();
      case Types.DECIMAL:
      case Types.NEWDECIMAL:
        return config.decimalNumbers
          ? packet.parseLengthCodedFloat()
          : packet.readLengthCodedString('ascii');
      case Types.GEOMETRY:
        return packet.parseGeometryValue();
      case Types.VECTOR:
        return packet.parseVector();
      case Types.JSON:
        // Since for JSON columns mysql always returns charset 63 (BINARY),
        // we have to handle it according to JSON specs and use "utf8",
        // see https://github.com/sidorares/node-mysql2/issues/409
        return config.jsonStrings
          ? packet.readLengthCodedString('utf8')
          : JSON.parse(packet.readLengthCodedString('utf8'));
      case Types.LONGLONG:
        if (!supportBigNumbers)
          return unsigned
            ? packet.readInt64JSNumber()
            : packet.readSInt64JSNumber();
        return bigNumberStrings
          ? unsigned
            ? packet.readInt64String()
            : packet.readSInt64String()
          : unsigned
            ? packet.readInt64()
            : packet.readSInt64();
      default:
        return field.characterSet === Charsets.BINARY
          ? packet.readLengthCodedBuffer()
          : packet.readLengthCodedString(fields[fieldNum].encoding);
    }
  }

  return class BinaryRow {
    constructor() {}

    next(packet, fields, options) {
      packet.readInt8(); // status byte

      const nullBitmapLength = Math.floor((fields.length + 7 + 2) / 8);
      const nullBitmaskBytes = new Array(nullBitmapLength);

      for (let i = 0; i < nullBitmapLength; i++) {
        nullBitmaskBytes[i] = packet.readInt8();
      }

      const result = options.rowsAsArray ? new Array(fields.length) : {};
      let currentFieldNullBit = 4;
      let nullByteIndex = 0;

      for (let i = 0; i < fields.length; i++) {
        const field = fields[i];
        const typeCast =
          options.typeCast !== undefined ? options.typeCast : config.typeCast;

        let value;
        if (nullBitmaskBytes[nullByteIndex] & currentFieldNullBit) {
          value = null;
        } else if (options.typeCast === false) {
          value = packet.readLengthCodedBuffer();
        } else {
          const next = () => readCode(field, config, options, i, packet);
          value =
            typeof typeCast === 'function'
              ? typeCast(
                  {
                    type: typeNames[field.columnType],
                    length: field.columnLength,
                    db: field.schema,
                    table: field.table,
                    name: field.name,
                    string: function (encoding = field.encoding) {
                      if (
                        field.columnType === Types.JSON &&
                        encoding === field.encoding
                      ) {
                        // Since for JSON columns mysql always returns charset 63 (BINARY),
                        // we have to handle it according to JSON specs and use "utf8",
                        // see https://github.com/sidorares/node-mysql2/issues/1661
                        console.warn(
                          `typeCast: JSON column "${field.name}" is interpreted as BINARY by default, recommended to manually set utf8 encoding: \`field.string("utf8")\``
                        );
                      }

                      if (
                        [
                          Types.DATETIME,
                          Types.NEWDATE,
                          Types.TIMESTAMP,
                          Types.DATE,
                        ].includes(field.columnType)
                      ) {
                        return packet.readDateTimeString(
                          parseInt(field.decimals, 10)
                        );
                      }

                      if (field.columnType === Types.TINY) {
                        const unsigned = field.flags & FieldFlags.UNSIGNED;

                        return String(
                          unsigned ? packet.readInt8() : packet.readSInt8()
                        );
                      }

                      if (field.columnType === Types.TIME) {
                        return packet.readTimeString();
                      }

                      return packet.readLengthCodedString(encoding);
                    },
                    buffer: function () {
                      return packet.readLengthCodedBuffer();
                    },
                    geometry: function () {
                      return packet.parseGeometryValue();
                    },
                  },
                  next
                )
              : next();
        }

        if (options.rowsAsArray) {
          result[i] = value;
        } else if (typeof options.nestTables === 'string') {
          const key = helpers.fieldEscape(
            field.table + options.nestTables + field.name,
            false
          );
          result[key] = value;
        } else if (options.nestTables === true) {
          const tableName = helpers.fieldEscape(field.table, false);
          if (!result[tableName]) {
            result[tableName] = {};
          }
          const fieldName = helpers.fieldEscape(field.name, false);
          result[tableName][fieldName] = value;
        } else {
          const key = helpers.fieldEscape(field.name, false);
          result[key] = value;
        }

        currentFieldNullBit *= 2;
        if (currentFieldNullBit === 0x100) {
          currentFieldNullBit = 1;
          nullByteIndex++;
        }
      }

      return result;
    }
  };
}

module.exports = getBinaryParser;
</file>

<file path="lib/parsers/static_text_parser.js">
'use strict';

const Types = require('../constants/types.js');
const Charsets = require('../constants/charsets.js');
const helpers = require('../helpers');

const typeNames = [];
for (const t in Types) {
  typeNames[Types[t]] = t;
}

function readField({ packet, type, charset, encoding, config, options }) {
  const supportBigNumbers = Boolean(
    options.supportBigNumbers || config.supportBigNumbers
  );
  const bigNumberStrings = Boolean(
    options.bigNumberStrings || config.bigNumberStrings
  );
  const timezone = options.timezone || config.timezone;
  const dateStrings = options.dateStrings || config.dateStrings;

  switch (type) {
    case Types.TINY:
    case Types.SHORT:
    case Types.LONG:
    case Types.INT24:
    case Types.YEAR:
      return packet.parseLengthCodedIntNoBigCheck();
    case Types.LONGLONG:
      if (supportBigNumbers && bigNumberStrings) {
        return packet.parseLengthCodedIntString();
      }
      return packet.parseLengthCodedInt(supportBigNumbers);
    case Types.FLOAT:
    case Types.DOUBLE:
      return packet.parseLengthCodedFloat();
    case Types.NULL:
    case Types.DECIMAL:
    case Types.NEWDECIMAL:
      if (config.decimalNumbers) {
        return packet.parseLengthCodedFloat();
      }
      return packet.readLengthCodedString('ascii');
    case Types.DATE:
      if (helpers.typeMatch(type, dateStrings, Types)) {
        return packet.readLengthCodedString('ascii');
      }
      return packet.parseDate(timezone);
    case Types.DATETIME:
    case Types.TIMESTAMP:
      if (helpers.typeMatch(type, dateStrings, Types)) {
        return packet.readLengthCodedString('ascii');
      }
      return packet.parseDateTime(timezone);
    case Types.TIME:
      return packet.readLengthCodedString('ascii');
    case Types.GEOMETRY:
      return packet.parseGeometryValue();
    case Types.VECTOR:
      return packet.parseVector();
    case Types.JSON:
      // Since for JSON columns mysql always returns charset 63 (BINARY),
      // we have to handle it according to JSON specs and use "utf8",
      // see https://github.com/sidorares/node-mysql2/issues/409
      return config.jsonStrings
        ? packet.readLengthCodedString('utf8')
        : JSON.parse(packet.readLengthCodedString('utf8'));
    default:
      if (charset === Charsets.BINARY) {
        return packet.readLengthCodedBuffer();
      }
      return packet.readLengthCodedString(encoding);
  }
}

function createTypecastField(field, packet) {
  return {
    type: typeNames[field.columnType],
    length: field.columnLength,
    db: field.schema,
    table: field.table,
    name: field.name,
    string: function (encoding = field.encoding) {
      if (field.columnType === Types.JSON && encoding === field.encoding) {
        // Since for JSON columns mysql always returns charset 63 (BINARY),
        // we have to handle it according to JSON specs and use "utf8",
        // see https://github.com/sidorares/node-mysql2/issues/1661
        console.warn(
          `typeCast: JSON column "${field.name}" is interpreted as BINARY by default, recommended to manually set utf8 encoding: \`field.string("utf8")\``
        );
      }
      return packet.readLengthCodedString(encoding);
    },
    buffer: function () {
      return packet.readLengthCodedBuffer();
    },
    geometry: function () {
      return packet.parseGeometryValue();
    },
  };
}

function getTextParser(_fields, _options, config) {
  return {
    next(packet, fields, options) {
      const result = options.rowsAsArray ? [] : {};
      for (let i = 0; i < fields.length; i++) {
        const field = fields[i];
        const typeCast = options.typeCast ? options.typeCast : config.typeCast;
        const next = () =>
          readField({
            packet,
            type: field.columnType,
            encoding: field.encoding,
            charset: field.characterSet,
            config,
            options,
          });

        let value;

        if (options.typeCast === false) {
          value = packet.readLengthCodedBuffer();
        } else if (typeof typeCast === 'function') {
          value = typeCast(createTypecastField(field, packet), next);
        } else {
          value = next();
        }

        if (options.rowsAsArray) {
          result.push(value);
        } else if (typeof options.nestTables === 'string') {
          result[
            `${helpers.fieldEscape(field.table, false)}${options.nestTables}${helpers.fieldEscape(field.name, false)}`
          ] = value;
        } else if (options.nestTables) {
          const tableName = helpers.fieldEscape(field.table, false);
          if (!result[tableName]) {
            result[tableName] = {};
          }
          result[tableName][helpers.fieldEscape(field.name, false)] = value;
        } else {
          result[helpers.fieldEscape(field.name, false)] = value;
        }
      }

      return result;
    },
  };
}

module.exports = getTextParser;
</file>

<file path="lib/parsers/string.js">
'use strict';

const Iconv = require('iconv-lite');
const { createLRU } = require('lru.min');

const decoderCache = createLRU({
  max: 500,
});

exports.decode = function (buffer, encoding, start, end, options) {
  if (Buffer.isEncoding(encoding)) {
    return buffer.toString(encoding, start, end);
  }

  // Optimize for common case: encoding="short_string", options=undefined.
  let decoder;
  if (!options) {
    decoder = decoderCache.get(encoding);
    if (!decoder) {
      decoder = Iconv.getDecoder(encoding);
      decoderCache.set(encoding, decoder);
    }
  } else {
    const decoderArgs = { encoding, options };
    const decoderKey = JSON.stringify(decoderArgs);
    decoder = decoderCache.get(decoderKey);
    if (!decoder) {
      decoder = Iconv.getDecoder(decoderArgs.encoding, decoderArgs.options);
      decoderCache.set(decoderKey, decoder);
    }
  }

  const res = decoder.write(buffer.slice(start, end));
  const trail = decoder.end();

  return trail ? res + trail : res;
};

exports.encode = function (string, encoding, options) {
  if (Buffer.isEncoding(encoding)) {
    return Buffer.from(string, encoding);
  }

  const encoder = Iconv.getEncoder(encoding, options || {});

  const res = encoder.write(string);
  const trail = encoder.end();

  return trail && trail.length > 0 ? Buffer.concat([res, trail]) : res;
};
</file>

<file path="lib/parsers/text_parser.js">
'use strict';

const Types = require('../constants/types.js');
const Charsets = require('../constants/charsets.js');
const helpers = require('../helpers');
const genFunc = require('generate-function');
const parserCache = require('./parser_cache.js');

const typeNames = [];
for (const t in Types) {
  typeNames[Types[t]] = t;
}

function readCodeFor(type, charset, encodingExpr, config, options) {
  const supportBigNumbers = Boolean(
    options.supportBigNumbers || config.supportBigNumbers
  );
  const bigNumberStrings = Boolean(
    options.bigNumberStrings || config.bigNumberStrings
  );
  const timezone = options.timezone || config.timezone;
  const dateStrings = options.dateStrings || config.dateStrings;

  switch (type) {
    case Types.TINY:
    case Types.SHORT:
    case Types.LONG:
    case Types.INT24:
    case Types.YEAR:
      return 'packet.parseLengthCodedIntNoBigCheck()';
    case Types.LONGLONG:
      if (supportBigNumbers && bigNumberStrings) {
        return 'packet.parseLengthCodedIntString()';
      }
      return `packet.parseLengthCodedInt(${supportBigNumbers})`;
    case Types.FLOAT:
    case Types.DOUBLE:
      return 'packet.parseLengthCodedFloat()';
    case Types.NULL:
      return 'packet.readLengthCodedNumber()';
    case Types.DECIMAL:
    case Types.NEWDECIMAL:
      if (config.decimalNumbers) {
        return 'packet.parseLengthCodedFloat()';
      }
      return 'packet.readLengthCodedString("ascii")';
    case Types.DATE:
      if (helpers.typeMatch(type, dateStrings, Types)) {
        return 'packet.readLengthCodedString("ascii")';
      }
      return `packet.parseDate(${helpers.srcEscape(timezone)})`;
    case Types.DATETIME:
    case Types.TIMESTAMP:
      if (helpers.typeMatch(type, dateStrings, Types)) {
        return 'packet.readLengthCodedString("ascii")';
      }
      return `packet.parseDateTime(${helpers.srcEscape(timezone)})`;
    case Types.TIME:
      return 'packet.readLengthCodedString("ascii")';
    case Types.GEOMETRY:
      return 'packet.parseGeometryValue()';
    case Types.VECTOR:
      return 'packet.parseVector()';
    case Types.JSON:
      // Since for JSON columns mysql always returns charset 63 (BINARY),
      // we have to handle it according to JSON specs and use "utf8",
      // see https://github.com/sidorares/node-mysql2/issues/409
      return config.jsonStrings
        ? 'packet.readLengthCodedString("utf8")'
        : 'JSON.parse(packet.readLengthCodedString("utf8"))';
    default:
      if (charset === Charsets.BINARY) {
        return 'packet.readLengthCodedBuffer()';
      }
      return `packet.readLengthCodedString(${encodingExpr})`;
  }
}

function compile(fields, options, config) {
  // use global typeCast if current query doesn't specify one
  if (
    typeof config.typeCast === 'function' &&
    typeof options.typeCast !== 'function'
  ) {
    options.typeCast = config.typeCast;
  }

  function wrap(field, _this) {
    return {
      type: typeNames[field.columnType],
      length: field.columnLength,
      db: field.schema,
      table: field.table,
      name: field.name,
      string: function (encoding = field.encoding) {
        if (field.columnType === Types.JSON && encoding === field.encoding) {
          // Since for JSON columns mysql always returns charset 63 (BINARY),
          // we have to handle it according to JSON specs and use "utf8",
          // see https://github.com/sidorares/node-mysql2/issues/1661
          console.warn(
            `typeCast: JSON column "${field.name}" is interpreted as BINARY by default, recommended to manually set utf8 encoding: \`field.string("utf8")\``
          );
        }

        return _this.packet.readLengthCodedString(encoding);
      },
      buffer: function () {
        return _this.packet.readLengthCodedBuffer();
      },
      geometry: function () {
        return _this.packet.parseGeometryValue();
      },
    };
  }

  const parserFn = genFunc();

  parserFn('(function () {')('return class TextRow {');

  // constructor method
  parserFn('constructor(fields) {');
  // node-mysql typeCast compatibility wrapper
  // see https://github.com/mysqljs/mysql/blob/96fdd0566b654436624e2375c7b6604b1f50f825/lib/protocol/packets/Field.js
  if (typeof options.typeCast === 'function') {
    parserFn('const _this = this;');
    parserFn('for(let i=0; i<fields.length; ++i) {');
    parserFn('this[`wrap${i}`] = wrap(fields[i], _this);');
    parserFn('}');
  }
  parserFn('}');

  // next method
  parserFn('next(packet, fields, options) {');
  parserFn('this.packet = packet;');
  if (options.rowsAsArray) {
    parserFn(`const result = new Array(${fields.length});`);
  } else {
    parserFn('const result = {};');
  }

  const resultTables = {};
  let resultTablesArray = [];

  if (options.nestTables === true) {
    for (let i = 0; i < fields.length; i++) {
      resultTables[fields[i].table] = 1;
    }
    resultTablesArray = Object.keys(resultTables);
    for (let i = 0; i < resultTablesArray.length; i++) {
      parserFn(`result[${helpers.fieldEscape(resultTablesArray[i])}] = {};`);
    }
  }

  let lvalue = '';
  let fieldName = '';
  let tableName = '';
  for (let i = 0; i < fields.length; i++) {
    fieldName = helpers.fieldEscape(fields[i].name);
    // parserFn(`// ${fieldName}: ${typeNames[fields[i].columnType]}`);

    if (typeof options.nestTables === 'string') {
      lvalue = `result[${helpers.fieldEscape(fields[i].table + options.nestTables + fields[i].name)}]`;
    } else if (options.nestTables === true) {
      tableName = helpers.fieldEscape(fields[i].table);

      parserFn(`if (!result[${tableName}]) result[${tableName}] = {};`);
      lvalue = `result[${tableName}][${fieldName}]`;
    } else if (options.rowsAsArray) {
      lvalue = `result[${i.toString(10)}]`;
    } else {
      lvalue = `result[${fieldName}]`;
    }
    if (options.typeCast === false) {
      parserFn(`${lvalue} = packet.readLengthCodedBuffer();`);
    } else {
      const encodingExpr = `fields[${i}].encoding`;
      const readCode = readCodeFor(
        fields[i].columnType,
        fields[i].characterSet,
        encodingExpr,
        config,
        options
      );
      if (typeof options.typeCast === 'function') {
        parserFn(
          `${lvalue} = options.typeCast(this.wrap${i}, function() { return ${readCode} });`
        );
      } else {
        parserFn(`${lvalue} = ${readCode};`);
      }
    }
  }

  parserFn('return result;');
  parserFn('}');
  parserFn('};')('})()');

  if (config.debug) {
    helpers.printDebugWithCode(
      'Compiled text protocol row parser',
      parserFn.toString()
    );
  }
  if (typeof options.typeCast === 'function') {
    return parserFn.toFunction({ wrap });
  }
  return parserFn.toFunction();
}

function getTextParser(fields, options, config) {
  return parserCache.getParser('text', fields, options, config, compile);
}

module.exports = getTextParser;
</file>

<file path="lib/pool_cluster.js">
'use strict';

const process = require('process');

const Pool = require('./pool.js');
const PoolConfig = require('./pool_config.js');
const Connection = require('./connection.js');
const EventEmitter = require('events').EventEmitter;

/**
 * Selector
 */
const makeSelector = {
  RR() {
    let index = 0;
    return (clusterIds) => clusterIds[index++ % clusterIds.length];
  },
  RANDOM() {
    return (clusterIds) =>
      clusterIds[Math.floor(Math.random() * clusterIds.length)];
  },
  ORDER() {
    return (clusterIds) => clusterIds[0];
  },
};

const getMonotonicMilliseconds = function () {
  let ms;

  if (typeof process.hrtime === 'function') {
    ms = process.hrtime();
    ms = ms[0] * 1e3 + ms[1] * 1e-6;
  } else {
    ms = process.uptime() * 1000;
  }

  return Math.floor(ms);
};

const patternRegExp = function (pattern) {
  if (pattern instanceof RegExp) {
    return pattern;
  }

  const source = pattern
    .replace(/([.+?^=!:${}()|[\]/\\])/g, '\\$1')
    .replace(/\*/g, '.*');

  return new RegExp(`^${source}$`);
};

class PoolNamespace {
  constructor(cluster, pattern, selector) {
    this._cluster = cluster;
    this._pattern = pattern;
    this._selector = makeSelector[selector]();
  }

  getConnection(cb) {
    const clusterNode = this._getClusterNode();
    if (clusterNode === null) {
      let err = new Error('Pool does Not exist.');
      err.code = 'POOL_NOEXIST';

      if (this._cluster._findNodeIds(this._pattern, true).length !== 0) {
        err = new Error('Pool does Not have online node.');
        err.code = 'POOL_NONEONLINE';
      }

      return cb(err);
    }
    return this._cluster._getConnection(clusterNode, (err, connection) => {
      if (err) {
        if (
          this._cluster._canRetry &&
          this._cluster._findNodeIds(this._pattern).length !== 0
        ) {
          this._cluster.emit('warn', err);
          return this.getConnection(cb);
        }

        return cb(err);
      }
      return cb(null, connection);
    });
  }

  /**
   * pool cluster query
   * @param {*} sql
   * @param {*} values
   * @param {*} cb
   * @returns query
   */
  query(sql, values, cb) {
    const query = Connection.createQuery(sql, values, cb, {});
    this.getConnection((err, conn) => {
      if (err) {
        if (typeof query.onResult === 'function') {
          query.onResult(err);
        } else {
          query.emit('error', err);
        }
        return;
      }
      try {
        conn.query(query).once('end', () => {
          conn.release();
        });
      } catch (e) {
        conn.release();
        throw e;
      }
    });
    return query;
  }

  /**
   * pool cluster execute
   * @param {*} sql
   * @param {*} values
   * @param {*} cb
   */
  execute(sql, values, cb) {
    if (typeof values === 'function') {
      cb = values;
      values = [];
    }
    this.getConnection((err, conn) => {
      if (err) {
        return cb(err);
      }
      try {
        conn.execute(sql, values, cb).once('end', () => {
          conn.release();
        });
      } catch (e) {
        conn.release();
        throw e;
      }
    });
  }

  _getClusterNode() {
    const foundNodeIds = this._cluster._findNodeIds(this._pattern);
    if (foundNodeIds.length === 0) {
      return null;
    }
    const nodeId =
      foundNodeIds.length === 1
        ? foundNodeIds[0]
        : this._selector(foundNodeIds);
    return this._cluster._getNode(nodeId);
  }
}

class PoolCluster extends EventEmitter {
  constructor(config) {
    super();
    config = config || {};
    this._canRetry =
      typeof config.canRetry === 'undefined' ? true : config.canRetry;
    this._removeNodeErrorCount = config.removeNodeErrorCount || 5;
    this._restoreNodeTimeout = config.restoreNodeTimeout || 0;
    this._defaultSelector = config.defaultSelector || 'RR';
    this._closed = false;
    this._lastId = 0;
    this._nodes = {};
    this._serviceableNodeIds = [];
    this._namespaces = {};
    this._findCaches = {};
  }

  of(pattern, selector) {
    pattern = pattern || '*';
    selector = selector || this._defaultSelector;
    selector = selector.toUpperCase();
    if (!makeSelector[selector] === 'undefined') {
      selector = this._defaultSelector;
    }
    const key = pattern + selector;
    if (typeof this._namespaces[key] === 'undefined') {
      this._namespaces[key] = new PoolNamespace(this, pattern, selector);
    }
    return this._namespaces[key];
  }

  add(id, config) {
    if (typeof id === 'object') {
      config = id;
      id = `CLUSTER::${++this._lastId}`;
    }
    if (typeof this._nodes[id] === 'undefined') {
      this._nodes[id] = {
        id: id,
        errorCount: 0,
        pool: new Pool({ config: new PoolConfig(config) }),
        _offlineUntil: 0,
      };
      this._serviceableNodeIds.push(id);
      this._clearFindCaches();
    }
  }

  remove(pattern) {
    const foundNodeIds = this._findNodeIds(pattern, true);

    for (let i = 0; i < foundNodeIds.length; i++) {
      const node = this._getNode(foundNodeIds[i]);

      if (node) {
        this._removeNode(node);
      }
    }
  }

  getConnection(pattern, selector, cb) {
    let namespace;
    if (typeof pattern === 'function') {
      cb = pattern;
      namespace = this.of();
    } else {
      if (typeof selector === 'function') {
        cb = selector;
        selector = this._defaultSelector;
      }
      namespace = this.of(pattern, selector);
    }
    namespace.getConnection(cb);
  }

  end(callback) {
    const cb =
      callback !== undefined
        ? callback
        : (err) => {
            if (err) {
              throw err;
            }
          };
    if (this._closed) {
      process.nextTick(cb);
      return;
    }

    this._closed = true;

    let calledBack = false;
    let waitingClose = 0;
    const onEnd = (err) => {
      if (!calledBack && (err || --waitingClose <= 0)) {
        calledBack = true;
        return cb(err);
      }
    };

    for (const id in this._nodes) {
      waitingClose++;
      this._nodes[id].pool.end(onEnd);
    }

    if (waitingClose === 0) {
      process.nextTick(onEnd);
    }
  }

  _findNodeIds(pattern, includeOffline) {
    let currentTime = 0;
    let foundNodeIds = this._findCaches[pattern];

    if (foundNodeIds === undefined) {
      const expression = patternRegExp(pattern);

      foundNodeIds = this._serviceableNodeIds.filter((id) =>
        id.match(expression)
      );
    }

    this._findCaches[pattern] = foundNodeIds;

    if (includeOffline) {
      return foundNodeIds;
    }

    return foundNodeIds.filter((nodeId) => {
      const node = this._getNode(nodeId);

      if (!node._offlineUntil) {
        return true;
      }

      if (!currentTime) {
        currentTime = getMonotonicMilliseconds();
      }

      return node._offlineUntil <= currentTime;
    });
  }

  _getNode(id) {
    return this._nodes[id] || null;
  }

  _increaseErrorCount(node) {
    const errorCount = ++node.errorCount;

    if (this._removeNodeErrorCount > errorCount) {
      return;
    }

    if (this._restoreNodeTimeout > 0) {
      node._offlineUntil =
        getMonotonicMilliseconds() + this._restoreNodeTimeout;
      this.emit('offline', node.id);
      return;
    }

    this._removeNode(node);
    this.emit('remove', node.id);
  }

  _decreaseErrorCount(node) {
    let errorCount = node.errorCount;

    if (errorCount > this._removeNodeErrorCount) {
      errorCount = this._removeNodeErrorCount;
    }

    if (errorCount < 1) {
      errorCount = 1;
    }

    node.errorCount = errorCount - 1;

    if (node._offlineUntil) {
      node._offlineUntil = 0;
      this.emit('online', node.id);
    }
  }

  _getConnection(node, cb) {
    node.pool.getConnection((err, connection) => {
      if (err) {
        this._increaseErrorCount(node);
        return cb(err);
      }
      this._decreaseErrorCount(node);

      connection._clusterId = node.id;
      return cb(null, connection);
    });
  }

  _removeNode(node) {
    const index = this._serviceableNodeIds.indexOf(node.id);
    if (index !== -1) {
      this._serviceableNodeIds.splice(index, 1);
      delete this._nodes[node.id];
      this._clearFindCaches();
      node.pool.end();
    }
  }

  _clearFindCaches() {
    this._findCaches = {};
  }
}

module.exports = PoolCluster;
</file>

<file path="lib/pool_config.js">
'use strict';

const ConnectionConfig = require('./connection_config.js');

class PoolConfig {
  constructor(options) {
    if (typeof options === 'string') {
      options = ConnectionConfig.parseUrl(options);
    }
    this.connectionConfig = new ConnectionConfig(options);
    this.waitForConnections =
      options.waitForConnections === undefined
        ? true
        : Boolean(options.waitForConnections);
    this.connectionLimit = isNaN(options.connectionLimit)
      ? 10
      : Number(options.connectionLimit);
    this.maxIdle = isNaN(options.maxIdle)
      ? this.connectionLimit
      : Number(options.maxIdle);
    this.idleTimeout = isNaN(options.idleTimeout)
      ? 60000
      : Number(options.idleTimeout);
    this.queueLimit = isNaN(options.queueLimit)
      ? 0
      : Number(options.queueLimit);
  }
}

module.exports = PoolConfig;
</file>

<file path="lib/pool_connection.js">
'use strict';

const BasePoolConnection = require('./base/pool_connection.js');

class PoolConnection extends BasePoolConnection {
  promise(promiseImpl) {
    const PromisePoolConnection = require('./promise/pool_connection.js');
    return new PromisePoolConnection(this, promiseImpl);
  }
}

module.exports = PoolConnection;
</file>

<file path="lib/pool.js">
'use strict';

const BasePool = require('./base/pool.js');

class Pool extends BasePool {
  promise(promiseImpl) {
    const PromisePool = require('./promise/pool.js');
    return new PromisePool(this, promiseImpl);
  }
}

module.exports = Pool;
</file>

<file path="lib/promise/connection.js">
'use strict';

const EventEmitter = require('events').EventEmitter;
const PromisePreparedStatementInfo = require('./prepared_statement_info.js');
const makeDoneCb = require('./make_done_cb.js');
const inheritEvents = require('./inherit_events.js');
const BaseConnection = require('../base/connection.js');

class PromiseConnection extends EventEmitter {
  constructor(connection, promiseImpl) {
    super();
    this.connection = connection;
    this.Promise = promiseImpl || Promise;
    inheritEvents(connection, this, [
      'error',
      'drain',
      'connect',
      'end',
      'enqueue',
    ]);
  }

  release() {
    this.connection.release();
  }

  query(query, params) {
    const c = this.connection;
    const localErr = new Error();
    if (typeof params === 'function') {
      throw new Error(
        'Callback function is not available with promise clients.'
      );
    }
    return new this.Promise((resolve, reject) => {
      const done = makeDoneCb(resolve, reject, localErr);
      if (params !== undefined) {
        c.query(query, params, done);
      } else {
        c.query(query, done);
      }
    });
  }

  execute(query, params) {
    const c = this.connection;
    const localErr = new Error();
    if (typeof params === 'function') {
      throw new Error(
        'Callback function is not available with promise clients.'
      );
    }
    return new this.Promise((resolve, reject) => {
      const done = makeDoneCb(resolve, reject, localErr);
      if (params !== undefined) {
        c.execute(query, params, done);
      } else {
        c.execute(query, done);
      }
    });
  }

  end() {
    return new this.Promise((resolve) => {
      this.connection.end(resolve);
    });
  }

  beginTransaction() {
    const c = this.connection;
    const localErr = new Error();
    return new this.Promise((resolve, reject) => {
      const done = makeDoneCb(resolve, reject, localErr);
      c.beginTransaction(done);
    });
  }

  commit() {
    const c = this.connection;
    const localErr = new Error();
    return new this.Promise((resolve, reject) => {
      const done = makeDoneCb(resolve, reject, localErr);
      c.commit(done);
    });
  }

  rollback() {
    const c = this.connection;
    const localErr = new Error();
    return new this.Promise((resolve, reject) => {
      const done = makeDoneCb(resolve, reject, localErr);
      c.rollback(done);
    });
  }

  ping() {
    const c = this.connection;
    const localErr = new Error();
    return new this.Promise((resolve, reject) => {
      c.ping((err) => {
        if (err) {
          localErr.message = err.message;
          localErr.code = err.code;
          localErr.errno = err.errno;
          localErr.sqlState = err.sqlState;
          localErr.sqlMessage = err.sqlMessage;
          reject(localErr);
        } else {
          resolve(true);
        }
      });
    });
  }

  connect() {
    const c = this.connection;
    const localErr = new Error();
    return new this.Promise((resolve, reject) => {
      c.connect((err, param) => {
        if (err) {
          localErr.message = err.message;
          localErr.code = err.code;
          localErr.errno = err.errno;
          localErr.sqlState = err.sqlState;
          localErr.sqlMessage = err.sqlMessage;
          reject(localErr);
        } else {
          resolve(param);
        }
      });
    });
  }

  prepare(options) {
    const c = this.connection;
    const promiseImpl = this.Promise;
    const localErr = new Error();
    return new this.Promise((resolve, reject) => {
      c.prepare(options, (err, statement) => {
        if (err) {
          localErr.message = err.message;
          localErr.code = err.code;
          localErr.errno = err.errno;
          localErr.sqlState = err.sqlState;
          localErr.sqlMessage = err.sqlMessage;
          reject(localErr);
        } else {
          const wrappedStatement = new PromisePreparedStatementInfo(
            statement,
            promiseImpl
          );
          resolve(wrappedStatement);
        }
      });
    });
  }

  changeUser(options) {
    const c = this.connection;
    const localErr = new Error();
    return new this.Promise((resolve, reject) => {
      c.changeUser(options, (err) => {
        if (err) {
          localErr.message = err.message;
          localErr.code = err.code;
          localErr.errno = err.errno;
          localErr.sqlState = err.sqlState;
          localErr.sqlMessage = err.sqlMessage;
          reject(localErr);
        } else {
          resolve();
        }
      });
    });
  }

  get config() {
    return this.connection.config;
  }

  get threadId() {
    return this.connection.threadId;
  }
}
// patching PromiseConnection
// create facade functions for prototype functions on "Connection" that are not yet
// implemented with PromiseConnection

// proxy synchronous functions only
(function (functionsToWrap) {
  for (let i = 0; functionsToWrap && i < functionsToWrap.length; i++) {
    const func = functionsToWrap[i];

    if (
      typeof BaseConnection.prototype[func] === 'function' &&
      PromiseConnection.prototype[func] === undefined
    ) {
      PromiseConnection.prototype[func] = (function factory(funcName) {
        return function () {
          return BaseConnection.prototype[funcName].apply(
            this.connection,
            arguments
          );
        };
      })(func);
    }
  }
})([
  // synchronous functions
  'close',
  'createBinlogStream',
  'destroy',
  'escape',
  'escapeId',
  'format',
  'pause',
  'pipe',
  'resume',
  'unprepare',
]);

module.exports = PromiseConnection;
</file>

<file path="lib/promise/inherit_events.js">
'use strict';

function inheritEvents(source, target, events) {
  const listeners = {};
  target
    .on('newListener', (eventName) => {
      if (events.indexOf(eventName) >= 0 && !target.listenerCount(eventName)) {
        source.on(
          eventName,
          (listeners[eventName] = function () {
            const args = [].slice.call(arguments);
            args.unshift(eventName);

            target.emit.apply(target, args);
          })
        );
      }
    })
    .on('removeListener', (eventName) => {
      if (events.indexOf(eventName) >= 0 && !target.listenerCount(eventName)) {
        source.removeListener(eventName, listeners[eventName]);
        delete listeners[eventName];
      }
    });
}

module.exports = inheritEvents;
</file>

<file path="lib/promise/make_done_cb.js">
'use strict';

function makeDoneCb(resolve, reject, localErr) {
  return function (err, rows, fields) {
    if (err) {
      localErr.message = err.message;
      localErr.code = err.code;
      localErr.errno = err.errno;
      localErr.sql = err.sql;
      localErr.sqlState = err.sqlState;
      localErr.sqlMessage = err.sqlMessage;
      reject(localErr);
    } else {
      resolve([rows, fields]);
    }
  };
}

module.exports = makeDoneCb;
</file>

<file path="lib/promise/pool_cluster.js">
'use strict';

const PromisePoolConnection = require('./pool_connection');
const makeDoneCb = require('./make_done_cb');

class PromisePoolNamespace {
  constructor(poolNamespace, thePromise) {
    this.poolNamespace = poolNamespace;
    this.Promise = thePromise || Promise;
  }

  getConnection() {
    const corePoolNamespace = this.poolNamespace;
    return new this.Promise((resolve, reject) => {
      corePoolNamespace.getConnection((err, coreConnection) => {
        if (err) {
          reject(err);
        } else {
          resolve(new PromisePoolConnection(coreConnection, this.Promise));
        }
      });
    });
  }

  query(sql, values) {
    const corePoolNamespace = this.poolNamespace;
    const localErr = new Error();
    if (typeof values === 'function') {
      throw new Error(
        'Callback function is not available with promise clients.'
      );
    }
    return new this.Promise((resolve, reject) => {
      const done = makeDoneCb(resolve, reject, localErr);
      corePoolNamespace.query(sql, values, done);
    });
  }

  execute(sql, values) {
    const corePoolNamespace = this.poolNamespace;
    const localErr = new Error();
    if (typeof values === 'function') {
      throw new Error(
        'Callback function is not available with promise clients.'
      );
    }
    return new this.Promise((resolve, reject) => {
      const done = makeDoneCb(resolve, reject, localErr);
      corePoolNamespace.execute(sql, values, done);
    });
  }
}

module.exports = PromisePoolNamespace;
</file>

<file path="lib/promise/pool_connection.js">
'use strict';

const PromiseConnection = require('./connection.js');
const BasePoolConnection = require('../base/pool_connection.js');

class PromisePoolConnection extends PromiseConnection {
  constructor(connection, promiseImpl) {
    super(connection, promiseImpl);
  }

  destroy() {
    return BasePoolConnection.prototype.destroy.apply(
      this.connection,
      arguments
    );
  }
}

module.exports = PromisePoolConnection;
</file>

<file path="lib/promise/pool.js">
'use strict';

const EventEmitter = require('events').EventEmitter;
const makeDoneCb = require('./make_done_cb.js');
const PromisePoolConnection = require('./pool_connection.js');
const inheritEvents = require('./inherit_events.js');
const BasePool = require('../base/pool.js');

class PromisePool extends EventEmitter {
  constructor(pool, thePromise) {
    super();
    this.pool = pool;
    this.Promise = thePromise || Promise;
    inheritEvents(pool, this, ['acquire', 'connection', 'enqueue', 'release']);
  }

  getConnection() {
    const corePool = this.pool;
    return new this.Promise((resolve, reject) => {
      corePool.getConnection((err, coreConnection) => {
        if (err) {
          reject(err);
        } else {
          resolve(new PromisePoolConnection(coreConnection, this.Promise));
        }
      });
    });
  }

  releaseConnection(connection) {
    if (connection instanceof PromisePoolConnection) connection.release();
  }

  query(sql, args) {
    const corePool = this.pool;
    const localErr = new Error();
    if (typeof args === 'function') {
      throw new Error(
        'Callback function is not available with promise clients.'
      );
    }
    return new this.Promise((resolve, reject) => {
      const done = makeDoneCb(resolve, reject, localErr);
      if (args !== undefined) {
        corePool.query(sql, args, done);
      } else {
        corePool.query(sql, done);
      }
    });
  }

  execute(sql, args) {
    const corePool = this.pool;
    const localErr = new Error();
    if (typeof args === 'function') {
      throw new Error(
        'Callback function is not available with promise clients.'
      );
    }
    return new this.Promise((resolve, reject) => {
      const done = makeDoneCb(resolve, reject, localErr);
      if (args) {
        corePool.execute(sql, args, done);
      } else {
        corePool.execute(sql, done);
      }
    });
  }

  end() {
    const corePool = this.pool;
    const localErr = new Error();
    return new this.Promise((resolve, reject) => {
      corePool.end((err) => {
        if (err) {
          localErr.message = err.message;
          localErr.code = err.code;
          localErr.errno = err.errno;
          localErr.sqlState = err.sqlState;
          localErr.sqlMessage = err.sqlMessage;
          reject(localErr);
        } else {
          resolve();
        }
      });
    });
  }
}

(function (functionsToWrap) {
  for (let i = 0; functionsToWrap && i < functionsToWrap.length; i++) {
    const func = functionsToWrap[i];

    if (
      typeof BasePool.prototype[func] === 'function' &&
      PromisePool.prototype[func] === undefined
    ) {
      PromisePool.prototype[func] = (function factory(funcName) {
        return function () {
          return BasePool.prototype[funcName].apply(this.pool, arguments);
        };
      })(func);
    }
  }
})([
  // synchronous functions
  'escape',
  'escapeId',
  'format',
]);

module.exports = PromisePool;
</file>

<file path="lib/promise/prepared_statement_info.js">
'use strict';

const makeDoneCb = require('./make_done_cb.js');

class PromisePreparedStatementInfo {
  constructor(statement, promiseImpl) {
    this.statement = statement;
    this.Promise = promiseImpl;
  }

  execute(parameters) {
    const s = this.statement;
    const localErr = new Error();
    return new this.Promise((resolve, reject) => {
      const done = makeDoneCb(resolve, reject, localErr);
      if (parameters) {
        s.execute(parameters, done);
      } else {
        s.execute(done);
      }
    });
  }

  close() {
    return new this.Promise((resolve) => {
      this.statement.close();
      resolve();
    });
  }
}

module.exports = PromisePreparedStatementInfo;
</file>

<file path="lib/results_stream.js">
'use strict';

const Readable = require('stream').Readable;

// copy-paste from https://github.com/mysqljs/mysql/blob/master/lib/protocol/sequences/Query.js
module.exports = function (command, connectionStream) {
  command.stream = function (options) {
    let stream;

    options = options || {};
    options.objectMode = true;
    (stream = new Readable(options)),
      (stream._read = function () {
        connectionStream.resume();
      });

    this.on('result', (row, i) => {
      if (!stream.push(row)) {
        connectionStream.pause();
      }
      stream.emit('result', row, i); // replicate old emitter
    });

    this.on('error', (err) => {
      stream.emit('error', err); // Pass on any errors
    });

    this.on('end', () => {
      stream.push(null); // pushing null, indicating EOF
    });

    this.on('fields', (fields, i) => {
      stream.emit('fields', fields, i); // replicate old emitter
    });

    return stream;
  };
};
</file>

<file path="lib/server.js">
'use strict';

const net = require('net');
const EventEmitter = require('events').EventEmitter;

const Connection = require('./connection');
const ConnectionConfig = require('./connection_config');

// TODO: inherit Server from net.Server
class Server extends EventEmitter {
  constructor() {
    super();
    this.connections = [];
    this._server = net.createServer(this._handleConnection.bind(this));
  }

  _handleConnection(socket) {
    const connectionConfig = new ConnectionConfig({
      stream: socket,
      isServer: true,
    });
    const connection = new Connection({ config: connectionConfig });
    this.emit('connection', connection);
  }

  listen(port) {
    this._port = port;
    this._server.listen.apply(this._server, arguments);
    return this;
  }

  close(cb) {
    this._server.close(cb);
  }
}

module.exports = Server;
</file>

<file path="License">
Copyright (c) 2016 Andrey Sidorov (sidorares@yandex.ru) and contributors

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in
 all copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
</file>

<file path="package.json">
{
  "name": "mysql2",
  "version": "3.14.1",
  "description": "fast mysql driver. Implements core protocol, prepared statements, ssl and compression in native JS",
  "main": "index.js",
  "typings": "typings/mysql/index",
  "type": "commonjs",
  "scripts": {
    "lint": "eslint . && prettier --check .",
    "lint:fix": "eslint . --fix && prettier --write .",
    "test": "poku -d -r=verbose --sequential test/esm test/unit test/integration",
    "test:bun": "bun poku -d --sequential test/esm test/unit test/integration",
    "test:deno": "deno run --allow-read --allow-env --allow-run npm:poku -d --sequential --denoAllow=\"read,env,net,sys\" test/esm test/unit test/integration",
    "test:tsc-build": "cd \"test/tsc-build\" && npx tsc -p \"tsconfig.json\"",
    "coverage-test": "c8 npm run test",
    "benchmark": "node ./benchmarks/benchmark.js",
    "wait-port": "wait-on"
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/sidorares/node-mysql2.git"
  },
  "homepage": "https://sidorares.github.io/node-mysql2/docs",
  "keywords": [
    "mysql",
    "client",
    "server"
  ],
  "files": [
    "lib",
    "typings/mysql",
    "index.js",
    "index.d.ts",
    "promise.js",
    "promise.d.ts"
  ],
  "exports": {
    ".": "./index.js",
    "./package.json": "./package.json",
    "./promise": "./promise.js",
    "./promise.js": "./promise.js"
  },
  "engines": {
    "node": ">= 8.0"
  },
  "author": "Andrey Sidorov <andrey.sidorov@gmail.com>",
  "license": "MIT",
  "dependencies": {
    "aws-ssl-profiles": "^1.1.1",
    "denque": "^2.1.0",
    "generate-function": "^2.3.1",
    "iconv-lite": "^0.6.3",
    "long": "^5.2.1",
    "lru.min": "^1.0.0",
    "named-placeholders": "^1.1.3",
    "seq-queue": "^0.0.5",
    "sqlstring": "^2.3.2"
  },
  "devDependencies": {
    "@eslint/eslintrc": "^3.3.0",
    "@eslint/js": "^9.21.0",
    "@eslint/markdown": "^6.2.2",
    "@types/node": "^22.0.0",
    "@typescript-eslint/eslint-plugin": "^8.26.0",
    "@typescript-eslint/parser": "^8.26.0",
    "assert-diff": "^3.0.2",
    "benchmark": "^2.1.4",
    "c8": "^10.1.1",
    "error-stack-parser": "^2.0.3",
    "eslint-config-prettier": "^10.0.2",
    "eslint-plugin-async-await": "^0.0.0",
    "eslint-plugin-markdown": "^5.1.0",
    "eslint-plugin-prettier": "^5.2.3",
    "globals": "^16.0.0",
    "poku": "^3.0.0",
    "portfinder": "^1.0.28",
    "prettier": "^3.0.0",
    "typescript": "^5.0.2"
  }
}
</file>

<file path="promise.d.ts">
import { EventEmitter } from 'events';

import {
  RowDataPacket,
  OkPacket,
  ResultSetHeader,
  FieldPacket,
  QueryOptions,
  ConnectionOptions,
  PoolOptions,
  PoolClusterOptions,
  Pool as CorePool,
} from './index.js';
import { ExecutableBase as ExecutableBaseClass } from './typings/mysql/lib/protocol/sequences/promise/ExecutableBase.js';
import { QueryableBase as QueryableBaseClass } from './typings/mysql/lib/protocol/sequences/promise/QueryableBase.js';

export * from './index.js';

// Expose class interfaces
declare class QueryableAndExecutableBase extends QueryableBaseClass(
  ExecutableBaseClass(EventEmitter)
) {}

export interface PreparedStatementInfo {
  close(): Promise<void>;
  execute(
    parameters: any | any[] | { [param: string]: any }
  ): Promise<
    [
      (
        | RowDataPacket[][]
        | RowDataPacket[]
        | OkPacket
        | OkPacket[]
        | ResultSetHeader
      ),
      FieldPacket[],
    ]
  >;
}

export interface Connection extends QueryableAndExecutableBase {
  config: ConnectionOptions;

  threadId: number;

  connect(): Promise<void>;

  ping(): Promise<void>;

  beginTransaction(): Promise<void>;

  commit(): Promise<void>;

  rollback(): Promise<void>;

  changeUser(options: ConnectionOptions): Promise<void>;

  prepare(options: string | QueryOptions): Promise<PreparedStatementInfo>;

  unprepare(sql: string | QueryOptions): void;

  end(options?: any): Promise<void>;

  destroy(): void;

  pause(): void;

  resume(): void;

  escape(value: any): string;

  escapeId(value: string): string;
  escapeId(values: string[]): string;

  format(sql: string, values?: any | any[] | { [param: string]: any }): string;
}

export interface PoolConnection extends Connection {
  release(): void;
  connection: Connection;
}

export interface Pool extends Connection {
  getConnection(): Promise<PoolConnection>;

  releaseConnection(connection: PoolConnection): void;

  on(event: 'connection', listener: (connection: PoolConnection) => any): this;
  on(event: 'acquire', listener: (connection: PoolConnection) => any): this;
  on(event: 'release', listener: (connection: PoolConnection) => any): this;
  on(event: 'enqueue', listener: () => any): this;

  end(): Promise<void>;

  pool: CorePool;
}

export interface PoolNamespace extends QueryableAndExecutableBase {
  getConnection(): Promise<PoolConnection>;
}

export interface PoolCluster extends EventEmitter {
  config: PoolClusterOptions;

  add(config: PoolOptions): void;
  add(group: string, connectionUri: string): void;
  add(group: string, config: PoolOptions): void;

  end(): Promise<void>;

  getConnection(): Promise<PoolConnection>;
  getConnection(group: string): Promise<PoolConnection>;
  getConnection(group: string, selector: string): Promise<PoolConnection>;

  of(pattern: string, selector?: string): PoolNamespace;

  on(event: string, listener: (...args: any[]) => void): this;
  on(event: 'remove', listener: (nodeId: number) => void): this;
  on(event: 'warn', listener: (err: Error) => void): this;
}

export function createConnection(connectionUri: string): Promise<Connection>;
export function createConnection(
  config: ConnectionOptions
): Promise<Connection>;

export function createPool(connectionUri: string): Pool;
export function createPool(config: PoolOptions): Pool;

export function createPoolCluster(config?: PoolClusterOptions): PoolCluster;
</file>

<file path="promise.js">
'use strict';

const SqlString = require('sqlstring');
const EventEmitter = require('events').EventEmitter;
const parserCache = require('./lib/parsers/parser_cache.js');
const PoolCluster = require('./lib/pool_cluster.js');
const createConnection = require('./lib/create_connection.js');
const createPool = require('./lib/create_pool.js');
const createPoolCluster = require('./lib/create_pool_cluster.js');
const PromiseConnection = require('./lib/promise/connection.js');
const PromisePool = require('./lib/promise/pool.js');
const makeDoneCb = require('./lib/promise/make_done_cb.js');
const PromisePoolConnection = require('./lib/promise/pool_connection.js');
const inheritEvents = require('./lib/promise/inherit_events.js');
const PromisePoolNamespace = require('./lib/promise/pool_cluster');

function createConnectionPromise(opts) {
  const coreConnection = createConnection(opts);
  const createConnectionErr = new Error();
  const thePromise = opts.Promise || Promise;
  if (!thePromise) {
    throw new Error(
      'no Promise implementation available.' +
        'Use promise-enabled node version or pass userland Promise' +
        " implementation as parameter, for example: { Promise: require('bluebird') }"
    );
  }
  return new thePromise((resolve, reject) => {
    coreConnection.once('connect', () => {
      resolve(new PromiseConnection(coreConnection, thePromise));
    });
    coreConnection.once('error', (err) => {
      createConnectionErr.message = err.message;
      createConnectionErr.code = err.code;
      createConnectionErr.errno = err.errno;
      createConnectionErr.sqlState = err.sqlState;
      reject(createConnectionErr);
    });
  });
}

// note: the callback of "changeUser" is not called on success
// hence there is no possibility to call "resolve"

function createPromisePool(opts) {
  const corePool = createPool(opts);
  const thePromise = opts.Promise || Promise;
  if (!thePromise) {
    throw new Error(
      'no Promise implementation available.' +
        'Use promise-enabled node version or pass userland Promise' +
        " implementation as parameter, for example: { Promise: require('bluebird') }"
    );
  }

  return new PromisePool(corePool, thePromise);
}

class PromisePoolCluster extends EventEmitter {
  constructor(poolCluster, thePromise) {
    super();
    this.poolCluster = poolCluster;
    this.Promise = thePromise || Promise;
    inheritEvents(poolCluster, this, ['warn', 'remove', 'online', 'offline']);
  }

  getConnection(pattern, selector) {
    const corePoolCluster = this.poolCluster;
    return new this.Promise((resolve, reject) => {
      corePoolCluster.getConnection(
        pattern,
        selector,
        (err, coreConnection) => {
          if (err) {
            reject(err);
          } else {
            resolve(new PromisePoolConnection(coreConnection, this.Promise));
          }
        }
      );
    });
  }

  query(sql, args) {
    const corePoolCluster = this.poolCluster;
    const localErr = new Error();
    if (typeof args === 'function') {
      throw new Error(
        'Callback function is not available with promise clients.'
      );
    }
    return new this.Promise((resolve, reject) => {
      const done = makeDoneCb(resolve, reject, localErr);
      corePoolCluster.query(sql, args, done);
    });
  }

  execute(sql, args) {
    const corePoolCluster = this.poolCluster;
    const localErr = new Error();
    if (typeof args === 'function') {
      throw new Error(
        'Callback function is not available with promise clients.'
      );
    }
    return new this.Promise((resolve, reject) => {
      const done = makeDoneCb(resolve, reject, localErr);
      corePoolCluster.execute(sql, args, done);
    });
  }

  of(pattern, selector) {
    return new PromisePoolNamespace(
      this.poolCluster.of(pattern, selector),
      this.Promise
    );
  }

  end() {
    const corePoolCluster = this.poolCluster;
    const localErr = new Error();
    return new this.Promise((resolve, reject) => {
      corePoolCluster.end((err) => {
        if (err) {
          localErr.message = err.message;
          localErr.code = err.code;
          localErr.errno = err.errno;
          localErr.sqlState = err.sqlState;
          localErr.sqlMessage = err.sqlMessage;
          reject(localErr);
        } else {
          resolve();
        }
      });
    });
  }
}

/**
 * proxy poolCluster synchronous functions
 */
(function (functionsToWrap) {
  for (let i = 0; functionsToWrap && i < functionsToWrap.length; i++) {
    const func = functionsToWrap[i];

    if (
      typeof PoolCluster.prototype[func] === 'function' &&
      PromisePoolCluster.prototype[func] === undefined
    ) {
      PromisePoolCluster.prototype[func] = (function factory(funcName) {
        return function () {
          return PoolCluster.prototype[funcName].apply(
            this.poolCluster,
            arguments
          );
        };
      })(func);
    }
  }
})(['add', 'remove']);

function createPromisePoolCluster(opts) {
  const corePoolCluster = createPoolCluster(opts);
  const thePromise = (opts && opts.Promise) || Promise;
  if (!thePromise) {
    throw new Error(
      'no Promise implementation available.' +
        'Use promise-enabled node version or pass userland Promise' +
        " implementation as parameter, for example: { Promise: require('bluebird') }"
    );
  }
  return new PromisePoolCluster(corePoolCluster, thePromise);
}

exports.createConnection = createConnectionPromise;
exports.createPool = createPromisePool;
exports.createPoolCluster = createPromisePoolCluster;
exports.escape = SqlString.escape;
exports.escapeId = SqlString.escapeId;
exports.format = SqlString.format;
exports.raw = SqlString.raw;
exports.PromisePool = PromisePool;
exports.PromiseConnection = PromiseConnection;
exports.PromisePoolConnection = PromisePoolConnection;

exports.__defineGetter__('Types', () => require('./lib/constants/types.js'));

exports.__defineGetter__('Charsets', () =>
  require('./lib/constants/charsets.js')
);

exports.__defineGetter__('CharsetToEncoding', () =>
  require('./lib/constants/charset_encodings.js')
);

exports.setMaxParserCache = function (max) {
  parserCache.setMaxCache(max);
};

exports.clearParserCache = function () {
  parserCache.clearCache();
};
</file>

<file path="README.md">
[npm-image]: https://img.shields.io/npm/v/mysql2.svg
[npm-url]: https://npmjs.com/package/mysql2
[node-version-image]: https://img.shields.io/node/v/mysql2.svg
[node-version-url]: https://nodejs.org/en/download
[downloads-image]: https://img.shields.io/npm/dm/mysql2.svg
[downloads-url]: https://npmjs.com/package/mysql2
[license-url]: https://github.com/sidorares/node-mysql2/blob/master/License
[license-image]: https://img.shields.io/npm/l/mysql2.svg?maxAge=2592000
[node-mysql]: https://github.com/mysqljs/mysql
[mysqljs]: https://github.com/mysqljs
[mysql-native]: https://github.com/sidorares/nodejs-mysql-native
[sidorares]: https://github.com/sidorares
[TooTallNate]: https://gist.github.com/TooTallNate
[starttls.js]: https://gist.github.com/TooTallNate/848444
[node-mariasql]: https://github.com/mscdex/node-mariasql
[contributors]: https://github.com/sidorares/node-mysql2/graphs/contributors
[contributing]: https://github.com/sidorares/node-mysql2/blob/master/Contributing.md
[docs-base]: https://sidorares.github.io/node-mysql2/docs
[docs-base-zh-CN]: https://sidorares.github.io/node-mysql2/zh-CN/docs
[docs-base-pt-BR]: https://sidorares.github.io/node-mysql2/pt-BR/docs
[docs-prepared-statements]: https://sidorares.github.io/node-mysql2/docs/documentation/prepared-statements
[docs-mysql-server]: https://sidorares.github.io/node-mysql2/docs/documentation/mysql-server
[docs-promise-wrapper]: https://sidorares.github.io/node-mysql2/docs/documentation/promise-wrapper
[docs-authentication-switch]: https://sidorares.github.io/node-mysql2/docs/documentation/authentication-switch
[docs-streams]: https://sidorares.github.io/node-mysql2/docs/documentation/extras
[docs-typescript-docs]: https://sidorares.github.io/node-mysql2/docs/documentation/typescript-examples
[docs-qs-pooling]: https://sidorares.github.io/node-mysql2/docs#using-connection-pools
[docs-qs-first-query]: https://sidorares.github.io/node-mysql2/docs#first-query
[docs-qs-using-prepared-statements]: https://sidorares.github.io/node-mysql2/docs#using-prepared-statements
[docs-examples]: https://sidorares.github.io/node-mysql2/docs/examples
[docs-faq]: https://sidorares.github.io/node-mysql2/docs/faq
[docs-documentation]: https://sidorares.github.io/node-mysql2/docs/documentation
[docs-contributing]: https://sidorares.github.io/node-mysql2/docs/contributing/website
[coverage]: https://img.shields.io/codecov/c/github/sidorares/node-mysql2
[coverage-url]: https://app.codecov.io/github/sidorares/node-mysql2
[ci-url]: https://github.com/sidorares/node-mysql2/actions/workflows/ci-coverage.yml?query=branch%3Amaster
[ci-image]: https://img.shields.io/github/actions/workflow/status/sidorares/node-mysql2/ci-coverage.yml?event=push&style=flat&label=CI&branch=master

# MySQL2

[![NPM Version][npm-image]][npm-url]
[![NPM Downloads][downloads-image]][downloads-url]
[![Node.js Version][node-version-image]][node-version-url]
[![GitHub Workflow Status (with event)][ci-image]][ci-url]
[![Codecov][coverage]][coverage-url]
[![License][license-image]][license-url]

[English][docs-base] | [简体中文][docs-base-zh-CN] | [Português (BR)][docs-base-pt-BR]

> MySQL client for Node.js with focus on performance. Supports prepared statements, non-utf8 encodings, binary log protocol, compression, ssl [much more][docs-documentation].

**Table of Contents**

- [History and Why MySQL2](#history-and-why-mysql2)
- [Installation](#installation)
- [Documentation](#documentation)
- [Acknowledgements](#acknowledgements)
- [Contributing](#contributing)

## History and Why MySQL2

MySQL2 project is a continuation of [MySQL-Native][mysql-native]. Protocol parser code was rewritten from scratch and api changed to match popular [Node MySQL][node-mysql]. MySQL2 team is working together with [Node MySQL][node-mysql] team to factor out shared code and move it under [mysqljs][mysqljs] organization.

MySQL2 is mostly API compatible with [Node MySQL][node-mysql] and supports majority of features. MySQL2 also offers these additional features:

- Faster / Better Performance
- [Prepared Statements][docs-prepared-statements]
- MySQL Binary Log Protocol
- [MySQL Server][docs-mysql-server]
- Extended support for Encoding and Collation
- [Promise Wrapper][docs-promise-wrapper]
- Compression
- SSL and [Authentication Switch][docs-authentication-switch]
- [Custom Streams][docs-streams]
- [Pooling][docs-qs-pooling]

## Installation

MySQL2 is free from native bindings and can be installed on Linux, Mac OS or Windows without any issues.

```bash
npm install --save mysql2
```

If you are using TypeScript, you will need to install `@types/node`.

```bash
npm install --save-dev @types/node
```

> For TypeScript documentation and examples, see [here][docs-typescript-docs].

## Documentation

- [Quickstart][docs-base]
  - [First Query][docs-qs-first-query], [Using Prepared Statements][docs-qs-using-prepared-statements], [Using Connection Pools][docs-qs-pooling] and more.
- [Documentation][docs-documentation]
- [Examples][docs-examples]
- [FAQ][docs-faq]

## Acknowledgements

- Internal protocol is written by [@sidorares][sidorares] [MySQL-Native][mysql-native].
- Constants, SQL parameters interpolation, Pooling, `ConnectionConfig` class taken from [Node MySQL][node-mysql].
- SSL upgrade code based on [@TooTallNate][TooTallNate] [code][starttls.js].
- Secure connection / compressed connection api flags compatible to [MariaSQL][node-mariasql] client.
- [Contributors][contributors].

## Contributing

Want to improve something in **MySQL2**?
Please check [Contributing.md][contributing] for detailed instruction on how to get started.

To contribute in **MySQL2 Documentation**, please visit the [Website Contributing Guidelines][docs-contributing] for detailed instruction on how to get started.
</file>

<file path="SECURITY.md">
# Security Policy

## Reporting a Vulnerability

**Please do not file a public ticket** mentioning the vulnerability.

If you believe you found a security vulnerability please contact [current maintainer](mailto:andrey.sidorov@gmail.com?subject=mysql2%20security%20vulnerability%20report) as soon as practical - the team will triage severity and plan for rectification.
</file>

<file path="tea.yaml">
# https://tea.xyz/what-is-this-file
---
version: 1.0.0
codeOwners:
  - '0xE29b117AD9088c71DC0BC48CA84Ff7328Ab3bfd1'
  - '0xCd4AB81DBe170a88717F952d28a3e6319E9Ce2E2'
quorum: 1
</file>

<file path="test/common.test.cjs">
'use strict';

const fs = require('node:fs');
const path = require('node:path');
const process = require('node:process');

const disableEval = process.env.STATIC_PARSER === '1';
exports.disableEval = disableEval;

const config = {
  host: process.env.MYSQL_HOST || 'localhost',
  user: process.env.MYSQL_USER || 'root',
  password: (process.env.CI ? process.env.MYSQL_PASSWORD : '') || '',
  database: process.env.MYSQL_DATABASE || 'test',
  compress: process.env.MYSQL_USE_COMPRESSION,
  port: process.env.MYSQL_PORT || 3306,
  disableEval,
};

if (process.env.MYSQL_USE_TLS === '1') {
  config.ssl = {
    rejectUnauthorized: false,
    ca: fs.readFileSync(
      path.join(__dirname, '../test/fixtures/ssl/certs/ca.pem'),
      'utf-8'
    ),
  };
}

const configURI = `mysql://${config.user}:${config.password}@${config.host}:${config.port}/${config.database}`;

exports.SqlString = require('sqlstring');
exports.config = config;

exports.waitDatabaseReady = function (callback) {
  const start = Date.now();
  const timeout = 300000; // 5 minutes in milliseconds

  const tryConnect = function () {
    if (Date.now() - start > timeout) {
      console.log('Connection attempt timed out after 5 minutes.');
      process.exit(1);
    }

    const conn = exports.createConnection({
      database: 'mysql',
      password: process.env.MYSQL_PASSWORD,
    });

    conn.once('error', (err) => {
      if (
        err.code !== 'PROTOCOL_CONNECTION_LOST' &&
        err.code !== 'ETIMEDOUT' &&
        err.code !== 'ECONNREFUSED'
      ) {
        console.log('Unexpected error waiting for connection', err);
        process.exit(-1);
      }

      try {
        conn.close();
      } catch (err) {
        console.log(err);
      }

      console.log('not ready');
      setTimeout(tryConnect, 1000);
    });

    conn.once('connect', () => {
      console.log(`ready after ${Date.now() - start}ms!`);
      conn.close();
      callback();
    });
  };

  tryConnect();
};

exports.createConnection = function (args) {
  const driver = require('../index.js');
  if (!args?.port && process.env.MYSQL_CONNECTION_URL) {
    return driver.createConnection({
      ...args,
      uri: process.env.MYSQL_CONNECTION_URL,
    });
  }

  if (!args) {
    args = {};
  }

  const params = {
    host: args.host || config.host,
    rowsAsArray: args.rowsAsArray,
    user: (args && args.user) || config.user,
    password: (args && args.password) || config.password,
    database: (args && args.database) || config.database,
    multipleStatements: args ? args.multipleStatements : false,
    port: (args && args.port) || config.port,
    debug: process.env.DEBUG || (args && args.debug),
    supportBigNumbers: args && args.supportBigNumbers,
    bigNumberStrings: args && args.bigNumberStrings,
    compress: (args && args.compress) || config.compress,
    decimalNumbers: args && args.decimalNumbers,
    charset: args && args.charset,
    timezone: args && args.timezone,
    dateStrings: args && args.dateStrings,
    authSwitchHandler: args && args.authSwitchHandler,
    typeCast: args && args.typeCast,
    namedPlaceholders: args && args.namedPlaceholders,
    connectTimeout: args && args.connectTimeout,
    nestTables: args && args.nestTables,
    ssl: (args && args.ssl) ?? config.ssl,
    jsonStrings: args && args.jsonStrings,
    disableEval,
  };

  const conn = driver.createConnection(params);
  return conn;
};

exports.getConfig = function (input) {
  const args = input || {};
  const params = {
    host: args.host || config.host,
    rowsAsArray: args.rowsAsArray,
    user: (args && args.user) || config.user,
    password: (args && args.password) || config.password,
    database: (args && args.database) || config.database,
    multipleStatements: args ? args.multipleStatements : false,
    port: (args && args.port) || config.port,
    debug: process.env.DEBUG || (args && args.debug),
    supportBigNumbers: args && args.supportBigNumbers,
    bigNumberStrings: args && args.bigNumberStrings,
    compress: (args && args.compress) || config.compress,
    decimalNumbers: args && args.decimalNumbers,
    charset: args && args.charset,
    timezone: args && args.timezone,
    dateStrings: args && args.dateStrings,
    authSwitchHandler: args && args.authSwitchHandler,
    typeCast: args && args.typeCast,
    connectionLimit: args && args.connectionLimit,
    maxIdle: args && args.maxIdle,
    idleTimeout: args && args.idleTimeout,
    jsonStrings: args && args.jsonStrings,
    disableEval,
  };
  return params;
};

exports.createPool = function (args) {
  let driver = require('../index.js');
  if (!args?.port && process.env.MYSQL_CONNECTION_URL) {
    return driver.createPool({
      ...args,
      uri: process.env.MYSQL_CONNECTION_URL,
    });
  }

  if (!args) {
    args = {};
  }

  if (process.env.BENCHMARK_MYSQL1) {
    driver = require('mysql');
  }

  return driver.createPool(exports.getConfig(args));
};

exports.createPoolCluster = function (args = {}) {
  const driver = require('../index.js');
  if (!args?.port && process.env.MYSQL_CONNECTION_URL) {
    return driver.createPoolCluster({
      ...args,
      uri: process.env.MYSQL_CONNECTION_URL,
    });
  }
  return driver.createPoolCluster(args);
};

exports.createConnectionWithURI = function () {
  const driver = require('../index.js');

  return driver.createConnection({ uri: configURI });
};

exports.createTemplate = function () {
  const jade = require('jade');
  const template = require('node:fs').readFileSync(
    `${__dirname}/template.jade`,
    'ascii'
  );
  return jade.compile(template);
};

const ClientFlags = require('../lib/constants/client.js');

const portfinder = require('portfinder');

exports.createServer = function (onListening, handler) {
  const server = require('../index.js').createServer();
  server.on('connection', (conn) => {
    conn.on('error', () => {
      // server side of the connection
      // ignore disconnects
    });
    // remove ssl bit from the flags
    let flags = 0xffffff;
    flags = flags ^ (ClientFlags.COMPRESS | ClientFlags.SSL);

    conn.serverHandshake({
      protocolVersion: 10,
      serverVersion: 'node.js rocks',
      connectionId: 1234,
      statusFlags: 2,
      characterSet: 8,
      capabilityFlags: flags,
    });
    if (handler) {
      handler(conn);
    }
  });
  portfinder.getPort((err, port) => {
    server.listen(port, onListening);
  });
  return server;
};

exports.useTestDb = function () {
  // no-op in my setup, need it for compatibility with node-mysql tests
};

exports.version = Number(process.version.match(/v(\d+)\./)?.[1]);

exports.describeOptions = {
  icon: '🔬',
  background: false,
};

exports.getMysqlVersion = async function (connection) {
  const conn = connection.promise ? connection.promise() : connection;

  const [rows] = await conn.query('SELECT VERSION() AS `version`');
  const serverVersion = rows[0].version;

  const [major, minor, patch] = serverVersion
    .split('.')
    .map((x) => parseInt(x, 10));

  return {
    major,
    minor,
    patch,
  };
};
</file>

<file path="test/esm/integration/connection/test-column-inspect.test.mjs">
import { test, assert, describe, beforeEach } from 'poku';
import util from 'node:util';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const common = require('../../../common.test.cjs');

(async () => {
  const connection = common.createConnection().promise();

  describe('Custom inspect for column definition', common.describeOptions);

  beforeEach(
    async () => await connection.query(`DROP TABLE IF EXISTS test_fields`),
    { assert: false }
  );

  await test(async () => {
    const schema = `
        id INT NOT NULL AUTO_INCREMENT,
        weight INT(2) UNSIGNED ZEROFILL,
        usignedInt INT UNSIGNED NOT NULL,
        signedInt INT NOT NULL,
        unsignedShort SMALLINT UNSIGNED NOT NULL,
        signedShort SMALLINT NOT NULL,
        tinyIntUnsigned TINYINT UNSIGNED NOT NULL,
        tinyIntSigned TINYINT NOT NULL,
        mediumIntUnsigned MEDIUMINT UNSIGNED NOT NULL,
        mediumIntSigned MEDIUMINT NOT NULL,
        bigIntSigned BIGINT NOT NULL,
        bigIntUnsigned BIGINT UNSIGNED NOT NULL,
        longText_ LONGTEXT NOT NULL,
        mediumText_ MEDIUMTEXT NOT NULL,
        text_ TEXT NOT NULL,
        tinyText_ TINYTEXT NOT NULL,
        varString_1000 VARCHAR(1000) NOT NULL,
        decimalDefault DECIMAL,
        decimal13_10 DECIMAL(13,10),
        floatDefault FLOAT,
        float11_7 FLOAT(11,7),
        dummyLastFieldToAllowForTrailingComma INT,
      `;

    await connection.query(
      `CREATE TEMPORARY TABLE test_fields (${schema} PRIMARY KEY (id))`
    );

    const [, columns] = await connection.query('select * from test_fields');
    const inspectResults = util.inspect(columns);
    const schemaArray = schema
      .split('\n')
      .map((line) => line.trim())
      .filter((line) => line.length > 0)
      .map((line) => {
        const words = line.split(' ');
        const name = `\`${words[0]}\``;
        return [name, ...words.slice(1)].join(' ');
      });

    const normalizedInspectResults = inspectResults
      .split('\n')
      .slice(1, -2) // remove "[" and "]" lines and also last dummy field
      .map((line) => line.trim())
      // remove primary key - it's not in the schema explicitly but worth having in inspect
      .map((line) => line.split('PRIMARY KEY ').join(''));

    for (let l = 0; l < normalizedInspectResults.length; l++) {
      const inspectLine = normalizedInspectResults[l];
      const schemaLine = schemaArray[l];

      assert.equal(
        inspectLine,
        schemaLine,
        'Loop: Should map fields to a schema-like description when depth is > 1'
      );
    }
  });

  common.version >= 16 &&
    (await test(async () => {
      await connection.query(`
        CREATE TEMPORARY TABLE test_fields2 (
            id INT,
            decimal13_10 DECIMAL(13,10) UNSIGNED NOT NULL,
            PRIMARY KEY (id)
        )
      `);

      const [, columns] = await connection.query('select * from test_fields2');
      const inspectResults = util.inspect(columns[1]);

      assert.deepEqual(
        inspectResults,
        util.inspect({
          catalog: 'def',
          schema: 'test',
          name: 'decimal13_10',
          orgName: 'decimal13_10',
          table: 'test_fields2',
          orgTable: 'test_fields2',
          characterSet: 63,
          encoding: 'binary',
          columnLength: 14,
          type: 246,
          flags: ['NOT NULL'],
          decimals: 10,
          typeName: 'NEWDECIMAL',
        }),
        'should show detailed description when depth is < 1'
      );
    }));

  await connection.end();
})();
</file>

<file path="test/esm/integration/connection/test-execute-1.test.mjs">
import { test, assert, describe } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const common = require('../../../common.test.cjs');

(async () => {
  const connection = common.createConnection().promise();

  await test(async () => {
    describe(
      'Simple execute should return expected values',
      common.describeOptions
    );

    const [_rows, _fields] = await connection.execute('SELECT 1 as test');

    assert.deepEqual(
      _rows,
      [{ test: 1 }],
      'should execute simple SELECT 1 statement'
    );
    assert.equal(_fields[0].name, 'test', 'should field name test');
  });

  await test(async () => {
    describe(
      'Simple execute with parameters should return expected values',
      common.describeOptions
    );

    const [_rows, _fields] = await connection.execute('SELECT 1+? as test', [
      123,
    ]);

    assert.deepEqual(
      _rows,
      [{ test: 124 }],
      'should execute simple SELECT 1+? statement'
    );
    assert.equal(_fields[0].name, 'test', 'should field name test');
  });

  await test(async () => {
    describe(
      'should execute simple INSERT + SELECT statements',
      common.describeOptions
    );

    await connection.query(
      [
        'CREATE TEMPORARY TABLE `announcements` (',
        '`id` int(11) NOT NULL AUTO_INCREMENT,',
        '`title` varchar(255) DEFAULT NULL,',
        '`text` varchar(255) DEFAULT NULL,',
        'PRIMARY KEY (`id`)',
        ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
      ].join('\n')
    );

    await connection.execute(
      'INSERT INTO announcements(title, text) VALUES(?, ?)',
      ['Есть место, где заканчивается тротуар', 'Расти борода, расти']
    );
    connection.execute('INSERT INTO announcements(title, text) VALUES(?, ?)', [
      'Граждане Российской Федерации имеют право собираться мирно без оружия',
      'проводить собрания, митинги и демонстрации, шествия и пикетирование',
    ]);

    const [_rows] = await connection.execute('SELECT * FROM announcements');

    assert.equal(_rows.length, 2, 'rows length needs to be 2');
    assert.equal(
      _rows[0].title,
      'Есть место, где заканчивается тротуар',
      'first row title'
    );
    assert.equal(_rows[0].text, 'Расти борода, расти', 'first row text');
    assert.equal(
      _rows[1].title,
      'Граждане Российской Федерации имеют право собираться мирно без оружия',
      'second row title'
    );
    assert.equal(
      _rows[1].text,
      'проводить собрания, митинги и демонстрации, шествия и пикетирование',
      'second row text'
    );
  });

  await connection.end();
})();
</file>

<file path="test/esm/integration/connection/test-vector.test.mjs">
import { test, assert, describe } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const common = require('../../../common.test.cjs');

const sql = `SELECT TO_VECTOR("[1.05, -17.8, 32, 123.456]") as test`;
const expectedArray = [1.05, -17.8, 32, 123.456];
const epsilon = 1e-6;

const compareFloat = (a, b) => Math.abs((a - b) / a) < epsilon;
const compareFLoatsArray = (a, b) => a.every((v, i) => compareFloat(v, b[i]));

(async () => {
  const connection = common.createConnection().promise();

  const mySqlVersion = await common.getMysqlVersion(connection);

  if (mySqlVersion.major < 9) {
    console.log(
      `Skipping the test, required mysql version is 9 and above, actual version is ${mySqlVersion.major}`
    );
    await connection.end();
    return;
  }

  await test(async () => {
    describe(
      'Execute PS with vector response is parsed correctly',
      common.describeOptions
    );

    const [_rows] = await connection.execute(sql);
    assert.equal(
      compareFLoatsArray(_rows[0].test, expectedArray),
      true,
      `${_rows[0].test} should be equal to ${expectedArray}`
    );
  });

  await test(async () => {
    describe(
      'Select returning vector is parsed correctly',
      common.describeOptions
    );

    const [_rows] = await connection.query(sql);
    assert.equal(
      compareFLoatsArray(_rows[0].test, expectedArray),
      true,
      `${_rows[0].test}  should be equal to  ${expectedArray}`
    );
  });

  await connection.end();
})();
</file>

<file path="test/esm/integration/named-placeholders.test.mjs">
// TODO: `namedPlaceholders` can't be disabled at query level
import { assert, test, describe } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const {
  createConnection,
  describeOptions,
  createPool,
} = require('../../common.test.cjs');

const query =
  'SELECT result FROM (SELECT 1 as result) temp WHERE temp.result=:named';
const values = { named: 1 };

describe(
  'Test namedPlaceholder as command parameter in connection',
  describeOptions
);

// test(() => {
//   const c = createConnection({ namedPlaceholders: true });

//   c.query({ sql: query, namedPlaceholders: false }, values, (err) => {
//     c.end();

//     assert(
//       err || err?.sqlMessage.match(/right syntax to use near ':named'/),
//       'Enabled in connection config, disabled in query command',
//     );
//   });
// });

test(() => {
  const c = createConnection({ namedPlaceholders: false });

  c.query({ sql: query, namedPlaceholders: true }, values, (err, rows) => {
    c.end();

    assert.ifError(err);
    assert.equal(
      rows[0].result,
      1,
      'Disabled in connection config, enabled in query command'
    );
  });
});

// test(() => {
//   const c = createConnection({ namedPlaceholders: true });

//   c.execute({ sql: query, namedPlaceholders: false }, values, (err) => {
//     c.end();

//     assert(
//       err || err?.sqlMessage.match(/right syntax to use near ':named'/),
//       'Enabled in connection config, disabled in execute command',
//     );
//   });
// });

test(() => {
  const c = createConnection({ namedPlaceholders: false });

  c.execute({ sql: query, namedPlaceholders: true }, values, (err, rows) => {
    c.end();

    assert.ifError(err);
    assert.equal(
      rows[0].result,
      1,
      'Disabled in connection config, enabled in execute command'
    );
  });
});

// test(() => {
//   const c = createPool({ namedPlaceholders: true });

//   c.query({ sql: query, namedPlaceholders: false }, values, (err) => {
//     c.end();

//     assert(
//       err || err?.sqlMessage.match(/right syntax to use near ':named'/),
//       'Enabled in pool config, disabled in query command',
//     );
//   });
// });

test(() => {
  const c = createPool({ namedPlaceholders: false });

  c.query({ sql: query, namedPlaceholders: true }, values, (err, rows) => {
    c.end();

    assert.ifError(err);
    assert.equal(
      rows[0].result,
      1,
      'Disabled in pool config, enabled in query command'
    );
  });
});

// test(() => {
//   const c = createPool({ namedPlaceholders: true });

//   c.execute({ sql: query, namedPlaceholders: false }, values, (err) => {
//     c.end();

//     assert(
//       err || err?.sqlMessage.match(/right syntax to use near ':named'/),
//       'Enabled in pool config, disabled in execute command',
//     );
//   });
// });

test(() => {
  const c = createPool({ namedPlaceholders: false });

  c.execute({ sql: query, namedPlaceholders: true }, values, (err, rows) => {
    c.end();

    assert.ifError(err);
    assert.equal(
      rows[0].result,
      1,
      'Disabled in pool config, enabled in execute command'
    );
  });
});
</file>

<file path="test/esm/integration/parsers/execute-results-creation.test.mjs">
import { test, describe, assert } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const {
  createConnection,
  describeOptions,
} = require('../../../common.test.cjs');

const connection = createConnection().promise();

describe('Execute: Results Creation', describeOptions);

Promise.all([
  test(async () => {
    const expected = [
      {
        test: 2,
      },
    ];
    const emptyObject = {};
    const proto = Object.getPrototypeOf(emptyObject);
    const privateObjectProps = Object.getOwnPropertyNames(proto);

    const [results] = await connection.execute('SELECT 1+1 AS `test`');

    assert.deepStrictEqual(results, expected, 'Ensure exact object "results"');
    assert.deepStrictEqual(
      Object.getOwnPropertyNames(results[0]),
      Object.getOwnPropertyNames(expected[0]),
      'Deep ensure exact object "results"'
    );
    assert.deepStrictEqual(
      Object.getPrototypeOf(results[0]),
      Object.getPrototypeOf({}),
      'Ensure clean properties in results items'
    );

    privateObjectProps.forEach((prop) => {
      assert(prop in results[0], `Ensure ${prop} exists`);
    });

    results[0].customProp = true;
    assert.strictEqual(
      results[0].customProp,
      true,
      'Ensure that the end-user is able to use custom props'
    );
  }),
  test(async () => {
    const [result] = await connection.execute('SET @1 = 1;');

    assert.strictEqual(
      result.constructor.name,
      'ResultSetHeader',
      'Ensure constructor name in result object'
    );
  }),
]).then(async () => {
  await connection.end();
});
</file>

<file path="test/esm/integration/parsers/json-parse.test.mjs">
import { test, describe, assert } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const {
  createConnection,
  describeOptions,
} = require('../../../common.test.cjs');

describe('JSON Parser', describeOptions);

const connection = createConnection().promise();

Promise.all([
  test(async () => {
    const [result] = await connection.query(
      `SELECT CAST('{"test": true}' AS JSON) AS json_result`
    );

    assert.deepStrictEqual(
      result[0].json_result,
      { test: true },
      'Ensure JSON return parsed (query)'
    );
  }),
  test(async () => {
    const [result] = await connection.execute(
      `SELECT CAST('{"test": true}' AS JSON) AS json_result`
    );

    assert.deepStrictEqual(
      result[0].json_result,
      { test: true },
      'Ensure JSON return parsed (execute)'
    );
  }),
]).then(async () => {
  await connection.end();
});
</file>

<file path="test/esm/integration/parsers/json-string.test.mjs">
import { test, describe, assert } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const {
  createConnection,
  describeOptions,
} = require('../../../common.test.cjs');

describe('JSON String', describeOptions);

const connection = createConnection({
  jsonStrings: true,
}).promise();

Promise.all([
  test(async () => {
    const [result] = await connection.query(
      `SELECT CAST('{"test": true}' AS JSON) AS json_result`
    );

    assert.deepStrictEqual(
      result[0].json_result,
      '{"test": true}',
      'Ensure JSON return as string (query)'
    );
  }),
  test(async () => {
    const [result] = await connection.execute(
      `SELECT CAST('{"test": true}' AS JSON) AS json_result`
    );

    assert.deepStrictEqual(
      result[0].json_result,
      '{"test": true}',
      'Ensure JSON return as string (execute)'
    );
  }),
]).then(async () => {
  await connection.end();
});
</file>

<file path="test/esm/integration/parsers/query-results-creation.test.mjs">
import { test, describe, assert } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const {
  createConnection,
  describeOptions,
} = require('../../../common.test.cjs');

const connection = createConnection().promise();

describe('Query: Results Creation', describeOptions);

Promise.all([
  test(async () => {
    const expected = [
      {
        test: 2,
      },
    ];
    const emptyObject = {};
    const proto = Object.getPrototypeOf(emptyObject);
    const privateObjectProps = Object.getOwnPropertyNames(proto);

    const [results] = await connection.query('SELECT 1+1 AS `test`');

    assert.deepStrictEqual(results, expected, 'Ensure exact object "results"');
    assert.deepStrictEqual(
      Object.getOwnPropertyNames(results[0]),
      Object.getOwnPropertyNames(expected[0]),
      'Deep ensure exact object "results"'
    );
    assert.deepStrictEqual(
      Object.getPrototypeOf(results[0]),
      Object.getPrototypeOf({}),
      'Ensure clean properties in results items'
    );

    privateObjectProps.forEach((prop) => {
      assert(prop in results[0], `Ensure ${prop} exists`);
    });

    results[0].customProp = true;
    assert.strictEqual(
      results[0].customProp,
      true,
      'Ensure that the end-user is able to use custom props'
    );
  }),
  test(async () => {
    const [result] = await connection.query('SET @1 = 1;');

    assert.strictEqual(
      result.constructor.name,
      'ResultSetHeader',
      'Ensure constructor name in result object'
    );
  }),
]).then(async () => {
  await connection.end();
});
</file>

<file path="test/esm/integration/parsers/typecast-field-string.test.mjs">
import { describe, assert } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const {
  createConnection,
  describeOptions,
} = require('../../../common.test.cjs');

const conn = createConnection({
  typeCast: (field) => field.string(),
}).promise();

describe('typeCast field.string', describeOptions);

const query = {};
const execute = {};

await conn.query(
  'CREATE TEMPORARY TABLE `tmp_tiny` (`signed` TINYINT, `unsigned` TINYINT UNSIGNED)'
);
await conn.query('CREATE TEMPORARY TABLE `tmp_date` (`timestamp` TIMESTAMP)');

await conn.query('INSERT INTO `tmp_tiny` (`signed`, `unsigned`) VALUES (0, 1)');
await conn.query(
  'INSERT INTO `tmp_date` (`timestamp`) VALUES (CURRENT_TIMESTAMP())'
);

{
  const [date] = await conn.query(
    'SELECT STR_TO_DATE("2022-06-28", "%Y-%m-%d") AS `date`'
  );
  const [time] = await conn.query(
    'SELECT STR_TO_DATE("12:34:56", "%H:%i:%s") AS `time`'
  );
  const [datetime] = await conn.query(
    'SELECT STR_TO_DATE("2022-06-28 12:34:56", "%Y-%m-%d %H:%i:%s") AS `datetime`'
  );
  const [timestamp] = await conn.query('SELECT `timestamp` FROM `tmp_date`');
  const [tiny] = await conn.query(
    'SELECT `signed`, `unsigned` FROM `tmp_tiny`'
  );

  query.date = date[0].date;
  query.time = time[0].time;
  query.timestamp = timestamp[0].timestamp;
  query.datetime = datetime[0].datetime;
  query.tiny = tiny[0];
}

{
  const [date] = await conn.execute(
    'SELECT STR_TO_DATE("2022-06-28", "%Y-%m-%d") AS `date`'
  );
  const [time] = await conn.execute(
    'SELECT STR_TO_DATE("12:34:56", "%H:%i:%s") AS `time`'
  );
  const [datetime] = await conn.execute(
    'SELECT STR_TO_DATE("2022-06-28 12:34:56", "%Y-%m-%d %H:%i:%s") AS `datetime`'
  );
  const [timestamp] = await conn.execute('SELECT `timestamp` FROM `tmp_date`');
  const [tiny] = await conn.execute(
    'SELECT `signed`, `unsigned` FROM `tmp_tiny`'
  );

  execute.date = date[0].date;
  execute.time = time[0].time;
  execute.timestamp = timestamp[0].timestamp;
  execute.datetime = datetime[0].datetime;
  execute.tiny = tiny[0];
}

await conn.end();

assert.deepStrictEqual(query.date, execute.date, 'DATE');
assert.deepStrictEqual(query.time, execute.time, 'TIME');
assert.deepStrictEqual(query.datetime, execute.datetime, 'DATETIME');
assert.deepStrictEqual(query.timestamp, execute.timestamp, 'TIMESTAMP');
assert.deepStrictEqual(query.tiny.signed, execute.tiny.signed, 'TINY (signed)');
assert.deepStrictEqual(
  query.tiny.unsigned,
  execute.tiny.unsigned,
  'TINY (unsigned)'
);
</file>

<file path="test/esm/integration/pool-cluster/test-promise-wrapper.test.mjs">
import { test, assert, describe } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const common = require('../../../common.test.cjs');
const { createPoolCluster } = require('../../../../promise.js');

(async () => {
  describe('Test pool cluster', common.describeOptions);

  await test(async () => {
    const poolCluster = createPoolCluster();

    poolCluster.once('warn', async function () {
      await new Promise((resolve) => {
        assert.equal(
          // eslint-disable-next-line no-invalid-this
          this,
          poolCluster,
          'should propagate warn event to promise wrapper'
        );
        resolve(true);
      });
    });

    poolCluster.poolCluster.emit('warn', new Error());
  });

  await test(async () => {
    const poolCluster = createPoolCluster();

    poolCluster.once('remove', async function () {
      await new Promise((resolve) => {
        assert.equal(
          // eslint-disable-next-line no-invalid-this
          this,
          poolCluster,
          'should propagate remove event to promise wrapper'
        );
        resolve(true);
      });
    });

    poolCluster.poolCluster.emit('remove');
  });

  await test(async () => {
    const poolCluster = createPoolCluster();

    poolCluster.once('offline', async function () {
      await new Promise((resolve) => {
        assert.equal(
          // eslint-disable-next-line no-invalid-this
          this,
          poolCluster,
          'should propagate offline event to promise wrapper'
        );
        resolve(true);
      });
    });

    poolCluster.poolCluster.emit('offline');
  });

  await test(async () => {
    const poolCluster = createPoolCluster();

    poolCluster.once('online', async function () {
      await new Promise((resolve) => {
        assert.equal(
          // eslint-disable-next-line no-invalid-this
          this,
          poolCluster,
          'should propagate online event to promise wrapper'
        );
        resolve(true);
      });
    });

    poolCluster.poolCluster.emit('online');
  });

  await test(async () => {
    const poolCluster = createPoolCluster();
    poolCluster.add('MASTER', common.config);

    const poolNamespace = poolCluster.of('MASTER');

    assert.equal(
      poolNamespace.poolNamespace,
      poolCluster.poolCluster.of('MASTER')
    );

    const connection = await poolNamespace.getConnection();

    assert.ok(connection, 'should get connection');
    connection.release();

    const [result] = await poolNamespace.query(
      'SELECT 1 as a from dual where 1 = ?',
      [1]
    );
    assert.equal(result[0]['a'], 1, 'should query successfully');

    const [result2] = await poolNamespace.execute(
      'SELECT 1 as a from dual where 1 = ?',
      [1]
    );
    assert.equal(result2[0]['a'], 1, 'should execute successfully');

    poolCluster.end();
  });

  await test(async () => {
    const poolCluster = createPoolCluster();
    poolCluster.add('SLAVE', common.config);

    try {
      await poolCluster.getConnection('SLAVE1');
      assert.fail('An error was expected');
    } catch (error) {
      assert.equal(
        error.code,
        'POOL_NOEXIST',
        'should throw when PoolNamespace does not exist'
      );
    } finally {
      poolCluster.end();
    }
  });

  await test(async () => {
    const poolCluster = createPoolCluster();
    poolCluster.add('SLAVE1', common.config);

    try {
      const connection = await poolCluster.getConnection(/SLAVE[12]/);
      assert.equal(
        connection.connection._clusterId,
        'SLAVE1',
        'should match regex pattern'
      );
    } catch (error) {
      assert.fail('should not throw');
    } finally {
      poolCluster.end();
    }
  });
})();
</file>

<file path="test/esm/integration/test-pool.test.mjs">
import { assert, test, describe } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const { describeOptions } = require('../../common.test.cjs');
const mysql = require('../../../index.js');

const poolConfig = {}; // config: { connectionConfig: {} };

const pool = mysql.createPool(poolConfig);

describe('Pool methods tests', describeOptions);

assert.equal(pool.escape(123), '123', 'escape method works correctly');

assert.equal(
  pool.escapeId('table name'),
  '`table name`',
  'escapeId method works correctly'
);

test(() => {
  const params = ['table name', 'thing'];
  assert.equal(
    pool.format('SELECT a FROM ?? WHERE b = ?', params),
    "SELECT a FROM `table name` WHERE b = 'thing'",
    'format method works correctly'
  );
});

const poolDotPromise = pool.promise();

describe('Pool.promise() methods tests', describeOptions);

assert.equal(
  poolDotPromise.escape(123),
  '123',
  'promise escape method works correctly'
);

assert.equal(
  poolDotPromise.escapeId('table name'),
  '`table name`',
  'promise escapeId method works correctly'
);

test(() => {
  const params = ['table name', 'thing'];
  assert.equal(
    poolDotPromise.format('SELECT a FROM ?? WHERE b = ?', params),
    "SELECT a FROM `table name` WHERE b = 'thing'",
    'promise format method works correctly'
  );
});

const promisePool = mysql.createPoolPromise(poolConfig);

describe('PromisePool methods tests', describeOptions);

assert.equal(
  promisePool.escape(123),
  '123',
  'PromisePool escape method works correctly'
);

assert.equal(
  promisePool.escapeId('table name'),
  '`table name`',
  'PromisePool escapeId method works correctly'
);

test(() => {
  const params = ['table name', 'thing'];
  assert.equal(
    promisePool.format('SELECT a FROM ?? WHERE b = ?', params),
    "SELECT a FROM `table name` WHERE b = 'thing'",
    'PromisePool format method works correctly'
  );
});
</file>

<file path="test/esm/regressions/2052.test.mjs">
import { assert, describe, test } from 'poku';
import { createRequire } from 'node:module';
import { Buffer } from 'node:buffer';

const require = createRequire(import.meta.url);
const common = require('../../common.test.cjs');
const packets = require('../../../lib/packets/index.js');
const PrepareCommand = require('../../../lib/commands/prepare.js');

test(async () => {
  await test(async () => {
    describe(
      'Unit Test - Prepare result with number of parameters incorrectly reported by the server',
      common.describeOptions
    );

    const connection = {
      sequenceId: 1,
      constructor: {
        statementKey: () => 0,
      },
      _handshakePacket: {},
      _resetSequenceId: () => {},
      _statements: new Map(),
      serverEncoding: 'utf8',
      clientEncoding: 'utf8',
      config: {
        charsetNumber: 33,
      },
      writePacket: (packet) => {
        // client -> server COM_PREPARE
        packet.writeHeader(1);
        assert.equal(
          packet.buffer.toString('hex'),
          '1f0000011673656c656374202a2066726f6d207573657273206f72646572206279203f',
          'should report 0 actual parameters when 1 placeholder is used in ORDER BY ?'
        );
      },
    };

    await new Promise((resolve, reject) => {
      const prepareCommand = new PrepareCommand(
        { sql: 'select * from users order by ?' },
        (err, result) => {
          try {
            assert.equal(err, null, 'expect no error');

            assert.equal(result.parameters.length, 0, 'parameters');
            assert.equal(result.columns.length, 51, 'columns');
            assert.equal(result.id, 1, 'id');

            resolve(null);
          } catch (error) {
            reject(error);
          }
        }
      );

      prepareCommand.execute(null, connection);
      const headerPacket = new packets.Packet(
        0,
        Buffer.from('0000000000010000003300010000000005000002', 'hex'),
        0,
        20
      );
      prepareCommand.execute(headerPacket, connection);
      const paramsEofPacket = new packets.Packet(
        0,
        Buffer.from('00000000fe000002002b000004', 'hex'),
        0,
        11
      );
      prepareCommand.execute(paramsEofPacket, connection);
      for (let i = 0; i < 51; ++i) {
        const columnDefinitionPacket = new packets.Packet(
          0,
          Buffer.from(
            '0000000003646566056d7973716c0475736572047573657204486f737404486f73740ce000fc030000fe034000000005000005',
            'hex'
          ),
          0,
          47
        );
        prepareCommand.execute(columnDefinitionPacket, connection);
      }
      const columnsEofPacket = new packets.Packet(
        0,
        Buffer.from('00000000fe000002002b000004', 'hex'),
        0,
        11
      );
      prepareCommand.execute(columnsEofPacket, connection);
    });
  });

  const connection = common.createConnection({
    database: 'mysql',
  });

  const mySqlVersion = await common.getMysqlVersion(connection);

  const hasIncorrectPrepareParameter = (() => {
    const { major, minor, patch } = mySqlVersion;

    if (major === 9) return false;
    if (major === 8 && minor === 4 && patch === 1) return false;
    if (major === 8 && minor === 0 && patch >= 38) return false;

    if (major > 8) {
      return true;
    }

    if (major === 8 && minor > 0) {
      return true;
    }

    if (major === 8 && minor === 0 && patch >= 22) {
      return true;
    }

    return false;
  })();

  await test(
    async () =>
      new Promise((resolve, reject) => {
        describe(
          `E2E Prepare result with number of parameters incorrectly reported by the server`,
          common.describeOptions
        );

        connection.prepare(
          'select * from user order by ?',
          async (err, stmt) => {
            if (err) {
              connection.end();
              reject(err);

              return;
            }

            if (hasIncorrectPrepareParameter) {
              assert.equal(
                stmt.parameters.length,
                0,
                'parameters length needs to be 0',
                'should report 0 actual parameters when 1 placeholder is used in ORDER BY ?'
              );
            } else {
              assert.equal(
                stmt.parameters.length,
                1,
                'parameters length needs to be 1'
              );
            }

            resolve(null);
          }
        );
      })
  );

  await test(
    async () =>
      new Promise((resolve, reject) => {
        connection.prepare(
          'select * from user where user.User like ? order by ?',
          async (err, stmt) => {
            if (err) {
              connection.end();
              reject(err);

              return;
            }

            if (hasIncorrectPrepareParameter) {
              assert.equal(
                stmt.parameters.length,
                1,
                'parameters length needs to be 1',
                'should report 1 actual parameters when 2 placeholders used in ORDER BY?'
              );
            } else {
              assert.equal(
                stmt.parameters.length,
                2,
                'parameters length needs to be 2'
              );
            }

            resolve(null);
          }
        );
      })
  );

  connection.end((err) => {
    assert.ifError(err);
  });
});
</file>

<file path="test/esm/unit/check-extensions.test.mjs">
import { EOL } from 'node:os';
import { listFiles, test, assert } from 'poku';

const invalidFiles = [];
const message = [
  'Check for invalid file types found in restricted directories',
];

const checkExtensions = async (
  dirs,
  allowedExtensions,
  ignoreList = /\.DS_Store/
) => {
  for (const dir of dirs) {
    const files = await listFiles(dir, { filter: /\./ });

    for (const file of files) {
      if (!ignoreList.test(file) && !allowedExtensions.test(file)) {
        invalidFiles.push(file);
        message.push(`${EOL}${String(allowedExtensions)}`);
        message.push(`- ${file}`);
      }
    }
  }
};

test(async () => {
  await checkExtensions(['test/unit', 'test/integration'], /\.test\.cjs$/);
  await checkExtensions(['test/esm'], /\.test\.mjs$/);
  await checkExtensions(['test/tsc-build'], /(\.test\.ts|tsconfig\.json)$/);

  assert.deepStrictEqual(
    invalidFiles.length,
    0,
    Array.from(new Set(message)).join(EOL)
  );
});
</file>

<file path="test/esm/unit/parsers/big-numbers-strings-binary-sanitization.test.mjs">
import { describe, test, assert } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const {
  createConnection,
  describeOptions,
} = require('../../../common.test.cjs');

const connection = createConnection().promise();

const sql = 'SELECT 9007199254740991+100 AS `total`';

describe('Binary Parser: bigNumberStrings Sanitization', describeOptions);

Promise.all([
  test(async () => {
    const [results] = await connection.execute({
      sql,
      supportBigNumbers: true,
      bigNumberStrings: true,
    });

    assert.strictEqual(
      typeof results[0].total,
      'string',
      'Valid bigNumberStrings enabled'
    );
  }),
  test(async () => {
    const [results] = await connection.execute({
      sql,
      supportBigNumbers: false,
      bigNumberStrings: false,
    });

    assert.strictEqual(
      typeof results[0].total,
      'number',
      'Valid bigNumberStrings disabled'
    );
  }),

  test(async () => {
    const [results] = await connection.execute({
      sql,
      supportBigNumbers: 'text',
      bigNumberStrings: 'text',
    });

    assert.strictEqual(
      typeof results[0].total,
      'string',
      'bigNumberStrings as a random string should be enabled'
    );
  }),
  test(async () => {
    const [results] = await connection.execute({
      sql,
      supportBigNumbers: '',
      bigNumberStrings: '',
    });

    assert.strictEqual(
      typeof results[0].total,
      'number',
      'bigNumberStrings as an empty string should be disabled'
    );
  }),
]).then(async () => {
  await connection.end();
});
</file>

<file path="test/esm/unit/parsers/big-numbers-strings-text-sanitization.test.mjs">
import { describe, test, assert } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const {
  createConnection,
  describeOptions,
} = require('../../../common.test.cjs');

const connection = createConnection().promise();

const sql = 'SELECT 9007199254740991+100 AS `total`';

describe('Text Parser: bigNumberStrings Sanitization', describeOptions);

Promise.all([
  test(async () => {
    const [results] = await connection.query({
      sql,
      supportBigNumbers: true,
      bigNumberStrings: true,
    });

    assert.strictEqual(
      typeof results[0].total,
      'string',
      'Valid bigNumberStrings enabled'
    );
  }),
  test(async () => {
    const [results] = await connection.query({
      sql,
      supportBigNumbers: false,
      bigNumberStrings: false,
    });

    assert.strictEqual(
      typeof results[0].total,
      'number',
      'Valid bigNumberStrings disabled'
    );
  }),

  test(async () => {
    const [results] = await connection.query({
      sql,
      supportBigNumbers: 'text',
      bigNumberStrings: 'text',
    });

    assert.strictEqual(
      typeof results[0].total,
      'string',
      'bigNumberStrings as a random string should be enabled'
    );
  }),
  test(async () => {
    const [results] = await connection.query({
      sql,
      supportBigNumbers: '',
      bigNumberStrings: '',
    });

    assert.strictEqual(
      typeof results[0].total,
      'number',
      'bigNumberStrings as an empty string should be disabled'
    );
  }),
]).then(async () => {
  await connection.end();
});
</file>

<file path="test/esm/unit/parsers/cache-key-serialization.test.mjs">
import { assert } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);

const { _keyFromFields } = require('../../../../lib/parsers/parser_cache.js');

// Invalid
const test1 = {
  type: undefined,
  fields: [
    {
      name: undefined,
      columnType: undefined,
      length: undefined,
      schema: undefined,
      table: undefined,
      flags: undefined,
      characterSet: undefined,
    },
  ],
  options: {
    nestTables: undefined,
    rowsAsArray: undefined,
    supportBigNumbers: undefined,
    bigNumberStrings: undefined,
    typeCast: undefined,
    timezone: undefined,
    decimalNumbers: undefined,
    dateStrings: undefined,
  },
  config: {
    supportBigNumbers: undefined,
    bigNumberStrings: undefined,
    timezone: undefined,
  },
};

// Invalid, except for `config` (global overwriting)
const test2 = {
  type: undefined,
  fields: [
    {
      name: undefined,
      columnType: undefined,
      length: undefined,
      schema: undefined,
      table: undefined,
      flags: undefined,
      characterSet: undefined,
    },
  ],
  options: {
    nestTables: undefined,
    rowsAsArray: undefined,
    supportBigNumbers: undefined,
    bigNumberStrings: undefined,
    typeCast: undefined,
    timezone: undefined,
    decimalNumbers: undefined,
    dateStrings: undefined,
  },
  config: {
    supportBigNumbers: false,
    bigNumberStrings: false,
    timezone: 'local',
  },
};

// Invalid, except for options
const test3 = {
  type: undefined,
  fields: [
    {
      name: undefined,
      columnType: undefined,
      length: undefined,
      schema: undefined,
      table: undefined,
      flags: undefined,
      characterSet: undefined,
    },
  ],
  options: {
    nestTables: '',
    rowsAsArray: false,
    supportBigNumbers: false,
    bigNumberStrings: false,
    typeCast: true,
    timezone: 'local',
    decimalNumbers: false,
    dateStrings: false,
  },
  config: {
    supportBigNumbers: undefined,
    bigNumberStrings: undefined,
    timezone: undefined,
  },
};

// Based on results of `SELECT * FROM test WHERE value = ?`
const test4 = {
  type: 'binary',
  fields: [
    {
      name: 'id',
      columnType: '3',
      length: undefined,
      schema: 'test',
      table: 'test',
      flags: '16899',
      characterSet: '63',
    },
    {
      name: 'value',
      columnType: '246',
      length: undefined,
      schema: 'test',
      table: 'test',
      flags: '0',
      characterSet: '63',
    },
  ],
  options: {
    nestTables: false,
    rowsAsArray: false,
    supportBigNumbers: false,
    bigNumberStrings: false,
    typeCast: true,
    timezone: 'local',
    decimalNumbers: false,
    dateStrings: 'DATETIME',
  },
  config: {
    supportBigNumbers: undefined,
    bigNumberStrings: undefined,
    timezone: undefined,
  },
};

// Same from test4, but with invalid booleans need to reach out the same key
const test5 = {
  type: 'binary',
  fields: [
    {
      name: 'id',
      columnType: '3',
      length: undefined,
      schema: 'test',
      table: 'test',
      flags: '16899',
      characterSet: '63',
    },
    {
      name: 'value',
      columnType: '246',
      length: undefined,
      schema: 'test',
      table: 'test',
      flags: '0',
      characterSet: '63',
    },
  ],
  options: {
    nestTables: false,
    rowsAsArray: undefined,
    supportBigNumbers: undefined,
    bigNumberStrings: undefined,
    typeCast: true,
    timezone: 'local',
    decimalNumbers: undefined,
    dateStrings: 'DATETIME',
  },
  config: {
    supportBigNumbers: undefined,
    bigNumberStrings: undefined,
    timezone: undefined,
  },
};

// Forcing delimiters on strings fields
// Checking for quotes escape
const test6 = {
  type: 'binary',
  fields: [
    {
      name: ':',
      columnType: '©',
      length: undefined,
      schema: '/',
      table: ',',
      flags: '_',
      characterSet: '❌',
    },
  ],
  options: {
    nestTables: false,
    rowsAsArray: true,
    supportBigNumbers: true,
    bigNumberStrings: true,
    typeCast: true,
    timezone: '""`\'',
    decimalNumbers: true,
    dateStrings: '#',
  },
  config: {
    supportBigNumbers: undefined,
    bigNumberStrings: undefined,
    timezone: undefined,
  },
};

// valid with `true` on booleans
const test7 = {
  type: 'binary',
  fields: [
    {
      name: 'id',
      columnType: '3',
      length: undefined,
      schema: 'test',
      table: 'test',
      flags: '16899',
      characterSet: '63',
    },
    {
      name: 'value',
      columnType: '246',
      length: undefined,
      schema: 'test',
      table: 'test',
      flags: '0',
      characterSet: '63',
    },
  ],
  options: {
    nestTables: true,
    rowsAsArray: true,
    supportBigNumbers: true,
    bigNumberStrings: true,
    typeCast: true,
    timezone: 'local',
    decimalNumbers: true,
    dateStrings: 'DATETIME',
  },
  config: {
    supportBigNumbers: true,
    bigNumberStrings: true,
    timezone: true,
  },
};

// Expects the same result from test7, but using valid values instead of `true` on booleans fields
const test8 = {
  type: 'binary',
  fields: [
    {
      name: 'id',
      columnType: '3',
      length: undefined,
      schema: 'test',
      table: 'test',
      flags: '16899',
      characterSet: '63',
    },
    {
      name: 'value',
      columnType: '246',
      length: undefined,
      schema: 'test',
      table: 'test',
      flags: '0',
      characterSet: '63',
    },
  ],
  options: {
    nestTables: true,
    rowsAsArray: 2,
    supportBigNumbers: 'yes',
    bigNumberStrings: [],
    typeCast: true,
    timezone: 'local',
    decimalNumbers: {
      a: null,
    },
    dateStrings: 'DATETIME',
  },
  config: {
    supportBigNumbers: true,
    bigNumberStrings: true,
    timezone: true,
  },
};

// Invalid: checking function parser in wrong fields, expecting to be `null`
const test9 = {
  type: 'binary',
  fields: [
    {
      name: 'id',
      columnType: '3',
      length: undefined,
      schema: 'test',
      table: 'test',
      flags: '16899',
      characterSet: '63',
    },
  ],
  options: {
    nestTables: false,
    rowsAsArray: false,
    supportBigNumbers: false,
    // Expected: true
    bigNumberStrings: (_, next) => next(),
    // Expected: "function"
    typeCast: (_, next) => next(),
    timezone: 'local',
    decimalNumbers: false,
    // Expected: null
    dateStrings: (_, next) => next(),
  },
  config: {
    supportBigNumbers: undefined,
    bigNumberStrings: undefined,
    timezone: undefined,
  },
};

const result1 = _keyFromFields(
  test1.type,
  test1.fields,
  test1.options,
  test1.config
);
const result2 = _keyFromFields(
  test2.type,
  test2.fields,
  test2.options,
  test2.config
);
const result3 = _keyFromFields(
  test3.type,
  test3.fields,
  test3.options,
  test3.config
);
const result4 = _keyFromFields(
  test4.type,
  test4.fields,
  test4.options,
  test4.config
);
const result5 = _keyFromFields(
  test5.type,
  test5.fields,
  test5.options,
  test5.config
);
const result6 = _keyFromFields(
  test6.type,
  test6.fields,
  test6.options,
  test6.config
);
const result7 = _keyFromFields(
  test7.type,
  test7.fields,
  test7.options,
  test7.config
);
const result8 = _keyFromFields(
  test8.type,
  test8.fields,
  test8.options,
  test8.config
);
const result9 = _keyFromFields(
  test9.type,
  test9.fields,
  test9.options,
  test9.config
);

assert.deepStrictEqual(
  result1,
  '[null,"undefined",null,false,false,false,"undefined",null,false,null,[null,null,null,null,null,null,null]]'
);
assert(JSON.parse(result1));

assert.deepStrictEqual(
  result2,
  '[null,"undefined",null,false,false,false,"undefined","local",false,null,[null,null,null,null,null,null,null]]'
);
assert(JSON.parse(result2));

assert.deepStrictEqual(
  result3,
  '[null,"string","",false,false,false,"boolean","local",false,false,[null,null,null,null,null,null,null]]'
);
assert(JSON.parse(result3));

assert.deepStrictEqual(
  result4,
  '["binary","boolean",false,false,false,false,"boolean","local",false,"DATETIME",["id","3",null,"test","test","16899","63"],["value","246",null,"test","test","0","63"]]'
);
assert(JSON.parse(result4));

assert.deepStrictEqual(result4, result5);
assert(JSON.parse(result5));

assert.deepStrictEqual(
  result6,
  '["binary","boolean",false,true,true,true,"boolean","\\"\\"`\'",true,"#",[":","©",null,"/",",","_","❌"]]'
);
// Ensuring that JSON is valid with invalid delimiters
assert(JSON.parse(result6));

assert.deepStrictEqual(
  result7,
  '["binary","boolean",true,true,true,true,"boolean","local",true,"DATETIME",["id","3",null,"test","test","16899","63"],["value","246",null,"test","test","0","63"]]'
);
assert(JSON.parse(result7));

assert.deepStrictEqual(result7, result8);
assert(JSON.parse(result8));

assert.deepStrictEqual(
  result9,
  '["binary","boolean",false,false,false,true,"function","local",false,null,["id","3",null,"test","test","16899","63"]]'
);
assert(JSON.parse(result9));
assert(JSON.parse(result9)[5] === true);
assert(JSON.parse(result9)[6] === 'function');
assert(JSON.parse(result9)[9] === null);

// Testing twice all existent tests needs to return 7 keys, since two of them expects to be the same
assert(
  Array.from(
    new Set([
      _keyFromFields(test1.type, test1.fields, test1.options, test1.config),
      _keyFromFields(test1.type, test1.fields, test1.options, test1.config),
      _keyFromFields(test2.type, test2.fields, test2.options, test2.config),
      _keyFromFields(test2.type, test2.fields, test2.options, test2.config),
      _keyFromFields(test3.type, test3.fields, test3.options, test3.config),
      _keyFromFields(test3.type, test3.fields, test3.options, test3.config),
      _keyFromFields(test4.type, test4.fields, test4.options, test4.config),
      _keyFromFields(test4.type, test4.fields, test4.options, test4.config),
      _keyFromFields(test5.type, test5.fields, test5.options, test5.config),
      _keyFromFields(test5.type, test5.fields, test5.options, test5.config),
      _keyFromFields(test6.type, test6.fields, test6.options, test6.config),
      _keyFromFields(test6.type, test6.fields, test6.options, test6.config),
      _keyFromFields(test7.type, test7.fields, test7.options, test7.config),
      _keyFromFields(test7.type, test7.fields, test7.options, test7.config),
      _keyFromFields(test8.type, test8.fields, test8.options, test8.config),
      _keyFromFields(test8.type, test8.fields, test8.options, test8.config),
      _keyFromFields(test9.type, test9.fields, test9.options, test9.config),
      _keyFromFields(test9.type, test9.fields, test9.options, test9.config),
    ])
  ).length === 7
);

const stringify = JSON.stringify;

// Overwriting the native `JSON.stringify`
JSON.stringify = (value, replacer, space = 8) =>
  stringify(value, replacer, space);

// Testing twice all existent tests needs to return 7 keys, since two of them expects to be the same
assert(
  Array.from(
    new Set([
      result1,
      _keyFromFields(test1.type, test1.fields, test1.options, test1.config),
      result2,
      _keyFromFields(test2.type, test2.fields, test2.options, test2.config),
      result3,
      _keyFromFields(test3.type, test3.fields, test3.options, test3.config),
      result4,
      _keyFromFields(test4.type, test4.fields, test4.options, test4.config),
      result5,
      _keyFromFields(test5.type, test5.fields, test5.options, test5.config),
      result6,
      _keyFromFields(test6.type, test6.fields, test6.options, test6.config),
      result7,
      _keyFromFields(test7.type, test7.fields, test7.options, test7.config),
      result8,
      _keyFromFields(test8.type, test8.fields, test8.options, test8.config),
      result9,
      _keyFromFields(test9.type, test9.fields, test9.options, test9.config),
    ])
  ).length === 7
);
</file>

<file path="test/esm/unit/parsers/ensure-safe-binary-fields.test.mjs">
import { describe, assert } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const { describeOptions } = require('../../../common.test.cjs');
const getBinaryParser = require('../../../../lib/parsers/binary_parser.js');
const { privateObjectProps } = require('../../../../lib/helpers.js');

describe('Binary Parser: Block Native Object Props', describeOptions);

const blockedFields = Array.from(privateObjectProps).map((prop) => [
  { name: prop, table: '' },
]);

blockedFields.forEach((fields) => {
  try {
    getBinaryParser(fields, {}, {});
    assert.fail('An error was expected');
  } catch (error) {
    assert.strictEqual(
      error.message,
      `The field name (${fields[0].name}) can't be the same as an object's private property.`,
      `Ensure safe ${fields[0].name}`
    );
  }
});

blockedFields
  .map((fields) =>
    fields.map((field) => ({ ...field, name: field.name.slice(1) }))
  )
  .forEach((fields) => {
    try {
      getBinaryParser(fields, { nestTables: '_' }, {});
      assert.fail('An error was expected');
    } catch (error) {
      assert.strictEqual(
        error.message,
        `The field name (_${fields[0].name}) can't be the same as an object's private property.`,
        `Ensure safe _${fields[0].name} for nestTables as string`
      );
    }
  });

blockedFields
  .map((fields) =>
    fields.map((field) => ({ ...field, name: '', table: field.name }))
  )
  .forEach((fields) => {
    try {
      getBinaryParser(fields, { nestTables: true }, {});
      assert.fail('An error was expected');
    } catch (error) {
      assert.strictEqual(
        error.message,
        `The field name (${fields[0].table}) can't be the same as an object's private property.`,
        `Ensure safe ${fields[0].table} for nestTables as true`
      );
    }
  });
</file>

<file path="test/esm/unit/parsers/ensure-safe-text-fields.test.mjs">
import { describe, assert } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const { describeOptions } = require('../../../common.test.cjs');
const TextRowParser = require('../../../../lib/parsers/text_parser.js');
const { privateObjectProps } = require('../../../../lib/helpers.js');

describe('Text Parser: Block Native Object Props', describeOptions);

const blockedFields = Array.from(privateObjectProps).map((prop) => [
  { name: prop, table: '' },
]);

blockedFields.forEach((fields) => {
  try {
    TextRowParser(fields, {}, {});
    assert.fail('An error was expected');
  } catch (error) {
    assert.strictEqual(
      error.message,
      `The field name (${fields[0].name}) can't be the same as an object's private property.`,
      `Ensure safe ${fields[0].name}`
    );
  }
});

blockedFields
  .map((fields) =>
    fields.map((field) => ({ ...field, name: field.name.slice(1) }))
  )
  .forEach((fields) => {
    try {
      TextRowParser(fields, { nestTables: '_' }, {});
      assert.fail('An error was expected');
    } catch (error) {
      assert.strictEqual(
        error.message,
        `The field name (_${fields[0].name}) can't be the same as an object's private property.`,
        `Ensure safe _${fields[0].name} for nestTables as string`
      );
    }
  });

blockedFields
  .map((fields) =>
    fields.map((field) => ({ ...field, name: '', table: field.name }))
  )
  .forEach((fields) => {
    try {
      TextRowParser(fields, { nestTables: true }, {});
      assert.fail('An error was expected');
    } catch (error) {
      assert.strictEqual(
        error.message,
        `The field name (${fields[0].table}) can't be the same as an object's private property.`,
        `Ensure safe ${fields[0].table} for nestTables as true`
      );
    }
  });
</file>

<file path="test/esm/unit/parsers/support-big-numbers-binary-sanitization.test.mjs">
import { describe, test, assert } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const {
  createConnection,
  describeOptions,
} = require('../../../common.test.cjs');

const connection = createConnection().promise();

const sql = 'SELECT 9007199254740991+100 AS `total`';

describe('Binary Parser: supportBigNumbers Sanitization', describeOptions);

Promise.all([
  test(async () => {
    const [results] = await connection.execute({
      sql,
      supportBigNumbers: true,
    });

    assert.strictEqual(
      typeof results[0].total,
      'string',
      'Valid supportBigNumbers enabled'
    );
  }),
  test(async () => {
    const [results] = await connection.execute({
      sql,
      supportBigNumbers: false,
    });

    assert.strictEqual(
      typeof results[0].total,
      'number',
      'Valid supportBigNumbers disabled'
    );
  }),

  test(async () => {
    const [results] = await connection.execute({
      sql,
      supportBigNumbers: 'text',
    });

    assert.strictEqual(
      typeof results[0].total,
      'string',
      'supportBigNumbers as a random string should be enabled'
    );
  }),
  test(async () => {
    const [results] = await connection.execute({
      sql,
      supportBigNumbers: '',
    });

    assert.strictEqual(
      typeof results[0].total,
      'number',
      'supportBigNumbers as an empty string should be disabled'
    );
  }),
]).then(async () => {
  await connection.end();
});
</file>

<file path="test/esm/unit/parsers/support-big-numbers-text-sanitization.test.mjs">
import { describe, test, assert } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const {
  createConnection,
  describeOptions,
} = require('../../../common.test.cjs');

const connection = createConnection().promise();

const sql = 'SELECT 9007199254740991+100 AS `total`';

describe('Text Parser: supportBigNumbers Sanitization', describeOptions);

Promise.all([
  test(async () => {
    const [results] = await connection.query({
      sql,
      supportBigNumbers: true,
    });

    assert.strictEqual(
      typeof results[0].total,
      'string',
      'Valid supportBigNumbers enabled'
    );
  }),
  test(async () => {
    const [results] = await connection.query({
      sql,
      supportBigNumbers: false,
    });

    assert.strictEqual(
      typeof results[0].total,
      'number',
      'Valid supportBigNumbers disabled'
    );
  }),

  test(async () => {
    const [results] = await connection.query({
      sql,
      supportBigNumbers: 'text',
    });

    assert.strictEqual(
      typeof results[0].total,
      'string',
      'supportBigNumbers as a random string should be enabled'
    );
  }),
  test(async () => {
    const [results] = await connection.query({
      sql,
      supportBigNumbers: '',
    });

    assert.strictEqual(
      typeof results[0].total,
      'number',
      'supportBigNumbers as an empty string should be disabled'
    );
  }),
]).then(async () => {
  await connection.end();
});
</file>

<file path="test/esm/unit/parsers/timezone-binary-sanitization.test.mjs">
import process from 'node:process';
import { describe, test, assert } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const {
  createConnection,
  describeOptions,
} = require('../../../common.test.cjs');

const connection = createConnection().promise();

describe('Binary Parser: timezone Sanitization', describeOptions);

Promise.all([
  test(async () => {
    process.env.TEST_ENV_VALUE = 'secure';
    await connection.execute({
      sql: 'SELECT NOW()',
      timezone: `'); process.env.TEST_ENV_VALUE = "not so much"; //`,
    });

    assert.strictEqual(
      process.env.TEST_ENV_VALUE,
      'secure',
      'Timezone sanitization failed - code injection possible'
    );
  }),
]).then(async () => {
  await connection.end();
});
</file>

<file path="test/esm/unit/parsers/timezone-text-sanitization.test.mjs">
import process from 'node:process';
import { describe, test, assert } from 'poku';
import { createRequire } from 'node:module';

const require = createRequire(import.meta.url);
const {
  createConnection,
  describeOptions,
} = require('../../../common.test.cjs');

const connection = createConnection().promise();

describe('Text Parser: timezone Sanitization', describeOptions);

Promise.all([
  test(async () => {
    process.env.TEST_ENV_VALUE = 'secure';
    await connection.query({
      sql: 'SELECT NOW()',
      timezone: `'); process.env.TEST_ENV_VALUE = "not so much"; //`,
    });

    assert.strictEqual(
      process.env.TEST_ENV_VALUE,
      'secure',
      'Timezone sanitization failed - code injection possible'
    );
  }),
]).then(async () => {
  await connection.end();
});
</file>

<file path="test/esm/unit/protocol/SqlString.test.mjs">
import { assert, test, describe } from 'poku';
import { createRequire } from 'node:module';
import { Buffer } from 'node:buffer';

const require = createRequire(import.meta.url);
const { SqlString, describeOptions } = require('../../../common.test.cjs');

describe('SqlString.escapeId tests', describeOptions);

assert.equal(SqlString.escapeId('id'), '`id`', 'value is quoted');

assert.equal(
  SqlString.escapeId('i`d'),
  '`i``d`',
  'value containing escapes is quoted'
);

assert.equal(
  SqlString.escapeId('id1.id2'),
  '`id1`.`id2`',
  'value containing separator is quoted'
);

assert.equal(
  SqlString.escapeId('id`1.i`d2'),
  '`id``1`.`i``d2`',
  'value containing separator and escapes is quoted'
);

assert.equal(
  SqlString.escapeId(['a', 'b', 't.c']),
  '`a`, `b`, `t`.`c`',
  'arrays are turned into lists'
);

assert.equal(
  SqlString.escapeId(['a', ['b', ['t.c']]]),
  '`a`, `b`, `t`.`c`',
  'nested arrays are flattened'
);

describe('SqlString.escape tests', describeOptions);

assert.equal(SqlString.escape(undefined), 'NULL', 'undefined -> NULL');

assert.equal(SqlString.escape(null), 'NULL', 'null -> NULL');

assert.equal(
  SqlString.escape(false),
  'false',
  'booleans convert to strings (false)'
);
assert.equal(
  SqlString.escape(true),
  'true',
  'booleans convert to strings (true)'
);

assert.equal(SqlString.escape(5), '5', 'numbers convert to strings');

assert.equal(
  SqlString.escape({ a: 'b', c: 'd' }),
  "`a` = 'b', `c` = 'd'",
  'objects are turned into key value pairs'
);

assert.equal(
  SqlString.escape({ a: 'b', c: function () {} }),
  "`a` = 'b'",
  'objects function properties are ignored'
);

assert.equal(
  SqlString.escape({ a: { nested: true } }),
  "`a` = '[object Object]'",
  'nested objects are cast to strings'
);

assert.equal(
  SqlString.escape([1, 2, 'c']),
  "1, 2, 'c'",
  'arrays are turned into lists'
);

assert.equal(
  SqlString.escape([
    [1, 2, 3],
    [4, 5, 6],
    ['a', 'b', { nested: true }],
  ]),
  "(1, 2, 3), (4, 5, 6), ('a', 'b', '[object Object]')",
  'nested arrays are turned into grouped lists'
);

assert.equal(
  SqlString.escape([1, { nested: true }, 2]),
  "1, '[object Object]', 2",
  'nested objects inside arrays are cast to strings'
);

assert.equal(SqlString.escape('Super'), "'Super'", 'strings are quoted');

assert.equal(SqlString.escape('Sup\0er'), "'Sup\\0er'", '\0 gets escaped');

assert.equal(SqlString.escape('Sup\ber'), "'Sup\\ber'", '\b gets escaped');

assert.equal(SqlString.escape('Sup\ner'), "'Sup\\ner'", '\n gets escaped');

assert.equal(SqlString.escape('Sup\rer'), "'Sup\\rer'", '\r gets escaped');

assert.equal(SqlString.escape('Sup\ter'), "'Sup\\ter'", '\t gets escaped');

assert.equal(SqlString.escape('Sup\\er'), "'Sup\\\\er'", '\\ gets escaped');

assert.equal(
  SqlString.escape('Sup\u001aer'),
  "'Sup\\Zer'",
  '\u001a (ascii 26) gets replaced with \\Z'
);

assert.equal(
  SqlString.escape("Sup'er"),
  "'Sup\\'er'",
  'single quotes get escaped'
);

assert.equal(
  SqlString.escape('Sup"er'),
  "'Sup\\\"er'",
  'double quotes get escaped'
);

test(() => {
  const expected = '2012-05-07 11:42:03.002';
  const date = new Date(2012, 4, 7, 11, 42, 3, 2);
  const string = SqlString.escape(date);
  assert.strictEqual(
    string,
    `'${expected}'`,
    'dates are converted to YYYY-MM-DD HH:II:SS.sss'
  );
});

test(() => {
  const buffer = Buffer.from([0, 1, 254, 255]);
  const string = SqlString.escape(buffer);
  assert.strictEqual(string, "X'0001feff'", 'buffers are converted to hex');
});

assert.equal(SqlString.escape(NaN), 'NaN', 'NaN -> NaN');

assert.equal(SqlString.escape(Infinity), 'Infinity', 'Infinity -> Infinity');

describe('SqlString.format tests', describeOptions);

test(() => {
  const sql = SqlString.format('? and ?', ['a', 'b']);
  assert.equal(
    sql,
    "'a' and 'b'",
    'question marks are replaced with escaped array values'
  );
});

test(() => {
  const sql = SqlString.format('? and ?', ['a']);
  assert.equal(sql, "'a' and ?", 'extra question marks are left untouched');
});

test(() => {
  const sql = SqlString.format('? and ?', ['a', 'b', 'c']);
  assert.equal(sql, "'a' and 'b'", 'extra arguments are not used');
});

test(() => {
  const sql = SqlString.format('? and ?', ['hello?', 'b']);
  assert.equal(
    sql,
    "'hello?' and 'b'",
    'question marks within values do not cause issues'
  );
});

test(() => {
  const sql = SqlString.format('?', undefined);
  assert.equal(sql, '?', 'undefined is ignored');
});

test(() => {
  const sql = SqlString.format('?', { hello: 'world' });
  assert.equal(sql, "`hello` = 'world'", 'objects is converted to values');
});

test(() => {
  const sql = SqlString.format('?', { hello: 'world' }, true);
  assert.equal(
    sql,
    "'[object Object]'",
    'objects is not converted to values when flag is true'
  );

  const sql2 = SqlString.format(
    '?',
    {
      toString: function () {
        return 'hello';
      },
    },
    true
  );
  assert.equal(sql2, "'hello'", 'custom toString function is respected');
});
</file>

<file path="test/fixtures/custom-conf/config-file.cnf">
[mysqld]
ssl-ca=/certs/ca.pem
ssl-cert=/certs/server-cert.pem
ssl-key=/certs/server-key.pem
</file>

<file path="test/fixtures/data.csv">
1,Hello World
2,This is a test
3,For loading data from a file
4,中文内容
</file>

<file path="test/fixtures/ssl/certs/ca.pem">
-----BEGIN CERTIFICATE-----
MIICsjCCAZoCCQDe1QK5Efu90jANBgkqhkiG9w0BAQsFADAbMQswCQYDVQQGEwJB
VTEMMAoGA1UECAwDVklDMB4XDTE5MDkyOTEzMDI1OFoXDTI5MDgwNzEzMDI1OFow
GzELMAkGA1UEBhMCQVUxDDAKBgNVBAgMA1ZJQzCCASIwDQYJKoZIhvcNAQEBBQAD
ggEPADCCAQoCggEBAMKchojHs540/esAhMmvt5qJWpelWKG2gsKkKTeBc50sD2XR
66Yh7+d61bDYE44xjk0t4BK/6l5lYLNtX9q8Xxx7lmSkWVb96f0pVxV+3gvdPTH2
1qpRDS5lXm+o0WfG5sF/yaQJRn+UQPo/vsAtglfLm1QDn+Gwbq7ur+P877WYEZ/o
K1lDwsFBqBjHu9LkywVquSajtDP4jhFRLFIR3tgTAQ1D4BxaKHFetierfrFXCwUV
osnXoOArqHHE6UyUKWNUPAWFOeNEMELMU6lQnEkg0SoMBgIvjifGhT7BCa8+vP71
UO85nFMsADbTvJ6ziyasKnXnwbppB3RnEj1JkX0CAwEAATANBgkqhkiG9w0BAQsF
AAOCAQEAqCH1UN4wN6rMQw2DtdFb0XBKGb6TpHj+rGpsNimmAxYMhLb/09ua3Y33
OfRudl0Q5ZPZ0KQSQU/WoETyei44OLaSqfTPww6L53Mbf+qyla4e602b9/nWNe8n
y0n9nL2s3u6rhCvFXxZiu813blw1GPd7/B5mfu+QEA/UhkiASMA5msr7fNIMzke9
5rUYjMBzvSuy/vYbiTrXmKpAu5h4Z14qO8EDZy6gMzi0VhsUwur3I/ApOMt18BKx
rOagdnBFQ9XAde7wmkO7ODr3cj1yA7GmIMTWGwCaJh5F/RlsfCdT2jlWPXQ2T8Fn
PYufwpqtHrvN2qw7bU7SiV5UuX1I3A==
-----END CERTIFICATE-----
</file>

<file path="test/fixtures/ssl/certs/mkcerts.sh">
# from https://dev.mysql.com/doc/refman/8.0/en/creating-ssl-files-using-openssl.html

# Create CA certificate
openssl genrsa 2048 > ca-key.pem
openssl req -new -x509 -nodes -days 3600 \
        -key ca-key.pem -out ca.pem

# Create server certificate, remove passphrase, and sign it
# server-cert.pem = public key, server-key.pem = private key
openssl req -newkey rsa:2048 -days 3600 \
        -nodes -keyout server-key.pem -out server-req.pem
openssl rsa -in server-key.pem -out server-key.pem
openssl x509 -req -in server-req.pem -days 3600 \
        -CA ca.pem -CAkey ca-key.pem -set_serial 01 -out server-cert.pem

# Create client certificate, remove passphrase, and sign it
# client-cert.pem = public key, client-key.pem = private key
openssl req -newkey rsa:2048 -days 3600 \
        -nodes -keyout client-key.pem -out client-req.pem
openssl rsa -in client-key.pem -out client-key.pem
openssl x509 -req -in client-req.pem -days 3600 \
        -CA ca.pem -CAkey ca-key.pem -set_serial 01 -out client-cert.pem
</file>

<file path="test/fixtures/ssl/certs/server-cert.pem">
-----BEGIN CERTIFICATE-----
MIICqjCCAZICAQEwDQYJKoZIhvcNAQEFBQAwGzELMAkGA1UEBhMCQVUxDDAKBgNV
BAgMA1ZJQzAeFw0xOTA5MjkxMzAzMDdaFw0yOTA4MDcxMzAzMDdaMBsxCzAJBgNV
BAYTAkFVMQwwCgYDVQQIDANWSUMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEK
AoIBAQC2NaLE0M9LNghfK0CK8WP4TsDP4oGtX+SxfF2NAT6BLNEaM/k7p8htbfoP
zv6YBSKKO9vgcKPsC19BbHuf1bE3HK0le/OLtcE9sI7DgfdFOgcHV2/LF+2EGLdP
Ccvde/Jtqsfo6RaQB8SF7tQ9FNc49UdHGry9CfNUVmi/HHyqKAoYGTFvkwsDvI6R
UfBev6Q6gpAxVkD560sholY8IWxYwI2vqzxYKKYfyuJAcHeSLPON3b+E9XftP8hL
CMXTBjtRKrxoFT5fVxg8yFWC/7bMosQD10NbqJpZAPxPBIf/3DDqADGNcA8FEMPN
FxeAPmledv3fF+JPF/zrKI+qR1zfAgMBAAEwDQYJKoZIhvcNAQEFBQADggEBAHB3
D33d8i4j813Aut1Pxm7Ntk0JNDDq1smIDbxnY9MiOpVAEJ3nQkgbmN/vy/MhFE7m
xnARgaiCOx7gYQDtTwKEAuSTyKJ5xsaS4O55ClPUEkzA8EiXyxgu1MiJQgZk7k8h
uHaKjhX4dIRMDNcGWbrZBEBJMlbrHLco6tg2DwTSuF/nNwmZ4YU4xWsz8/aT+uSc
qMPtWrOPRme6zfSKG/SPYreV1GA73Ema+Is9yE7buwPri+IWnzVdPStkEI8yn1S9
uYrZd1i630lcUFiYq+c9ETDkNgX3ldNH2wdsbJI1nkFh6SMi4y8DseyFo7HWMC3w
suH0xMMEPpjyNeVfsMw=
-----END CERTIFICATE-----
</file>

<file path="test/fixtures/ssl/certs/server-req.pem">
-----BEGIN CERTIFICATE REQUEST-----
MIICYDCCAUgCAQAwGzELMAkGA1UEBhMCQVUxDDAKBgNVBAgMA1ZJQzCCASIwDQYJ
KoZIhvcNAQEBBQADggEPADCCAQoCggEBALY1osTQz0s2CF8rQIrxY/hOwM/iga1f
5LF8XY0BPoEs0Roz+TunyG1t+g/O/pgFIoo72+Bwo+wLX0Fse5/VsTccrSV784u1
wT2wjsOB90U6BwdXb8sX7YQYt08Jy9178m2qx+jpFpAHxIXu1D0U1zj1R0cavL0J
81RWaL8cfKooChgZMW+TCwO8jpFR8F6/pDqCkDFWQPnrSyGiVjwhbFjAja+rPFgo
ph/K4kBwd5Is843dv4T1d+0/yEsIxdMGO1EqvGgVPl9XGDzIVYL/tsyixAPXQ1uo
mlkA/E8Eh//cMOoAMY1wDwUQw80XF4A+aV52/d8X4k8X/Osoj6pHXN8CAwEAAaAA
MA0GCSqGSIb3DQEBCwUAA4IBAQBVpcCRFnRT5IARzXdhGSxo+P9T8IxDqYltnvni
fs2yLR9E8EEpypY11qzN/0HX42av0RTTrcCQvR+Bfud1TPLGYKA0oUhKlX8kN4XC
E29QGS5RMd7UZLByaGSlKiHSzRuzAt1np4GYUEDoAX3UMxkf3gAgErJEBooSoGmK
qAew16W68dOqzklUiNN9AzmCzbkpjveYtYYC+k5+oBnuU4o+0/rkY6fKI4WpMQ3K
tbYIv51s9wa3vqkdzEY8pZWkfnGRAj+UxRg7yHM44ec2xMxcnyjWZZKEy6z32BoF
rm794RVdobl5Lj6r5lZqpeMvrr9p3QOG5kxL5Q+bIrxJv7Fj
-----END CERTIFICATE REQUEST-----
</file>

<file path="test/fixtures/ssl/client-flags.sh">
mysql --ssl-key=certs/client-key.pem --ssl-cert=certs/client-cert.pem -h 127.0.0.1 -P 3307
</file>

<file path="test/integration/config/test-connect-timeout.test.cjs">
'use strict';
const portfinder = require('portfinder');
const mysql = require('../../../index.js');
const assert = require('node:assert');
const process = require('node:process');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

console.log('test connect timeout');

portfinder.getPort((err, port) => {
  const server = mysql.createServer();
  server.on('connection', () => {
    // Let connection time out
  });

  server.listen(port);

  const connection = mysql.createConnection({
    host: 'localhost',
    port: port,
    connectTimeout: 1000,
  });

  connection.on('error', (err) => {
    assert.equal(err.code, 'ETIMEDOUT');
    connection.destroy();
    server._server.close();
    console.log('ok');
  });
});

process.on('uncaughtException', (err) => {
  assert.equal(
    err.message,
    'Connection lost: The server closed the connection.'
  );
  assert.equal(err.code, 'PROTOCOL_CONNECTION_LOST');
});
</file>

<file path="test/integration/config/test-typecast-global-false.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const connection = common.createConnection({
  typeCast: false,
});

const { assert } = require('poku');

const COL_1_VALUE = 'col v1';
const COL_2_VALUE = 'col v2';

function executeTests(res) {
  assert.equal(res[0].v1.toString('ascii'), COL_1_VALUE);
  assert.equal(res[0].n1, null);
  assert.equal(res[0].v2.toString('ascii'), COL_2_VALUE);
}

connection.query(
  'CREATE TEMPORARY TABLE binpar_null_test (v1 VARCHAR(16) NOT NULL, n1 VARCHAR(16), v2 VARCHAR(16) NOT NULL)'
);
connection.query(
  `INSERT INTO binpar_null_test (v1, n1, v2) VALUES ("${COL_1_VALUE}", NULL, "${COL_2_VALUE}")`,
  (err) => {
    if (err) throw err;
  }
);

connection.execute('SELECT * FROM binpar_null_test', (err, res) => {
  if (err) throw err;
  executeTests(res);
  connection.end();
});
</file>

<file path="test/integration/config/test-typecast-global-option.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');

const typeCastWrapper = function (stringMethod) {
  return function (field, next) {
    if (field.type === 'VAR_STRING') {
      return field.string()[stringMethod]();
    }
    return next();
  };
};

const connection = common.createConnection({
  typeCast: typeCastWrapper('toUpperCase'),
});

// query option override global typeCast
connection.query(
  {
    sql: 'select "FOOBAR" as foo',
    typeCast: typeCastWrapper('toLowerCase'),
  },
  (err, res) => {
    assert.ifError(err);
    assert.equal(res[0].foo, 'foobar');
  }
);

// global typecast works
connection.query(
  {
    sql: 'select "foobar" as foo',
  },
  (err, res) => {
    assert.ifError(err);
    assert.equal(res[0].foo, 'FOOBAR');
  }
);

connection.end();
</file>

<file path="test/integration/connection/encoding/test-charset-results.test.cjs">
'use strict';

const mysql = require('../../../../index.js');
const common = require('../../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale (unsupported non utf8 charsets)');
  process.exit(0);
}

const connection = common.createConnection();

const payload = 'привет, мир';

function tryEncoding(encoding, cb) {
  connection.query('set character_set_results = ?', [encoding], (err) => {
    assert.ifError(err);
    connection.query('SELECT ?', [payload], (err, rows, fields) => {
      assert.ifError(err);
      let iconvEncoding = encoding;
      if (encoding === 'utf8mb4') {
        iconvEncoding = 'utf8';
      }
      assert.equal(
        mysql.CharsetToEncoding[fields[0].characterSet],
        iconvEncoding
      );
      assert.equal(fields[0].name, payload);
      assert.equal(rows[0][fields[0].name], payload);
      cb();
    });
  });
}

function tryEncodingExecute(encoding, cb) {
  connection.execute('set character_set_results = ?', [encoding], (err) => {
    assert.ifError(err);
    connection.execute('SELECT ? as n', [payload], (err, rows, fields) => {
      assert.ifError(err);
      let iconvEncoding = encoding;
      if (encoding === 'utf8mb4') {
        iconvEncoding = 'utf8';
      }
      assert.equal(
        mysql.CharsetToEncoding[fields[0].characterSet],
        iconvEncoding
      );
      // TODO: figure out correct metadata encodings setup for binary protocol
      //  assert.equal(fields[0].name, payload);
      assert.equal(rows[0][fields[0].name], payload);
      cb();
    });
  });
}

// christmas tree!!! :)
tryEncoding('cp1251', () => {
  tryEncoding('koi8r', () => {
    tryEncoding('cp866', () => {
      tryEncoding('utf8mb4', () => {
        tryEncodingExecute('cp1251', () => {
          tryEncodingExecute('koi8r', () => {
            tryEncodingExecute('cp866', () => {
              tryEncodingExecute('utf8mb4', () => {
                connection.end();
              });
            });
          });
        });
      });
    });
  });
});
</file>

<file path="test/integration/connection/encoding/test-client-encodings.test.cjs">
'use strict';

const common = require('../../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale (unsupported non utf8 charsets)');
  process.exit(0);
}

const connection = common.createConnection({ charset: 'UTF8MB4_GENERAL_CI' });
connection.query('drop table if exists __test_client_encodings');
connection.query(
  'create table if not exists __test_client_encodings (name VARCHAR(200)) CHARACTER SET=utf8mb4',
  (err) => {
    assert.ifError(err);
    connection.query('delete from __test_client_encodings', (err) => {
      assert.ifError(err);
      connection.end();

      const connection1 = common.createConnection({
        charset: 'CP1251_GENERAL_CI',
      });
      connection1.query(
        'insert into __test_client_encodings values("привет, мир")',
        (err) => {
          assert.ifError(err);
          connection1.end();

          const connection2 = common.createConnection({
            charset: 'KOI8R_GENERAL_CI',
          });
          connection2.query(
            'select * from __test_client_encodings',
            (err, rows) => {
              assert.ifError(err);
              assert.equal(rows[0].name, 'привет, мир');
              connection2.end();
            }
          );
        }
      );
    });
  }
);
</file>

<file path="test/integration/connection/encoding/test-non-bmp-chars.test.cjs">
'use strict';

const common = require('../../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

// 4 bytes in utf8
const pileOfPoo = '💩';

const connection = common.createConnection({ charset: 'UTF8_GENERAL_CI' });
connection.query('select "💩"', (err, rows, fields) => {
  assert.ifError(err);
  assert.equal(fields[0].name, pileOfPoo);
  assert.equal(rows[0][fields[0].name], pileOfPoo);
  connection.end();
});

const connection2 = common.createConnection({ charset: 'UTF8MB4_GENERAL_CI' });
connection2.query('select "💩"', (err, rows, fields) => {
  assert.ifError(err);
  assert.equal(fields[0].name, '?');
  assert.equal(rows[0]['?'], pileOfPoo);
  connection2.end();
});
</file>

<file path="test/integration/connection/encoding/test-track-encodings.test.cjs">
'use strict';

const common = require('../../../common.test.cjs');
const { assert } = require('poku');

const connection = common.createConnection({ charset: 'UTF8MB4_GENERAL_CI' });
const text = 'привет, мир';

connection.query('SET character_set_client=koi8r', (err) => {
  assert.ifError(err);
  connection.query(`SELECT ? as result`, [text], (err, rows) => {
    assert.ifError(err);
    assert.equal(rows[0].result, text);
    connection.query('SET character_set_client=cp1251', (err) => {
      assert.ifError(err);
      connection.query(`SELECT ? as result`, [text], (err, rows) => {
        assert.ifError(err);
        assert.equal(rows[0].result, text);
        connection.end();
      });
    });
  });
});
</file>

<file path="test/integration/connection/test-binary-charset-string.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const { Buffer } = require('node:buffer');
const process = require('node:process');

const connection = common.createConnection();

// TODO - this could be re-enabled
if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

let rows = undefined;
let fields = undefined;
let rows1 = undefined;
let fields1 = undefined;
let rows2 = undefined;
let fields2 = undefined;
let rows3 = undefined;
let fields3 = undefined;

let rows4 = undefined;
let fields4 = undefined;
let rows5 = undefined;
let fields5 = undefined;

const query = "SELECT x'010203'";
const query1 = "SELECT '010203'";

connection.query(query, (err, _rows, _fields) => {
  if (err) {
    throw err;
  }
  rows = _rows;
  fields = _fields;
});

connection.query(query, (err, _rows, _fields) => {
  if (err) {
    throw err;
  }
  rows5 = _rows;
  fields5 = _fields;
});

connection.query(query1, (err, _rows, _fields) => {
  if (err) {
    throw err;
  }
  rows1 = _rows;
  fields1 = _fields;
});

connection.execute(query, [], (err, _rows, _fields) => {
  if (err) {
    throw err;
  }
  rows2 = _rows;
  fields2 = _fields;
});

// repeat same query - test cached fields and parser
connection.execute(query, [], (err, _rows, _fields) => {
  if (err) {
    throw err;
  }
  rows4 = _rows;
  fields4 = _fields;
});

connection.execute(query1, [], (err, _rows, _fields) => {
  if (err) {
    throw err;
  }
  rows3 = _rows;
  fields3 = _fields;
  connection.end();
});

process.on('exit', () => {
  assert.deepEqual(rows, [{ "x'010203'": Buffer.from([1, 2, 3]) }]);
  assert.equal(fields[0].name, "x'010203'");
  assert.deepEqual(rows1, [{ '010203': '010203' }]);
  assert.equal(fields1[0].name, '010203');
  assert.deepEqual(rows2, [{ "x'010203'": Buffer.from([1, 2, 3]) }]);
  assert.equal(fields2[0].name, "x'010203'");
  assert.deepEqual(rows3, [{ '010203': '010203' }]);
  assert.equal(fields3[0].name, '010203');

  assert.deepEqual(rows4, [{ "x'010203'": Buffer.from([1, 2, 3]) }]);
  assert.equal(fields4[0].name, "x'010203'");
  assert.deepEqual(rows5, [{ "x'010203'": Buffer.from([1, 2, 3]) }]);
  assert.equal(fields5[0].name, "x'010203'");
});
</file>

<file path="test/integration/connection/test-binary-longlong.test.cjs">
'use strict';

const { assert } = require('poku');
const common = require('../../common.test.cjs');

const conn = common.createConnection();

conn.query(
  'CREATE TEMPORARY TABLE `tmp_longlong` ( ' +
    ' `id` int(11) NOT NULL AUTO_INCREMENT, ' +
    ' `ls` BIGINT SIGNED, ' +
    ' `lu` BIGINT UNSIGNED, ' +
    ' PRIMARY KEY (`id`) ' +
    ' ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8'
);

const values = [
  ['10', '10'],
  ['-11', '11'],
  ['965432100123456789', '1965432100123456789'],
  ['-965432100123456789', '2965432100123456789'],
  [null, null],
];

conn.connect((err) => {
  if (err) {
    console.error(err);
    return;
  }

  for (let i = 0; i < values.length; ++i) {
    conn.query('INSERT INTO `tmp_longlong` VALUES (?, ?, ?)', [
      i + 1,
      values[i][0],
      values[i][1],
    ]);
  }

  const bigNums_bnStringsFalse = [
    { id: 1, ls: 10, lu: 10 },
    { id: 2, ls: -11, lu: 11 },
    { id: 3, ls: 965432100123456800, lu: 1965432100123456800 },
    { id: 4, ls: -965432100123456800, lu: 2965432100123457000 },
    { id: 5, ls: null, lu: null },
  ];

  const bigNums_bnStringsTrueFalse = [
    { id: 1, ls: 10, lu: 10 },
    { id: 2, ls: -11, lu: 11 },
    { id: 3, ls: '965432100123456789', lu: '1965432100123456789' },
    { id: 4, ls: '-965432100123456789', lu: '2965432100123456789' },
    { id: 5, ls: null, lu: null },
  ];

  const bigNums_bnStringsTrueTrue = [
    { id: 1, ls: 10, lu: 10 },
    { id: 2, ls: -11, lu: 11 },
    { id: 3, ls: '965432100123456789', lu: '1965432100123456789' },
    { id: 4, ls: '-965432100123456789', lu: '2965432100123456789' },
    { id: 5, ls: null, lu: null },
  ];

  let completed = 0;
  let started = 0;

  function testQuery(supportBigNumbers, bigNumberStrings, expectation) {
    started++;
    conn.query(
      {
        sql: 'SELECT * from tmp_longlong',
        supportBigNumbers: supportBigNumbers,
        bigNumberStrings: bigNumberStrings,
      },
      (err, rows) => {
        assert.ifError(err);
        assert.deepEqual(rows, expectation);
        completed++;
        if (completed === started) {
          conn.end();
        }
      }
    );
  }

  function testExecute(supportBigNumbers, bigNumberStrings, expectation) {
    started++;
    conn.execute(
      {
        sql: 'SELECT * from tmp_longlong',
        supportBigNumbers: supportBigNumbers,
        bigNumberStrings: bigNumberStrings,
      },
      (err, rows) => {
        assert.ifError(err);
        assert.deepEqual(rows, expectation);
        completed++;
        if (completed === started) {
          conn.end();
        }
      }
    );
  }

  testQuery(false, false, bigNums_bnStringsFalse);
  testQuery(true, false, bigNums_bnStringsTrueFalse);
  testQuery(true, true, bigNums_bnStringsTrueTrue);

  testExecute(false, false, bigNums_bnStringsFalse);
  testExecute(true, false, bigNums_bnStringsTrueFalse);
  testExecute(true, true, bigNums_bnStringsTrueTrue);
});
</file>

<file path="test/integration/connection/test-binary-multiple-results.test.cjs">
// This file was modified by Oracle on June 2, 2021.
// The test has been updated to remove all expectations with regards to the
// "columnLength" metadata field.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const assert = require('assert-diff');
const process = require('node:process');

if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

const mysql = require('../../common.test.cjs').createConnection({
  multipleStatements: true,
});

mysql.query('CREATE TEMPORARY TABLE no_rows (test int)');
mysql.query('CREATE TEMPORARY TABLE some_rows (test int)');
mysql.query('INSERT INTO some_rows values(0)');
mysql.query('INSERT INTO some_rows values(42)');
mysql.query('INSERT INTO some_rows values(314149)');

const clone = function (obj) {
  return JSON.parse(JSON.stringify(obj));
};

const rs1 = {
  affectedRows: 0,
  fieldCount: 0,
  insertId: 0,
  serverStatus: 10,
  warningStatus: 0,
  info: '',
  changedRows: 0,
};
const rs2 = clone(rs1);
rs2.serverStatus = 2;
const rs3 = clone(rs1);
rs3.serverStatus = 34;

const select1 = [{ 1: '1' }];
const select2 = [{ 2: '2' }];
const fields1 = [
  {
    catalog: 'def',
    characterSet: 63,
    encoding: 'binary',
    type: 8,
    decimals: 0,
    flags: 129,
    name: '1',
    orgName: '',
    orgTable: '',
    schema: '',
    table: '',
  },
];
const nr_fields = [
  {
    catalog: 'def',
    characterSet: 63,
    encoding: 'binary',
    type: 3,
    decimals: 0,
    flags: 0,
    name: 'test',
    orgName: 'test',
    orgTable: 'no_rows',
    schema: mysql.config.database,
    table: 'no_rows',
  },
];

const sr_fields = clone(nr_fields);
sr_fields[0].orgTable = 'some_rows';
sr_fields[0].table = 'some_rows';
const select3 = [{ test: 0 }, { test: 42 }, { test: 314149 }];

const fields2 = clone(fields1);
fields2[0].name = '2';

const tests = [
  ['select * from some_rows', [[select3, rs3], [sr_fields, undefined], 2]], //  select 3 rows
  [
    'SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT; SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS',
    [rs2, undefined, 1],
  ],
  ['set @a = 1', [rs2, undefined, 1]],
  ['set @a = 1; set @b = 2', [rs2, undefined, 1]],
  [
    'select 1; select 2',
    [[select1, select2, rs2], [fields1, fields2, undefined], 3],
  ],
  ['set @a = 1; select 1', [[select1, rs2], [fields1, undefined], 2]],
  ['select 1; set @a = 1', [[select1, rs2], [fields1, undefined], 2]],
  ['select * from no_rows', [[[], rs3], [nr_fields, undefined], 2]], // select 0 rows"
  ['set @a = 1; select * from no_rows', [[[], rs3], [nr_fields, undefined], 2]], // insert + select 0 rows
  ['select * from no_rows; set @a = 1', [[[], rs3], [nr_fields, undefined], 2]], //  select 0 rows + insert
  [
    'set @a = 1; select * from some_rows',
    [[select3, rs3], [sr_fields, undefined], 2],
  ], // insert + select 3 rows
  [
    'select * from some_rows; set @a = 1',
    [[select3, rs3], [sr_fields, undefined], 2],
  ], //  select 3 rows + insert
];

function procedurise(sql) {
  return [
    'DROP PROCEDURE IF EXISTS _as_sp_call;',
    'CREATE PROCEDURE _as_sp_call()',
    'BEGIN',
    `${sql};`,
    'END',
  ].join('\n');
}

function do_test(testIndex) {
  const next = function () {
    if (testIndex + 1 < tests.length) {
      do_test(testIndex + 1);
    } else {
      mysql.end();
    }
  };

  const entry = tests[testIndex];
  let sql = entry[0];
  const expectation = entry[1];
  // prepared statements do not support multiple statements itself, we need to wrap quey in a stored procedure
  const sp = procedurise(sql);
  mysql.query(sp, (err) => {
    if (err) {
      throw err;
    }

    sql = 'CALL _as_sp_call()'; // this call is allowed with prepared statements, and result contain multiple statements
    let _numResults = 0;
    const textCmd = mysql.query(sql, (err, _rows, _columns) => {
      if (err) {
        throw err;
      }

      const arrOrColumn = function (c) {
        if (Array.isArray(c)) {
          return c.map(arrOrColumn);
        }

        if (typeof c === 'undefined') {
          return void 0;
        }

        const column = c.inspect();
        // "columnLength" is non-deterministic and the display width for integer
        // data types was deprecated on MySQL 8.0.17.
        // https://dev.mysql.com/doc/refman/8.0/en/numeric-type-syntax.html
        delete column.columnLength;

        return column;
      };

      assert.deepEqual(expectation[0], _rows);
      assert.deepEqual(expectation[1], arrOrColumn(_columns));

      const q = mysql.execute(sql);
      let resIndex = 0;
      let rowIndex = 0;
      let fieldIndex = -1;

      function checkRow(row) {
        const index = fieldIndex;
        if (_numResults === 1) {
          assert.equal(index, 0);
          if (row.constructor.name === 'ResultSetHeader') {
            assert.deepEqual(_rows, row);
          } else {
            assert.deepEqual(_rows[rowIndex], row);
          }
        } else {
          if (resIndex !== index) {
            rowIndex = 0;
            resIndex = index;
          }
          if (row.constructor.name === 'ResultSetHeader') {
            assert.deepEqual(_rows[index], row);
          } else {
            assert.deepEqual(_rows[index][rowIndex], row);
          }
        }
        rowIndex++;
      }

      function checkFields(fields) {
        fieldIndex++;
        const index = fieldIndex;
        if (_numResults === 1) {
          assert.equal(index, 0);
          assert.deepEqual(arrOrColumn(_columns), arrOrColumn(fields));
        } else {
          assert.deepEqual(arrOrColumn(_columns[index]), arrOrColumn(fields));
        }
      }

      q.on('result', checkRow);
      q.on('fields', checkFields);
      q.on('end', next);
    });

    textCmd.on('fields', () => {
      _numResults++;
    });
  });
}
do_test(0);
</file>

<file path="test/integration/connection/test-binary-notnull-nulls.test.cjs">
'use strict';

const { assert } = require('poku');

const common = require('../../common.test.cjs');
const conn = common.createConnection();

// it's possible to receive null values for columns marked with NOT_NULL flag
// see https://github.com/sidorares/node-mysql2/issues/178 for info

conn.query('set sql_mode=""');

conn.query(
  'CREATE TEMPORARY TABLE `tmp_account` ( ' +
    ' `id` int(11) NOT NULL AUTO_INCREMENT, ' +
    ' `username` varchar(64) NOT NULL, ' +
    ' `auth_code` varchar(30) NOT NULL, ' +
    ' `access_token` varchar(30) NOT NULL, ' +
    ' `refresh_token` tinytext NOT NULL, ' +
    ' PRIMARY KEY (`id`) ' +
    ' ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8'
);
conn.query("INSERT INTO `tmp_account` VALUES ('1', 'xgredx', '', '', '')");

conn.query(
  'CREATE TEMPORARY TABLE `tmp_account_flags` ( ' +
    ' `account` int(11) NOT NULL, ' +
    ' `flag` tinyint(3) NOT NULL, ' +
    ' PRIMARY KEY (`account`,`flag`) ' +
    ' ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8'
);

conn.query("INSERT INTO `tmp_account_flags` VALUES ('1', '100')");

conn.query(
  'CREATE TEMPORARY TABLE `tmp_account_session` ( ' +
    ' `account` int(11) NOT NULL, ' +
    ' `ip` varchar(15) NOT NULL, ' +
    ' `session` varchar(114) NOT NULL, ' +
    ' `time` int(11) NOT NULL, ' +
    ' PRIMARY KEY (`account`,`ip`) ' +
    ' ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8'
);

conn.query(
  "INSERT INTO `tmp_account_session` VALUES ('1', '::1', '75efb145482ce22f4544390cad233c749c1b43e4', '1')"
);

conn.connect((err) => {
  if (err) {
    console.error(err);
    return;
  }

  conn.execute(
    "SELECT `ac`.`username`, CONCAT('[', GROUP_CONCAT(DISTINCT `acf`.`flag` SEPARATOR ','), ']') flags FROM tmp_account ac LEFT JOIN tmp_account_flags acf ON `acf`.account = `ac`.id LEFT JOIN tmp_account_session acs ON `acs`.account = `ac`.id WHERE `acs`.`session`=?",
    ['asid=75efb145482ce22f4544390cad233c749c1b43e4'],
    (err, rows, fields) => {
      /*
      this assertion is valid for mysql8 < 8.0.17 and not longer valid in 8.0.18
      TODO: investigate why and remove
      const flagNotNull = fields[0].flags & FieldFlags.NOT_NULL;
      const valueIsNull = rows[0][fields[0].name] === null;
      assert(flagNotNull && valueIsNull);
      */

      const valueIsNull = rows[0][fields[0].name] === null;
      assert(valueIsNull);
      conn.end();
    }
  );
});
</file>

<file path="test/integration/connection/test-buffer-params.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const connection = common.createConnection();
const { assert } = require('poku');
const { Buffer } = require('node:buffer');
const process = require('node:process');

let rows = undefined;
let rows1 = undefined;

const buf = Buffer.from([
  0x80, 0x90, 1, 2, 3, 4, 5, 6, 7, 8, 9, 100, 100, 255, 255,
]);
connection.execute('SELECT HEX(?) as buf', [buf], (err, _rows) => {
  if (err) {
    throw err;
  }
  rows = _rows;
});

connection.query('SELECT HEX(?) as buf', [buf], (err, _rows) => {
  if (err) {
    throw err;
  }
  rows1 = _rows;
  connection.end();
});

process.on('exit', () => {
  assert.deepEqual(rows, [{ buf: buf.toString('hex').toUpperCase() }]);
  assert.deepEqual(rows1, [{ buf: buf.toString('hex').toUpperCase() }]);
});
</file>

<file path="test/integration/connection/test-change-user-multi-factor.test.cjs">
// Copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const mysql = require('../../../index.js');
const Command = require('../../../lib/commands/command.js');
const Packets = require('../../../lib/packets/index.js');
const { Buffer } = require('node:buffer');
const { assert } = require('poku');
const process = require('node:process');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

class TestChangeUserMultiFactor extends Command {
  constructor(args) {
    super();
    this.args = args;
    this.authFactor = 0;
  }

  start(_, connection) {
    const serverHelloPacket = new Packets.Handshake({
      // "required" properties
      serverVersion: 'node.js rocks',
      // the server should announce support for the
      // "MULTI_FACTOR_AUTHENTICATION" capability
      capabilityFlags: 0xdfffffff,
    });
    this.serverHello = serverHelloPacket;
    serverHelloPacket.setScrambleData(() => {
      connection.writePacket(serverHelloPacket.toPacket(0));
    });
    return TestChangeUserMultiFactor.prototype.acceptConnection;
  }

  acceptConnection(_, connection) {
    connection.writeOk();
    return TestChangeUserMultiFactor.prototype.readChangeUser;
  }

  readChangeUser(_, connection) {
    const asr = new Packets.AuthSwitchRequest(this.args[this.authFactor]);
    connection.writePacket(asr.toPacket());
    return TestChangeUserMultiFactor.prototype.sendAuthNextFactor;
  }

  sendAuthNextFactor(_, connection) {
    console.log('this.authFactor:', this.authFactor);
    // const asr = Packets.AuthSwitchResponse.fromPacket(packet);
    // assert.deepStrictEqual(asr.data.toString(), this.args[this.authFactor].pluginName);
    if (this.authFactor === 1) {
      // send OK_Packet after the 3rd authentication factor
      connection.writeOk();
      return TestChangeUserMultiFactor.prototype.dispatchCommands;
    }
    this.authFactor += 1;
    const anf = new Packets.AuthNextFactor(this.args[this.authFactor]);
    connection.writePacket(anf.toPacket(connection.serverConfig.encoding));
    return TestChangeUserMultiFactor.prototype.sendAuthNextFactor;
  }

  dispatchCommands(_, connection) {
    connection.end();
    return TestChangeUserMultiFactor.prototype.dispatchCommands;
  }
}

const server = mysql.createServer((conn) => {
  conn.serverConfig = {};
  conn.serverConfig.encoding = 'cesu8';
  conn.addCommand(
    new TestChangeUserMultiFactor([
      {
        // already covered by test-auth-switch
        pluginName: 'auth_test_plugin1',
        pluginData: Buffer.from('foo'),
      },
      {
        // 2nd factor auth plugin
        pluginName: 'auth_test_plugin2',
        pluginData: Buffer.from('bar'),
      },
    ])
  );
});

const completed = [];
const password1 = 'secret1';
const password2 = 'secret2';

const portfinder = require('portfinder');
portfinder.getPort((_, port) => {
  server.listen(port);
  const conn = mysql.createConnection({
    port: port,
    authPlugins: {
      auth_test_plugin1(options) {
        return () => {
          if (options.connection.config.password !== password1) {
            return assert.fail('Incorrect authentication factor password.');
          }

          const pluginName = 'auth_test_plugin1';
          completed.push(pluginName);

          return Buffer.from(pluginName);
        };
      },
      auth_test_plugin2(options) {
        return () => {
          if (options.connection.config.password !== password2) {
            return assert.fail('Incorrect authentication factor password.');
          }

          const pluginName = 'auth_test_plugin2';
          completed.push(pluginName);

          return Buffer.from(pluginName);
        };
      },
    },
  });

  conn.on('connect', () => {
    conn.changeUser({ password1, password2 }, () => {
      assert.deepStrictEqual(completed, [
        'auth_test_plugin1',
        'auth_test_plugin2',
      ]);

      conn.end();
      server.close();
    });
  });
});
</file>

<file path="test/integration/connection/test-change-user-plugin-auth.test.cjs">
'use strict';

const { assert } = require('poku');
const common = require('../../common.test.cjs');
const { Buffer } = require('node:buffer');
const process = require('node:process');

if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

const connection = common.createConnection();
const onlyUsername = function (name) {
  return name.substring(0, name.indexOf('@'));
};

connection.query(
  "CREATE USER IF NOT EXISTS 'changeuser1'@'%' IDENTIFIED BY 'changeuser1pass'"
);
connection.query(
  "CREATE USER IF NOT EXISTS 'changeuser2'@'%' IDENTIFIED BY 'changeuser2pass'"
);
connection.query("GRANT ALL ON *.* TO 'changeuser1'@'%'");
connection.query("GRANT ALL ON *.* TO 'changeuser2'@'%'");
connection.query('FLUSH PRIVILEGES');

connection.changeUser(
  {
    user: 'changeuser1',
    password: 'changeuser1pass',
  },
  (err) => {
    assert.ifError(err);
    connection.query('select current_user()', (err, rows) => {
      assert.ifError(err);
      assert.deepEqual(onlyUsername(rows[0]['current_user()']), 'changeuser1');

      connection.changeUser(
        {
          user: 'changeuser2',
          password: 'changeuser2pass',
        },
        (err) => {
          assert.ifError(err);

          connection.query('select current_user()', (err, rows) => {
            assert.ifError(err);
            assert.deepEqual(
              onlyUsername(rows[0]['current_user()']),
              'changeuser2'
            );

            connection.changeUser(
              {
                user: 'changeuser1',
                password: 'changeuser1pass',
                passwordSha1: Buffer.from(
                  'f961d39c82138dcec42b8d0dcb3e40a14fb7e8cd',
                  'hex'
                ), // sha1(changeuser1pass)
              },
              () => {
                connection.query('select current_user()', (err, rows) => {
                  assert.ifError(err);
                  assert.deepEqual(
                    onlyUsername(rows[0]['current_user()']),
                    'changeuser1'
                  );
                  connection.end();
                });
              }
            );
          });
        }
      );
    });
  }
);
</file>

<file path="test/integration/connection/test-change-user.test.cjs">
'use strict';

const { assert } = require('poku');
const common = require('../../common.test.cjs');
const { Buffer } = require('node:buffer');
const process = require('node:process');

if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

const connection = common.createConnection();
const onlyUsername = function (name) {
  return name.substring(0, name.indexOf('@'));
};

connection.query(
  "CREATE USER IF NOT EXISTS 'changeuser1'@'%' IDENTIFIED BY 'changeuser1pass'"
);
connection.query(
  "CREATE USER IF NOT EXISTS 'changeuser2'@'%' IDENTIFIED BY 'changeuser2pass'"
);
connection.query("GRANT ALL ON *.* TO 'changeuser1'@'%'");
connection.query("GRANT ALL ON *.* TO 'changeuser2'@'%'");
connection.query('FLUSH PRIVILEGES');

connection.changeUser(
  {
    user: 'changeuser1',
    password: 'changeuser1pass',
  },
  (err) => {
    assert.ifError(err);
    connection.query('select current_user()', (err, rows) => {
      assert.ifError(err);
      assert.deepEqual(onlyUsername(rows[0]['current_user()']), 'changeuser1');

      connection.changeUser(
        {
          user: 'changeuser2',
          password: 'changeuser2pass',
        },
        (err) => {
          assert.ifError(err);

          connection.query('select current_user()', (err, rows) => {
            assert.ifError(err);
            assert.deepEqual(
              onlyUsername(rows[0]['current_user()']),
              'changeuser2'
            );

            connection.changeUser(
              {
                user: 'changeuser1',
                password: 'changeuser1pass',
                passwordSha1: Buffer.from(
                  'f961d39c82138dcec42b8d0dcb3e40a14fb7e8cd',
                  'hex'
                ), // sha1(changeuser1pass)
              },
              () => {
                connection.query('select current_user()', (err, rows) => {
                  assert.ifError(err);
                  assert.deepEqual(
                    onlyUsername(rows[0]['current_user()']),
                    'changeuser1'
                  );
                  connection.end();
                });
              }
            );
          });
        }
      );
    });
  }
);
</file>

<file path="test/integration/connection/test-charset-encoding.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const connection = common.createConnection();
const { assert } = require('poku');
const process = require('node:process');

// test data stores
const testData = [
  'ютф восемь',
  'Experimental',
  'परीक्षण',
  'test тест テスト փորձաsրկում পরীক্ষা kiểm tra',
  'ტესტი પરીક્ષણ  מבחן פּרובירן اختبار',
];

let resultData = null;

// test inserting of non latin data if we are able to parse it

const testEncoding = function (err) {
  assert.ifError(err);

  testData.forEach((data) => {
    connection.query(
      'INSERT INTO `test-charset-encoding` (field) values(?)',
      [data],
      (err2) => {
        assert.ifError(err2);
      }
    );
  });

  connection.query('SELECT * from `test-charset-encoding`', (err, results) => {
    assert.ifError(err);
    resultData = results;
  });
  connection.end();
};

// init test sequence
(function () {
  connection.query('DROP TABLE IF EXISTS `test-charset-encoding`', () => {
    connection.query(
      'CREATE TABLE IF NOT EXISTS `test-charset-encoding` ' +
        '( `field` VARCHAR(1000) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci)',
      (err) => {
        assert.ifError(err);
        connection.query('DELETE from `test-charset-encoding`', testEncoding);
      }
    );
  });
})();

process.on('exit', () => {
  resultData.forEach((data, index) => {
    assert.equal(data.field, testData[index]);
  });
});
</file>

<file path="test/integration/connection/test-connect-after-connection-error.test.cjs">
'use strict';

const mysql = require('../../../index.js');
const { assert } = require('poku');
const process = require('node:process');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

const ERROR_TEXT = 'Connection lost: The server closed the connection.';

const portfinder = require('portfinder');
portfinder.getPort((err, port) => {
  const server = mysql.createServer();
  let serverConnection;
  server.listen(port);
  server.on('connection', (conn) => {
    conn.serverHandshake({
      serverVersion: '5.6.10',
      capabilityFlags: 2181036031,
    });
    serverConnection = conn;
  });

  const clientConnection = mysql.createConnection({
    host: 'localhost',
    port: port,
    user: 'testuser',
    database: 'testdatabase',
    password: 'testpassword',
  });

  clientConnection.on('connect', () => {
    serverConnection.close();
  });

  clientConnection.once('error', () => {
    clientConnection.connect((err) => {
      assert.equal(err.message, ERROR_TEXT);
      clientConnection.close();
      server._server.close();
    });
  });
});
</file>

<file path="test/integration/connection/test-connect-after-connection.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let connection2;

connection.once('connect', () => {
  connection.connect((err, _connection) => {
    if (err) {
      throw err;
    }
    connection2 = _connection;
    connection.end();
  });
});

process.on('exit', () => {
  assert.equal(connection, connection2);
});
</file>

<file path="test/integration/connection/test-connect-connection-closed-error.test.cjs">
'use strict';

const mysql = require('../../../index.js');
const { assert } = require('poku');
const process = require('node:process');
const portfinder = require('portfinder');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

const ERROR_TEXT = 'Connection lost: The server closed the connection.';

portfinder.getPort((err, port) => {
  const server = mysql.createServer();
  server.listen(port);
  server.on('connection', (conn) => {
    conn.close();
  });

  const connection = mysql.createConnection({
    host: 'localhost',
    port: port,
    user: 'testuser',
    database: 'testdatabase',
    password: 'testpassword',
  });

  connection.query('select 1', (err) => {
    assert.equal(err.message, ERROR_TEXT);
    server._server.close();
  });
});
</file>

<file path="test/integration/connection/test-connect-sha1.test.cjs">
'use strict';

const mysql = require('../../../index.js');
const auth = require('../../../lib/auth_41.js');
const { assert } = require('poku');
const { Buffer } = require('node:buffer');
const process = require('node:process');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

function authenticate(params, cb) {
  const doubleSha = auth.doubleSha1('testpassword');
  const isValid = auth.verifyToken(
    params.authPluginData1,
    params.authPluginData2,
    params.authToken,
    doubleSha
  );
  assert(isValid);
  cb(null);
}

let _1_2 = false;
let _1_3 = false;

let queryCalls = 0;

const portfinder = require('portfinder');
portfinder.getPort((err, port) => {
  const server = mysql.createServer();
  server.listen(port);
  server.on('connection', (conn) => {
    conn.serverHandshake({
      protocolVersion: 10,
      serverVersion: 'node.js rocks',
      connectionId: 1234,
      statusFlags: 2,
      characterSet: 8,
      capabilityFlags: 0xffffff,
      authCallback: authenticate,
    });
    conn.on('query', (sql) => {
      assert.equal(sql, 'select 1+1');
      queryCalls++;
      conn.close();
    });
  });

  const connection = mysql.createConnection({
    port: port,
    user: 'testuser',
    database: 'testdatabase',
    passwordSha1: Buffer.from(
      '8bb6118f8fd6935ad0876a3be34a717d32708ffd',
      'hex'
    ),
  });

  connection.on('error', (err) => {
    assert.equal(err.code, 'PROTOCOL_CONNECTION_LOST');
  });

  connection.query('select 1+1', (err) => {
    assert.equal(err.code, 'PROTOCOL_CONNECTION_LOST');
    server._server.close();
  });

  connection.query('select 1+2', (err) => {
    assert.equal(err.code, 'PROTOCOL_CONNECTION_LOST');
    _1_2 = true;
  });

  connection.query('select 1+3', (err) => {
    assert.equal(err.code, 'PROTOCOL_CONNECTION_LOST');
    _1_3 = true;
  });
});

process.on('exit', () => {
  assert.equal(queryCalls, 1);
  assert.equal(_1_2, true);
  assert.equal(_1_3, true);
});
</file>

<file path="test/integration/connection/test-connect-time-error.test.cjs">
'use strict';

const mysql = require('../../../index.js');
const { assert } = require('poku');
const process = require('node:process');
const portfinder = require('portfinder');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

const ERROR_TEXT = 'test error';

portfinder.getPort((err, port) => {
  const server = mysql.createServer();
  server.listen(port);
  server.on('connection', (conn) => {
    conn.writeError(new Error(ERROR_TEXT));
    conn.close();
  });

  const connection = mysql.createConnection({
    host: 'localhost',
    port: port,
    user: 'testuser',
    database: 'testdatabase',
    password: 'testpassword',
  });

  connection.query('select 1+1', (err) => {
    assert.equal(err.message, ERROR_TEXT);
  });

  connection.query('select 1+2', (err) => {
    assert.equal(err.message, ERROR_TEXT);
    connection.close();
    server._server.close();
  });
});
</file>

<file path="test/integration/connection/test-connect-with-uri.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

if (process.env.MYSQL_CONNECTION_URL) {
  console.log(
    'skipping test when mysql server is configured using MYSQL_CONNECTION_URL'
  );
  process.exit(0);
}

const connection = common.createConnectionWithURI();

let rows = undefined;
let fields = undefined;
connection.query('SELECT 1', (err, _rows, _fields) => {
  if (err) {
    throw err;
  }

  rows = _rows;
  fields = _fields;
  connection.end();
});

process.on('exit', () => {
  assert.deepEqual(rows, [{ 1: 1 }]);
  assert.equal(fields[0].name, '1');
});
</file>

<file path="test/integration/connection/test-connection-reset-while-closing.test.cjs">
'use strict';

const assert = require('node:assert');
const common = require('../../common.test.cjs');
const process = require('node:process');

const error = new Error('read ECONNRESET');
error.code = 'ECONNRESET';
error.errno = -54;
error.syscall = 'read';

const connection = common.createConnection();

// Test that we ignore a ECONNRESET error if the connection
// is already closing, we close and then emit the error
connection.query(`select 1 as "1"`, (err, rows) => {
  assert.equal(rows[0]['1'], 1);
  connection.close();
  connection.stream.emit('error', error);
});

process.on('uncaughtException', (err) => {
  assert.notEqual(err.code, 'ECONNRESET');
});
</file>

<file path="test/integration/connection/test-custom-date-parameter.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection({ timezone: 'Z' });

let rows = undefined;

// eslint-disable-next-line no-global-assign
Date = (function () {
  const NativeDate = Date;
  function CustomDate(str) {
    return new NativeDate(str);
  }
  CustomDate.now = Date.now;
  return CustomDate;
})();

connection.query("set time_zone = '+00:00'");
connection.execute(
  'SELECT UNIX_TIMESTAMP(?) t',
  [new Date('1990-08-08 UTC')],
  (err, _rows) => {
    if (err) {
      throw err;
    }
    rows = _rows;
    connection.end();
  }
);

process.on('exit', () => {
  assert.equal(rows[0].t, 650073600);
});
</file>

<file path="test/integration/connection/test-date-parameter.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection({ timezone: 'Z' });

let rows = undefined;

connection.query("set time_zone = '+00:00'");
connection.execute(
  'SELECT UNIX_TIMESTAMP(?) t',
  [new Date('1990-01-01 UTC')],
  (err, _rows) => {
    if (err) {
      throw err;
    }
    rows = _rows;
    connection.end();
  }
);

process.on('exit', () => {
  assert.deepEqual(rows, [{ t: 631152000 }]);
});
</file>

<file path="test/integration/connection/test-datetime.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();
const connection1 = common.createConnection({ dateStrings: true });
const connection2 = common.createConnection({ dateStrings: ['DATE'] });
const connectionZ = common.createConnection({ timezone: 'Z' });
const connection0930 = common.createConnection({ timezone: '+09:30' });

let rows,
  rowsZ,
  rows0930,
  rows1,
  rows1Z,
  rows10930,
  rows2,
  rows3,
  rows4,
  rows5,
  rows6,
  rows7,
  rows8;

const date = new Date('1990-01-01 08:15:11 UTC');
const datetime = new Date('2010-12-10 14:12:09.019473');

const date1 = new Date('2000-03-03 08:15:11 UTC');
const date2 = '2010-12-10 14:12:09.019473';
const date3 = null;
const date4 = '2010-12-10 14:12:09.123456';
const date5 = '2010-12-10 14:12:09.019';
const date6 = '2024-11-10 00:00:00';

function adjustTZ(d, offset) {
  if (offset === undefined) {
    offset = d.getTimezoneOffset();
  }
  return new Date(d.getTime() - offset * 60000);
}

function toMidnight(d, offset) {
  const t = d.getTime();
  if (offset === undefined) {
    offset = d.getTimezoneOffset();
  }
  return new Date(t - (t % (24 * 60 * 60 * 1000)) + offset * 60000);
}

function formatUTCDate(d) {
  return d.toISOString().substring(0, 10);
}

function formatUTCDateTime(d, precision) {
  const raw = d.toISOString().replace('T', ' ');
  if (precision === undefined) {
    precision = 0;
  }
  return precision <= 3
    ? raw.substring(0, 19 + (precision && 1) + precision)
    : raw.substring(0, 23) + '0'.repeat(precision - 3);
}

connection.query(
  'CREATE TEMPORARY TABLE t (d1 DATE, d2 DATETIME(3), d3 DATETIME(6))'
);
connection.query('INSERT INTO t set d1=?, d2=?, d3=?', [
  date,
  datetime,
  datetime,
]);

connection1.query(
  'CREATE TEMPORARY TABLE t (d1 DATE, d2 TIMESTAMP, d3 DATETIME, d4 DATETIME, d5 DATETIME(6), d6 DATETIME(3), d7 DATETIME)'
);
connection1.query(
  'INSERT INTO t set d1=?, d2=?, d3=?, d4=?, d5=?, d6=?, d7=?',
  [date, date1, date2, date3, date4, date5, date6]
);

connection2.query(
  'CREATE TEMPORARY TABLE t (d1 DATE, d2 TIMESTAMP, d3 DATETIME, d4 DATETIME, d5 DATETIME(6), d6 DATETIME(3), d7 DATETIME)'
);
connection2.query(
  'INSERT INTO t set d1=?, d2=?, d3=?, d4=?, d5=?, d6=?, d7=?',
  [date, date1, date2, date3, date4, date5, date6]
);

connectionZ.query(
  'CREATE TEMPORARY TABLE t (d1 DATE, d2 DATETIME(3), d3 DATETIME(6))'
);
connectionZ.query("set time_zone = '+00:00'");
connectionZ.query('INSERT INTO t set d1=?, d2=?, d3=?', [
  date,
  datetime,
  datetime,
]);

connection0930.query(
  'CREATE TEMPORARY TABLE t (d1 DATE, d2 DATETIME(3), d3 DATETIME(6))'
);
connection0930.query("set time_zone = '+09:30'");
connection0930.query('INSERT INTO t set d1=?, d2=?, d3=?', [
  date,
  datetime,
  datetime,
]);

const dateAsStringExpected = [
  {
    d1: formatUTCDate(adjustTZ(date)),
    d2: formatUTCDateTime(adjustTZ(date1)),
    d3: date2.substring(0, 19),
    d4: date3,
    d5: date4,
    d6: date5,
    d7: date6,
  },
];

connection.execute(
  'select from_unixtime(?) t',
  [(+date).valueOf() / 1000],
  (err, _rows) => {
    if (err) {
      throw err;
    }
    rows = _rows;
  }
);

connectionZ.execute(
  'select from_unixtime(?) t',
  [(+date).valueOf() / 1000],
  (err, _rows) => {
    if (err) {
      throw err;
    }
    rowsZ = _rows;
  }
);

connection0930.execute(
  'select from_unixtime(?) t',
  [(+date).valueOf() / 1000],
  (err, _rows) => {
    if (err) {
      throw err;
    }
    rows0930 = _rows;
  }
);

connection.query('select from_unixtime(631152000) t', (err, _rows) => {
  if (err) {
    throw err;
  }
  rows1 = _rows;
});

connectionZ.query('select from_unixtime(631152000) t', (err, _rows) => {
  if (err) {
    throw err;
  }
  rows1Z = _rows;
});

connection0930.query('select from_unixtime(631152000) t', (err, _rows) => {
  if (err) {
    throw err;
  }
  rows10930 = _rows;
});

connection.query(
  'select *, cast(d1 as char) as d4, cast(d2 as char) as d5, cast(d3 as char) as d6 from t',
  (err, _rows) => {
    if (err) {
      throw err;
    }
    rows2 = _rows;
    connection.end();
  }
);

connectionZ.execute(
  'select *, cast(d1 as char) as d4, cast(d2 as char) as d5, cast(d3 as char) as d6 from t',
  (err, _rows) => {
    if (err) {
      throw err;
    }
    rows3 = _rows;
    connectionZ.end();
  }
);

connection1.query('select * from t', (err, _rows) => {
  if (err) {
    throw err;
  }
  rows4 = _rows;
});

connection1.execute('select * from t', (err, _rows) => {
  if (err) {
    throw err;
  }
  rows5 = _rows;
});

connection1.execute(
  'select * from t where d6 = ?',
  [new Date(date5)],
  (err, _rows) => {
    if (err) {
      throw err;
    }
    rows6 = _rows;
    connection1.end();
  }
);

connection2.execute('select * from t', (err, _rows) => {
  if (err) {
    throw err;
  }
  rows8 = _rows;
  connection2.end();
});

connection0930.execute(
  'select *, cast(d1 as char) as d4, cast(d2 as char) as d5, cast(d3 as char) as d6 from t',
  (err, _rows) => {
    if (err) {
      throw err;
    }
    rows7 = _rows;
    connection0930.end();
  }
);

process.on('exit', () => {
  const connBadTz = common.createConnection({ timezone: 'utc' });
  assert.equal(connBadTz.config.timezone, 'Z');
  connBadTz.end();

  // local TZ
  assert.equal(rows[0].t.constructor, Date);
  assert.equal(rows[0].t.getDate(), date.getDate());
  assert.equal(rows[0].t.getHours(), date.getHours());
  assert.equal(rows[0].t.getMinutes(), date.getMinutes());
  assert.equal(rows[0].t.getSeconds(), date.getSeconds());

  // UTC
  assert.equal(rowsZ[0].t.constructor, Date);
  assert.equal(rowsZ[0].t.getDate(), date.getDate());
  assert.equal(rowsZ[0].t.getHours(), date.getHours());
  assert.equal(rowsZ[0].t.getMinutes(), date.getMinutes());
  assert.equal(rowsZ[0].t.getSeconds(), date.getSeconds());

  // +09:30
  assert.equal(rows0930[0].t.constructor, Date);
  assert.equal(rows0930[0].t.getDate(), date.getDate());
  assert.equal(rows0930[0].t.getHours(), date.getHours());
  assert.equal(rows0930[0].t.getMinutes(), date.getMinutes());
  assert.equal(rows0930[0].t.getSeconds(), date.getSeconds());

  // local TZ
  assert.equal(rows1[0].t.constructor, Date);
  assert.equal(
    rows1[0].t.getTime(),
    new Date('Mon Jan 01 1990 00:00:00 UTC').getTime()
  );

  // UTC
  assert.equal(rows1Z[0].t.constructor, Date);
  assert.equal(
    rows1Z[0].t.getTime(),
    new Date('Mon Jan 01 1990 00:00:00 UTC').getTime()
  );

  // +09:30
  assert.equal(rows10930[0].t.constructor, Date);
  assert.equal(
    rows10930[0].t.getTime(),
    new Date('Mon Jan 01 1990 00:00:00 UTC').getTime()
  );

  // local TZ
  assert.equal(rows2[0].d1.getTime(), toMidnight(date).getTime());
  assert.equal(rows2[0].d2.getTime(), datetime.getTime());
  assert.equal(rows2[0].d3.getTime(), datetime.getTime());
  assert.equal(rows2[0].d4, formatUTCDate(adjustTZ(date)));
  assert.equal(rows2[0].d5, formatUTCDateTime(adjustTZ(datetime), 3));
  assert.equal(rows2[0].d6, formatUTCDateTime(adjustTZ(datetime), 6));

  // UTC
  assert.equal(rows3[0].d1.getTime(), toMidnight(date, 0).getTime());
  assert.equal(rows3[0].d2.getTime(), datetime.getTime());
  assert.equal(rows3[0].d3.getTime(), datetime.getTime());
  assert.equal(rows3[0].d4, formatUTCDate(date));
  assert.equal(rows3[0].d5, formatUTCDateTime(datetime, 3));
  assert.equal(rows3[0].d6, formatUTCDateTime(datetime, 6));

  // dateStrings
  assert.deepEqual(rows4, dateAsStringExpected);
  assert.deepEqual(rows5, dateAsStringExpected);
  assert.equal(rows6.length, 1);

  // dateStrings as array
  assert.equal(rows8[0].d1, '1990-01-01');
  assert.equal(rows8[0].d1.constructor, String);
  assert.equal(rows8[0].d2.constructor, Date);
  assert.equal(rows8[0].d3.constructor, Date);
  assert.equal(rows8[0].d4, null);
  assert.equal(rows8[0].d5.constructor, Date);
  assert.equal(rows8[0].d6.constructor, Date);

  // +09:30
  const tzOffset = -570;
  assert.equal(rows7[0].d1.getTime(), toMidnight(date, tzOffset).getTime());
  assert.equal(rows7[0].d2.getTime(), datetime.getTime());
  assert.equal(rows7[0].d3.getTime(), datetime.getTime());
  assert.equal(rows7[0].d4, formatUTCDate(adjustTZ(date, tzOffset)));
  assert.equal(rows7[0].d5, formatUTCDateTime(adjustTZ(datetime, tzOffset), 3));
  assert.equal(rows7[0].d6, formatUTCDateTime(adjustTZ(datetime, tzOffset), 6));
});
</file>

<file path="test/integration/connection/test-decimals-as-numbers.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');

const connection1 = common.createConnection({
  decimalNumbers: false,
});
const connection2 = common.createConnection({
  decimalNumbers: true,
});

const largeDecimal = 900719.547409;
const largeDecimalExpected = '900719.547409000000000000000000000000';
const largeMoneyValue = 900719925474.99;

connection1.query('CREATE TEMPORARY TABLE t1 (d1 DECIMAL(65, 30))');
connection1.query('INSERT INTO t1 set d1=?', [largeDecimal]);

connection2.query('CREATE TEMPORARY TABLE t2 (d1 DECIMAL(14, 2))');
connection2.query('INSERT INTO t2 set d1=?', [largeMoneyValue]);

connection1.execute('select d1 from t1', (err, _rows) => {
  if (err) {
    throw err;
  }
  assert.equal(_rows[0].d1.constructor, String);
  assert.equal(_rows[0].d1, largeDecimalExpected);
  connection1.end();
});

connection2.query('select d1 from t2', (err, _rows) => {
  if (err) {
    throw err;
  }
  assert.equal(_rows[0].d1.constructor, Number);
  assert.equal(_rows[0].d1, largeMoneyValue);
  connection2.end();
});
</file>

<file path="test/integration/connection/test-disconnects.test.cjs">
// This file was modified by Oracle on January 21, 2021.
// The connection with the mock server needs to happen in the same host where
// the tests are running in order to avoid connecting a potential MySQL server
// instance running in the host identified by the MYSQL_HOST environment
// variable.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

let rows;
let fields;

const connections = [];

const server = common.createServer(
  () => {
    const connection = common.createConnection({
      // The mock server is running on the same host machine.
      // We need to explicitly define the host to avoid connecting to a potential
      // different host provided via MYSQL_HOST that identifies a real MySQL
      // server instance.
      host: 'localhost',
      port: server._port,
      ssl: false,
    });
    connection.query('SELECT 123', (err, _rows, _fields) => {
      if (err) {
        throw err;
      }

      rows = _rows;
      fields = _fields;
      connection.on('error', (_err) => {
        err = _err;
      });

      connections.forEach((conn) => {
        conn.stream.end();
      });
      server._server.close(() => {
        assert.equal(err.code, 'PROTOCOL_CONNECTION_LOST');
      });
    });
    // TODO: test connection.end() etc where we expect disconnect to happen
  },
  (conn) => {
    connections.push(conn);
    conn.on('query', () => {
      conn.writeTextResult(
        [{ 1: '1' }],
        [
          {
            catalog: 'def',
            schema: '',
            table: '',
            orgTable: '',
            name: '1',
            orgName: '',
            characterSet: 63,
            columnLength: 1,
            columnType: 8,
            type: 8,
            flags: 129,
            decimals: 0,
          },
        ]
      );
    });
  }
);

process.on('exit', () => {
  assert.deepEqual(rows, [{ 1: 1 }]);
  assert.equal(fields[0].name, '1');
});
</file>

<file path="test/integration/connection/test-error-events.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

let callCount = 0;
let exceptionCount = 0;

process.on('uncaughtException', (err) => {
  assert.ifError(err);
  exceptionCount++;
});

const connection1 = common.createConnection({
  password: 'lol',
});

// error will NOT bubble up to process level if `on` is used
connection1.on('error', () => {
  callCount++;
});

const connection2 = common.createConnection({
  password: 'lol',
});

// error will bubble up to process level if `once` is used
connection2.once('error', () => {
  callCount++;
});

process.on('exit', () => {
  assert.equal(callCount, 2);
  assert.equal(exceptionCount, 0);
});
</file>

<file path="test/integration/connection/test-errors.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

// different error codes for PS, disabling for now
if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

const connection = common.createConnection();

let onExecuteResultError = undefined;
let onQueryResultError = undefined;
let onExecuteErrorEvent = undefined;
let onQueryErrorEvent = undefined;
let onExecuteErrorEvent1 = undefined;
let onQueryErrorEvent1 = undefined;

connection
  .execute('error in execute', [], (err) => {
    assert.equal(err.errno, 1064);
    assert.equal(err.code, 'ER_PARSE_ERROR');
    assert.equal(err.sql, 'error in execute');
    if (err) {
      onExecuteResultError = true;
    }
  })
  .on('error', () => {
    onExecuteErrorEvent = true;
  });
connection
  .query('error in query', [], (err) => {
    assert.equal(err.errno, 1064);
    assert.equal(err.code, 'ER_PARSE_ERROR');
    assert.equal(err.sql, 'error in query');
    if (err) {
      onQueryResultError = true;
    }
  })
  .on('error', () => {
    onQueryErrorEvent = true;
  });
connection.execute('error in execute 1', []).on('error', () => {
  onExecuteErrorEvent1 = true;
});
connection.query('error in query 1').on('error', () => {
  onQueryErrorEvent1 = true;
  connection.end();
});

process.on('exit', () => {
  assert.equal(onExecuteResultError, true);
  assert.equal(onQueryResultError, true);
  assert.equal(onExecuteErrorEvent, undefined);
  assert.equal(onQueryErrorEvent, undefined);
  assert.equal(onExecuteErrorEvent1, true);
  assert.equal(onQueryErrorEvent1, true);
});
</file>

<file path="test/integration/connection/test-execute-and-unprepare.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const connection = common.createConnection();

const max = 500;
function exec(i) {
  const query = `select 1+${i}`;
  connection.execute(query, (err) => {
    connection.unprepare(query);
    if (err) {
      throw err;
    }
    if (i > max) {
      connection.end();
    } else {
      exec(i + 1);
    }
  });
}
connection.query('SET GLOBAL max_prepared_stmt_count=10', (err) => {
  if (err) {
    throw err;
  }
  exec(1);
});
</file>

<file path="test/integration/connection/test-execute-bind-boolean.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let rows;
connection.execute(
  'SELECT ? AS trueValue, ? AS falseValue',
  [true, false],
  (err, _rows) => {
    if (err) {
      throw err;
    }
    rows = _rows;
    connection.end();
  }
);

process.on('exit', () => {
  assert.deepEqual(rows, [{ trueValue: 1, falseValue: 0 }]);
});
</file>

<file path="test/integration/connection/test-execute-bind-date.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();
const date = new Date(2018, 2, 10, 15, 12, 34, 1234);

let rows;
connection.execute(
  'SELECT CAST(? AS DATETIME(6)) AS result',
  [date],
  (err, _rows) => {
    if (err) {
      throw err;
    }
    rows = _rows;
    connection.end();
  }
);

process.on('exit', () => {
  assert.deepEqual(rows, [{ result: date }]);
});
</file>

<file path="test/integration/connection/test-execute-bind-function.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let error = null;

try {
  connection.execute('SELECT ? AS result', [function () {}], () => {});
} catch (err) {
  error = err;
  connection.end();
}

process.on('exit', () => {
  assert.equal(error.name, 'TypeError');
  if (!error.message.match(/function/)) {
    assert.fail("Expected error.message to contain 'function'");
  }
});
</file>

<file path="test/integration/connection/test-execute-bind-json.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();
const table = 'jsontable';
const testJson = [{ a: 1, b: true, c: ['foo'] }];

let rows;
connection.query(`CREATE TEMPORARY TABLE ${table} (data JSON)`);
connection.query(
  `INSERT INTO ${table} (data) VALUES ('${JSON.stringify(testJson)}')`
);
connection.execute(`SELECT * from ${table}`, (err, _rows) => {
  if (err) {
    throw err;
  }
  rows = _rows;
  connection.end();
});

process.on('exit', () => {
  assert.deepEqual(rows, [{ data: testJson }]);
});
</file>

<file path="test/integration/connection/test-execute-bind-null.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let rows;
connection.execute(
  'SELECT ? AS firstValue, ? AS nullValue, ? AS lastValue',
  ['foo', null, 'bar'],
  (err, _rows) => {
    if (err) {
      throw err;
    }
    rows = _rows;
    connection.end();
  }
);

process.on('exit', () => {
  assert.deepEqual(rows, [
    { firstValue: 'foo', nullValue: null, lastValue: 'bar' },
  ]);
});
</file>

<file path="test/integration/connection/test-execute-bind-number.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let rows;
connection.execute(
  'SELECT ? AS zeroValue, ? AS positiveValue, ? AS negativeValue, ? AS decimalValue',
  [0, 123, -123, 1.25],
  (err, _rows) => {
    if (err) {
      throw err;
    }
    rows = _rows;
    connection.end();
  }
);

process.on('exit', () => {
  assert.deepEqual(rows, [
    {
      zeroValue: 0,
      positiveValue: 123,
      negativeValue: -123,
      decimalValue: 1.25,
    },
  ]);
});
</file>

<file path="test/integration/connection/test-execute-bind-undefined.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let error = null;

try {
  connection.execute('SELECT ? AS result', [undefined], () => {});
} catch (err) {
  error = err;
  connection.end();
}

process.on('exit', () => {
  assert.equal(error.name, 'TypeError');
  if (!error.message.match(/undefined/)) {
    assert.fail("Expected error.message to contain 'undefined'");
  }
});
</file>

<file path="test/integration/connection/test-execute-cached.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let rows = undefined;
let rows1 = undefined;
let rows2 = undefined;

const q = 'select 1 + ? as test';
const key = `undefined/undefined/undefined${q}`;

connection.execute(q, [123], (err, _rows) => {
  if (err) {
    throw err;
  }
  rows = _rows;
  connection.execute(q, [124], (err, _rows) => {
    if (err) {
      throw err;
    }
    rows1 = _rows;
    connection.execute(q, [125], (err, _rows) => {
      if (err) {
        throw err;
      }
      rows2 = _rows;
      assert(connection._statements.size === 1);
      assert(connection._statements.get(key).query === q);
      assert(connection._statements.get(key).parameters.length === 1);
      connection.end();
    });
  });
});

process.on('exit', () => {
  assert.deepEqual(rows, [{ test: 124 }]);
  assert.deepEqual(rows1, [{ test: 125 }]);
  assert.deepEqual(rows2, [{ test: 126 }]);
});
</file>

<file path="test/integration/connection/test-execute-newdecimal.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

connection.query('CREATE TEMPORARY TABLE t (f DECIMAL(19,4))');
connection.query('INSERT INTO t VALUES(12345.67)');

let rows, fields;
connection.execute('SELECT f FROM t', (err, _rows, _fields) => {
  if (err) {
    throw err;
  }
  rows = _rows;
  fields = _fields;
  connection.end();
});

process.on('exit', () => {
  assert.deepEqual(rows, [{ f: '12345.6700' }]);
  assert.equal(fields[0].name, 'f');
});
</file>

<file path="test/integration/connection/test-execute-nocolumndef.test.cjs">
// This file was modified by Oracle on June 2, 2021.
// The test has been updated to remove all expectations with regards to the
// "columnLength" metadata field.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const common = require('../../common.test.cjs');
const assert = require('assert-diff');
const process = require('node:process');

// different error codes for PS, disabling for now
if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

const connection = common.createConnection();

// https://github.com/sidorares/node-mysql2/issues/130
// https://github.com/sidorares/node-mysql2/issues/37
// binary protocol examples where `prepare` returns no column definitions but execute() does return fields/rows

let rows;
let fields;

connection.execute('explain SELECT 1', (err, _rows, _fields) => {
  if (err) {
    throw err;
  }

  rows = _rows;
  fields = _fields;
  connection.end();
});

const expectedRows = [
  {
    id: 1,
    select_type: 'SIMPLE',
    table: null,
    type: null,
    possible_keys: null,
    key: null,
    key_len: null,
    ref: null,
    rows: null,
    Extra: 'No tables used',
    partitions: null,
    filtered: null,
  },
];

const expectedFields = [
  {
    catalog: 'def',
    schema: '',
    name: 'id',
    orgName: '',
    table: '',
    orgTable: '',
    characterSet: 63,
    encoding: 'binary',
    type: 8,
    flags: 161,
    decimals: 0,
  },
  {
    catalog: 'def',
    schema: '',
    name: 'select_type',
    orgName: '',
    table: '',
    orgTable: '',
    characterSet: 224,
    encoding: 'utf8',
    type: 253,
    flags: 1,
    decimals: 31,
  },
  {
    catalog: 'def',
    schema: '',
    name: 'table',
    orgName: '',
    table: '',
    orgTable: '',
    characterSet: 224,
    encoding: 'utf8',
    type: 253,
    flags: 0,
    decimals: 31,
  },
  {
    catalog: 'def',
    schema: '',
    name: 'partitions',
    orgName: '',
    table: '',
    orgTable: '',
    characterSet: 224,
    encoding: 'utf8',
    type: 250,
    flags: 0,
    decimals: 31,
  },
  {
    catalog: 'def',
    schema: '',
    name: 'type',
    orgName: '',
    table: '',
    orgTable: '',
    characterSet: 224,
    encoding: 'utf8',
    type: 253,
    flags: 0,
    decimals: 31,
  },
  {
    catalog: 'def',
    schema: '',
    name: 'possible_keys',
    orgName: '',
    table: '',
    orgTable: '',
    characterSet: 224,
    encoding: 'utf8',
    type: 253,
    flags: 0,
    decimals: 31,
  },
  {
    catalog: 'def',
    schema: '',
    name: 'key',
    orgName: '',
    table: '',
    orgTable: '',
    characterSet: 224,
    encoding: 'utf8',
    type: 253,
    flags: 0,
    decimals: 31,
  },
  {
    catalog: 'def',
    schema: '',
    name: 'key_len',
    orgName: '',
    table: '',
    orgTable: '',
    characterSet: 224,
    encoding: 'utf8',
    type: 253,
    flags: 0,
    decimals: 31,
  },
  {
    catalog: 'def',
    schema: '',
    name: 'ref',
    orgName: '',
    table: '',
    orgTable: '',
    characterSet: 224,
    encoding: 'utf8',
    type: 253,
    flags: 0,
    decimals: 31,
  },
  {
    catalog: 'def',
    schema: '',
    name: 'rows',
    orgName: '',
    table: '',
    orgTable: '',
    characterSet: 63,
    encoding: 'binary',
    type: 8,
    flags: 160,
    decimals: 0,
  },
  {
    catalog: 'def',
    schema: '',
    name: 'filtered',
    orgName: '',
    table: '',
    orgTable: '',
    characterSet: 63,
    encoding: 'binary',
    type: 5,
    flags: 128,
    decimals: 2,
  },
  {
    catalog: 'def',
    schema: '',
    name: 'Extra',
    orgName: '',
    table: '',
    orgTable: '',
    characterSet: 224,
    encoding: 'utf8',
    type: 253,
    flags: 1,
    decimals: 31,
  },
];

process.on('exit', () => {
  assert.deepEqual(rows, expectedRows);
  fields.forEach((f, index) => {
    const fi = f.inspect();
    // "columnLength" is non-deterministic
    delete fi.columnLength;

    assert.deepEqual(
      Object.keys(fi).sort(),
      Object.keys(expectedFields[index]).sort()
    );
    assert.deepEqual(expectedFields[index], fi);
  });
});
</file>

<file path="test/integration/connection/test-execute-null-bitmap.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const connection = common.createConnection();
const { assert } = require('poku');

const params = [1, 2];
let query = 'select ? + ?';

function dotest() {
  connection.execute(`${query} as t`, params, (err, _rows) => {
    assert.equal(err, null);
    if (params.length < 50) {
      assert.equal(
        _rows[0].t,
        params.reduce((x, y) => x + y)
      );
      query += ' + ?';
      params.push(params.length);
      dotest();
    } else {
      connection.end();
    }
  });
}

connection.query('SET GLOBAL max_prepared_stmt_count=300', dotest);
</file>

<file path="test/integration/connection/test-execute-order.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

const order = [];
connection.execute('select 1+2', (err) => {
  assert.ifError(err);
  order.push(0);
});
connection.execute('select 2+2', (err) => {
  assert.ifError(err);
  order.push(1);
});
connection.query('select 1+1', (err) => {
  assert.ifError(err);
  order.push(2);
  connection.end();
});

process.on('exit', () => {
  assert.deepEqual(order, [0, 1, 2]);
});
</file>

<file path="test/integration/connection/test-execute-signed.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let rows = undefined;

connection.query(
  [
    'CREATE TEMPORARY TABLE `test_table` (',
    '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    '`num` int(15),',
    '`l` long,',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n')
);

connection.query('insert into test_table(num,l) values(?, 3)', [1]);
connection.query('insert into test_table(num,l) values(3-?, -10)', [5]);
connection.query(
  'insert into test_table(num,l) values(4+?, 4000000-?)',
  [-5, 8000000]
);

connection.execute('SELECT * from test_table', [], (err, _rows) => {
  if (err) {
    throw err;
  }
  rows = _rows;
  connection.end();
});

process.on('exit', () => {
  assert.deepEqual(rows, [
    { id: 1, num: 1, l: 3 },
    { id: 2, num: -2, l: -10 },
    { id: 3, num: -1, l: -4000000 },
  ]);
});
</file>

<file path="test/integration/connection/test-execute-type-casting.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert, test } = require('poku');
const { Buffer } = require('node:buffer');
const process = require('node:process');

test(async () => {
  const connection = common.createConnection();

  common.useTestDb(connection);

  connection.query('select 1', async (waitConnectErr) => {
    assert.ifError(waitConnectErr);
    const tests = await require('./type-casting-tests.test.cjs')(connection);

    const table = 'type_casting';

    const schema = [];
    const inserts = [];

    tests.forEach((test, index) => {
      const escaped = test.insertRaw || connection.escape(test.insert);

      test.columnName = `${test.type}_${index}`;

      schema.push(`\`${test.columnName}\` ${test.type},`);
      inserts.push(`\`${test.columnName}\` = ${escaped}`);
    });

    const createTable = [
      `CREATE TEMPORARY TABLE \`${table}\` (`,
      '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    ]
      .concat(schema)
      .concat(['PRIMARY KEY (`id`)', ') ENGINE=InnoDB DEFAULT CHARSET=utf8'])
      .join('\n');

    connection.query(createTable);

    connection.query(`INSERT INTO ${table} SET${inserts.join(',\n')}`);

    let row;
    connection.execute(
      `SELECT * FROM ${table} WHERE id = ?;`,
      [1],
      (err, rows) => {
        if (err) {
          throw err;
        }

        row = rows[0];
        connection.end();
      }
    );

    process.on('exit', () => {
      tests.forEach((test) => {
        let expected = test.expect || test.insert;
        let got = row[test.columnName];
        let message;

        if (expected instanceof Date) {
          assert.equal(got instanceof Date, true, test.type);

          expected = String(expected);
          got = String(got);
        } else if (Buffer.isBuffer(expected)) {
          assert.equal(Buffer.isBuffer(got), true, test.type);

          expected = String(Array.prototype.slice.call(expected));
          got = String(Array.prototype.slice.call(got));
        }

        if (test.deep) {
          message = `got: "${JSON.stringify(got)}" expected: "${JSON.stringify(
            expected
          )}" test: ${test.type}`;
          assert.deepEqual(expected, got, message);
        } else {
          message = `got: "${got}" (${typeof got}) expected: "${expected}" (${typeof expected}) test: ${
            test.type
          }`;
          assert.strictEqual(expected, got, message);
        }
      });
    });
  });
});
</file>

<file path="test/integration/connection/test-insert-bigint-big-number-strings.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');

const connection = common.createConnection({
  supportBigNumbers: true,
  bigNumberStrings: true,
});

connection.query(
  [
    'CREATE TEMPORARY TABLE `bigs` (',
    '`id` bigint NOT NULL AUTO_INCREMENT,',
    '`title` varchar(255),',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n')
);

connection.query("INSERT INTO bigs SET title='test', id=123");
connection.query("INSERT INTO bigs SET title='test1'", (err, result) => {
  if (err) {
    throw err;
  }
  assert.strictEqual(result.insertId, 124);
  // > 24 bits
  connection.query("INSERT INTO bigs SET title='test', id=123456789");
  connection.query("INSERT INTO bigs SET title='test2'", (err, result) => {
    assert.strictEqual(result.insertId, 123456790);
    // big int
    connection.query("INSERT INTO bigs SET title='test', id=9007199254740992");
    connection.query("INSERT INTO bigs SET title='test3'", (err, result) => {
      assert.strictEqual(result.insertId, '9007199254740993');
      connection.query(
        "INSERT INTO bigs SET title='test', id=90071992547409924"
      );
      connection.query("INSERT INTO bigs SET title='test4'", (err, result) => {
        assert.strictEqual(result.insertId, '90071992547409925');
        connection.query('select * from bigs', (err, result) => {
          assert.strictEqual(result[0].id, '123');
          assert.strictEqual(result[1].id, '124');
          assert.strictEqual(result[2].id, '123456789');
          assert.strictEqual(result[3].id, '123456790');
          assert.strictEqual(result[4].id, '9007199254740992');
          assert.strictEqual(result[5].id, '9007199254740993');
          assert.strictEqual(result[6].id, '90071992547409924');
          assert.strictEqual(result[7].id, '90071992547409925');
          connection.end();
        });
      });
    });
  });
});
</file>

<file path="test/integration/connection/test-insert-bigint.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const Long = require('long');

const connection = common.createConnection();

connection.query(
  [
    'CREATE TEMPORARY TABLE `bigs` (',
    '`id` bigint NOT NULL AUTO_INCREMENT,',
    '`title` varchar(255),',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n')
);

connection.query("INSERT INTO bigs SET title='test', id=123");
connection.query("INSERT INTO bigs SET title='test1'", (err, result) => {
  if (err) {
    throw err;
  }
  assert.strictEqual(result.insertId, 124);
  // > 24 bits
  connection.query("INSERT INTO bigs SET title='test', id=123456789");
  connection.query("INSERT INTO bigs SET title='test2'", (err, result) => {
    assert.strictEqual(result.insertId, 123456790);
    // big int
    connection.query("INSERT INTO bigs SET title='test', id=9007199254740992");
    connection.query("INSERT INTO bigs SET title='test3'", (err, result) => {
      assert.strictEqual(
        Long.fromString('9007199254740993').compare(result.insertId),
        0
      );
      connection.query(
        "INSERT INTO bigs SET title='test', id=90071992547409924"
      );
      connection.query("INSERT INTO bigs SET title='test4'", (err, result) => {
        assert.strictEqual(
          Long.fromString('90071992547409925').compare(result.insertId),
          0
        );
        connection.query(
          {
            sql: 'select * from bigs',
            supportBigNumbers: true,
            bigNumberString: false,
          },
          (err, result) => {
            assert.strictEqual(result[0].id, 123);
            assert.strictEqual(result[1].id, 124);
            assert.strictEqual(result[2].id, 123456789);
            assert.strictEqual(result[3].id, 123456790);
            assert.strictEqual(result[4].id, 9007199254740992);
            assert.strictEqual(result[5].id, '9007199254740993');
            assert.strictEqual(result[6].id, '90071992547409924');
            assert.strictEqual(result[7].id, '90071992547409925');
            connection.end();
          }
        );
      });
    });
  });
});
</file>

<file path="test/integration/connection/test-insert-json.test.cjs">
'use strict';

/**
 * Created by Elijah Melton on 2023.05.03
 * issue#1924: https://github.com/sidorares/node-mysql2/issues/1924
 */

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let result;
let errorCodeInvalidJSON;
let errorNumInvalidJSON;

connection.query('CREATE TEMPORARY TABLE json_test (data JSON)');
connection.query('INSERT INTO json_test VALUES (?)', ['{"k": "v"'], (err) => {
  errorCodeInvalidJSON = err.code;
  errorNumInvalidJSON = err.errno;
});

connection.query('INSERT INTO json_test VALUES (?)', ['{"k": "v"}'], (err) => {
  if (err) throw err;
});

connection.query('SELECT * FROM json_test;', [], (err, res) => {
  if (err) throw err;
  result = res;
  connection.end();
});

process.on('exit', () => {
  assert.equal(errorCodeInvalidJSON, 'ER_INVALID_JSON_TEXT');
  assert.equal(errorNumInvalidJSON, 3140);
  assert.equal(result[0].data.k, 'v');
});
</file>

<file path="test/integration/connection/test-insert-large-blob.test.cjs">
'use strict';

// intentionally disabled
// eslint-disable-next-line no-constant-condition
if (false) {
  const common = require('../../common.test.cjs');
  const { assert } = require('poku');
  const { Buffer } = require('node:buffer');
  const process = require('node:process');

  const connection = common.createConnection();

  /*
  connection.query('SELECT repeat("a", 60000000) as qqq', function (err, res) {
    console.log(err);
    console.log(err, res[0].qqq.length);
    connection.end();
  });
  return;
*/

  const table = 'insert_large_test';
  const length = 35777416;
  const content = Buffer.allocUnsafe(length); // > 16 megabytes
  const content1 = Buffer.allocUnsafe(length); // > 16 megabytes

  // this is to force compressed packed to be larger than uncompressed
  for (let i = 0; i < content.length; ++i) {
    content[i] = Math.floor(Math.random() * 256);
    content1[i] = Math.floor(Math.random() * 256);

    // low entropy version, compressed < uncompressed
    if (i < length / 2) {
      content1[i] = 100;
    }
  }

  let result, result2, result3, result4;

  connection.query(
    `SET GLOBAL max_allowed_packet=${length * 2 + 2000}`,
    (err) => {
      assert.ifError(err);
      connection.end();
      const connection2 = common.createConnection();
      connection2.query(
        [
          `CREATE TEMPORARY TABLE \`${table}\` (`,
          '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
          '`content` longblob NOT NULL,',
          'PRIMARY KEY (`id`)',
          ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
        ].join('\n')
      );
      connection2.query(
        `INSERT INTO ${table} (content) VALUES(?)`,
        [content],
        (err, _result) => {
          assert.ifError(err);
          result = _result;
          connection2.query(
            `SELECT * FROM ${table} WHERE id = ${result.insertId}`,
            (err, _result2) => {
              result2 = _result2;
              connection2.query(
                `INSERT INTO ${table} (content) VALUES(?)`,
                [content1],
                (err, _result) => {
                  assert.ifError(err);
                  result3 = _result;
                  connection2.query(
                    `SELECT * FROM ${table} WHERE id = ${result3.insertId}`,
                    (err, _result) => {
                      assert.ifError(err);
                      result4 = _result;
                      connection2.end();
                    }
                  );
                }
              );
            }
          );
        }
      );
    }
  );

  process.on('exit', () => {
    assert.equal(result2[0].id, String(result.insertId));
    assert.equal(result2[0].content.toString('hex'), content.toString('hex'));
    assert.equal(result4[0].content.toString('hex'), content1.toString('hex'));
  });
}
</file>

<file path="test/integration/connection/test-insert-negative-ai.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

const testTable = 'neg-ai-test';
const testData = 'test negative ai';

let selectResult, insertResult;

const testNegativeAI = function (err) {
  assert.ifError(err);
  // insert the negative AI
  connection.query(
    `INSERT INTO \`${testTable}\`` +
      ` (id, title) values (-999, "${testData}")`,
    (err, result) => {
      assert.ifError(err);
      insertResult = result;

      // select the row with negative AI
      connection.query(
        `SELECT * FROM \`${testTable}\`` + ` WHERE id = ${result.insertId}`,
        (err, result_) => {
          assert.ifError(err);
          selectResult = result_;
          connection.end();
        }
      );
    }
  );
};

const prepareAndTest = function () {
  connection.query(
    `CREATE TEMPORARY TABLE \`${testTable}\` (` +
      `\`id\` int(11) signed NOT NULL AUTO_INCREMENT,` +
      `\`title\` varchar(255),` +
      `PRIMARY KEY (\`id\`)` +
      `) ENGINE=InnoDB DEFAULT CHARSET=utf8`,
    testNegativeAI
  );
};

prepareAndTest();

process.on('exit', () => {
  assert.strictEqual(insertResult.insertId, -999);
  assert.strictEqual(selectResult.length, 1);

  assert.equal(selectResult[0].id, String(insertResult.insertId));
  assert.equal(selectResult[0].title, testData);
});
</file>

<file path="test/integration/connection/test-insert-results.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

// common.useTestDb(connection);

const table = 'insert_test';
// const text = "本日は晴天なり";
const text = ' test test test ';
connection.query(
  [
    `CREATE TEMPORARY TABLE \`${table}\` (`,
    '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    '`title` varchar(255),',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n')
);

let result, result2;
connection.query(`INSERT INTO ${table} SET title="${text}"`, (err, _result) => {
  if (err) {
    throw err;
  }
  result = _result;
  connection.query(
    `SELECT * FROM ${table} WHERE id = ${result.insertId}`,
    (err, _result2) => {
      result2 = _result2;
      connection.end();
    }
  );
});

process.on('exit', () => {
  assert.strictEqual(result.insertId, 1);
  assert.strictEqual(result2.length, 1);
  // TODO: type conversions
  assert.equal(result2[0].id, String(result.insertId));
  assert.equal(result2[0].title, text);
});
</file>

<file path="test/integration/connection/test-invalid-date-result.test.cjs">
// This file was modified by Oracle on June 1, 2021.
// The test has been updated to be able to pass with different default
// strict modes used by different MySQL server versions.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let rows = undefined;

// Disable NO_ZERO_DATE mode and NO_ZERO_IN_DATE mode to ensure the old
// behaviour.
const strictModes = ['NO_ZERO_DATE', 'NO_ZERO_IN_DATE'];

connection.query(
  'SELECT variable_value as value FROM performance_schema.session_variables where variable_name = ?',
  ['sql_mode'],
  (err, _rows) => {
    if (err) {
      throw err;
    }

    const deprecatedSqlMode = _rows[0].value
      .split(',')
      .filter((mode) => strictModes.indexOf(mode) === -1)
      .join(',');

    connection.query(`SET sql_mode=?`, [deprecatedSqlMode], (err) => {
      if (err) {
        throw err;
      }

      connection.execute('SELECT TIMESTAMP(0000-00-00) t', [], (err, _rows) => {
        if (err) {
          throw err;
        }

        rows = _rows;
        connection.end();
      });
    });
  }
);

function isInvalidTime(t) {
  return isNaN(t.getTime());
}

process.on('exit', () => {
  assert.deepEqual(Object.prototype.toString.call(rows[0].t), '[object Date]');
  assert.deepEqual(isInvalidTime(rows[0].t), true);
});
</file>

<file path="test/integration/connection/test-load-infile.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const fs = require('node:fs');
const process = require('node:process');

if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

const connection = common.createConnection();

const table = 'load_data_test';
connection.query('SET GLOBAL local_infile = true', assert.ifError);
connection.query(
  [
    `CREATE TEMPORARY TABLE \`${table}\` (`,
    '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    '`title` varchar(255),',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n')
);

const path = './test/fixtures/data.csv';
const sql =
  `LOAD DATA LOCAL INFILE ? INTO TABLE ${table} ` +
  `FIELDS TERMINATED BY ? (id, title)`;

let ok;
connection.query(
  {
    sql,
    values: [path, ','],
    infileStreamFactory: () => fs.createReadStream(path),
  },
  (err, _ok) => {
    if (err) {
      throw err;
    }
    ok = _ok;
  }
);

let rows;
connection.query(`SELECT * FROM ${table}`, (err, _rows) => {
  if (err) {
    throw err;
  }
  rows = _rows;
});

// Try to load a file that does not exist to see if we handle this properly
let loadErr;
let loadResult;
const badPath = '/does_not_exist.csv';

connection.query(sql, [badPath, ','], (err, result) => {
  loadErr = err;
  loadResult = result;
});

// test path mapping
const createMyStream = function () {
  const Stream = require('node:stream').PassThrough;
  const myStream = new Stream();
  setTimeout(() => {
    myStream.write('11,Hello World\n');
    myStream.write('21,One ');
    myStream.write('more row\n');
    myStream.end();
  }, 1000);
  return myStream;
};

let streamResult;
connection.query(
  {
    sql: sql,
    values: [badPath, ','],
    infileStreamFactory: createMyStream,
  },
  (err, result) => {
    if (err) {
      throw err;
    }
    streamResult = result;
    connection.end();
  }
);

process.on('exit', () => {
  assert.equal(ok.affectedRows, 4);
  assert.equal(rows.length, 4);
  assert.equal(rows[0].id, 1);
  assert.equal(rows[0].title.trim(), 'Hello World');

  assert.equal(
    loadErr.message,
    `As a result of LOCAL INFILE command server wants to read /does_not_exist.csv file, but as of v2.0 you must provide streamFactory option returning ReadStream.`
  );
  assert.equal(loadResult.affectedRows, 0);

  assert.equal(streamResult.affectedRows, 2);
});
</file>

<file path="test/integration/connection/test-multiple-results.test.cjs">
// This file was modified by Oracle on June 2, 2021.
// The test has been updated to remove all expectations with regards to the
// "columnLength" metadata field.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const assert = require('assert-diff');
const process = require('node:process');

if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

const mysql = require('../../common.test.cjs').createConnection({
  multipleStatements: true,
});
mysql.query('CREATE TEMPORARY TABLE no_rows (test int)');
mysql.query('CREATE TEMPORARY TABLE some_rows (test int)');
mysql.query('INSERT INTO some_rows values(0)');
mysql.query('INSERT INTO some_rows values(42)');
mysql.query('INSERT INTO some_rows values(314149)');

const clone = function (obj) {
  return JSON.parse(JSON.stringify(obj));
};

const rs1 = {
  affectedRows: 0,
  fieldCount: 0,
  insertId: 0,
  serverStatus: 10,
  warningStatus: 0,
  info: '',
  changedRows: 0,
};
const rs2 = clone(rs1);
rs2.serverStatus = 2;

const twoInsertResult = [[rs1, rs2], [undefined, undefined], 2];
const select1 = [{ 1: '1' }];
const select2 = [{ 2: '2' }];
const fields1 = [
  {
    catalog: 'def',
    characterSet: 63,
    encoding: 'binary',
    type: 8,
    decimals: 0,
    flags: 129,
    name: '1',
    orgName: '',
    orgTable: '',
    schema: '',
    table: '',
  },
];
const nr_fields = [
  {
    catalog: 'def',
    characterSet: 63,
    encoding: 'binary',
    type: 3,
    decimals: 0,
    flags: 0,
    name: 'test',
    orgName: 'test',
    orgTable: 'no_rows',
    schema: mysql.config.database,
    table: 'no_rows',
  },
];
const sr_fields = clone(nr_fields);
sr_fields[0].orgTable = 'some_rows';
sr_fields[0].table = 'some_rows';
const select3 = [{ test: 0 }, { test: 42 }, { test: 314149 }];

const fields2 = clone(fields1);
fields2[0].name = '2';

const tests = [
  ['select * from some_rows', [select3, sr_fields, 1]], //  select 3 rows
  [
    'SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT; SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS;',
    twoInsertResult,
  ],
  [
    '/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;',
    twoInsertResult,
  ], // issue #26
  ['set @a = 1', [rs2, undefined, 1]], // one insert result
  ['set @a = 1; set @b = 2', twoInsertResult],
  ['select 1; select 2', [[select1, select2], [fields1, fields2], 2]],
  ['set @a = 1; select 1', [[rs1, select1], [undefined, fields1], 2]],
  ['select 1; set @a = 1', [[select1, rs2], [fields1, undefined], 2]],
  ['select * from no_rows', [[], nr_fields, 1]], // select 0 rows"
  ['set @a = 1; select * from no_rows', [[rs1, []], [undefined, nr_fields], 2]], // insert + select 0 rows
  ['select * from no_rows; set @a = 1', [[[], rs2], [nr_fields, undefined], 2]], //  select 0 rows + insert
  [
    'set @a = 1; select * from some_rows',
    [[rs1, select3], [undefined, sr_fields], 2],
  ], // insert + select 3 rows
  [
    'select * from some_rows; set @a = 1',
    [[select3, rs2], [sr_fields, undefined], 2],
  ], //  select 3 rows + insert
];

// TODO: tests with error in the query with different index
// TODO: multiple results from single query

function do_test(testIndex) {
  const entry = tests[testIndex];
  const sql = entry[0];
  const expectation = entry[1];
  mysql.query(sql, (err, _rows, _columns) => {
    let _numResults = 0;
    if (_rows.constructor.name === 'ResultSetHeader') {
      _numResults = 1;
    } else if (_rows.length === 0) {
      // empty select
      _numResults = 1;
    } else if (_rows.length > 0) {
      if (_rows.constructor.name === 'Array') {
        _numResults = 1;
      }

      if (
        _rows.constructor.name === 'Array' &&
        (_rows[0].constructor.name === 'Array' ||
          _rows[0].constructor.name === 'ResultSetHeader')
      ) {
        _numResults = _rows.length;
      }
    }
    if (err) {
      console.log(err);
      process.exit(-1);
    }
    const arrOrColumn = function (c) {
      if (Array.isArray(c)) {
        return c.map(arrOrColumn);
      }

      if (typeof c === 'undefined') {
        return void 0;
      }

      const column = c.inspect();
      // "columnLength" is non-deterministic and the display width for integer
      // data types was deprecated on MySQL 8.0.17.
      // https://dev.mysql.com/doc/refman/8.0/en/numeric-type-syntax.html
      delete column.columnLength;

      return column;
    };

    assert.deepEqual(expectation, [_rows, arrOrColumn(_columns), _numResults]);

    const q = mysql.query(sql);
    let resIndex = 0;
    let rowIndex = 0;

    let fieldIndex = -1;

    function checkRow(row) {
      const index = fieldIndex;
      if (_numResults === 1) {
        assert.equal(fieldIndex, 0);
        if (row.constructor.name === 'ResultSetHeader') {
          assert.deepEqual(_rows, row);
        } else {
          assert.deepEqual(_rows[rowIndex], row);
        }
      } else {
        if (resIndex !== index) {
          rowIndex = 0;
          resIndex = index;
        }
        if (row.constructor.name === 'ResultSetHeader') {
          assert.deepEqual(_rows[index], row);
        } else {
          assert.deepEqual(_rows[index][rowIndex], row);
        }
      }
      rowIndex++;
    }

    function checkFields(fields) {
      fieldIndex++;
      if (_numResults === 1) {
        assert.equal(fieldIndex, 0);
        assert.deepEqual(arrOrColumn(_columns), arrOrColumn(fields));
      } else {
        assert.deepEqual(
          arrOrColumn(_columns[fieldIndex]),
          arrOrColumn(fields)
        );
      }
    }
    q.on('result', checkRow);
    q.on('fields', checkFields);
    q.on('end', () => {
      if (testIndex + 1 < tests.length) {
        do_test(testIndex + 1);
      } else {
        mysql.end();
      }
    });
  });
}
do_test(0);
</file>

<file path="test/integration/connection/test-named-placeholders.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');

const connection = common.createConnection();

connection.query(
  [
    'CREATE TEMPORARY TABLE `test_table` (',
    '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    '`num1` int(15),',
    '`num2` int(15),',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n')
);

connection.query('insert into test_table(num1,num2) values(?, 3)', [1]);
connection.query('insert into test_table(num1,num2) values(3-?, -10)', [5]);
connection.query(
  'insert into test_table(num1,num2) values(4+?, 4000000-?)',
  [-5, 8000000]
);
connection.query(
  'insert into test_table(num1,num2) values(?, ?)',
  [-5, 8000000]
);

connection.config.namedPlaceholders = true;
const cmd = connection.execute(
  'SELECT * from test_table where num1 < :numParam and num2 > :lParam',
  { lParam: 100, numParam: 2 },
  (err, rows) => {
    if (err) {
      throw err;
    }
    assert.deepEqual(rows, [{ id: 4, num1: -5, num2: 8000000 }]);
  }
);
assert.equal(cmd.sql, 'SELECT * from test_table where num1 < ? and num2 > ?');
assert.deepEqual(cmd.values, [2, 100]);

connection.execute('SELECT :a + :a as sum', { a: 2 }, (err, rows) => {
  if (err) {
    throw err;
  }
  assert.deepEqual(rows, [{ sum: 4 }]);
});

const qCmd = connection.query(
  'SELECT * from test_table where num1 < :numParam and num2 > :lParam',
  { lParam: 100, numParam: 2 },
  (err, rows) => {
    if (err) {
      throw err;
    }
    assert.deepEqual(rows, [{ id: 4, num1: -5, num2: 8000000 }]);
  }
);
assert.equal(
  qCmd.sql,
  'SELECT * from test_table where num1 < 2 and num2 > 100'
);
assert.deepEqual(qCmd.values, [2, 100]);

connection.query('SELECT :a + :a as sum', { a: 2 }, (err, rows) => {
  if (err) {
    throw err;
  }
  assert.deepEqual(rows, [{ sum: 4 }]);
  connection.end();
});

const namedSql = connection.format(
  'SELECT * from test_table where num1 < :numParam and num2 > :lParam',
  { lParam: 100, numParam: 2 }
);
assert.equal(
  namedSql,
  'SELECT * from test_table where num1 < 2 and num2 > 100'
);

const unnamedSql = connection.format(
  'SELECT * from test_table where num1 < ? and num2 > ?',
  [2, 100]
);
assert.equal(
  unnamedSql,
  'SELECT * from test_table where num1 < 2 and num2 > 100'
);

const pool = common.createPool();
pool.config.connectionConfig.namedPlaceholders = true;
pool.query('SELECT :a + :a as sum', { a: 2 }, (err, rows) => {
  pool.end();
  if (err) {
    throw err;
  }
  assert.deepEqual(rows, [{ sum: 4 }]);
});
</file>

<file path="test/integration/connection/test-nested-tables-query.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

common.useTestDb(connection);

const table = 'nested_test';
connection.query(
  [
    `CREATE TEMPORARY TABLE \`${table}\` (`,
    '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    '`title` varchar(255),',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n')
);
connection.query(
  [
    `CREATE TEMPORARY TABLE \`${table}1\` (`,
    '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    '`title` varchar(255),',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n')
);

connection.query(`INSERT INTO ${table} SET ?`, { title: 'test' });
connection.query(`INSERT INTO ${table}1 SET ?`, { title: 'test1' });

const options1 = {
  nestTables: true,
  sql: `SELECT * FROM ${table}`,
};
const options2 = {
  nestTables: '_',
  sql: `SELECT * FROM ${table}`,
};
const options3 = {
  rowsAsArray: true,
  sql: `SELECT * FROM ${table}`,
};
const options4 = {
  nestTables: true,
  sql: `SELECT notNested.id, notNested.title, nested.title FROM ${table} notNested LEFT JOIN ${table}1 nested ON notNested.id = nested.id`,
};
const options5 = {
  nestTables: true,
  sql: `SELECT notNested.id, notNested.title, nested2.title FROM ${table} notNested LEFT JOIN ${table}1 nested2 ON notNested.id = nested2.id`,
};
let rows1, rows2, rows3, rows4, rows5, rows1e, rows2e, rows3e;

connection.query(options1, (err, _rows) => {
  if (err) {
    throw err;
  }

  rows1 = _rows;
});

connection.query(options2, (err, _rows) => {
  if (err) {
    throw err;
  }

  rows2 = _rows;
});

connection.query(options3, (err, _rows) => {
  if (err) {
    throw err;
  }

  rows3 = _rows;
});

connection.query(options4, (err, _rows) => {
  if (err) {
    throw err;
  }

  rows4 = _rows;
});

connection.query(options5, (err, _rows) => {
  if (err) {
    throw err;
  }

  rows5 = _rows;
});

connection.execute(options1, (err, _rows) => {
  if (err) {
    throw err;
  }

  rows1e = _rows;
});

connection.execute(options2, (err, _rows) => {
  if (err) {
    throw err;
  }

  rows2e = _rows;
});

connection.execute(options3, (err, _rows) => {
  if (err) {
    throw err;
  }

  rows3e = _rows;
  connection.end();
});

process.on('exit', () => {
  assert.equal(rows1.length, 1, 'First row length');
  assert.equal(rows1[0].nested_test.id, 1, 'First row nested id');
  assert.equal(rows1[0].nested_test.title, 'test', 'First row nested title');
  assert.equal(rows2.length, 1, 'Second row length');
  assert.equal(rows2[0].nested_test_id, 1, 'Second row nested id');
  assert.equal(rows2[0].nested_test_title, 'test', 'Second row nested title');

  assert.equal(Array.isArray(rows3[0]), true, 'Third row type');
  assert.equal(rows3[0][0], 1, 'Third row value 1');
  assert.equal(rows3[0][1], 'test', 'Third row value 2');

  assert.equal(rows4.length, 1, 'Fourth row length');
  assert.deepEqual(
    rows4[0],
    {
      nested: {
        title: 'test1',
      },
      notNested: {
        id: 1,
        title: 'test',
      },
    },
    'Fourth row value'
  );
  assert.equal(rows5.length, 1, 'Fifth row length');
  assert.deepEqual(
    rows5[0],
    {
      nested2: {
        title: 'test1',
      },
      notNested: {
        id: 1,
        title: 'test',
      },
    },
    'Fifth row value'
  );

  assert.deepEqual(rows1, rows1e, 'Compare rows1 with rows1e');
  assert.deepEqual(rows2, rows2e, 'Compare rows2 with rows2e');
  assert.deepEqual(rows3, rows3e, 'Compare rows3 with rows3e');
});
</file>

<file path="test/integration/connection/test-null-buffer.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let rowsTextProtocol;
let rowsBinaryProtocol;

connection.query('CREATE TEMPORARY TABLE binary_table (stuff BINARY(16));');
connection.query('INSERT INTO binary_table VALUES(null)');

connection.query('SELECT * from binary_table', (err, _rows) => {
  if (err) {
    throw err;
  }
  rowsTextProtocol = _rows;
  connection.execute('SELECT * from binary_table', (err, _rows) => {
    if (err) {
      throw err;
    }
    rowsBinaryProtocol = _rows;
    connection.end();
  });
});

process.on('exit', () => {
  assert.deepEqual(rowsTextProtocol[0], { stuff: null });
  assert.deepEqual(rowsBinaryProtocol[0], { stuff: null });
});
</file>

<file path="test/integration/connection/test-null-double.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let rows;

connection.query('CREATE TEMPORARY TABLE t (i int)');
connection.query('INSERT INTO t VALUES(null)');
connection.query('INSERT INTO t VALUES(123)');

connection.query('SELECT * from t', (err, _rows) => {
  if (err) {
    throw err;
  }
  rows = _rows;
  connection.end();
});

process.on('exit', () => {
  assert.deepEqual(rows[0], { i: null });
  assert.deepEqual(rows[1], { i: 123 });
});
</file>

<file path="test/integration/connection/test-null-int.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let rows;

connection.query('CREATE TEMPORARY TABLE t (i int)');
connection.query('INSERT INTO t VALUES(null)');
connection.query('INSERT INTO t VALUES(123)');

connection.query('SELECT * from t', (err, _rows) => {
  if (err) {
    throw err;
  }
  rows = _rows;
  connection.end();
});

process.on('exit', () => {
  assert.deepEqual(rows[0], { i: null });
  assert.deepEqual(rows[1], { i: 123 });
});
</file>

<file path="test/integration/connection/test-null.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let rows, rows1;
let fields1;

connection.query('CREATE TEMPORARY TABLE t (i int)');
connection.query('INSERT INTO t VALUES(null)');
connection.query('SELECT cast(NULL AS CHAR) as cast_result', (err, _rows) => {
  if (err) {
    throw err;
  }
  rows = _rows;
});
connection.query('SELECT * from t', (err, _rows, _fields) => {
  if (err) {
    throw err;
  }
  rows1 = _rows;
  fields1 = _fields;
  connection.end();
});

process.on('exit', () => {
  assert.deepEqual(rows, [{ cast_result: null }]);
  // assert.equal(fields[0].columnType, 253); // depeding on the server type could be 253 or 3, disabling this check for now
  assert.deepEqual(rows1, [{ i: null }]);
  assert.equal(fields1[0].columnType, 3);
});
</file>

<file path="test/integration/connection/test-parameters-questionmark.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');

const pool = common.createPool();
pool.config.connectionLimit = 1;

pool.query(
  [
    'CREATE TEMPORARY TABLE `test_table` (',
    '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    '`str` varchar(64),',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n')
);
pool.query('insert into test_table(str) values(?)', ['abc?']);
pool.query('UPDATE test_table SET str = ? WHERE id = ?', [
  'should not change ?',
  1,
]);
pool.query('SELECT str FROM test_table WHERE id = ?', [1], (err, rows) => {
  pool.end();
  if (err) {
    throw err;
  }
  assert.deepEqual(rows, [{ str: 'should not change ?' }]);
});
</file>

<file path="test/integration/connection/test-prepare-and-close.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

const max = 500;
const start = process.hrtime();
function prepare(i) {
  connection.prepare(`select 1+${i}`, (err, stmt) => {
    assert.ifError(err);
    stmt.close();
    if (!err) {
      if (i > max) {
        const end = process.hrtime(start);
        const ns = end[0] * 1e9 + end[1];
        console.log(`${(max * 1e9) / ns} prepares/sec`);
        connection.end();
        return;
      }
      setTimeout(() => {
        prepare(i + 1);
      }, 2);
      return;
    }
    assert(0, 'Error in prepare!');
  });
}
connection.query('SET GLOBAL max_prepared_stmt_count=10', (err) => {
  assert.ifError(err);
  prepare(1);
});
</file>

<file path="test/integration/connection/test-prepare-simple.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let _stmt1, _stmt2, _stmt3;
const query1 = 'select 1 + ? + ? as test';
const query2 = 'select 1 + 1'; // no parameters
const query3 = 'create temporary table aaa(i int);'; // no parameters, no result columns

connection.prepare(query1, (err1, stmt1) => {
  assert.ifError(err1);
  _stmt1 = stmt1;
  _stmt1.close();
  connection.prepare(query2, (err2, stmt2) => {
    assert.ifError(err2);
    _stmt2 = stmt2;
    connection.prepare(query3, (err3, stmt3) => {
      assert.ifError(err3);
      _stmt3 = stmt3;
      _stmt2.close();
      _stmt3.close();
      connection.end();
    });
  });
});

process.on('exit', () => {
  assert.equal(_stmt1.query, query1);
  assert(_stmt1.id >= 0);
  assert.equal(_stmt1.columns.length, 1);
  assert.equal(_stmt1.parameters.length, 2);
});
</file>

<file path="test/integration/connection/test-prepare-then-execute.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let _stmt = null;
let _columns = null;
let _rows = null;

connection.prepare('select 1 + ? + ? as test', (err, stmt) => {
  if (err) {
    throw err;
  }
  _stmt = stmt;
  stmt.execute([111, 123], (err, rows, columns) => {
    if (err) {
      throw err;
    }
    _columns = columns;
    _rows = rows;
    connection.end();
  });
});

process.on('exit', () => {
  assert.equal(_stmt.columns.length, 1);
  assert.equal(_stmt.parameters.length, 2);
  assert.deepEqual(_rows, [{ test: 235 }]);
  assert.equal(_columns[0].name, 'test');
});
</file>

<file path="test/integration/connection/test-protocol-errors.test.cjs">
// This file was modified by Oracle on January 21, 2021.
// The connection with the mock server needs to happen in the same host where
// the tests are running in order to avoid connecting a potential MySQL server
// instance running in the host identified by the MYSQL_HOST environment
// variable.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const { assert } = require('poku');
const common = require('../../common.test.cjs');
const process = require('node:process');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

let fields, error;
const query = 'SELECT 1';
let rows;

const server = common.createServer(
  () => {
    const connection = common.createConnection({
      // The mock server is running on the same host machine.
      // We need to explicitly define the host to avoid connecting to a potential
      // different host provided via MYSQL_HOST that identifies a real MySQL
      // server instance.
      host: 'localhost',
      port: server._port,
      ssl: false,
    });
    connection.query(query, (err, _rows, _fields) => {
      if (err) {
        throw err;
      }
      rows = _rows;
      fields = _fields;
    });

    connection.on('error', (err) => {
      error = err;
      if (server._server._handle) {
        server.close();
      }
    });
  },
  (conn) => {
    conn.on('query', () => {
      conn.writeTextResult(
        [{ 1: '1' }],
        [
          {
            catalog: 'def',
            schema: '',
            table: '',
            orgTable: '',
            name: '1',
            orgName: '',
            characterSet: 63,
            columnLength: 1,
            columnType: 8,
            flags: 129,
            decimals: 0,
          },
        ]
      );
      // this is extra (incorrect) packet - client should emit error on receiving it
      conn.writeOk();
    });
  }
);

process.on('exit', () => {
  assert.deepEqual(rows, [{ 1: 1 }]);
  assert.equal(fields[0].name, '1');
  assert.equal(
    error.message,
    'Unexpected packet while no commands in the queue'
  );
  assert.equal(error.fatal, true);
  assert.equal(error.code, 'PROTOCOL_UNEXPECTED_PACKET');
});
</file>

<file path="test/integration/connection/test-query-timeout.test.cjs">
'use strict';

const portfinder = require('portfinder');
const common = require('../../common.test.cjs');
const mysql = require('../../../index.js');
const assert = require('node:assert');
const process = require('node:process');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

const connection = common.createConnection({ debug: false });

connection.query({ sql: 'SELECT sleep(3) as a', timeout: 500 }, (err, res) => {
  assert.equal(res, null);
  assert.ok(err);
  assert.equal(err.code, 'PROTOCOL_SEQUENCE_TIMEOUT');
  assert.equal(err.message, 'Query inactivity timeout');
});

connection.query({ sql: 'SELECT sleep(1) as a', timeout: 5000 }, (err, res) => {
  assert.deepEqual(res, [{ a: 0 }]);
});

connection.query('SELECT sleep(1) as a', (err, res) => {
  assert.deepEqual(res, [{ a: 0 }]);
});

connection.execute(
  { sql: 'SELECT sleep(3) as a', timeout: 500 },
  (err, res) => {
    assert.equal(res, null);
    assert.ok(err);
    assert.equal(err.code, 'PROTOCOL_SEQUENCE_TIMEOUT');
    assert.equal(err.message, 'Query inactivity timeout');
  }
);

connection.execute(
  { sql: 'SELECT sleep(1) as a', timeout: 5000 },
  (err, res) => {
    assert.deepEqual(res, [{ a: 0 }]);
  }
);

connection.query(
  { sql: 'select 1 from non_existing_table', timeout: 500 },
  (err, res) => {
    assert.equal(res, null);
    assert.ok(err);
    assert.equal(err.code, 'ER_NO_SUCH_TABLE');
  }
);

connection.execute('SELECT sleep(1) as a', (err, res) => {
  assert.deepEqual(res, [{ a: 0 }]);
  connection.end();
});

/**
 * if connect timeout
 * we should return connect timeout error instead of query timeout error
 */
portfinder.getPort((err, port) => {
  const server = mysql.createServer();
  server.on('connection', () => {
    // Let connection time out
  });
  server.listen(port);

  const connectionTimeout = mysql.createConnection({
    host: 'localhost',
    port: port,
    connectTimeout: 1000,
  });

  // return connect timeout error first
  connectionTimeout.query(
    { sql: 'SELECT sleep(3) as a', timeout: 50 },
    (err, res) => {
      console.log('ok');
      assert.equal(res, null);
      assert.ok(err);
      assert.equal(err.code, 'ETIMEDOUT');
      assert.equal(err.message, 'connect ETIMEDOUT');
      connectionTimeout.destroy();
      server._server.close();
    }
  );
});

process.on('uncaughtException', (err) => {
  assert.equal(
    err.message,
    'Connection lost: The server closed the connection.'
  );
  assert.equal(err.code, 'PROTOCOL_CONNECTION_LOST');
});
</file>

<file path="test/integration/connection/test-query-zero.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let rows;
connection.query('SELECT ? AS result', 0, (err, _rows) => {
  if (err) {
    throw err;
  }
  rows = _rows;
  connection.end();
});

process.on('exit', () => {
  assert.deepEqual(rows, [{ result: 0 }]);
});
</file>

<file path="test/integration/connection/test-quit.test.cjs">
// This file was modified by Oracle on January 21, 2021.
// The connection with the mock server needs to happen in the same host where
// the tests are running in order to avoid connecting a potential MySQL server
// instance running in the host identified by the MYSQL_HOST environment
// variable.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const { assert } = require('poku');
const common = require('../../common.test.cjs');
const process = require('node:process');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

let quitReceived = false;
const queryCli = 'SELECT 1';
let queryServ;
let rows;
let fields;
const server = common.createServer(
  () => {
    const connection = common.createConnection({
      // The mock server is running on the same host machine.
      // We need to explicitly define the host to avoid connecting to a potential
      // different host provided via MYSQL_HOST that identifies a real MySQL
      // server instance.
      host: 'localhost',
      port: server._port,
      ssl: false,
    });

    connection.query(queryCli, (err, _rows, _fields) => {
      if (err) {
        throw err;
      }
      rows = _rows;
      fields = _fields;

      connection.end();
    });
  },
  (conn) => {
    conn.on('quit', () => {
      // COM_QUIT
      quitReceived = true;
      conn.stream.end();
      server.close();
    });

    conn.on('query', (q) => {
      queryServ = q;
      conn.writeTextResult(
        [{ 1: '1' }],
        [
          {
            catalog: 'def',
            schema: '',
            table: '',
            orgTable: '',
            name: '1',
            orgName: '',
            characterSet: 63,
            columnLength: 1,
            columnType: 8,
            flags: 129,
            decimals: 0,
          },
        ]
      );
    });
  }
);

process.on('exit', () => {
  assert.deepEqual(rows, [{ 1: 1 }]);
  assert.equal(fields[0].name, '1');
  assert.equal(quitReceived, true);
  assert.equal(queryCli, queryServ);
});
</file>

<file path="test/integration/connection/test-select-1.test.cjs">
'use strict';

const { assert } = require('poku');
const common = require('../../common.test.cjs');
const process = require('node:process');

const connection = common.createConnection();

connection.query('SELECT 1 as result', (err, rows, fields) => {
  assert.ifError(err);
  assert.deepEqual(rows, [{ result: 1 }]);
  assert.equal(fields[0].name, 'result');

  connection.execute('SELECT 1 as result', (err, rows, fields) => {
    assert.ifError(err);
    assert.deepEqual(rows, [{ result: 1 }]);
    assert.equal(fields[0].name, 'result');

    connection.end((err) => {
      assert.ifError(err);
      process.exit(0);
    });
  });
});
</file>

<file path="test/integration/connection/test-select-empty-string.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let rows, fields;
connection.query('SELECT ""', (err, _rows, _fields) => {
  if (err) {
    throw err;
  }

  rows = _rows;
  fields = _fields;
  connection.end();
});

process.on('exit', () => {
  assert.deepEqual(rows, [{ [fields[0].name]: '' }]);
});
</file>

<file path="test/integration/connection/test-select-json.test.cjs">
'use strict';

/**
 * Created by Alexander Panko <god@panki.ru> on 2016.09.23 18:02
 * issue#409: https://github.com/sidorares/node-mysql2/issues/409
 */
const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let textFetchedRows = undefined;
let binaryFetchedRows = undefined;

const face = '\uD83D\uDE02';

connection.query('CREATE TEMPORARY TABLE json_test (json_test JSON)');
connection.query('INSERT INTO json_test VALUES (?)', JSON.stringify(face));
connection.query('SELECT * FROM json_test', (err, _rows) => {
  if (err) {
    throw err;
  }
  textFetchedRows = _rows;
  connection.execute('SELECT * FROM json_test', (err, _rows) => {
    if (err) {
      throw err;
    }
    binaryFetchedRows = _rows;
    connection.end();
  });
});

process.on('exit', () => {
  assert.equal(textFetchedRows[0].json_test, face);
  assert.equal(binaryFetchedRows[0].json_test, face);
});
</file>

<file path="test/integration/connection/test-select-negative.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let rows = undefined;
let rows1 = undefined;

connection.execute('SELECT -1 v', [], (err, _rows) => {
  if (err) {
    throw err;
  }
  rows = _rows;
});

connection.query('SELECT -1 v', (err, _rows) => {
  if (err) {
    throw err;
  }
  rows1 = _rows;
  connection.end();
});

process.on('exit', () => {
  assert.deepEqual(rows, [{ v: -1 }]);
  assert.deepEqual(rows1, [{ v: -1 }]);
});
</file>

<file path="test/integration/connection/test-select-ssl.test.cjs">
'use strict';

const { assert } = require('poku');
const common = require('../../common.test.cjs');
const process = require('node:process');

const connection = common.createConnection();

connection.query(`SHOW STATUS LIKE 'Ssl_cipher'`, (err, rows) => {
  assert.ifError(err);
  if (process.env.MYSQL_USE_TLS === '1') {
    assert.equal(rows[0].Value.length > 0, true);
  } else {
    assert.deepEqual(rows, [{ Variable_name: 'Ssl_cipher', Value: '' }]);
  }

  connection.execute(`SHOW STATUS LIKE 'Ssl_cipher'`, (err, rows) => {
    assert.ifError(err);
    if (process.env.MYSQL_USE_TLS === '1') {
      assert.equal(rows[0].Value.length > 0, true);
    } else {
      assert.deepEqual(rows, [{ Variable_name: 'Ssl_cipher', Value: '' }]);
    }

    connection.end((err) => {
      assert.ifError(err);
      process.exit(0);
    });
  });
});
</file>

<file path="test/integration/connection/test-select-utf8.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let rows = undefined;
const multibyteText = '本日は晴天なり';
connection.query(`SELECT '${multibyteText}' as result`, (err, _rows) => {
  if (err) {
    throw err;
  }
  rows = _rows;
  connection.end();
});

process.on('exit', () => {
  assert.equal(rows[0].result, multibyteText);
});
</file>

<file path="test/integration/connection/test-server-listen.test.cjs">
'use strict';

const { assert } = require('poku');
const mysql = require('../../../index.js');

// Verifies that the Server.listen can be called with any combination of
// pararameters valid for net.Server.listen.

function testListen(argsDescription, listenCaller) {
  const server = mysql.createServer();
  let listenCallbackFired = false;

  listenCaller(server, () => {
    listenCallbackFired = true;
  });
  setTimeout(() => {
    assert.ok(
      listenCallbackFired,
      `Callback for call with ${argsDescription} did not fire`
    );
    server._server.close();
  }, 100);
}

testListen('port', (server, callback) => {
  server.listen(0, callback);
});

testListen('port, host', (server, callback) => {
  server.listen(0, '127.0.0.1', callback);
});

testListen('port, host, backlog', (server, callback) => {
  server.listen(0, '127.0.0.1', 50, callback);
});
</file>

<file path="test/integration/connection/test-signed-tinyint.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let rows = undefined;

connection.query(
  'CREATE TEMPORARY TABLE signed_ints  (b11 tinyint NOT NULL, b12 tinyint NOT NULL, b21 smallint NOT NULL)'
);
connection.query('INSERT INTO signed_ints values (-3, -120, 500)');
connection.query('INSERT INTO signed_ints values (3,  -110, -500)');

connection.execute('SELECT * from signed_ints', [5], (err, _rows) => {
  if (err) {
    throw err;
  }
  rows = _rows;
  connection.end();
});

process.on('exit', () => {
  assert.deepEqual(rows, [
    { b11: -3, b12: -120, b21: 500 },
    { b11: 3, b12: -110, b21: -500 },
  ]);
});
</file>

<file path="test/integration/connection/test-stream-errors.test.cjs">
// This file was modified by Oracle on January 21, 2021.
// The connection with the mock server needs to happen in the same host where
// the tests are running in order to avoid connecting a potential MySQL server
// instance running in the host identified by the MYSQL_HOST environment
// variable.
// Modifications copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const { assert } = require('poku');
const common = require('../../common.test.cjs');
const process = require('node:process');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

let clientConnection;
const err = new Error('This socket has been ended by the other party');
err.code = 'EPIPE';

let receivedError1, receivedError2, receivedError3;
const query = 'SELECT 1';

const server = common.createServer(
  () => {
    clientConnection = common.createConnection({
      // The mock server is running on the same host machine.
      // We need to explicitly define the host to avoid connecting to a potential
      // different host provided via MYSQL_HOST that identifies a real MySQL
      // server instance.
      host: 'localhost',
      port: server._port,
      ssl: false,
    });
    clientConnection.query(query, (err) => {
      if (err && err.code === 'HANDSHAKE_NO_SSL_SUPPORT') {
        clientConnection.end();
      }
      receivedError1 = err;
    });
    clientConnection.query('second query, should not be executed', () => {
      receivedError2 = err;
      clientConnection.query(
        'trying to enqueue command to a connection which is already in error state',
        (err1) => {
          receivedError3 = err1;
        }
      );
    });
  },
  (conn) => {
    conn.on('query', () => {
      conn.writeColumns([
        {
          catalog: 'def',
          schema: '',
          table: '',
          orgTable: '',
          name: '1',
          orgName: '',
          characterSet: 63,
          columnLength: 1,
          columnType: 8,
          flags: 129,
          decimals: 0,
        },
      ]);
      // emulate  stream error here
      clientConnection.stream.emit('error', err);
      clientConnection.stream.end();
      server.close();
    });
  }
);

process.on('exit', () => {
  assert.equal(receivedError1.fatal, true);
  assert.equal(receivedError1.code, err.code);
  assert.equal(receivedError2.fatal, true);
  assert.equal(receivedError2.code, err.code);
  assert.equal(receivedError3.fatal, true);
  assert.equal(
    receivedError3.message,
    "Can't add new command when connection is in closed state"
  );
});
</file>

<file path="test/integration/connection/test-stream.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let rows;
const rows1 = [];
const rows2 = [];
const rows3 = [];
const rows4 = [];

connection.query(
  [
    'CREATE TEMPORARY TABLE `announcements` (',
    '`id` int(11) NOT NULL AUTO_INCREMENT,',
    '`title` varchar(255) DEFAULT NULL,',
    '`text` varchar(255) DEFAULT NULL,',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n'),
  (err) => {
    if (err) {
      throw err;
    }
  }
);

connection.execute(
  'INSERT INTO announcements(title, text) VALUES(?, ?)',
  ['Есть место, где заканчивается тротуар', 'Расти борода, расти'],
  (err) => {
    if (err) {
      throw err;
    }
  }
);
connection.execute(
  'INSERT INTO announcements(title, text) VALUES(?, ?)',
  [
    'Граждане Российской Федерации имеют право собираться мирно без оружия',
    'проводить собрания, митинги и демонстрации, шествия и пикетирование',
  ],
  (err) => {
    if (err) {
      throw err;
    }
  }
);
connection.execute('SELECT * FROM announcements', async (err, _rows) => {
  rows = _rows;
  const s1 = connection.query('SELECT * FROM announcements').stream();
  s1.on('data', (row) => {
    rows1.push(row);
  });
  s1.on('end', () => {
    const s2 = connection.execute('SELECT * FROM announcements').stream();
    s2.on('data', (row) => {
      rows2.push(row);
    });
    s2.on('end', () => {
      connection.end();
    });
  });
  const s3 = connection.query('SELECT * FROM announcements').stream();
  for await (const row of s3) {
    rows3.push(row);
  }
  const s4 = connection.query('SELECT * FROM announcements').stream();
  for await (const row of s4) {
    await new Promise((resolve) => setTimeout(resolve, 1000));
    rows4.push(row);
  }
});

process.on('exit', () => {
  assert.deepEqual(rows.length, 2);
  assert.deepEqual(rows, rows1);
  assert.deepEqual(rows, rows2);
  assert.deepEqual(rows, rows3);
  assert.deepEqual(rows, rows4);
});
</file>

<file path="test/integration/connection/test-then-on-query.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

let error = true;

const q = connection.query('SELECT 1');
try {
  if (q.then) q.then();
} catch (err) {
  error = false;
}
q.on('end', () => {
  connection.end();
});

process.on('exit', () => {
  assert.equal(error, false);
});
</file>

<file path="test/integration/connection/test-timestamp.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

connection.query('SET SQL_MODE="ALLOW_INVALID_DATES";');
connection.query('CREATE TEMPORARY TABLE t (f TIMESTAMP)');
connection.query("INSERT INTO t VALUES('0000-00-00 00:00:00')");
connection.query("INSERT INTO t VALUES('2013-01-22 01:02:03')");

let rows, fields;
let rows1, fields1;
let rows2;
connection.query('SELECT f FROM t', (err, _rows, _fields) => {
  if (err) {
    throw err;
  }
  rows = _rows;
  fields = _fields;
});
connection.execute('SELECT f FROM t', (err, _rows, _fields) => {
  if (err) {
    throw err;
  }
  rows1 = _rows;
  fields1 = _fields;
});

// test 11-byte timestamp - https://github.com/sidorares/node-mysql2/issues/254
connection.execute('SELECT CURRENT_TIMESTAMP(6) as t11', (err, _rows) => {
  if (err) {
    throw err;
  }
  rows2 = _rows;
  connection.end();
});

process.on('exit', () => {
  assert.deepEqual(rows[0].f.toString(), 'Invalid Date');
  assert(rows[0].f instanceof Date);
  assert(rows[1].f instanceof Date);
  assert.equal(rows[1].f.getYear(), 113);
  assert.equal(rows[1].f.getMonth(), 0);
  assert.equal(rows[1].f.getDate(), 22);
  assert.equal(rows[1].f.getHours(), 1);
  assert.equal(rows[1].f.getMinutes(), 2);
  assert.equal(rows[1].f.getSeconds(), 3);
  assert.equal(fields[0].name, 'f');
  assert.deepEqual(rows[1], rows1[1]);
  assert.deepEqual(fields[0].inspect(), fields1[0].inspect());

  assert(rows2[0].t11 instanceof Date);
});
</file>

<file path="test/integration/connection/test-track-state-change.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

const connection = common.createConnection();

let result1, result2;

connection.query('SET NAMES koi8r', (err, _ok) => {
  assert.ifError(err);
  result1 = _ok;
});

connection.query('USE mysql', (err, _ok) => {
  assert.ifError(err);
  result2 = _ok;
  connection.end();
});

process.on('exit', () => {
  assert.deepEqual(result1.stateChanges.systemVariables, {
    character_set_connection: 'koi8r',
    character_set_client: 'koi8r',
    character_set_results: 'koi8r',
  });
  assert.deepEqual(result2.stateChanges.schema, 'mysql');
});
</file>

<file path="test/integration/connection/test-transaction-commit.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const connection = common.createConnection();
const { assert } = require('poku');

common.useTestDb(connection);

const table = 'transaction_test';
connection.query(
  [
    `CREATE TEMPORARY TABLE \`${table}\` (`,
    '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    '`title` varchar(255),',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n')
);

connection.beginTransaction((err) => {
  assert.ifError(err);

  const row = {
    id: 1,
    title: 'Test row',
  };

  connection.query(`INSERT INTO ${table} SET ?`, row, (err) => {
    assert.ifError(err);

    connection.commit((err) => {
      assert.ifError(err);

      connection.query(`SELECT * FROM ${table}`, (err, rows) => {
        assert.ifError(err);
        connection.end();
        assert.equal(rows.length, 1);
      });
    });
  });
});
</file>

<file path="test/integration/connection/test-transaction-rollback.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');

const connection = common.createConnection();

common.useTestDb(connection);

const table = 'transaction_test';
connection.query(
  [
    `CREATE TEMPORARY TABLE \`${table}\` (`,
    '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    '`title` varchar(255),',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n')
);

connection.beginTransaction((err) => {
  assert.ifError(err);

  const row = {
    id: 1,
    title: 'Test row',
  };

  connection.query(`INSERT INTO ${table} SET ?`, row, (err) => {
    assert.ifError(err);

    connection.rollback((err) => {
      assert.ifError(err);

      connection.query(`SELECT * FROM ${table}`, (err, rows) => {
        assert.ifError(err);
        connection.end();
        assert.equal(rows.length, 0);
      });
    });
  });
});
</file>

<file path="test/integration/connection/test-type-cast-null-fields-execute.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

common.useTestDb(connection);

const table = 'insert_test';
connection.execute(
  [
    `CREATE TEMPORARY TABLE \`${table}\` (`,
    '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    '`date` DATETIME NULL,',
    '`number` INT NULL,',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n'),
  (err) => {
    if (err) throw err;
  }
);

connection.execute(
  `INSERT INTO ${table} (date, number) VALUES (?, ?)`,
  [null, null],
  (err) => {
    if (err) throw err;
  }
);

let results;
connection.execute(`SELECT * FROM ${table}`, (err, _results) => {
  if (err) {
    throw err;
  }

  results = _results;
  connection.end();
});

process.on('exit', () => {
  assert.strictEqual(results[0].date, null);
  assert.strictEqual(results[0].number, null);
});
</file>

<file path="test/integration/connection/test-type-cast-null-fields.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

common.useTestDb(connection);

const table = 'insert_test';
connection.query(
  [
    `CREATE TEMPORARY TABLE \`${table}\` (`,
    '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    '`date` DATETIME NULL,',
    '`number` INT NULL,',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n')
);

connection.query(`INSERT INTO ${table} SET ?`, {
  date: null,
  number: null,
});

let results;
connection.query(`SELECT * FROM ${table}`, (err, _results) => {
  if (err) {
    throw err;
  }

  results = _results;
  connection.end();
});

process.on('exit', () => {
  assert.strictEqual(results[0].date, null);
  assert.strictEqual(results[0].number, null);
});
</file>

<file path="test/integration/connection/test-type-casting-execute.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const driver = require('../../../index.js'); //needed to check driver.Types
const { test, assert } = require('poku');
const { Buffer } = require('node:buffer');
const process = require('node:process');

test(async () => {
  const connection = common.createConnection();

  common.useTestDb(connection);

  connection.execute('select 1', async (waitConnectErr) => {
    assert.ifError(waitConnectErr);

    const tests = await require('./type-casting-tests.test.cjs')(connection);

    const table = 'type_casting';

    const schema = [];
    const inserts = [];

    tests.forEach((test, index) => {
      const escaped = test.insertRaw || connection.escape(test.insert);

      test.columnName = `${test.type}_${index}`;

      schema.push(`\`${test.columnName}\` ${test.type},`);
      inserts.push(`\`${test.columnName}\` = ${escaped}`);
    });

    const createTable = [
      `CREATE TEMPORARY TABLE \`${table}\` (`,
      '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    ]
      .concat(schema)
      .concat(['PRIMARY KEY (`id`)', ') ENGINE=InnoDB DEFAULT CHARSET=utf8'])
      .join('\n');

    connection.execute(createTable);

    connection.execute(`INSERT INTO ${table} SET ${inserts.join(',\n')}`);

    let row;
    let fieldData; // to lookup field types
    connection.execute(`SELECT * FROM ${table}`, (err, rows, fields) => {
      if (err) {
        throw err;
      }

      row = rows[0];
      // build a fieldName: fieldType lookup table
      fieldData = fields.reduce((a, v) => {
        a[v['name']] = v['type'];
        return a;
      }, {});
      connection.end();
    });

    process.on('exit', () => {
      tests.forEach((test) => {
        // check that the column type matches the type name stored in driver.Types
        const columnType = fieldData[test.columnName];
        assert.equal(
          test.columnType === driver.Types[columnType],
          true,
          test.columnName
        );
        let expected = test.expect || test.insert;
        let got = row[test.columnName];
        let message;

        if (expected instanceof Date) {
          assert.equal(got instanceof Date, true, test.type);

          expected = String(expected);
          got = String(got);
        } else if (Buffer.isBuffer(expected)) {
          assert.equal(Buffer.isBuffer(got), true, test.type);

          expected = String(Array.prototype.slice.call(expected));
          got = String(Array.prototype.slice.call(got));
        }

        if (test.deep) {
          message = `got: "${JSON.stringify(got)}" expected: "${JSON.stringify(
            expected
          )}" test: ${test.type}`;
          assert.deepEqual(expected, got, message);
        } else {
          message = `got: "${got}" (${typeof got}) expected: "${expected}" (${typeof expected}) test: ${
            test.type
          }`;
          assert.strictEqual(expected, got, message);
        }
      });
    });
  });
});
</file>

<file path="test/integration/connection/test-type-casting.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const driver = require('../../../index.js'); //needed to check driver.Types
const { test, assert } = require('poku');
const { Buffer } = require('node:buffer');
const process = require('node:process');

test(async () => {
  const connection = common.createConnection();

  common.useTestDb(connection);

  connection.query('select 1', async (waitConnectErr) => {
    assert.ifError(waitConnectErr);

    const tests = await require('./type-casting-tests.test.cjs')(connection);

    const table = 'type_casting';

    const schema = [];
    const inserts = [];

    tests.forEach((test, index) => {
      const escaped = test.insertRaw || connection.escape(test.insert);

      test.columnName = `${test.type}_${index}`;

      schema.push(`\`${test.columnName}\` ${test.type},`);
      inserts.push(`\`${test.columnName}\` = ${escaped}`);
    });

    const createTable = [
      `CREATE TEMPORARY TABLE \`${table}\` (`,
      '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    ]
      .concat(schema)
      .concat(['PRIMARY KEY (`id`)', ') ENGINE=InnoDB DEFAULT CHARSET=utf8'])
      .join('\n');

    connection.query(createTable);

    connection.query(`INSERT INTO ${table} SET${inserts.join(',\n')}`);

    let row;
    let fieldData; // to lookup field types
    connection.query(`SELECT * FROM ${table}`, (err, rows, fields) => {
      if (err) {
        throw err;
      }

      row = rows[0];
      // build a fieldName: fieldType lookup table
      fieldData = fields.reduce((a, v) => {
        a[v['name']] = v['type'];
        return a;
      }, {});
      connection.end();
    });

    process.on('exit', () => {
      tests.forEach((test) => {
        // check that the column type matches the type name stored in driver.Types
        const columnType = fieldData[test.columnName];
        assert.equal(
          test.columnType === driver.Types[columnType],
          true,
          test.columnName
        );
        let expected = test.expect || test.insert;
        let got = row[test.columnName];
        let message;

        if (expected instanceof Date) {
          assert.equal(got instanceof Date, true, test.type);

          expected = String(expected);
          got = String(got);
        } else if (Buffer.isBuffer(expected)) {
          assert.equal(Buffer.isBuffer(got), true, test.type);

          expected = String(Array.prototype.slice.call(expected));
          got = String(Array.prototype.slice.call(got));
        }

        if (test.deep) {
          message = `got: "${JSON.stringify(got)}" expected: "${JSON.stringify(
            expected
          )}" test: ${test.type}`;
          assert.deepEqual(expected, got, message);
        } else {
          message = `got: "${got}" (${typeof got}) expected: "${expected}" (${typeof expected}) test: ${
            test.type
          }`;
          assert.strictEqual(expected, got, message);
        }
      });
    });
  });
});
</file>

<file path="test/integration/connection/test-typecast-execute.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const { Buffer } = require('node:buffer');

const connection = common.createConnection();

connection.execute('CREATE TEMPORARY TABLE json_test (json_test JSON)');
connection.execute('INSERT INTO json_test VALUES (?)', [
  JSON.stringify({ test: 42 }),
]);

connection.execute(
  'CREATE TEMPORARY TABLE geom_test (p POINT, g GEOMETRY NOT NULL)'
);
connection.execute(
  'INSERT INTO geom_test VALUES (ST_GeomFromText(?), ST_GeomFromText(?))',
  [
    'POINT(1 1)',
    'LINESTRING(-71.160281 42.258729,-71.160837 42.259113,-71.161144 42.25932)',
  ]
);

connection.execute(
  {
    sql: 'select "foo uppercase" as foo',
    typeCast: function (field, next) {
      assert.equal('number', typeof field.length);
      if (field.type === 'VAR_STRING') {
        return field.string().toUpperCase();
      }
      return next();
    },
  },
  (err, res) => {
    assert.ifError(err);
    assert.equal(res[0].foo, 'FOO UPPERCASE');
  }
);

connection.execute(
  {
    sql: 'select "foobar" as foo',
    typeCast: false,
  },
  (err, res) => {
    assert.ifError(err);
    assert(Buffer.isBuffer(res[0].foo));
    assert.equal(res[0].foo.toString('utf8'), 'foobar');
  }
);

connection.execute(
  {
    sql: 'SELECT NULL as test, 6 as value;',
    typeCast: function (field, next) {
      return next();
    },
  },
  (err, _rows) => {
    assert.ifError(err);
    assert.equal(_rows[0].test, null);
    assert.equal(_rows[0].value, 6);
  }
);

connection.execute(
  {
    sql: 'SELECT * from json_test',
    typeCast: function (_field, next) {
      return next();
    },
  },
  (err, _rows) => {
    assert.ifError(err);
    assert.equal(_rows[0].json_test.test, 42);
  }
);

// read geo fields
connection.execute(
  {
    sql: 'select * from geom_test',
  },
  (err, res) => {
    assert.ifError(err);
    assert.deepEqual({ x: 1, y: 1 }, res[0].p);
    assert.deepEqual(
      [
        { x: -71.160281, y: 42.258729 },
        { x: -71.160837, y: 42.259113 },
        { x: -71.161144, y: 42.25932 },
      ],
      res[0].g
    );
  }
);

connection.execute(
  {
    sql: 'select * from geom_test',
    typeCast: function (field, next) {
      assert.equal('geom_test', field.table);

      if (field.name === 'p' && field.type === 'GEOMETRY') {
        assert.deepEqual({ x: 1, y: 1 }, field.geometry());
        return { x: 2, y: 2 };
      }

      if (field.name === 'g' && field.type === 'GEOMETRY') {
        assert.deepEqual(
          [
            { x: -71.160281, y: 42.258729 },
            { x: -71.160837, y: 42.259113 },
            { x: -71.161144, y: 42.25932 },
          ],
          field.geometry()
        );

        return [
          { x: -70, y: 40 },
          { x: -60, y: 50 },
          { x: -50, y: 60 },
        ];
      }

      assert.fail('should not reach here');

      return next();
    },
  },
  (err, res) => {
    assert.ifError(err);
    assert.deepEqual({ x: 2, y: 2 }, res[0].p);
    assert.deepEqual(
      [
        { x: -70, y: 40 },
        { x: -60, y: 50 },
        { x: -50, y: 60 },
      ],
      res[0].g
    );
  }
);

connection.end();
</file>

<file path="test/integration/connection/test-typecast-geometry-execute.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { test, assert } = require('poku');
const { Buffer } = require('node:buffer');

test(async () => {
  const connection = common.createConnection();
  const mySQLVersion = await common.getMysqlVersion(connection);

  connection.execute('select 1', () => {
    // mysql8 renamed some standard functions
    // see https://dev.mysql.com/doc/refman/8.0/en/gis-wkb-functions.html
    const stPrefix = mySQLVersion.major >= 8 ? 'ST_' : '';

    connection.execute(
      {
        sql: `select ${stPrefix}GeomFromText('POINT(11 0)') as foo`,
        typeCast: function (field, next) {
          if (field.type === 'GEOMETRY') {
            return field.geometry();
          }
          return next();
        },
      },
      (err, res) => {
        assert.ifError(err);
        assert.deepEqual(res[0].foo, { x: 11, y: 0 });
      }
    );

    connection.execute(
      {
        sql: `select ${stPrefix}GeomFromText('POINT(11 0)') as foo`,
        typeCast: function (field, next) {
          if (field.type === 'GEOMETRY') {
            return field.buffer();
          }
          return next();
        },
      },
      (err, res) => {
        assert.ifError(err);
        assert.equal(Buffer.isBuffer(res[0].foo), true);
      }
    );

    connection.end();
  });
});
</file>

<file path="test/integration/connection/test-typecast-geometry.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { test, assert } = require('poku');
const { Buffer } = require('node:buffer');

test(async () => {
  const connection = common.createConnection();
  const mySQLVersion = await common.getMysqlVersion(connection);

  connection.query('select 1', () => {
    // mysql8 renamed some standard functions
    // see https://dev.mysql.com/doc/refman/8.0/en/gis-wkb-functions.html
    const stPrefix = mySQLVersion.major >= 8 ? 'ST_' : '';

    connection.query(
      {
        sql: `select ${stPrefix}GeomFromText('POINT(11 0)') as foo`,
        typeCast: function (field, next) {
          if (field.type === 'GEOMETRY') {
            return field.geometry();
          }
          return next();
        },
      },
      (err, res) => {
        assert.ifError(err);
        assert.deepEqual(res[0].foo, { x: 11, y: 0 });
      }
    );

    connection.query(
      {
        sql: `select ${stPrefix}GeomFromText('POINT(11 0)') as foo`,
        typeCast: function (field, next) {
          if (field.type === 'GEOMETRY') {
            return field.buffer();
          }
          return next();
        },
      },
      (err, res) => {
        assert.ifError(err);
        assert.equal(Buffer.isBuffer(res[0].foo), true);
      }
    );

    connection.end();
  });
});
</file>

<file path="test/integration/connection/test-typecast-overwriting-execute.test.cjs">
'use strict';

const { assert } = require('poku');
const common = require('../../common.test.cjs');

const connection = common.createConnection({
  typeCast: function (field, next) {
    assert.equal('number', typeof field.length);
    if (field.type === 'VAR_STRING') {
      return field.string().toUpperCase();
    }
    return next();
  },
});

connection.execute(
  {
    sql: 'select "foo uppercase" as foo',
  },
  (err, res) => {
    assert.ifError(err);
    assert.equal(res[0].foo, 'FOO UPPERCASE');
  }
);

connection.execute(
  {
    sql: 'select "foo lowercase" as foo',
    typeCast: function (field, next) {
      assert.equal('number', typeof field.length);
      if (field.type === 'VAR_STRING') {
        return field.string().toLowerCase();
      }
      return next();
    },
  },
  (err, res) => {
    assert.ifError(err);
    assert.equal(res[0].foo, 'foo lowercase');
  }
);

connection.end();
</file>

<file path="test/integration/connection/test-typecast-overwriting.test.cjs">
'use strict';

const { assert } = require('poku');
const common = require('../../common.test.cjs');

const connection = common.createConnection({
  typeCast: function (field, next) {
    assert.equal('number', typeof field.length);
    if (field.type === 'VAR_STRING') {
      return field.string().toUpperCase();
    }
    return next();
  },
});

connection.query(
  {
    sql: 'select "foo uppercase" as foo',
  },
  (err, res) => {
    assert.ifError(err);
    assert.equal(res[0].foo, 'FOO UPPERCASE');
  }
);

connection.query(
  {
    sql: 'select "foo lowercase" as foo',
    typeCast: function (field, next) {
      assert.equal('number', typeof field.length);
      if (field.type === 'VAR_STRING') {
        return field.string().toLowerCase();
      }
      return next();
    },
  },
  (err, res) => {
    assert.ifError(err);
    assert.equal(res[0].foo, 'foo lowercase');
  }
);

connection.end();
</file>

<file path="test/integration/connection/test-typecast.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const { Buffer } = require('node:buffer');

const connection = common.createConnection();

connection.query('CREATE TEMPORARY TABLE json_test (json_test JSON)');
connection.query(
  'INSERT INTO json_test VALUES (?)',
  JSON.stringify({ test: 42 })
);

connection.query(
  'CREATE TEMPORARY TABLE geom_test (p POINT, g GEOMETRY NOT NULL)'
);
connection.query(
  'INSERT INTO geom_test VALUES (ST_GeomFromText("POINT(1 1)"), ' +
    'ST_GeomFromText("LINESTRING(-71.160281 42.258729,-71.160837 42.259113,-71.161144 42.25932)"))'
);

connection.query(
  {
    sql: 'select "foo uppercase" as foo',
    typeCast: function (field, next) {
      assert.equal('number', typeof field.length);
      if (field.type === 'VAR_STRING') {
        return field.string().toUpperCase();
      }
      return next();
    },
  },
  (err, res) => {
    assert.ifError(err);
    assert.equal(res[0].foo, 'FOO UPPERCASE');
  }
);

connection.query(
  {
    sql: 'select "foobar" as foo',
    typeCast: false,
  },
  (err, res) => {
    assert.ifError(err);
    assert(Buffer.isBuffer(res[0].foo), 'Check for Buffer');
    assert.equal(res[0].foo.toString('utf8'), 'foobar');
  }
);

connection.query(
  {
    sql: 'SELECT NULL as test, 6 as value;',
    typeCast: function (field, next) {
      return next();
    },
  },
  (err, _rows) => {
    assert.ifError(err);
    assert.equal(_rows[0].test, null);
    assert.equal(_rows[0].value, 6);
  }
);

connection.query(
  {
    sql: 'SELECT * from json_test',
    typeCast: function (_field, next) {
      return next();
    },
  },
  (err, _rows) => {
    assert.ifError(err);
    assert.equal(_rows[0].json_test.test, 42);
  }
);

connection.execute(
  {
    sql: 'SELECT * from json_test',
    typeCast: function (_field, next) {
      return next();
    },
  },
  (err, _rows) => {
    assert.ifError(err);
    assert.equal(_rows[0].json_test.test, 42);
  }
);

// read geo fields
connection.query(
  {
    sql: 'select * from geom_test',
  },
  (err, res) => {
    assert.ifError(err);
    assert.deepEqual({ x: 1, y: 1 }, res[0].p);
    assert.deepEqual(
      [
        { x: -71.160281, y: 42.258729 },
        { x: -71.160837, y: 42.259113 },
        { x: -71.161144, y: 42.25932 },
      ],
      res[0].g
    );
  }
);

connection.query(
  {
    sql: 'select * from geom_test',
    typeCast: function (field, next) {
      assert.equal('geom_test', field.table);

      if (field.name === 'p' && field.type === 'GEOMETRY') {
        assert.deepEqual({ x: 1, y: 1 }, field.geometry());
        return { x: 2, y: 2 };
      }

      if (field.name === 'g' && field.type === 'GEOMETRY') {
        assert.deepEqual(
          [
            { x: -71.160281, y: 42.258729 },
            { x: -71.160837, y: 42.259113 },
            { x: -71.161144, y: 42.25932 },
          ],
          field.geometry()
        );

        return [
          { x: -70, y: 40 },
          { x: -60, y: 50 },
          { x: -50, y: 60 },
        ];
      }

      assert.fail('should not reach here');

      return next();
    },
  },
  (err, res) => {
    assert.ifError(err);
    assert.deepEqual({ x: 2, y: 2 }, res[0].p);
    assert.deepEqual(
      [
        { x: -70, y: 40 },
        { x: -60, y: 50 },
        { x: -50, y: 60 },
      ],
      res[0].g
    );
  }
);

connection.end();
</file>

<file path="test/integration/connection/test-update-changed-rows.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

// "changedRows" is not part of the mysql protocol and extracted from "info string" response
// while valid for most mysql servers, it's not guaranteed to be present in all cases
if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

/**
 * <plusmancn@gmail.com> created at 2016.09.17 15:24:34
 *
 * issue#288: https://github.com/sidorares/node-mysql2/issues/288
 */
const connection = common.createConnection();

let result1 = undefined;
let result2 = undefined;

// connection.
connection.query(
  [
    'CREATE TEMPORARY TABLE `changed_rows` (',
    '`id` int(11) unsigned NOT NULL AUTO_INCREMENT,',
    '`value` int(5) NOT NULL,',
    'PRIMARY KEY (`id`)',
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join('\n')
);
connection.query('insert into changed_rows(value) values(1)');
connection.query('insert into changed_rows(value) values(1)');
connection.query('insert into changed_rows(value) values(2)');
connection.query('insert into changed_rows(value) values(3)');

connection.execute('update changed_rows set value=1', [], (err, _result) => {
  if (err) {
    throw err;
  }

  result1 = _result;
  connection.execute('update changed_rows set value=1', [], (err, _result) => {
    if (err) {
      throw err;
    }

    result2 = _result;
    connection.end();
  });
});

process.on('exit', () => {
  assert.equal(result1.affectedRows, 4);
  assert.equal(result1.changedRows, 2);
  assert.equal(result2.affectedRows, 4);
  assert.equal(result2.changedRows, 0);
});
</file>

<file path="test/integration/connection/type-casting-tests.test.cjs">
'use strict';

const { Buffer } = require('node:buffer');
const common = require('../../common.test.cjs');

module.exports = async function (connection) {
  const mySQLVersion = await common.getMysqlVersion(connection);

  // mysql8 renamed some standard functions
  // see https://dev.mysql.com/doc/refman/8.0/en/gis-wkb-functions.html
  const stPrefix = mySQLVersion.major >= 8 ? 'ST_' : '';

  return [
    { type: 'decimal(4,3)', insert: '1.234', columnType: 'NEWDECIMAL' },
    //  {type: 'decimal(3,3)', insert: 0.33},
    { type: 'tinyint', insert: 1, columnType: 'TINY' },
    { type: 'smallint', insert: 2, columnType: 'SHORT' },
    { type: 'int', insert: 3, columnType: 'LONG' },
    { type: 'float', insert: 4.5, columnType: 'FLOAT' },
    { type: 'double', insert: 5.5, columnType: 'DOUBLE' },
    { type: 'bigint', insert: '6', expect: 6, columnType: 'LONGLONG' },
    { type: 'bigint', insert: 6, columnType: 'LONGLONG' },
    { type: 'mediumint', insert: 7, columnType: 'INT24' },
    { type: 'year', insert: 2012, columnType: 'YEAR' },
    {
      type: 'timestamp',
      insert: new Date('2012-05-12 11:00:23'),
      columnType: 'TIMESTAMP',
    },
    {
      type: 'datetime',
      insert: new Date('2012-05-12 12:00:23'),
      columnType: 'DATETIME',
    },
    {
      type: 'date',
      insert: new Date('2012-05-12 00:00:00'),
      columnType: 'DATE',
    },
    { type: 'time', insert: '13:13:23', columnType: 'TIME' },
    { type: 'time', insert: '-13:13:23', columnType: 'TIME' },
    { type: 'time', insert: '413:13:23', columnType: 'TIME' },
    { type: 'time', insert: '-413:13:23', columnType: 'TIME' },
    {
      type: 'binary(4)',
      insert: Buffer.from([0, 1, 254, 255]),
      columnType: 'STRING',
    },
    {
      type: 'varbinary(4)',
      insert: Buffer.from([0, 1, 254, 255]),
      columnType: 'VAR_STRING',
    },
    {
      type: 'tinyblob',
      insert: Buffer.from([0, 1, 254, 255]),
      columnType: 'BLOB',
    },
    {
      type: 'mediumblob',
      insert: Buffer.from([0, 1, 254, 255]),
      columnType: 'BLOB',
    },
    {
      type: 'longblob',
      insert: Buffer.from([0, 1, 254, 255]),
      columnType: 'BLOB',
    },
    { type: 'blob', insert: Buffer.from([0, 1, 254, 255]), columnType: 'BLOB' },
    {
      type: 'bit(32)',
      insert: Buffer.from([0, 1, 254, 255]),
      columnType: 'BIT',
    },
    { type: 'char(5)', insert: 'Hello', columnType: 'STRING' },
    { type: 'varchar(5)', insert: 'Hello', columnType: 'VAR_STRING' },
    {
      type: 'varchar(3) character set utf8 collate utf8_bin',
      insert: 'bin',
      columnType: 'VAR_STRING',
    },
    { type: 'tinytext', insert: 'Hello World', columnType: 'BLOB' },
    { type: 'mediumtext', insert: 'Hello World', columnType: 'BLOB' },
    { type: 'longtext', insert: 'Hello World', columnType: 'BLOB' },
    { type: 'text', insert: 'Hello World', columnType: 'BLOB' },
    {
      type: 'point',
      insertRaw: 'POINT(1.2,-3.4)',
      expect: { x: 1.2, y: -3.4 },
      deep: true,
      columnType: 'GEOMETRY',
    },
    {
      type: 'point',
      insertRaw: (function () {
        const buffer = Buffer.alloc(21);
        buffer.writeUInt8(1, 0);
        buffer.writeUInt32LE(1, 1);
        buffer.writeDoubleLE(-5.6, 5);
        buffer.writeDoubleLE(10.23, 13);
        return `${stPrefix}GeomFromWKB(${connection.escape(buffer)})`;
      })(),
      expect: { x: -5.6, y: 10.23 },
      deep: true,
      columnType: 'GEOMETRY',
    },
    {
      type: 'point',
      insertRaw: '',
      insert: null,
      expect: null,
      columnType: 'GEOMETRY',
    },
    {
      type: 'linestring',
      insertRaw: 'LINESTRING(POINT(1.2,-3.4),POINT(-5.6,10.23),POINT(0.2,0.7))',
      expect: [
        { x: 1.2, y: -3.4 },
        { x: -5.6, y: 10.23 },
        { x: 0.2, y: 0.7 },
      ],
      deep: true,
      columnType: 'GEOMETRY',
    },
    {
      type: 'polygon',
      insertRaw: `${stPrefix}GeomFromText('POLYGON((0 0,10 0,10 10,0 10,0 0),(5 5,7 5,7 7,5 7, 5 5))')`,
      expect: [
        [
          { x: 0, y: 0 },
          { x: 10, y: 0 },
          { x: 10, y: 10 },
          { x: 0, y: 10 },
          { x: 0, y: 0 },
        ],
        [
          { x: 5, y: 5 },
          { x: 7, y: 5 },
          { x: 7, y: 7 },
          { x: 5, y: 7 },
          { x: 5, y: 5 },
        ],
      ],
      deep: true,
      columnType: 'GEOMETRY',
    },
    {
      type: 'geometry',
      insertRaw: 'POINT(1.2,-3.4)',
      expect: { x: 1.2, y: -3.4 },
      deep: true,
      columnType: 'GEOMETRY',
    },
    {
      type: 'multipoint',
      insertRaw: `${stPrefix}GeomFromText('MULTIPOINT(0 0, 20 20, 60 60)')`,
      expect: [
        { x: 0, y: 0 },
        { x: 20, y: 20 },
        { x: 60, y: 60 },
      ],
      deep: true,
      columnType: 'GEOMETRY',
    },
    {
      type: 'multilinestring',
      insertRaw: `${stPrefix}GeomFromText('MULTILINESTRING((10 10, 20 20), (15 15, 30 15))')`,
      expect: [
        [
          { x: 10, y: 10 },
          { x: 20, y: 20 },
        ],
        [
          { x: 15, y: 15 },
          { x: 30, y: 15 },
        ],
      ],
      deep: true,
      columnType: 'GEOMETRY',
    },
    {
      type: 'multipolygon',
      insertRaw: `${stPrefix}GeomFromText('MULTIPOLYGON(((0 0,10 0,10 10,0 10,0 0)),((5 5,7 5,7 7,5 7, 5 5)))')`,
      expect: [
        [
          [
            { x: 0, y: 0 },
            { x: 10, y: 0 },
            { x: 10, y: 10 },
            { x: 0, y: 10 },
            { x: 0, y: 0 },
          ],
        ],
        [
          [
            { x: 5, y: 5 },
            { x: 7, y: 5 },
            { x: 7, y: 7 },
            { x: 5, y: 7 },
            { x: 5, y: 5 },
          ],
        ],
      ],
      deep: true,
      columnType: 'GEOMETRY',
    },
    {
      type: 'geometrycollection',
      insertRaw: `${stPrefix}GeomFromText('GEOMETRYCOLLECTION(POINT(11 10), POINT(31 30), LINESTRING(15 15, 20 20))')`,
      expect: [
        { x: 11, y: 10 },
        { x: 31, y: 30 },
        [
          { x: 15, y: 15 },
          { x: 20, y: 20 },
        ],
      ],
      deep: true,
      columnType: 'GEOMETRY',
    },
  ];
};
</file>

<file path="test/integration/promise-wrappers/test-async-stack.test.cjs">
'use strict';

const process = require('node:process');
const config = require('../../common.test.cjs').config;
const { assert } = require('poku');
const ErrorStackParser = require('error-stack-parser');

// Uncaught Error: connect ECONNREFUSED 127.0.0.1:33066 - Local (undefined:undefined)
if (typeof Deno !== 'undefined') process.exit(0);

const createConnection = async function (args) {
  const connect = require('../../../promise.js').createConnection;
  if (!args && process.env.MYSQL_CONNECTION_URL) {
    return connect({ uri: process.env.MYSQL_CONNECTION_URL });
  }
  return connect({ ...config, ...args });
};

async function test() {
  // TODO check this is actially required. This meant as a help for pre async/await node
  // to load entire file and do isAsyncSupported check instead of failing with syntax error

  let e1, e2;

  // TODO: investigate why connection is still open after ENETUNREACH
  async function test1() {
    e1 = new Error();
    // expected not to connect
    await createConnection({ host: '127.0.0.1', port: 33066 });
  }

  async function test2() {
    const conn = await createConnection();
    try {
      e2 = new Error();
      await Promise.all([conn.query('select 1+1'), conn.query('syntax error')]);
    } catch (err) {
      const stack = ErrorStackParser.parse(err);
      const stackExpected = ErrorStackParser.parse(e2);
      assert(stack[1].getLineNumber() === stackExpected[0].getLineNumber() + 1);
      conn.end();
    }
  }

  test1().catch((err) => {
    const stack = ErrorStackParser.parse(err);
    const stackExpected = ErrorStackParser.parse(e1);
    assert(stack[2].getLineNumber() === stackExpected[0].getLineNumber() + 2);
    test2();
  });
}

test();
</file>

<file path="test/integration/promise-wrappers/test-promise-wrappers.test.cjs">
'use strict';

const config = require('../../common.test.cjs').config;
const { assert } = require('poku');
const process = require('node:process');

if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

const createConnection = require('../../../promise.js').createConnection;
const createPool = require('../../../promise.js').createPool;

// it's lazy exported from main index.js as well. Test that it's same function
const mainExport = require('../../../index.js').createConnectionPromise;
assert.equal(mainExport, createConnection);

let doneCalled = false;
let exceptionCaught = false;
let doneEventsConnect = false;

let doneCalledPool = false;
let exceptionCaughtPool = false;
let doneEventsPool = false;
let doneChangeUser = false;

function testBasic() {
  let connResolved;
  createConnection(config)
    .then((conn) => {
      connResolved = conn;
      return conn.query('select 1+2 as ttt');
    })
    .then((result1) => {
      assert.equal(result1[0][0].ttt, 3);
      return connResolved.query('select 2+2 as qqq');
    })
    .then((result2) => {
      assert.equal(result2[0][0].qqq, 4);
      return connResolved.end();
    })
    .then(() => {
      doneCalled = true;
    })
    .catch((err) => {
      throw err;
    });
}

function testErrors() {
  let connResolved;
  const connPromise = createConnection(config);

  connPromise
    .then((conn) => {
      connResolved = conn;
      return conn.query('select 1+2 as ttt');
    })
    .then((result1) => {
      assert.equal(result1[0][0].ttt, 3);
      return connResolved.query('bad sql');
    })
    .then((result2) => {
      assert.equal(result2[0][0].ttt, 3);
      return connResolved.query('select 2+2 as qqq');
    })
    .catch(() => {
      exceptionCaught = true;
      if (connResolved) {
        connResolved.end();
      } else {
        console.log('Warning: promise rejected before first query');
      }
    });
}

function testObjParams() {
  let connResolved;
  createConnection(config)
    .then((conn) => {
      connResolved = conn;
      return conn.query({
        sql: 'select ?-? as ttt',
        values: [5, 2],
      });
    })
    .then((result1) => {
      assert.equal(result1[0][0].ttt, 3);
      return connResolved.execute({
        sql: 'select ?-? as ttt',
        values: [8, 5],
      });
    })
    .then((result2) => {
      assert.equal(result2[0][0].ttt, 3);
      return connResolved.end();
    })
    .catch((err) => {
      console.log(err);
    });
}

function testPrepared() {
  let connResolved;
  createConnection(config)
    .then((conn) => {
      connResolved = conn;
      return conn.prepare('select ?-? as ttt, ? as uuu');
    })
    .then((statement) => statement.execute([11, 3, 'test']))
    .then((result) => {
      assert.equal(result[0][0].ttt, 8);
      assert.equal(result[0][0].uuu, 'test');
      return connResolved.end();
    })
    .catch((err) => {
      console.log(err);
      if (connResolved) {
        connResolved.end();
      } else {
        console.log(
          'Warning: promise rejected before executing prepared statement'
        );
      }
    });
}

// REVIEW: Unused

function testEventsConnect() {
  let connResolved;
  createConnection(config)
    .then((conn) => {
      connResolved = conn;
      let events = 0;

      const expectedListeners = {
        error: 1,
        drain: 0,
        connect: 0,
        enqueue: 0,
        end: 0,
      };
      for (const eventName in expectedListeners) {
        assert.equal(
          conn.connection.listenerCount(eventName),
          expectedListeners[eventName],
          eventName
        );
      }

      /* eslint-disable no-invalid-this */
      conn
        .once('error', function () {
          assert.equal(this, conn);
          ++events;
        })
        .once('drain', function () {
          assert.equal(this, conn);
          ++events;
        })
        .once('connect', function () {
          assert.equal(this, conn);
          ++events;
        })
        .once('enqueue', function () {
          assert.equal(this, conn);
          ++events;
        })
        .once('end', function () {
          assert.equal(this, conn);
          ++events;

          doneEventsConnect = events === 5;
        });
      /* eslint-enable no-invalid-this */

      conn.connection.emit('error', new Error());
      conn.connection.emit('drain');
      conn.connection.emit('connect');
      conn.connection.emit('enqueue');
      conn.connection.emit('end');

      expectedListeners.error = 0;
      for (const eventName in expectedListeners) {
        assert.equal(
          conn.connection.listenerCount(eventName),
          expectedListeners[eventName],
          eventName
        );
      }

      conn.end();
    })
    .catch((err) => {
      console.log(err);
      if (connResolved) {
        connResolved.end();
      } else {
        console.log(
          'Warning: promise rejected before executing prepared statement'
        );
      }
    });
}

function testBasicPool() {
  const pool = createPool(config);
  const promiseConn = pool.getConnection();

  promiseConn
    .then((connResolved) => {
      pool.releaseConnection(connResolved);
    })
    .catch((err) => {
      throw err;
    });

  pool
    .query('select 1+2 as ttt')
    .then((result1) => {
      assert.equal(result1[0][0].ttt, 3);
      return pool.query('select 2+2 as qqq');
    })
    .then((result2) => {
      assert.equal(result2[0][0].qqq, 4);
      return pool.end();
    })
    .then(() => {
      doneCalledPool = true;
    })
    .catch((err) => {
      throw err;
    });
}

function testErrorsPool() {
  const pool = createPool(config);
  pool
    .query('select 1+2 as ttt')
    .then((result1) => {
      assert.equal(result1[0][0].ttt, 3);
      return pool.query('bad sql');
    })
    .then((result2) => {
      assert.equal(result2[0][0].ttt, 3);
      return pool.query('select 2+2 as qqq');
    })
    .catch(() => {
      exceptionCaughtPool = true;
      return pool.end();
    });
}

function testObjParamsPool() {
  const pool = createPool(config);
  pool
    .query({
      sql: 'select ?-? as ttt',
      values: [5, 2],
    })
    .then((result1) => {
      assert.equal(result1[0][0].ttt, 3);
      return pool.execute({
        sql: 'select ?-? as ttt',
        values: [8, 5],
      });
    })
    .then((result2) => {
      assert.equal(result2[0][0].ttt, 3);
      return pool.end();
    })
    .catch((err) => {
      console.log(err);
    });
}
function testPromiseLibrary() {
  const pool = createPool(config);
  let promise = pool.execute({
    sql: 'select ?-? as ttt',
    values: [8, 5],
  });
  promise
    .then(() => {
      assert.ok(promise instanceof pool.Promise);
    })
    .then(() => {
      promise = pool.end();
      assert.ok(promise instanceof pool.Promise);
    })
    .catch((err) => {
      console.log(err);
    });
}

function testEventsPool() {
  const pool = createPool(config);
  let events = 0;

  const expectedListeners = {
    acquire: 0,
    connection: 0,
    enqueue: 0,
    release: 0,
  };
  for (const eventName in expectedListeners) {
    assert.equal(
      pool.pool.listenerCount(eventName),
      expectedListeners[eventName],
      eventName
    );
  }

  /* eslint-disable no-invalid-this */
  pool
    .once('acquire', function () {
      assert.equal(this, pool);
      ++events;
    })
    .once('connection', function () {
      assert.equal(this, pool);
      ++events;
    })
    .once('enqueue', function () {
      assert.equal(this, pool);
      ++events;
    })
    .once('release', function () {
      assert.equal(this, pool);
      ++events;

      doneEventsPool = events === 4;
    });
  /* eslint-enable no-invalid-this */

  pool.pool.emit('acquire');
  pool.pool.emit('connection');
  pool.pool.emit('enqueue');
  pool.pool.emit('release');

  for (const eventName in expectedListeners) {
    assert.equal(
      pool.pool.listenerCount(eventName),
      expectedListeners[eventName],
      eventName
    );
  }
}

function testChangeUser() {
  const onlyUsername = function (name) {
    return name.substring(0, name.indexOf('@'));
  };
  let connResolved;

  createConnection(config)
    .then((conn) => {
      connResolved = conn;
      return connResolved.query(
        "CREATE USER IF NOT EXISTS 'changeuser1'@'%' IDENTIFIED BY 'changeuser1pass'"
      );
    })
    .then(() => {
      connResolved.query(
        "CREATE USER IF NOT EXISTS 'changeuser2'@'%' IDENTIFIED BY 'changeuser2pass'"
      );
      connResolved.query("GRANT ALL ON *.* TO 'changeuser1'@'%'");
      connResolved.query("GRANT ALL ON *.* TO 'changeuser2'@'%'");
      return connResolved.query('FLUSH PRIVILEGES');
    })
    .then(() => {
      connResolved.changeUser({
        user: 'changeuser1',
        password: 'changeuser1pass',
      });
    })
    .then(() => connResolved.query('select current_user()'))
    .then((result) => {
      const rows = result[0];
      assert.deepEqual(onlyUsername(rows[0]['current_user()']), 'changeuser1');
      return connResolved.changeUser({
        user: 'changeuser2',
        password: 'changeuser2pass',
      });
    })
    .then(() => connResolved.query('select current_user()'))
    .then((result) => {
      const rows = result[0];
      assert.deepEqual(onlyUsername(rows[0]['current_user()']), 'changeuser2');
      return connResolved.changeUser({
        user: 'changeuser1',
        // TODO: re-enable testing passwordSha1 auth. Only works for mysql_native_password, so need to change test to create user with this auth method
        password: 'changeuser1pass',
        //passwordSha1: Buffer.from('f961d39c82138dcec42b8d0dcb3e40a14fb7e8cd', 'hex') // sha1(changeuser1pass)
      });
    })
    .then(() => connResolved.query('select current_user()'))
    .then((result) => {
      const rows = result[0];
      assert.deepEqual(onlyUsername(rows[0]['current_user()']), 'changeuser1');
      doneChangeUser = true;
      return connResolved.end();
    })
    .catch((err) => {
      console.log(err);
      if (connResolved) {
        connResolved.end();
      }
      throw err;
    });
}

function testConnectionProperties() {
  let connResolved;
  createConnection(config)
    .then((conn) => {
      connResolved = conn;
      assert.equal(typeof conn.config, 'object');
      assert.ok('queryFormat' in conn.config);
      assert.equal(typeof conn.threadId, 'number');
      return connResolved.end();
    })
    .catch((err) => {
      if (connResolved) {
        connResolved.end();
      }
      throw err;
    });
}

function timebomb(fuse) {
  let timebomb;

  return {
    arm() {
      timebomb = setTimeout(() => {
        throw new Error(`Timebomb not defused within ${fuse}ms`);
      }, fuse);
    },
    defuse() {
      clearTimeout(timebomb);
    },
  };
}

function testPoolConnectionDestroy() {
  // Only allow one connection
  const options = Object.assign({ connectionLimit: 1 }, config);
  const pool = createPool(options);

  const bomb = timebomb(2000);

  pool
    .getConnection()
    .then((connection) => connection.destroy())
    .then(bomb.arm)
    .then(() => pool.getConnection())
    .then(bomb.defuse)
    .then(() => pool.end());
}

testBasic();
testErrors();
testObjParams();
testPrepared();
testEventsConnect();
testBasicPool();
testErrorsPool();
testObjParamsPool();
testEventsPool();
testChangeUser();
testConnectionProperties();
testPoolConnectionDestroy();
testPromiseLibrary();

process.on('exit', () => {
  assert.equal(doneCalled, true, 'done not called');
  assert.equal(exceptionCaught, true, 'exception not caught');
  assert.equal(doneEventsConnect, true, 'wrong number of connection events');
  assert.equal(doneCalledPool, true, 'pool done not called');
  assert.equal(exceptionCaughtPool, true, 'pool exception not caught');
  assert.equal(doneEventsPool, true, 'wrong number of pool connection events');
  assert.equal(doneChangeUser, true, 'user not changed');
});

process.on('unhandledRejection', (err) => {
  console.log('error:', err.stack);
});
</file>

<file path="test/integration/regressions/test-#433.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

// TODO: reach out to PlanetScale to clarify charset support
if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

const connection = common.createConnection({ charset: 'KOI8R_GENERAL_CI' });

const tableName = 'МояТаблица';
const testFields = ['поле1', 'поле2', 'поле3', 'поле4'];
const testRows = [
  ['привет', 'мир', 47, 7],
  ['ура', 'тест', 11, 108],
];

let actualRows = null;
let actualError = null;

function executeErrorMessageTest() {
  // tableName does not have closing "`", we do this to have tableName in error string
  // it is sent back in original encoding (koi8r), we are testing that it's decoded correctly
  connection.query(`SELECT * FROM \`${tableName}`, (err) => {
    actualError = err.message;
    connection.end();
  });
}

function executeTest(err) {
  assert.ifError(err);
  connection.query(`SELECT * FROM \`${tableName}\``, (err, rows) => {
    assert.ifError(err);
    actualRows = rows;
    executeErrorMessageTest();
  });
}

connection.query(
  [
    `CREATE TEMPORARY TABLE \`${tableName}\` (`,
    ` \`${testFields[0]}\` varchar(255) NOT NULL,`,
    ` \`${testFields[1]}\` varchar(255) NOT NULL,`,
    ` \`${testFields[2]}\` int(11) NOT NULL,`,
    ` \`${testFields[3]}\` int(11) NOT NULL,`,
    ` PRIMARY KEY (\`${testFields[0]}\`)`,
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join(' '),
  (err) => {
    assert.ifError(err);
    connection.query(
      [
        `INSERT INTO \`${tableName}\` VALUES`,
        `("${testRows[0][0]}","${testRows[0][1]}", ${testRows[0][2]}, ${testRows[0][3]}),`,
        `("${testRows[1][0]}","${testRows[1][1]}", ${testRows[1][2]}, ${testRows[1][3]})`,
      ].join(' '),
      executeTest
    );
  }
);

/* eslint quotes: 0 */
const expectedErrorMysql =
  "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '`МояТаблица' at line 1";

const expectedErrorMariaDB =
  "You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near '`МояТаблица' at line 1";

process.on('exit', () => {
  testRows.map((tRow, index) => {
    const cols = testFields;
    const aRow = actualRows[index];
    assert.equal(aRow[cols[0]], tRow[0]);
    assert.equal(aRow[cols[1]], tRow[1]);
    assert.equal(aRow[cols[2]], tRow[2]);
    assert.equal(aRow[cols[3]], tRow[3]);
  });

  if (connection._handshakePacket.serverVersion.match(/MariaDB/)) {
    assert.equal(actualError, expectedErrorMariaDB);
  } else {
    assert.equal(actualError, expectedErrorMysql);
  }
});
</file>

<file path="test/integration/regressions/test-#442.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

const tableName = '商城';
const testFields = ['商品类型', '商品说明', '价格', '剩余'];
const testRows = [
  ['商类型', '商品型', 47, 7],
  ['类商型', '商型品', 11, 108],
];

let actualRows = null;

function executeTest(err) {
  assert.ifError(err);
  connection.query(`SELECT * FROM \`${tableName}\``, (err, rows) => {
    assert.ifError(err);
    actualRows = rows;
    connection.end();
  });
}

connection.query(
  [
    `CREATE TEMPORARY TABLE \`${tableName}\` (`,
    ` \`${testFields[0]}\` varchar(255) NOT NULL,`,
    ` \`${testFields[1]}\` varchar(255) NOT NULL,`,
    ` \`${testFields[2]}\` int(11) NOT NULL,`,
    ` \`${testFields[3]}\` int(11) NOT NULL,`,
    ` PRIMARY KEY (\`${testFields[0]}\`)`,
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join(' '),
  (err) => {
    assert.ifError(err);
    connection.query(
      [
        `INSERT INTO \`${tableName}\` VALUES`,
        `("${testRows[0][0]}","${testRows[0][1]}", ${testRows[0][2]}, ${testRows[0][3]}),`,
        `("${testRows[1][0]}","${testRows[1][1]}", ${testRows[1][2]}, ${testRows[1][3]})`,
      ].join(' '),
      executeTest
    );
  }
);

process.on('exit', () => {
  testRows.map((tRow, index) => {
    const cols = testFields;
    const aRow = actualRows[index];
    assert.equal(aRow[cols[0]], tRow[0]);
    assert.equal(aRow[cols[1]], tRow[1]);
    assert.equal(aRow[cols[2]], tRow[2]);
    assert.equal(aRow[cols[3]], tRow[3]);
  });
});
</file>

<file path="test/integration/regressions/test-#485.test.cjs">
'use strict';

const config = require('../../common.test.cjs').config;
const { assert } = require('poku');
const createPoolPromise = require('../../../promise.js').createPool;
const PoolConnection = require('../../../lib/pool_connection.js');
const process = require('node:process');

function createPool(args) {
  if (!args && process.env.MYSQL_CONNECTION_URL) {
    return createPoolPromise({ uri: process.env.MYSQL_CONNECTION_URL });
  }
  return createPoolPromise({ ...config, ...args });
}

// stub
const release = PoolConnection.prototype.release;
let releaseCalls = 0;
PoolConnection.prototype.release = function () {
  releaseCalls++;
};

function testPoolPromiseExecuteLeak() {
  const pool = createPool();
  pool
    .execute('select 1+2 as ttt')
    .then((result) => {
      assert.equal(result[0][0].ttt, 3);
      return pool.end();
    })
    .catch((err) => {
      assert.ifError(err);
    });
}

testPoolPromiseExecuteLeak();

process.on('exit', () => {
  PoolConnection.prototype.release = release;
  assert.equal(releaseCalls, 1, 'PoolConnection.release was not called');
});
</file>

<file path="test/integration/regressions/test-#617.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

// PlanetScale response has trailing 000 in 2017-07-26 09:36:42.000
// TODO: rewrite test to account for variations. Skipping for now on PS
if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

const connection = common.createConnection({ dateStrings: true });

const tableName = 'dates';
const testFields = ['id', 'date', 'name'];
const testRows = [
  [1, '2017-07-26 09:36:42.000', 'John'],
  [2, '2017-07-26 09:36:42.123', 'Jane'],
];
const expected = [
  {
    id: 1,
    date: '2017-07-26 09:36:42',
    name: 'John',
  },
  {
    id: 2,
    date: '2017-07-26 09:36:42.123',
    name: 'Jane',
  },
];

let actualRows = null;

function executeTest(err) {
  assert.ifError(err);
  connection.execute(`SELECT * FROM \`${tableName}\``, (err, rows) => {
    assert.ifError(err);
    actualRows = rows;
    connection.end();
  });
}

connection.query(
  [
    `CREATE TEMPORARY TABLE \`${tableName}\` (`,
    ` \`${testFields[0]}\` int,`,
    ` \`${testFields[1]}\` TIMESTAMP(3),`,
    ` \`${testFields[2]}\` varchar(10)`,
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join(' '),
  (err) => {
    assert.ifError(err);
    connection.query(
      [
        `INSERT INTO \`${tableName}\` VALUES`,
        `(${testRows[0][0]},"${testRows[0][1]}", "${testRows[0][2]}"),`,
        `(${testRows[1][0]},"${testRows[1][1]}", "${testRows[1][2]}")`,
      ].join(' '),
      executeTest
    );
  }
);

process.on('exit', () => {
  console.log(actualRows);
  expected.map((exp, index) => {
    const row = actualRows[index];
    Object.keys(exp).map((key) => {
      assert.equal(exp[key], row[key]);
    });
  });
});
</file>

<file path="test/integration/regressions/test-#629.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection({
  dateStrings: false,
  timezone: 'Z',
});

const tableName = 'dates';
const testFields = ['id', 'date1', 'date2', 'name'];
const testRows = [
  [1, '2017-07-26 09:36:42.000', '2017-07-29 09:22:24.000', 'John'],
  [2, '2017-07-26 09:36:42.123', '2017-07-29 09:22:24.321', 'Jane'],
];
const expected = [
  {
    id: 1,
    date1: new Date('2017-07-26T09:36:42.000Z'),
    date2: new Date('2017-07-29T09:22:24.000Z'),
    name: 'John',
  },
  {
    id: 2,
    date1: new Date('2017-07-26T09:36:42.123Z'),
    date2: new Date('2017-07-29T09:22:24.321Z'),
    name: 'Jane',
  },
];

let actualRows = null;

function executeTest(err) {
  assert.ifError(err);
  connection.execute(`SELECT * FROM \`${tableName}\``, (err, rows) => {
    assert.ifError(err);
    actualRows = rows;
    connection.end();
  });
}

connection.query(
  [
    `CREATE TEMPORARY TABLE \`${tableName}\` (`,
    ` \`${testFields[0]}\` int,`,
    ` \`${testFields[1]}\` TIMESTAMP(3),`,
    ` \`${testFields[2]}\` DATETIME(3),`,
    ` \`${testFields[3]}\` varchar(10)`,
    ') ENGINE=InnoDB DEFAULT CHARSET=utf8',
  ].join(' '),
  (err) => {
    assert.ifError(err);
    connection.query(
      [
        `INSERT INTO \`${tableName}\` VALUES`,
        `(${testRows[0][0]},"${testRows[0][1]}", "${testRows[0][2]}", "${testRows[0][3]}"),`,
        `(${testRows[1][0]},"${testRows[1][1]}", "${testRows[1][2]}", "${testRows[1][3]}")`,
      ].join(' '),
      executeTest
    );
  }
);

process.on('exit', () => {
  expected.map((exp, index) => {
    const row = actualRows[index];
    Object.keys(exp).map((key) => {
      if (key.startsWith('date')) {
        assert.equal(+exp[key], +row[key]);
      } else {
        assert.equal(exp[key], row[key]);
      }
    });
  });
});
</file>

<file path="test/integration/regressions/test-#82.test.cjs">
'use strict';

const common = require('../../common.test.cjs');
const { assert } = require('poku');
const process = require('node:process');

const connection = common.createConnection();

const config = {
  table1: 'test82t1',
  table2: 'test82t2',
  view1: 'view82v1',
  view2: 'view82v2',
};
let results = null;

const prepareTestSet = function (cb) {
  connection.query(`drop table if exists ${config.table1}`);
  connection.query(`drop table if exists ${config.table2}`);
  connection.query(`drop view if exists ${config.view1}`);
  connection.query(`drop view if exists ${config.view2}`);
  connection.query(
    `create table ${config.table1} (name1 varchar(20), linkId1 integer(11))`
  );
  connection.query(
    `create table ${config.table2} (name2 varchar(20), linkId2 integer(11))`
  );
  connection.query(
    `insert into ${config.table1} (name1, linkId1) values ("A", 1),("B", 2),("C", 3),("D", 4)`
  );
  connection.query(
    `insert into ${config.table2} (name2, linkId2) values ("AA", 1),("BB", 2),("CC", 3),("DD", 4)`
  );
  connection.query(
    `create view ${config.view1} as select name1, linkId1, name2 from ${config.table1} INNER JOIN ${config.table2} ON linkId1 = linkId2`
  );
  connection.query(
    `create view ${config.view2} as select name1, name2 from ${config.view1}`,
    cb
  );
};

prepareTestSet((err) => {
  assert.ifError(err);
  connection.query(
    `select * from ${config.view2} order by name2 desc`,
    (err, rows) => {
      assert.ifError(err);
      results = rows;
      connection.end();
    }
  );
});

process.on('exit', () => {
  assert.equal(results[0].name1, 'D');
  assert.equal(results[1].name1, 'C');
  assert.equal(results[2].name1, 'B');
  assert.equal(results[3].name1, 'A');
  assert.equal(results[0].name2, 'DD');
  assert.equal(results[1].name2, 'CC');
  assert.equal(results[2].name2, 'BB');
  assert.equal(results[3].name2, 'AA');
});
</file>

<file path="test/integration/test-auth-switch-multi-factor.test.cjs">
// Copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const mysql = require('../../index.js');
const Command = require('../../lib/commands/command.js');
const Packets = require('../../lib/packets/index.js');
const { Buffer } = require('node:buffer');
const { assert } = require('poku');
const process = require('node:process');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

class TestAuthMultiFactor extends Command {
  constructor(args) {
    super();
    this.args = args;
    this.authFactor = 0;
  }

  start(_, connection) {
    const serverHelloPacket = new Packets.Handshake({
      // "required" properties
      serverVersion: 'node.js rocks',
      // the server should announce support for the
      // "MULTI_FACTOR_AUTHENTICATION" capability
      capabilityFlags: 0xdfffffff,
    });
    this.serverHello = serverHelloPacket;
    serverHelloPacket.setScrambleData(() => {
      connection.writePacket(serverHelloPacket.toPacket(0));
    });
    return TestAuthMultiFactor.prototype.sendAuthSwitchRequest;
  }

  sendAuthSwitchRequest(_, connection) {
    const asr = new Packets.AuthSwitchRequest(this.args[this.authFactor]);
    connection.writePacket(asr.toPacket());
    return TestAuthMultiFactor.prototype.sendAuthNextFactor;
  }

  sendAuthNextFactor(packet, connection) {
    const asr = Packets.AuthSwitchResponse.fromPacket(packet);
    assert.deepStrictEqual(
      asr.data.toString(),
      this.args[this.authFactor].pluginName
    );
    if (this.authFactor === 2) {
      // send OK_Packet after the 3rd authentication factor
      connection.writeOk();
      return TestAuthMultiFactor.prototype.dispatchCommands;
    }
    this.authFactor += 1;
    const anf = new Packets.AuthNextFactor(this.args[this.authFactor]);
    connection.writePacket(anf.toPacket(connection.serverConfig.encoding));
    return TestAuthMultiFactor.prototype.sendAuthNextFactor;
  }

  dispatchCommands(_, connection) {
    connection.end();
    return TestAuthMultiFactor.prototype.dispatchCommands;
  }
}

const server = mysql.createServer((conn) => {
  conn.serverConfig = {};
  conn.serverConfig.encoding = 'cesu8';
  conn.addCommand(
    new TestAuthMultiFactor([
      {
        // already covered by test-auth-switch
        pluginName: 'auth_test_plugin1',
        pluginData: Buffer.from('foo'),
      },
      {
        // 2nd factor auth plugin
        pluginName: 'auth_test_plugin2',
        pluginData: Buffer.from('bar'),
      },
      {
        // 3rd factor auth plugin
        pluginName: 'auth_test_plugin3',
        pluginData: Buffer.from('baz'),
      },
    ])
  );
});

const completed = [];

const portfinder = require('portfinder');
portfinder.getPort((_, port) => {
  server.listen(port);
  const conn = mysql.createConnection({
    port: port,
    password: 'secret1',
    password2: 'secret2',
    password3: 'secret3',
    authPlugins: {
      auth_test_plugin1() {
        return () => {
          const pluginName = 'auth_test_plugin1';
          completed.push(pluginName);

          return Buffer.from(pluginName);
        };
      },
      auth_test_plugin2(options) {
        return () => {
          if (
            options.connection.config.password !==
            options.connection.config.password2
          ) {
            return assert.fail('Incorrect authentication factor password.');
          }

          const pluginName = 'auth_test_plugin2';
          completed.push(pluginName);

          return Buffer.from(pluginName);
        };
      },
      auth_test_plugin3(options) {
        return () => {
          if (
            options.connection.config.password !==
            options.connection.config.password3
          ) {
            return assert.fail('Incorrect authentication factor password.');
          }

          const pluginName = 'auth_test_plugin3';
          completed.push(pluginName);

          return Buffer.from(pluginName);
        };
      },
    },
  });

  conn.on('connect', () => {
    assert.deepStrictEqual(completed, [
      'auth_test_plugin1',
      'auth_test_plugin2',
      'auth_test_plugin3',
    ]);

    conn.end();
    server.close();
  });
});
</file>

<file path="test/integration/test-auth-switch-plugin-async-error.test.cjs">
// Copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const mysql = require('../../index.js');
const Command = require('../../lib/commands/command.js');
const Packets = require('../../lib/packets/index.js');
const { Buffer } = require('node:buffer');
const assert = require('node:assert');
const process = require('node:process');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

class TestAuthSwitchPluginError extends Command {
  constructor(args) {
    super();
    this.args = args;
  }

  start(_, connection) {
    const serverHelloPacket = new Packets.Handshake({
      // "required" properties
      protocolVersion: 10,
      serverVersion: 'node.js rocks',
    });
    this.serverHello = serverHelloPacket;
    serverHelloPacket.setScrambleData(() => {
      connection.writePacket(serverHelloPacket.toPacket(0));
    });
    return TestAuthSwitchPluginError.prototype.sendAuthSwitchRequest;
  }

  sendAuthSwitchRequest(_, connection) {
    const asr = new Packets.AuthSwitchRequest(this.args);
    connection.writePacket(asr.toPacket());
    return TestAuthSwitchPluginError.prototype.finish;
  }

  finish(_, connection) {
    connection.end();
    return TestAuthSwitchPluginError.prototype.finish;
  }
}

const server = mysql.createServer((conn) => {
  conn.addCommand(
    new TestAuthSwitchPluginError({
      pluginName: 'auth_test_plugin',
      pluginData: Buffer.allocUnsafe(0),
    })
  );
});

let error;
let uncaughtExceptions = 0;

const portfinder = require('portfinder');
portfinder.getPort((_, port) => {
  server.listen(port);
  const conn = mysql.createConnection({
    port: port,
    authPlugins: {
      auth_test_plugin() {
        return function () {
          return Promise.reject(Error('boom'));
        };
      },
    },
  });

  conn.on('error', (err) => {
    error = err;

    conn.end();
    server.close();
  });
});

process.on('uncaughtException', (err) => {
  // The plugin reports a fatal error
  assert.equal(error.code, 'AUTH_SWITCH_PLUGIN_ERROR');
  assert.equal(error.message, 'boom');
  assert.equal(error.fatal, true);
  // The server must close the connection
  assert.equal(err.code, 'PROTOCOL_CONNECTION_LOST');

  uncaughtExceptions += 1;
});

process.on('exit', () => {
  assert.equal(uncaughtExceptions, 1);
});
</file>

<file path="test/integration/test-auth-switch-plugin-error.test.cjs">
// Copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const mysql = require('../../index.js');
const Command = require('../../lib/commands/command.js');
const Packets = require('../../lib/packets/index.js');
const { Buffer } = require('node:buffer');
const assert = require('node:assert');
const process = require('node:process');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

class TestAuthSwitchPluginError extends Command {
  constructor(args) {
    super();
    this.args = args;
  }

  start(_, connection) {
    const serverHelloPacket = new Packets.Handshake({
      // "required" properties
      protocolVersion: 10,
      serverVersion: 'node.js rocks',
    });
    this.serverHello = serverHelloPacket;
    serverHelloPacket.setScrambleData(() => {
      connection.writePacket(serverHelloPacket.toPacket(0));
    });
    return TestAuthSwitchPluginError.prototype.sendAuthSwitchRequest;
  }

  sendAuthSwitchRequest(_, connection) {
    const asr = new Packets.AuthSwitchRequest(this.args);
    connection.writePacket(asr.toPacket());
    return TestAuthSwitchPluginError.prototype.finish;
  }

  finish(_, connection) {
    connection.end();
    return TestAuthSwitchPluginError.prototype.finish;
  }
}

const server = mysql.createServer((conn) => {
  conn.addCommand(
    new TestAuthSwitchPluginError({
      pluginName: 'auth_test_plugin',
      pluginData: Buffer.allocUnsafe(0),
    })
  );
});

let error;
let uncaughtExceptions = 0;

const portfinder = require('portfinder');
portfinder.getPort((_, port) => {
  server.listen(port);
  const conn = mysql.createConnection({
    port: port,
    authPlugins: {
      auth_test_plugin: () => {
        throw new Error('boom');
      },
    },
  });

  conn.on('error', (err) => {
    error = err;

    conn.end();
    server.close();
  });
});

process.on('uncaughtException', (err) => {
  // The plugin reports a fatal error
  assert.equal(error.code, 'AUTH_SWITCH_PLUGIN_ERROR');
  assert.equal(error.message, 'boom');
  assert.equal(error.fatal, true);
  // The server must close the connection
  assert.equal(err.code, 'PROTOCOL_CONNECTION_LOST');

  uncaughtExceptions += 1;
});

process.on('exit', () => {
  assert.equal(uncaughtExceptions, 1);
});
</file>

<file path="test/integration/test-auth-switch.test.cjs">
'use strict';

const mysql = require('../../index.js');
const Command = require('../../lib/commands/command.js');
const Packets = require('../../lib/packets/index.js');
const { version } = require('../../package.json');
const { Buffer } = require('node:buffer');
const { assert } = require('poku');
const process = require('node:process');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

const connectAttributes = { foo: 'bar', baz: 'foo' };

const defaultConnectAttributes = {
  _client_name: 'Node-MySQL-2',
  _client_version: version,
};

let count = 0;

class TestAuthSwitchHandshake extends Command {
  constructor(args) {
    super();
    this.args = args;
  }

  start(packet, connection) {
    const serverHelloPacket = new Packets.Handshake({
      protocolVersion: 10,
      serverVersion: 'node.js rocks',
      connectionId: 1234,
      statusFlags: 2,
      characterSet: 8,
      capabilityFlags: 0xffffff,
    });
    this.serverHello = serverHelloPacket;
    serverHelloPacket.setScrambleData(() => {
      connection.writePacket(serverHelloPacket.toPacket(0));
    });
    return TestAuthSwitchHandshake.prototype.readClientReply;
  }

  readClientReply(packet, connection) {
    const clientHelloReply = Packets.HandshakeResponse.fromPacket(packet);
    assert.equal(clientHelloReply.user, 'test_user');
    assert.equal(clientHelloReply.database, 'test_database');
    assert.equal(clientHelloReply.authPluginName, 'mysql_native_password');
    assert.deepEqual(clientHelloReply.connectAttributes, {
      ...connectAttributes,
      ...defaultConnectAttributes,
    });
    const asr = new Packets.AuthSwitchRequest(this.args);
    connection.writePacket(asr.toPacket());
    return TestAuthSwitchHandshake.prototype.readClientAuthSwitchResponse;
  }

  readClientAuthSwitchResponse(packet, connection) {
    Packets.AuthSwitchResponse.fromPacket(packet);
    count++;
    if (count < 10) {
      const asrmd = new Packets.AuthSwitchRequestMoreData(
        Buffer.from(`hahaha ${count}`)
      );
      connection.writePacket(asrmd.toPacket());
      return TestAuthSwitchHandshake.prototype.readClientAuthSwitchResponse;
    }
    connection.writeOk();
    return TestAuthSwitchHandshake.prototype.dispatchCommands;
  }

  dispatchCommands(packet, connection) {
    // Quit command here
    // TODO: assert it's actually Quit
    connection.end();
    return TestAuthSwitchHandshake.prototype.dispatchCommands;
  }
}

const server = mysql.createServer((conn) => {
  conn.serverConfig = {};
  conn.serverConfig.encoding = 'cesu8';
  conn.addCommand(
    new TestAuthSwitchHandshake({
      pluginName: 'auth_test_plugin',
      pluginData: Buffer.from('f{tU-{K@BhfHt/-4^Z,'),
    })
  );
});

// REVIEW: Unused var

const portfinder = require('portfinder');
portfinder.getPort((err, port) => {
  const makeSwitchHandler = function () {
    let count = 0;
    return function (data, cb) {
      if (count === 0) {
        assert.equal(data.pluginName, 'auth_test_plugin');
      } else {
        assert.equal(data.pluginData.toString(), `hahaha ${count}`);
      }

      count++;
      cb(null, `some data back${count}`);
    };
  };

  server.listen(port);
  const conn = mysql.createConnection({
    user: 'test_user',
    password: 'test',
    database: 'test_database',
    port: port,
    authSwitchHandler: makeSwitchHandler(),
    connectAttributes: connectAttributes,
  });

  conn.on('connect', (data) => {
    assert.equal(data.serverVersion, 'node.js rocks');
    assert.equal(data.connectionId, 1234);

    conn.end();
    server.close();
  });
});
</file>

<file path="test/integration/test-handshake-unknown-packet-error.test.cjs">
// Copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const mysql = require('../../index.js');
const Command = require('../../lib/commands/command.js');
const Packet = require('../../lib/packets/packet.js');
const Packets = require('../../lib/packets/index.js');
const { Buffer } = require('node:buffer');
const assert = require('node:assert');
const process = require('node:process');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

class TestUnknownHandshakePacket extends Command {
  constructor(args) {
    super();
    this.args = args;
  }

  start(_, connection) {
    const serverHelloPacket = new Packets.Handshake({
      // "required" properties
      protocolVersion: 10,
      serverVersion: 'node.js rocks',
    });
    this.serverHello = serverHelloPacket;
    serverHelloPacket.setScrambleData(() => {
      connection.writePacket(serverHelloPacket.toPacket(0));
    });
    return TestUnknownHandshakePacket.prototype.writeUnexpectedPacket;
  }

  writeUnexpectedPacket(_, connection) {
    const length = 6 + this.args.length;
    const buffer = Buffer.allocUnsafe(length);
    const up = new Packet(0, buffer, 0, length);
    up.offset = 4;
    up.writeInt8(0xfd);
    up.writeBuffer(this.args);
    connection.writePacket(up);
    return TestUnknownHandshakePacket.prototype.finish;
  }

  finish(_, connection) {
    connection.end();
    return TestUnknownHandshakePacket.prototype.finish;
  }
}

const server = mysql.createServer((conn) => {
  conn.addCommand(new TestUnknownHandshakePacket(Buffer.alloc(0)));
});

let error;
let uncaughtExceptions = 0;

const portfinder = require('portfinder');
portfinder.getPort((_, port) => {
  server.listen(port);
  const conn = mysql.createConnection({
    port: port,
  });

  conn.on('error', (err) => {
    error = err;

    conn.end();
    server.close();
  });
});

process.on('uncaughtException', (err) => {
  // The plugin reports a fatal error
  assert.equal(error.code, 'HANDSHAKE_UNKNOWN_ERROR');
  assert.equal(error.message, 'Unexpected packet during handshake phase');
  assert.equal(error.fatal, true);
  // The server must close the connection
  assert.equal(err.code, 'PROTOCOL_CONNECTION_LOST');

  uncaughtExceptions += 1;
});

process.on('exit', () => {
  assert.equal(uncaughtExceptions, 1);
});
</file>

<file path="test/integration/test-multi-result-streaming.test.cjs">
'use strict';

const { assert } = require('poku');
const { createConnection } = require('../common.test.cjs');

(async () => {
  const conn = createConnection({ multipleStatements: true });
  const captured1 = [];
  const captured2 = [];
  const sql1 =
    'select * from information_schema.columns order by table_schema, table_name, column_name limit 1;';
  const sql2 =
    'select * from information_schema.columns order by table_schema, table_name, ordinal_position limit 1;';

  await conn.promise().query('set global max_allowed_packet=524288000');

  const compare1 = await conn.promise().query(sql1);
  const compare2 = await conn.promise().query(sql2);

  if (!compare1 || compare1.length < 1) {
    assert.fail('no results for comparison 1');
  }
  if (!compare2 || compare2.length < 1) {
    assert.fail('no results for comparison 2');
  }

  const stream = conn.query(`${sql1}\n${sql2}`).stream();
  stream.on('result', (row, datasetIndex) => {
    if (datasetIndex === 0) {
      captured1.push(row);
    } else {
      captured2.push(row);
    }
  });
  // note: this is very important:
  // after each result set is complete,
  // the stream will emit "readable" and if we don't
  // read then 'end' won't be emitted and the
  // test will hang.
  stream.on('readable', () => {
    stream.read();
  });

  await new Promise((resolve, reject) => {
    stream.on('error', (e) => reject(e));
    stream.on('end', () => resolve());
  });

  assert.equal(captured1.length, 1);
  assert.equal(captured2.length, 1);
  assert.deepEqual(captured1[0], compare1[0][0]);
  assert.deepEqual(captured2[0], compare2[0][0]);

  conn.end();
})();
</file>

<file path="test/integration/test-pool-connect-error.test.cjs">
'use strict';

const mysql = require('../../index.js');
const { assert } = require('poku');
const process = require('node:process');
const portfinder = require('portfinder');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

const server = mysql.createServer((conn) => {
  conn.serverHandshake({
    protocolVersion: 10,
    serverVersion: '5.6.10',
    connectionId: 1234,
    statusFlags: 2,
    characterSet: 8,
    capabilityFlags: 0xffffff,
    authCallback: function (params, cb) {
      cb(null, { message: 'too many connections', code: 1040 });
    },
  });
});

let err1, err2;

portfinder.getPort((err, port) => {
  server.listen(port);
  const conn = mysql.createConnection({
    user: 'test_user',
    password: 'test',
    database: 'test_database',
    port: port,
  });
  conn.on('error', (err) => {
    err1 = err;
  });

  const pool = mysql.createPool({
    user: 'test_user',
    password: 'test',
    database: 'test_database',
    port: port,
  });

  pool.query('test sql', (err) => {
    err2 = err;
    pool.end();
    server.close();
  });
});

process.on('exit', () => {
  assert.equal(err1.errno, 1040);
  assert.equal(err2.errno, 1040);
});
</file>

<file path="test/integration/test-pool-disconnect.test.cjs">
'use strict';

const { assert } = require('poku');
const mysql = require('../common.test.cjs');
const process = require('node:process');

// planetscale does not support KILL, skipping this test
// https://planetscale.com/docs/reference/mysql-compatibility
if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test, planetscale does not support KILL');
  process.exit(0);
}

const pool = mysql.createPool();
const conn = mysql.createConnection({ multipleStatements: true });
pool.config.connectionLimit = 5;

const numSelectToPerform = 10;
const tids = [];
let numSelects = 0;
let killCount = 0;

function kill() {
  setTimeout(() => {
    const id = tids.shift();
    if (typeof id !== 'undefined') {
      // sleep required to give mysql time to close connection,
      // and callback called after connection with id is really closed
      conn.query('kill ?; select sleep(0.05)', [id], (err) => {
        assert.ifError(err);
        killCount++;
        // TODO: this assertion needs to be fixed, after kill
        // connection is removed from _allConnections but not at a point this callback is called
        //
        // assert.equal(pool._allConnections.length, tids.length);
      });
    } else {
      conn.end();
      pool.end();
    }
  }, 5);
}

pool.on('connection', (conn) => {
  tids.push(conn.threadId);
  conn.on('error', () => {
    setTimeout(kill, 5);
  });
});

for (let i = 0; i < numSelectToPerform; i++) {
  pool.query('select 1 as value', (err, rows) => {
    numSelects++;
    assert.ifError(err);
    assert.equal(rows[0].value, 1);

    // after all queries complete start killing connections
    if (numSelects === numSelectToPerform) {
      kill();
    }
  });
}

process.on('exit', () => {
  assert.equal(numSelects, numSelectToPerform);
  assert.equal(killCount, pool.config.connectionLimit);
});
</file>

<file path="test/integration/test-pool-end.test.cjs">
'use strict';

const { createPool } = require('../common.test.cjs');
const { assert } = require('poku');

const pool = createPool();

pool.getConnection((err, conn) => {
  assert.ifError(err);

  assert(pool._allConnections.length === 1);
  assert(pool._freeConnections.length === 0);

  // emit the end event, so the connection gets removed from the pool
  conn.stream.emit('end');

  assert(pool._allConnections.length === 0);
  assert(pool._freeConnections.length === 0);

  // As the connection has not really ended we need to do this ourselves
  conn.destroy();
});
</file>

<file path="test/integration/test-pool-release-idle-connection-replicate.test.cjs">
'use strict';
const createPool = require('../common.test.cjs').createPool;
const { assert } = require('poku');

/**
 * This test case tests the scenario where released connections are not
 * being destroyed after the idle timeout has passed, to do this we setup
 * a pool with a connection limit of 3, and a max idle of 2, and an idle
 * timeout of 1 second. We then create 3 connections, and release them
 * after 1 second, we then check that the pool has 0 connections, and 0
 * free connections.
 *
 * @see https://github.com/sidorares/node-mysql2/issues/3020
 */

/**
 * This test case
 */
const pool = new createPool({
  connectionLimit: 3,
  maxIdle: 2,
  idleTimeout: 1000,
});

/**
 * Create the first connection and ensure it's in the pool as expected
 */
pool.getConnection((err1, connection1) => {
  assert.ifError(err1);
  assert.ok(connection1);

  /**
   * Create the second connection and ensure it's in the pool as expected
   */
  pool.getConnection((err2, connection2) => {
    assert.ifError(err2);
    assert.ok(connection2);

    /**
     * Create the third connection and ensure it's in the pool as expected
     */
    pool.getConnection((err3, connection3) => {
      assert.ifError(err3);
      assert.ok(connection3);

      /**
       * Release all the connections
       */
      connection1.release();
      connection2.release();
      connection3.release();

      /**
       * After the idle timeout has passed, check that all items in the in the pool
       * that have been released are destroyed as expected.
       */
      setTimeout(() => {
        assert(
          pool._allConnections.length === 0,
          `Expected all connections to be closed, but found ${pool._allConnections.length}`
        );
        assert(
          pool._freeConnections.length === 0,
          `Expected all free connections to be closed, but found ${pool._freeConnections.length}`
        );

        pool.end();
      }, 5000);
    });
  });
});
</file>

<file path="test/integration/test-pool-release-idle-connection-timeout.test.cjs">
'use strict';

const createPool = require('../common.test.cjs').createPool;
const { assert } = require('poku');

const pool = new createPool({
  connectionLimit: 3, // 5 connections
  maxIdle: 1, // 1 idle connection
  idleTimeout: 1000, // remove idle connections after 1 second
});

pool.getConnection((err1, connection1) => {
  assert.ifError(err1);
  assert.ok(connection1);
  pool.getConnection((err2, connection2) => {
    assert.ifError(err2);
    assert.ok(connection2);
    assert.notStrictEqual(connection1, connection2);
    pool.getConnection((err3, connection3) => {
      assert.ifError(err3);
      assert.ok(connection3);
      assert.notStrictEqual(connection1, connection3);
      assert.notStrictEqual(connection2, connection3);
      connection1.release();
      connection2.release();
      connection3.release();
      assert(pool._allConnections.length === 3);
      assert(pool._freeConnections.length === 3);
      // after two seconds, the above 3 connection should have been destroyed
      setTimeout(() => {
        assert(pool._allConnections.length === 0);
        assert(pool._freeConnections.length === 0);
        // Creating a new connection should create a fresh one
        pool.getConnection((err4, connection4) => {
          assert.ifError(err4);
          assert.ok(connection4);
          assert(pool._allConnections.length === 1);
          assert(pool._freeConnections.length === 0);
          connection4.release();
          connection4.destroy();
          pool.end();
        });
      }, 2000);
    });
  });
});
</file>

<file path="test/integration/test-pool-release-idle-connection.test.cjs">
'use strict';

const createPool = require('../common.test.cjs').createPool;
const { assert } = require('poku');

const pool = new createPool({
  connectionLimit: 5, // 5 connections
  maxIdle: 1, // 1 idle connection
  idleTimeout: 5000, // 5 seconds
});

pool.getConnection((err1, connection1) => {
  assert.ifError(err1);
  assert.ok(connection1);
  pool.getConnection((err2, connection2) => {
    assert.ifError(err2);
    assert.ok(connection2);
    assert.notStrictEqual(connection1, connection2);
    pool.getConnection((err3, connection3) => {
      assert.ifError(err3);
      assert.ok(connection3);
      assert.notStrictEqual(connection1, connection3);
      assert.notStrictEqual(connection2, connection3);
      connection1.release();
      connection2.release();
      connection3.release();
      assert(pool._allConnections.length === 3);
      assert(pool._freeConnections.length === 3);
      setTimeout(() => {
        assert(pool._allConnections.length === 1);
        assert(pool._freeConnections.length === 1);
        pool.getConnection((err4, connection4) => {
          assert.ifError(err4);
          assert.ok(connection4);
          assert.strictEqual(connection3, connection4);
          assert(pool._allConnections.length === 1);
          assert(pool._freeConnections.length === 0);
          connection4.release();
          connection4.destroy();
          pool.end();
        });
        // Setting the time to a lower value than idleTimeout will ensure that the connection is not considered idle
        // during our assertions
      }, 4000);
    });
  });
});
</file>

<file path="test/integration/test-pool-release.test.cjs">
'use strict';

const createPool = require('../common.test.cjs').createPool;
const { assert } = require('poku');

const pool = createPool({
  idleTimeout: 15000,
});

pool.query('test sql', () => {
  pool.query('test sql', [], () => {
    pool.query('test sql', [], () => {
      pool.query('test sql', [], () => {
        pool.query('test sql', () => {
          pool.query('test sql').on('error', () => {
            pool.query('test sql', () => {
              pool.execute('test sql', () => {
                pool.execute('test sql', () => {
                  pool.execute('test sql', [], () => {
                    pool.execute('test sql', () => {
                      pool.execute('test sql', () => {
                        // TODO change order events are fires so that connection is released before callback
                        // that way this number will be more deterministic
                        assert(pool._allConnections.length < 3);
                        // on some setups with small CLIENT_INTERACTION_TIMEOUT value connection might be closed by the time we get here, hence "one or zero"
                        assert(pool._freeConnections.length <= 1);
                        assert(pool._connectionQueue.length === 0);
                        pool.end();
                      });
                    });
                  });
                });
              });
            });
          });
        });
      });
    });
  });
});
</file>

<file path="test/integration/test-rows-as-array.test.cjs">
'use strict';

const createConnection = require('../common.test.cjs').createConnection;
const { assert } = require('poku');

// enabled in initial config, disable in some tets
const c = createConnection({ rowsAsArray: true });
c.query('select 1+1 as a', (err, rows) => {
  assert.ifError(err);
  assert.equal(rows[0][0], 2);
});

c.query({ sql: 'select 1+2 as a', rowsAsArray: false }, (err, rows) => {
  assert.ifError(err);
  assert.equal(rows[0].a, 3);
});

c.execute('select 1+1 as a', (err, rows) => {
  assert.ifError(err);
  assert.equal(rows[0][0], 2);
});

c.execute({ sql: 'select 1+2 as a', rowsAsArray: false }, (err, rows) => {
  assert.ifError(err);
  assert.equal(rows[0].a, 3);
  c.end();
});

// disabled in initial config, enable in some tets
const c1 = createConnection({ rowsAsArray: false });
c1.query('select 1+1 as a', (err, rows) => {
  assert.ifError(err);
  assert.equal(rows[0].a, 2);
});

c1.query({ sql: 'select 1+2 as a', rowsAsArray: true }, (err, rows) => {
  assert.ifError(err);
  assert.equal(rows[0][0], 3);
});

c1.execute('select 1+1 as a', (err, rows) => {
  assert.ifError(err);
  assert.equal(rows[0].a, 2);
});

c1.execute({ sql: 'select 1+2 as a', rowsAsArray: true }, (err, rows) => {
  assert.ifError(err);
  assert.equal(rows[0][0], 3);
  c1.end();
});
</file>

<file path="test/integration/test-server-close.test.cjs">
// Copyright (c) 2021, Oracle and/or its affiliates.

'use strict';

const errors = require('../../lib/constants/errors.js');
const common = require('../common.test.cjs');
const assert = require('node:assert');
const process = require('node:process');

if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

// Uncaught AssertionError: Connection lost: The server closed the connection. == The client was disconnected by the server because of inactivity. See wait_timeout and interactive_timeout for configuring this behavior.
if (typeof Deno !== 'undefined') process.exit(0);

const connection = common.createConnection();

const customWaitTimeout = 1; // seconds

let error;

connection.on('error', (err) => {
  error = err;

  connection.close();
});

connection.query(`set wait_timeout=${customWaitTimeout}`, () => {
  setTimeout(() => {}, customWaitTimeout * 1000 * 2);
});

process.on('uncaughtException', (err) => {
  // The ERR Packet is only sent by MySQL server 8.0.24 or higher, so we
  // need to account for the fact it is not sent by older server versions.
  if (err.code !== 'ERR_ASSERTION') {
    throw err;
  }

  assert.equal(
    error.message,
    'Connection lost: The server closed the connection.'
  );
  assert.equal(error.code, 'PROTOCOL_CONNECTION_LOST');
});

process.on('exit', () => {
  assert.equal(
    error.message,
    'The client was disconnected by the server because of inactivity. See wait_timeout and interactive_timeout for configuring this behavior.'
  );
  assert.equal(error.code, errors.ER_CLIENT_INTERACTION_TIMEOUT);
});
</file>

<file path="test/tsc-build/helpers.test.ts">
import { mysql, mysqlp } from './index.test.js';

export const isResultSetHeader = (
  data: unknown
): data is mysql.ResultSetHeader | mysqlp.ResultSetHeader => {
  if (!data || typeof data !== 'object') return false;

  const keys = [
    'fieldCount',
    'affectedRows',
    'insertId',
    'info',
    'serverStatus',
    'warningStatus',
  ];

  return keys.every((key) => key in data);
};

export const isOkPacket = (
  data: unknown
): data is mysql.OkPacket | mysqlp.OkPacket => {
  if (!data || typeof data !== 'object') return false;

  const keys = [
    'fieldCount',
    'affectedRows',
    'changedRows',
    'insertId',
    'serverStatus',
    'warningCount',
    'message',
    'protocol41',
  ];

  return keys.every((key) => key in data);
};
</file>

<file path="test/tsc-build/index.test.ts">
/**
 * This tests doesn't execute the scripts or connect in any database.
 * It only compiles all typings in the project and ensures that the compilation will be successful.
 * To test it, run: npm run test:tsc-build
 *
 * The purpose of this test is to prevent changes that break the typings in new PRs
 *
 * Contributions:
 *
 * For mysql build tests:           './mysql/...'
 * For mysql/promise build tests:   './promise/...'
 */

import mysql from '../../index.js';
import mysqlp from '../../promise.js';

export { mysql, mysqlp };
</file>

<file path="test/tsc-build/mysql/baseConnection.test.ts">
import { mysql } from '../index.test.js';

export const access: mysql.ConnectionOptions = {
  host: '',
  user: '',
  password: '',
  database: '',
};

export const uriAccess = `mysql://${access.host}:${access.password}@${access.host}:${access.port}/${access.database}`;

/** The SQL for the query */
export const sql = 'SELECT * FROM `table`';

/** The SQL for the query with prepared statements */
export const sqlPS = 'SELECT * FROM `table` WHERE `id` = ?';

/** The values for the query with prepared statements */
export const values = [1];
</file>

<file path="test/tsc-build/mysql/constants/Charsets.test.ts">
import { mysql } from '../../index.test.js';

const BIG5_CHINESE_CI: number = mysql.Charsets.BIG5_CHINESE_CI;
const BIG5: number = mysql.Charsets.BIG5;

console.log(BIG5_CHINESE_CI, BIG5);
</file>

<file path="test/tsc-build/mysql/constants/CharsetToEncoding.test.ts">
import { mysql } from '../../index.test.js';

const charsetToEncoding: string[] = mysql.CharsetToEncoding;
const utf8: string = charsetToEncoding[0];

console.log(utf8, charsetToEncoding);
</file>

<file path="test/tsc-build/mysql/constants/Types.test.ts">
import { mysql } from '../../index.test.js';

const BLOB: number = mysql.Types.BLOB;
const DECIMAL: string = mysql.Types[0x00];
const DOUBLE: string = mysql.Types[5];

console.log(BLOB, DECIMAL, DOUBLE);
</file>

<file path="test/tsc-build/mysql/createConnection/callbacks/execute.test.ts">
import { mysql } from '../../../index.test.js';
import { access, sql, sqlPS, values } from '../../baseConnection.test.js';

{
  const db = mysql.createConnection(access);

  /** Overload: execute(sql, () => {}}) */
  db.execute(sql, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(sql, values, () => {}}) */
  db.execute(sqlPS, values, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(QueryOptions, () => {}}) I */
  db.execute({ sql }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(QueryOptions, () => {}}) II */
  db.execute({ sql: sqlPS, values }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(QueryOptions, values, () => {}}) */
  db.execute({ sql: sqlPS }, values, (err, result, fields) => {
    console.log(err, result, fields);
  });
}
</file>

<file path="test/tsc-build/mysql/createConnection/callbacks/query.test.ts">
import { mysql } from '../../../index.test.js';
import { access, sql, sqlPS, values } from '../../baseConnection.test.js';

{
  const db = mysql.createConnection(access);

  /** Overload: query(sql, () => {}}) */
  db.query(sql, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(sql, values, () => {}}) */
  db.query(sqlPS, values, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(QueryOptions, () => {}}) I */
  db.query({ sql }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(QueryOptions, () => {}}) II */
  db.query({ sql: sqlPS, values }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(QueryOptions, values, () => {}}) */
  db.query({ sql: sqlPS }, values, (err, result, fields) => {
    console.log(err, result, fields);
  });
}
</file>

<file path="test/tsc-build/mysql/createConnection/promise/execute.test.ts">
import { mysql } from '../../../index.test.js';
import { access, sql, sqlPS, values } from '../../baseConnection.test.js';

(async () => {
  const db = mysql.createConnection(access).promise();

  {
    /** Overload: execute(sql) */
    const [results, fields] = await db.execute(sql);
    console.log(results, fields);
  }

  {
    /** Overload: execute(sql, values) */
    const [results, fields] = await db.execute(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) I */
    const [results, fields] = await db.execute({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) II */
    const [results, fields] = await db.execute({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions, values) */
    const [results, fields] = await db.execute({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  await db.end();
})();
</file>

<file path="test/tsc-build/mysql/createConnection/promise/query.test.ts">
import { mysql } from '../../../index.test.js';
import { access, sql, sqlPS, values } from '../../baseConnection.test.js';

(async () => {
  const db = mysql.createConnection(access).promise();

  {
    /** Overload: query(sql) */
    const [results, fields] = await db.query(sql);
    console.log(results, fields);
  }

  {
    /** Overload: query(sql, values) */
    const [results, fields] = await db.query(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) I */
    const [results, fields] = await db.query({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) II */
    const [results, fields] = await db.query({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions, values) */
    const [results, fields] = await db.query({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  await db.end();
})();
</file>

<file path="test/tsc-build/mysql/createPool/callbacks/connection.test.ts">
import { mysql } from '../../../index.test.js';
import { access } from '../../baseConnection.test.js';

const pool = mysql.createPool(access);

pool.getConnection((_err, conn) => {
  conn.connection;

  try {
    // @ts-expect-error: The pool can't be a connection itself
    pool.connection;
  } catch (err) {
    console.log('This error is expected', err);
  }
});
</file>

<file path="test/tsc-build/mysql/createPool/callbacks/createPool.test.ts">
import { mysql } from '../../../index.test.js';
import { uriAccess, access } from '../../baseConnection.test.js';

(() => {
  let uriPool: mysql.Pool | null = null;
  let pool: mysql.Pool | null = null;

  if (uriPool === null || pool === null) return;

  uriPool = mysql.createPool(uriAccess);
  pool = mysql.createPool(access);
})();
</file>

<file path="test/tsc-build/mysql/createPool/callbacks/execute.test.ts">
import { mysql } from '../../../index.test.js';
import { access, sql, sqlPS, values } from '../../baseConnection.test.js';

{
  const db = mysql.createPool(access);

  /** Overload: execute(sql, () => {}}) */
  db.execute(sql, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(sql, values, () => {}}) */
  db.execute(sqlPS, values, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(QueryOptions, () => {}}) I */
  db.execute({ sql }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(QueryOptions, () => {}}) II */
  db.execute({ sql: sqlPS, values }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(QueryOptions, values, () => {}}) */
  db.execute({ sql: sqlPS }, values, (err, result, fields) => {
    console.log(err, result, fields);
  });
}

/** getConnection and query */
{
  mysql.createPool(access).getConnection((_err, connection) => {
    /** Overload: execute(sql, () => {}}) */
    connection.execute(sql, (err, result, fields) => {
      console.log(err, result, fields);
    });

    /** Overload: execute(sql, values, () => {}}) */
    connection.execute(sqlPS, values, (err, result, fields) => {
      console.log(err, result, fields);
    });

    /** Overload: execute(QueryOptions, () => {}}) I */
    connection.execute({ sql }, (err, result, fields) => {
      console.log(err, result, fields);
    });

    /** Overload: execute(QueryOptions, () => {}}) II */
    connection.execute({ sql: sqlPS, values }, (err, result, fields) => {
      console.log(err, result, fields);
    });

    /** Overload: execute(QueryOptions, values, () => {}}) */
    connection.execute({ sql: sqlPS }, values, (err, result, fields) => {
      console.log(err, result, fields);
    });
  });
}
</file>

<file path="test/tsc-build/mysql/createPool/callbacks/getConnection.test.ts">
import { mysql } from '../../../index.test.js';
import { access } from '../../baseConnection.test.js';

const pool = mysql.createPool(access);

pool.getConnection((_err, conn) => {
  try {
    // @ts-expect-error: The connection can't get another connection
    conn.getConnection();
  } catch (err) {
    console.log('This error is expected', err);
  }
});
</file>

<file path="test/tsc-build/mysql/createPool/callbacks/query.test.ts">
import { mysql } from '../../../index.test.js';
import { access, sql, sqlPS, values } from '../../baseConnection.test.js';

{
  const db = mysql.createPool(access);

  /** Overload: query(sql, () => {}}) */
  db.query(sql, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(sql, values, () => {}}) */
  db.query(sqlPS, values, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(QueryOptions, () => {}}) I */
  db.query({ sql }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(QueryOptions, () => {}}) II */
  db.query({ sql: sqlPS, values }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(QueryOptions, values, () => {}}) */
  db.query({ sql: sqlPS }, values, (err, result, fields) => {
    console.log(err, result, fields);
  });
}

/** getConnection */
{
  mysql.createPool(access).getConnection((_err, connection) => {
    /** Overload: query(sql, () => {}}) */
    connection.query(sql, (err, result, fields) => {
      console.log(err, result, fields);
    });

    /** Overload: query(sql, values, () => {}}) */
    connection.query(sqlPS, values, (err, result, fields) => {
      console.log(err, result, fields);
    });

    /** Overload: query(QueryOptions, () => {}}) I */
    connection.query({ sql }, (err, result, fields) => {
      console.log(err, result, fields);
    });

    /** Overload: query(QueryOptions, () => {}}) II */
    connection.query({ sql: sqlPS, values }, (err, result, fields) => {
      console.log(err, result, fields);
    });

    /** Overload: query(QueryOptions, values, () => {}}) */
    connection.query({ sql: sqlPS }, values, (err, result, fields) => {
      console.log(err, result, fields);
    });
  });
}
</file>

<file path="test/tsc-build/mysql/createPool/callbacks/release.test.ts">
import { mysql } from '../../../index.test.js';
import { access } from '../../baseConnection.test.js';

const pool = mysql.createPool(access);

pool.getConnection((_err, conn) => {
  conn.release();

  try {
    // @ts-expect-error: The pool isn't a connection itself, so it doesn't have the connection methods
    pool.release();
  } catch (err) {
    console.log('This error is expected', err);
  }
});
</file>

<file path="test/tsc-build/mysql/createPool/callbacks/releaseConnection.test.ts">
import { mysql } from '../../../index.test.js';
import { access } from '../../baseConnection.test.js';

const pool = mysql.createPool(access);

pool.getConnection((_err, conn) => {
  pool.releaseConnection(conn);
});
</file>

<file path="test/tsc-build/mysql/createPool/promise/connection.test.ts">
import { mysql } from '../../../index.test.js';
import { access } from '../../baseConnection.test.js';

(async () => {
  const pool = mysql.createPool(access);
  const conn = await pool.promise().getConnection();

  conn.connection;

  try {
    // @ts-expect-error: The pool can't be a connection itself
    pool.connection;
  } catch (err) {
    console.log('This error is expected', err);
  }
})();
</file>

<file path="test/tsc-build/mysql/createPool/promise/execute.test.ts">
import { mysql } from '../../../index.test.js';
import { access, sql, sqlPS, values } from '../../baseConnection.test.js';

(async () => {
  const db = mysql.createPool(access).promise();

  {
    /** Overload: execute(sql) */
    const [results, fields] = await db.execute(sql);
    console.log(results, fields);
  }

  {
    /** Overload: execute(sql, values) */
    const [results, fields] = await db.execute(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) I */
    const [results, fields] = await db.execute({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) II */
    const [results, fields] = await db.execute({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions, values) */
    const [results, fields] = await db.execute({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  await db.end();
})();

/** getConnection */
(async () => {
  const db = await mysql.createPool(access).promise().getConnection();

  {
    /** Overload: execute(sql) */
    const [results, fields] = await db.execute(sql);
    console.log(results, fields);
  }

  {
    /** Overload: execute(sql, values) */
    const [results, fields] = await db.execute(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) I */
    const [results, fields] = await db.execute({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) II */
    const [results, fields] = await db.execute({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions, values) */
    const [results, fields] = await db.execute({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  await db.end();
})();
</file>

<file path="test/tsc-build/mysql/createPool/promise/getConnection.test.ts">
import { mysql } from '../../../index.test.js';
import { access } from '../../baseConnection.test.js';

(async () => {
  const pool = mysql.createPool(access);
  const conn = await pool.promise().getConnection();

  try {
    // @ts-expect-error: The connection can't get another connection
    conn.getConnection();
  } catch (err) {
    console.log('This error is expected', err);
  }
})();
</file>

<file path="test/tsc-build/mysql/createPool/promise/promise.test.ts">
import { mysql, mysqlp } from '../../../index.test.js';
import { access } from '../../baseConnection.test.js';

(async () => {
  let pool: mysql.Pool | null = null;
  let promisePool: mysqlp.Pool | null = null;
  let conn: mysqlp.PoolConnection | null = null;

  if (pool === null) return;

  pool = mysql.createPool(access);
  promisePool = pool.promise();
  conn = await promisePool.getConnection();

  conn.release();
})();
</file>

<file path="test/tsc-build/mysql/createPool/promise/query.test.ts">
import { mysql } from '../../../index.test.js';
import { access, sql, sqlPS, values } from '../../baseConnection.test.js';

(async () => {
  const db = mysql.createPool(access).promise();

  {
    /** Overload: query(sql) */
    const [results, fields] = await db.query(sql);
    console.log(results, fields);
  }

  {
    /** Overload: query(sql, values) */
    const [results, fields] = await db.query(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) I */
    const [results, fields] = await db.query({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) II */
    const [results, fields] = await db.query({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions, values) */
    const [results, fields] = await db.query({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  await db.end();
})();

/** getConnection and query */
(async () => {
  const db = await mysql.createPool(access).promise().getConnection();

  {
    /** Overload: query(sql) */
    const [results, fields] = await db.query(sql);
    console.log(results, fields);
  }

  {
    /** Overload: query(sql, values) */
    const [results, fields] = await db.query(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) I */
    const [results, fields] = await db.query({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) II */
    const [results, fields] = await db.query({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions, values) */
    const [results, fields] = await db.query({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  await db.end();
})();
</file>

<file path="test/tsc-build/mysql/createPool/promise/release.test.ts">
import { mysql } from '../../../index.test.js';
import { access } from '../../baseConnection.test.js';

(async () => {
  const pool = mysql.createPool(access);
  const conn = await pool.promise().getConnection();

  conn.release();

  try {
    // @ts-expect-error: The pool isn't a connection itself, so it doesn't have the connection methods
    pool.release();
  } catch (err) {
    console.log('This error is expected', err);
  }
})();
</file>

<file path="test/tsc-build/mysql/createPool/promise/releaseConnection.test.ts">
import { mysql } from '../../../index.test.js';
import { access } from '../../baseConnection.test.js';

(async () => {
  const pool = mysql.createPool(access);
  const conn = await pool.promise().getConnection();

  pool.releaseConnection(conn);
})();
</file>

<file path="test/tsc-build/mysql/createPoolCluster/add.test.ts">
import { mysql } from '../../index.test.js';
import { access, uriAccess } from '../baseConnection.test.js';

const poolCluster = mysql.createPoolCluster();

// Overload: poolCluster.add(group, connectionUri);
poolCluster.add('cluster1', uriAccess);
// Overload: poolCluster.add(group, config);
poolCluster.add('cluster2', access);
// Overload: poolCluster.add(config);
poolCluster.add(access);

// @ts-expect-error: The option to pass only `URI` doesn't exists
poolCluster.add(uriAccess);
</file>

<file path="test/tsc-build/mysql/createPoolCluster/getConnection.test.ts">
import { mysql } from '../../index.test.js';
import {
  access,
  uriAccess,
  sql,
  sqlPS,
  values,
} from '../baseConnection.test.js';

const poolCluster = mysql.createPoolCluster();

poolCluster.add('cluster1', uriAccess);
poolCluster.add('cluster2', access);

/** execute */
poolCluster.getConnection((_err, conn) => {
  /** Overload: execute(sql, () => {}}) */
  conn.execute(sql, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(sql, values, () => {}}) */
  conn.execute(sqlPS, values, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(QueryOptions, () => {}}) I */
  conn.execute({ sql }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(QueryOptions, () => {}}) II */
  conn.execute({ sql: sqlPS, values }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(QueryOptions, values, () => {}}) */
  conn.execute({ sql: sqlPS }, values, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Checking `PoolConnection` */
  conn.release();
});

/** query */
poolCluster.getConnection('cluster1', (_err, conn) => {
  /** Overload: query(sql, () => {}}) */
  conn.query(sql, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(sql, values, () => {}}) */
  conn.query(sqlPS, values, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(QueryOptions, () => {}}) I */
  conn.query({ sql }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(QueryOptions, () => {}}) II */
  conn.query({ sql: sqlPS, values }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(QueryOptions, values, () => {}}) */
  conn.query({ sql: sqlPS }, values, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Checking `PoolConnection` */
  conn.release();
});
</file>

<file path="test/tsc-build/mysql/createPoolCluster/of/getConnection.test.ts">
import { mysql } from '../../../index.test.js';
import {
  access,
  uriAccess,
  sql,
  sqlPS,
  values,
} from '../../baseConnection.test.js';

const poolCluster = mysql.createPoolCluster();

poolCluster.add('cluster1', uriAccess);
poolCluster.add('cluster2', access);

/** execute */
poolCluster.of('cluster1').getConnection((_err, conn) => {
  /** Overload: execute(sql, () => {}}) */
  conn.execute(sql, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(sql, values, () => {}}) */
  conn.execute(sqlPS, values, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(QueryOptions, () => {}}) I */
  conn.execute({ sql }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(QueryOptions, () => {}}) II */
  conn.execute({ sql: sqlPS, values }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(QueryOptions, values, () => {}}) */
  conn.execute({ sql: sqlPS }, values, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Checking `PoolConnection` */
  conn.release();
});

/** query */
poolCluster.of('cluster2').getConnection((_err, conn) => {
  /** Overload: query(sql, () => {}}) */
  conn.query(sql, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(sql, values, () => {}}) */
  conn.query(sqlPS, values, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(QueryOptions, () => {}}) I */
  conn.query({ sql }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(QueryOptions, () => {}}) II */
  conn.query({ sql: sqlPS, values }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(QueryOptions, values, () => {}}) */
  conn.query({ sql: sqlPS }, values, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Checking `PoolConnection` */
  conn.release();
});
</file>

<file path="test/tsc-build/mysql/createPoolCluster/of/of.test.ts">
import { mysql } from '../../../index.test.js';
import {
  access,
  uriAccess,
  sql,
  sqlPS,
  values,
} from '../../baseConnection.test.js';

const poolCluster = mysql.createPoolCluster();

poolCluster.add('cluster1', uriAccess);
poolCluster.add('cluster2', access);

/** execute */
{
  const conn = poolCluster.of('cluster1');

  /** Overload: execute(sql, () => {}}) */
  conn.execute(sql, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(sql, values, () => {}}) */
  conn.execute(sqlPS, values, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(QueryOptions, () => {}}) I */
  conn.execute({ sql }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(QueryOptions, () => {}}) II */
  conn.execute({ sql: sqlPS, values }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: execute(QueryOptions, values, () => {}}) */
  conn.execute({ sql: sqlPS }, values, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** @ts-expect-error: PoolNamespace can't be a `PoolConnection` */
  conn.release();
}

/** query */
{
  const conn = poolCluster.of('cluster2');

  /** Overload: query(sql, () => {}}) */
  conn.query(sql, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(sql, values, () => {}}) */
  conn.query(sqlPS, values, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(QueryOptions, () => {}}) I */
  conn.query({ sql }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(QueryOptions, () => {}}) II */
  conn.query({ sql: sqlPS, values }, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** Overload: query(QueryOptions, values, () => {}}) */
  conn.query({ sql: sqlPS }, values, (err, result, fields) => {
    console.log(err, result, fields);
  });

  /** @ts-expect-error: PoolNamespace can't be a `PoolConnection` */
  conn.release();
}
</file>

<file path="test/tsc-build/mysql/createPoolCluster/remove.test.ts">
import { mysql } from '../../index.test.js';

const poolCluster = mysql.createPoolCluster();

// Overload: poolCluster.add(group, connectionUri);
poolCluster.remove('cluster1');
</file>

<file path="test/tsc-build/mysql/parsers/clearParserCache.test.ts">
import { mysql } from '../../index.test.js';

mysql.clearParserCache();
</file>

<file path="test/tsc-build/mysql/parsers/setMaxParserCache.test.ts">
import { mysql } from '../../index.test.js';

mysql.setMaxParserCache(1000);

// @ts-expect-error: The `max` param is required
mysql.setMaxParserCache();
</file>

<file path="test/tsc-build/promise/baseConnection.test.ts">
import { mysqlp as mysql } from '../index.test.js';

export const access: mysql.ConnectionOptions = {
  host: '',
  user: '',
  password: '',
  database: '',
};

export const uriAccess = `mysql://${access.host}:${access.password}@${access.host}:${access.port}/${access.database}`;

/** The SQL for the query */
export const sql = 'SELECT * FROM `table`';

/** The SQL for the query with prepared statements */
export const sqlPS = 'SELECT * FROM `table` WHERE `id` = ?';

/** The values for the query with prepared statements */
export const values = [1];
</file>

<file path="test/tsc-build/promise/constants/Charsets.test.ts">
import { mysqlp as mysql } from '../../index.test.js';

const BIG5_CHINESE_CI: number = mysql.Charsets.BIG5_CHINESE_CI;
const BIG5: number = mysql.Charsets.BIG5;

console.log(BIG5_CHINESE_CI, BIG5);
</file>

<file path="test/tsc-build/promise/constants/CharsetToEncoding.test.ts">
import { mysqlp as mysql } from '../../index.test.js';

const charsetToEncoding: string[] = mysql.CharsetToEncoding;
const utf8: string = charsetToEncoding[0];

console.log(utf8, charsetToEncoding);
</file>

<file path="test/tsc-build/promise/constants/Types.test.ts">
import { mysqlp as mysql } from '../../index.test.js';

const BLOB: number = mysql.Types.BLOB;
const DECIMAL: string = mysql.Types[0x00];
const DOUBLE: string = mysql.Types[5];

console.log(BLOB, DECIMAL, DOUBLE);
</file>

<file path="test/tsc-build/promise/createConnection/execute.test.ts">
import { mysqlp as mysql } from '../../index.test.js';
import { access, sql, sqlPS, values } from '../baseConnection.test.js';

(async () => {
  const db = await mysql.createConnection(access);

  {
    /** Overload: execute(sql) */
    const [results, fields] = await db.execute(sql);
    console.log(results, fields);
  }

  {
    /** Overload: execute(sql, values) */
    const [results, fields] = await db.execute(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) I */
    const [results, fields] = await db.execute({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) II */
    const [results, fields] = await db.execute({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions, values) */
    const [results, fields] = await db.execute({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  await db.end();
})();
</file>

<file path="test/tsc-build/promise/createConnection/query.test.ts">
import { mysqlp as mysql } from '../../index.test.js';
import { access, sql, sqlPS, values } from '../baseConnection.test.js';

(async () => {
  const db = await mysql.createConnection(access);

  {
    /** Overload: query(sql) */
    const [results, fields] = await db.query(sql);
    console.log(results, fields);
  }

  {
    /** Overload: query(sql, values) */
    const [results, fields] = await db.query(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) I */
    const [results, fields] = await db.query({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) II */
    const [results, fields] = await db.query({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions, values) */
    const [results, fields] = await db.query({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  await db.end();
})();
</file>

<file path="test/tsc-build/promise/createPool/connection.test.ts">
import { mysqlp as mysql } from '../../index.test.js';
import { access } from '../baseConnection.test.js';

(async () => {
  const pool = mysql.createPool(access);
  const conn = await pool.getConnection();

  conn.connection;

  try {
    // @ts-expect-error: The pool can't be a connection itself
    pool.connection;
  } catch (err) {
    console.log('This error is expected', err);
  }
})();
</file>

<file path="test/tsc-build/promise/createPool/createPool.test.ts">
import { mysqlp as mysql } from '../../index.test.js';
import { uriAccess, access } from '../baseConnection.test.js';

(() => {
  let uriPool: mysql.Pool | null = null;
  let pool: mysql.Pool | null = null;

  if (uriPool === null || pool === null) return;

  uriPool = mysql.createPool(uriAccess);
  pool = mysql.createPool(access);
})();
</file>

<file path="test/tsc-build/promise/createPool/execute.test.ts">
import { mysqlp as mysql } from '../../index.test.js';
import { access, sql, sqlPS, values } from '../baseConnection.test.js';

(async () => {
  const db = mysql.createPool(access);

  {
    /** Overload: execute(sql) */
    const [results, fields] = await db.execute(sql);
    console.log(results, fields);
  }

  {
    /** Overload: execute(sql, values) */
    const [results, fields] = await db.execute(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) I */
    const [results, fields] = await db.execute({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) II */
    const [results, fields] = await db.execute({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions, values) */
    const [results, fields] = await db.execute({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  await db.end();
})();

/** getConnection */
(async () => {
  const db = await mysql.createPool(access).getConnection();

  {
    /** Overload: execute(sql) */
    const [results, fields] = await db.execute(sql);
    console.log(results, fields);
  }

  {
    /** Overload: execute(sql, values) */
    const [results, fields] = await db.execute(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) I */
    const [results, fields] = await db.execute({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) II */
    const [results, fields] = await db.execute({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions, values) */
    const [results, fields] = await db.execute({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  await db.end();
})();
</file>

<file path="test/tsc-build/promise/createPool/getConnection.test.ts">
import { mysqlp as mysql } from '../../index.test.js';
import { access } from '../baseConnection.test.js';

(async () => {
  const pool = mysql.createPool(access);
  const conn = await pool.getConnection();

  conn.connection;

  try {
    // @ts-expect-error: The connection can't get another connection
    conn.getConnection();
  } catch (err) {
    console.log('This error is expected', err);
  }
})();
</file>

<file path="test/tsc-build/promise/createPool/query.test.ts">
import { mysqlp as mysql } from '../../index.test.js';
import { access, sql, sqlPS, values } from '../baseConnection.test.js';

(async () => {
  const db = mysql.createPool(access);

  {
    /** Overload: query(sql) */
    const [results, fields] = await db.query(sql);
    console.log(results, fields);
  }

  {
    /** Overload: query(sql, values) */
    const [results, fields] = await db.query(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) I */
    const [results, fields] = await db.query({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) II */
    const [results, fields] = await db.query({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions, values) */
    const [results, fields] = await db.query({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  await db.end();
})();

/** getConnection and query */
(async () => {
  const db = await mysql.createPool(access).getConnection();

  {
    /** Overload: query(sql) */
    const [results, fields] = await db.query(sql);
    console.log(results, fields);
  }

  {
    /** Overload: query(sql, values) */
    const [results, fields] = await db.query(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) I */
    const [results, fields] = await db.query({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) II */
    const [results, fields] = await db.query({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions, values) */
    const [results, fields] = await db.query({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  await db.end();
})();
</file>

<file path="test/tsc-build/promise/createPool/release.test.ts">
import { mysqlp as mysql } from '../../index.test.js';
import { access } from '../baseConnection.test.js';

(async () => {
  const pool = mysql.createPool(access);
  const conn = await pool.getConnection();

  conn.release();

  try {
    // @ts-expect-error: The pool isn't a connection itself, so it doesn't have the connection methods
    pool.release();
  } catch (err) {
    console.log('This error is expected', err);
  }
})();
</file>

<file path="test/tsc-build/promise/createPool/releaseConnection.test.ts">
import { mysqlp as mysql } from '../../index.test.js';
import { access } from '../baseConnection.test.js';

(async () => {
  const pool = mysql.createPool(access);
  const conn = await pool.getConnection();

  pool.releaseConnection(conn);
})();
</file>

<file path="test/tsc-build/promise/createPoolCluster/add.test.ts">
import { mysqlp as mysql } from '../../index.test.js';
import { access, uriAccess } from '../baseConnection.test.js';

const poolCluster = mysql.createPoolCluster();

// Overload: poolCluster.add(group, connectionUri);
poolCluster.add('cluster1', uriAccess);
// Overload: poolCluster.add(group, config);
poolCluster.add('cluster2', access);
// Overload: poolCluster.add(config);
poolCluster.add(access);

// @ts-expect-error: The option to pass only `URI` doesn't exists
poolCluster.add(uriAccess);
</file>

<file path="test/tsc-build/promise/createPoolCluster/getConnection.test.ts">
import { mysqlp as mysql } from '../../index.test.js';
import {
  access,
  uriAccess,
  sql,
  sqlPS,
  values,
} from '../baseConnection.test.js';

const poolCluster = mysql.createPoolCluster();

poolCluster.add('cluster1', uriAccess);
poolCluster.add('cluster2', access);

/** execute */
(async () => {
  const conn = await poolCluster.getConnection();

  {
    /** Overload: execute(sql) */
    const [results, fields] = await conn.execute(sql);
    console.log(results, fields);
  }

  {
    /** Overload: execute(sql, values) */
    const [results, fields] = await conn.execute(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) I */
    const [results, fields] = await conn.execute({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) II */
    const [results, fields] = await conn.execute({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions, values) */
    const [results, fields] = await conn.execute({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  /** Checking `PoolConnection` */
  conn.release();
})();

/** query */
(async () => {
  const conn = await poolCluster.getConnection('cluster1');

  {
    /** Overload: query(sql) */
    const [results, fields] = await conn.query(sql);
    console.log(results, fields);
  }

  {
    /** Overload: query(sql, values) */
    const [results, fields] = await conn.query(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) I */
    const [results, fields] = await conn.query({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) II */
    const [results, fields] = await conn.query({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions, values) */
    const [results, fields] = await conn.query({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  /** Checking `PoolConnection` */
  conn.release();
})();
</file>

<file path="test/tsc-build/promise/createPoolCluster/of/getConnection.test.ts">
import { mysqlp as mysql } from '../../../index.test.js';
import {
  access,
  uriAccess,
  sql,
  sqlPS,
  values,
} from '../../baseConnection.test.js';

const poolCluster = mysql.createPoolCluster();

poolCluster.add('cluster1', uriAccess);
poolCluster.add('cluster2', access);

/** execute */
(async () => {
  const conn = await poolCluster.of('cluster1').getConnection();

  {
    /** Overload: execute(sql) */
    const [results, fields] = await conn.execute(sql);
    console.log(results, fields);
  }

  {
    /** Overload: execute(sql, values) */
    const [results, fields] = await conn.execute(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) I */
    const [results, fields] = await conn.execute({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) II */
    const [results, fields] = await conn.execute({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions, values) */
    const [results, fields] = await conn.execute({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  /** Checking `PoolConnection` */
  conn.release();
})();

/** query */
(async () => {
  const conn = await poolCluster.of('cluster2').getConnection();

  {
    /** Overload: query(sql) */
    const [results, fields] = await conn.query(sql);
    console.log(results, fields);
  }

  {
    /** Overload: query(sql, values) */
    const [results, fields] = await conn.query(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) I */
    const [results, fields] = await conn.query({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) II */
    const [results, fields] = await conn.query({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions, values) */
    const [results, fields] = await conn.query({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  /** Checking `PoolConnection` */
  conn.release();
})();
</file>

<file path="test/tsc-build/promise/createPoolCluster/of/of.test.ts">
import { mysqlp as mysql } from '../../../index.test.js';
import {
  access,
  uriAccess,
  sql,
  sqlPS,
  values,
} from '../../baseConnection.test.js';

const poolCluster = mysql.createPoolCluster();

poolCluster.add('cluster1', uriAccess);
poolCluster.add('cluster2', access);

/** execute */
(async () => {
  const conn = poolCluster.of('cluster1');

  {
    /** Overload: execute(sql) */
    const [results, fields] = await conn.execute(sql);
    console.log(results, fields);
  }

  {
    /** Overload: execute(sql, values) */
    const [results, fields] = await conn.execute(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) I */
    const [results, fields] = await conn.execute({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions) II */
    const [results, fields] = await conn.execute({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: execute(QueryOptions, values) */
    const [results, fields] = await conn.execute({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  /** @ts-expect-error: PoolNamespace can't be a `PoolConnection` */
  conn.release();
})();

/** query */
(async () => {
  const conn = poolCluster.of('cluster2');

  {
    /** Overload: query(sql) */
    const [results, fields] = await conn.query(sql);
    console.log(results, fields);
  }

  {
    /** Overload: query(sql, values) */
    const [results, fields] = await conn.query(sqlPS, values);
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) I */
    const [results, fields] = await conn.query({ sql });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions) II */
    const [results, fields] = await conn.query({ sql: sqlPS, values });
    console.log(results, fields);
  }

  {
    /** Overload: query(QueryOptions, values) */
    const [results, fields] = await conn.query({ sql: sqlPS }, values);
    console.log(results, fields);
  }

  /** @ts-expect-error: PoolNamespace can't be a `PoolConnection` */
  conn.release();
})();
</file>

<file path="test/tsc-build/promise/parsers/clearParserCache.test.ts">
import { mysqlp as mysql } from '../../index.test.js';

mysql.clearParserCache();
</file>

<file path="test/tsc-build/promise/parsers/setMaxParserCache.test.ts">
import { mysqlp as mysql } from '../../index.test.js';

mysql.setMaxParserCache(1000);

// @ts-expect-error: The `max` param is required
mysql.setMaxParserCache();
</file>

<file path="test/tsc-build/strict-checks/enableKeepAlive-and-keepAliveInitialDelay.test.ts">
import { mysql, mysqlp } from '../index.test.js';

// Callback
(() => {
  const poolOptions: mysql.PoolOptions = {
    enableKeepAlive: true,
    keepAliveInitialDelay: 0,
  };

  const connectionOptions: mysql.ConnectionOptions = {
    enableKeepAlive: true,
    keepAliveInitialDelay: 0,
  };

  mysql.createConnection(connectionOptions);
  mysql.createPool(poolOptions);
  mysql.createPoolCluster().add(poolOptions);
})();

// Promise
(() => {
  const poolOptions: mysqlp.PoolOptions = {
    enableKeepAlive: true,
    keepAliveInitialDelay: 0,
  };

  const connectionOptions: mysqlp.ConnectionOptions = {
    enableKeepAlive: true,
    keepAliveInitialDelay: 0,
  };

  mysqlp.createConnection(connectionOptions);
  mysqlp.createPool(poolOptions);
  mysqlp.createPoolCluster().add(poolOptions);
})();
</file>

<file path="test/tsc-build/strict-checks/execute.test.ts">
/**
 * This test strictly validates each overload and its corresponding returned types.
 * For `execute` syntax tests, please use the '../mysql' and '../promise'.
 */

import { mysql, mysqlp } from '../index.test.js';
import { access, sql } from '../promise/baseConnection.test.js';

// Callbacks
{
  const conn = mysql.createConnection(access);

  conn.execute<mysql.RowDataPacket[]>(sql, (_e, _r, _f) => {
    const err: mysql.QueryError | null = _e;
    const result: mysql.RowDataPacket[] = _r;
    const fields: mysql.FieldPacket[] = _f;

    console.log(err, result, fields);
  });

  conn.execute<mysql.RowDataPacket[][]>(sql, (_e, _r, _f) => {
    const err: mysql.QueryError | null = _e;
    const result: mysql.RowDataPacket[][] = _r;
    const fields: mysql.FieldPacket[] = _f;

    console.log(err, result, fields);
  });

  conn.execute<mysql.OkPacket>(sql, (_e, _r, _f) => {
    const err: mysql.QueryError | null = _e;
    const result: mysql.OkPacket = _r;
    const fields: mysql.FieldPacket[] = _f;

    console.log(err, result, fields);
  });

  conn.execute<mysql.OkPacket[]>(sql, (_e, _r, _f) => {
    const err: mysql.QueryError | null = _e;
    const result: mysql.OkPacket[] = _r;
    const fields: mysql.FieldPacket[] = _f;

    console.log(err, result, fields);
  });

  conn.execute<mysql.ResultSetHeader>(sql, (_e, _r, _f) => {
    const err: mysql.QueryError | null = _e;
    const result: mysql.ResultSetHeader = _r;
    const fields: mysql.FieldPacket[] = _f;

    console.log(err, result, fields);
  });

  conn.execute<mysql.ProcedureCallPacket>(sql, (_e, _r, _f) => {
    const err: mysql.QueryError | null = _e;
    const result:
      | [mysqlp.RowDataPacket[], mysqlp.ResultSetHeader]
      | mysqlp.ResultSetHeader = _r;
    const fields: mysql.FieldPacket[] = _f;

    console.log(err, result, fields);
  });

  conn.execute<mysql.ProcedureCallPacket<mysql.RowDataPacket[]>>(
    sql,
    (_e, _r, _f) => {
      const err: mysql.QueryError | null = _e;
      const result: [mysqlp.RowDataPacket[], mysql.ResultSetHeader] = _r;
      const fields: mysql.FieldPacket[] = _f;

      console.log(err, result, fields);
    }
  );

  conn.execute<
    mysql.ProcedureCallPacket<mysql.OkPacket | mysql.ResultSetHeader>
  >(sql, (_e, _r, _f) => {
    const err: mysql.QueryError | null = _e;
    const result: mysql.ResultSetHeader = _r;
    const fields: mysql.FieldPacket[] = _f;

    console.log(err, result, fields);
  });
}

// Promise
(async () => {
  const conn = await mysqlp.createConnection(access);

  conn.execute<mysqlp.RowDataPacket[]>(sql).then(([_r, _f]) => {
    const result: mysqlp.RowDataPacket[] = _r;
    const fields: mysqlp.FieldPacket[] = _f;

    console.log(result, fields);
  });

  conn.execute<mysqlp.RowDataPacket[][]>(sql).then(([_r, _f]) => {
    const result: mysqlp.RowDataPacket[][] = _r;
    const fields: mysqlp.FieldPacket[] = _f;

    console.log(result, fields);
  });

  conn.execute<mysqlp.OkPacket>(sql).then(([_r, _f]) => {
    const result: mysqlp.OkPacket = _r;
    const fields: mysqlp.FieldPacket[] = _f;

    console.log(result, fields);
  });

  conn.execute<mysqlp.OkPacket[]>(sql).then(([_r, _f]) => {
    const result: mysqlp.OkPacket[] = _r;
    const fields: mysqlp.FieldPacket[] = _f;

    console.log(result, fields);
  });

  conn.execute<mysqlp.ResultSetHeader>(sql).then(([_r, _f]) => {
    const result: mysqlp.ResultSetHeader = _r;
    const fields: mysqlp.FieldPacket[] = _f;

    console.log(result, fields);
  });

  conn.execute<mysqlp.ProcedureCallPacket>(sql).then(([_r, _f]) => {
    const result:
      | [mysqlp.RowDataPacket[], mysqlp.ResultSetHeader]
      | mysqlp.ResultSetHeader = _r;
    const fields: mysqlp.FieldPacket[] = _f;

    console.log(result, fields);
  });

  conn
    .execute<mysqlp.ProcedureCallPacket<mysqlp.RowDataPacket[]>>(sql)
    .then(([_r, _f]) => {
      const result: [mysqlp.RowDataPacket[], mysql.ResultSetHeader] = _r;
      const fields: mysqlp.FieldPacket[] = _f;

      console.log(result, fields);
    });

  conn
    .execute<
      mysqlp.ProcedureCallPacket<mysqlp.OkPacket | mysqlp.ResultSetHeader>
    >(sql)
    .then(([_r, _f]) => {
      const result: mysqlp.ResultSetHeader = _r;
      const fields: mysqlp.FieldPacket[] = _f;

      console.log(result, fields);
    });
})();
</file>

<file path="test/tsc-build/strict-checks/ProcedureCallPacket.test.ts">
import { mysql, mysqlp } from '../index.test.js';
import { access } from '../mysql/baseConnection.test.js';
import { isResultSetHeader } from '../helpers.test.js';

const dropProcedure = {
  select: 'DROP PROCEDURE IF EXISTS selectProcedure',
  update: 'DROP PROCEDURE IF EXISTS updateProcedure',
};

const createProcedure = {
  select: `
    CREATE PROCEDURE selectProcedure()
    BEGIN
      SELECT 1 as id;
    END
  `,
  update: `
    CREATE PROCEDURE updateProcedure()
    BEGIN
      SET @a = 1;
    END
  `,
};

const procedureCall = {
  select: 'CALL selectProcedure()',
  update: 'CALL updateProcedure()',
};

// Callback
(() => {
  interface User extends mysql.RowDataPacket {
    id: number;
  }

  const conn = mysql.createConnection(access);

  // Checking `RowDataPacket[]` Procedure Calls
  conn.query(dropProcedure.select, () => {
    conn.query(createProcedure.select, () => {
      conn.query<mysql.ProcedureCallPacket<User[]>>(
        procedureCall.select,
        [],
        (_err, procedureResult) => {
          procedureResult.forEach((users) => {
            if (isResultSetHeader(users)) {
              console.log(users);

              return;
            }

            // Strict checking the `RowDataPacket[]`
            users.forEach((user) => {
              const id: number = user.id;

              console.log(id);
            });
          });
        }
      );
    });
  });

  // Checking `ResultSetHeader | OkPacket` Procedure Calls
  conn.query(dropProcedure.update, () => {
    conn.query(createProcedure.update, () => {
      conn.query<
        mysql.ProcedureCallPacket<mysql.ResultSetHeader | mysql.OkPacket>
      >(
        procedureCall.update,
        [],
        // Strict checking the `ResultSetHeader`
        (_err, procedureResult: mysql.ResultSetHeader) => {
          console.log(procedureResult);
        }
      );
    });
  });
})();

// Promise
(async () => {
  interface User extends mysqlp.RowDataPacket {
    id: number;
  }

  const conn = await mysqlp.createConnection(access);

  // Checking `RowDataPacket[]` Procedure Calls
  {
    await conn.query(dropProcedure.select);
    await conn.query(createProcedure.select);

    const [procedureResult] = await conn.query<
      mysqlp.ProcedureCallPacket<User[]>
    >(procedureCall.select, []);

    procedureResult.forEach((users) => {
      if (isResultSetHeader(users)) {
        console.log(users);

        return;
      }

      // Strict checking the `RowDataPacket[]`
      users.forEach((user) => {
        const id: number = user.id;

        console.log(id);
      });
    });
  }

  // Checking `ResultSetHeader | OkPacket` Procedure Calls
  {
    await conn.query(dropProcedure.update);
    await conn.query(createProcedure.update);

    const [procedureResult] = await conn.query<
      mysqlp.ProcedureCallPacket<mysqlp.ResultSetHeader | mysqlp.OkPacket>
    >(procedureCall.update, []);

    // Strict checking the `ResultSetHeader`
    const resultSetHeader: mysqlp.ResultSetHeader = procedureResult;
    console.log(resultSetHeader);
  }
})();
</file>

<file path="test/tsc-build/strict-checks/query.test.ts">
/**
 * This test strictly validates each overload and its corresponding returned types.
 * For `query` syntax tests, please use the '../mysql' and '../promise'.
 */

import { mysql, mysqlp } from '../index.test.js';
import { access, sql } from '../promise/baseConnection.test.js';

// Callbacks
{
  const conn = mysql.createConnection(access);

  conn.query<mysql.RowDataPacket[]>(sql, (_e, _r, _f) => {
    const err: mysql.QueryError | null = _e;
    const result: mysql.RowDataPacket[] = _r;
    const fields: mysql.FieldPacket[] = _f;

    console.log(err, result, fields);
  });

  conn.query<mysql.RowDataPacket[][]>(sql, (_e, _r, _f) => {
    const err: mysql.QueryError | null = _e;
    const result: mysql.RowDataPacket[][] = _r;
    const fields: mysql.FieldPacket[] = _f;

    console.log(err, result, fields);
  });

  conn.query<mysql.OkPacket>(sql, (_e, _r, _f) => {
    const err: mysql.QueryError | null = _e;
    const result: mysql.OkPacket = _r;
    const fields: mysql.FieldPacket[] = _f;

    console.log(err, result, fields);
  });

  conn.query<mysql.OkPacket[]>(sql, (_e, _r, _f) => {
    const err: mysql.QueryError | null = _e;
    const result: mysql.OkPacket[] = _r;
    const fields: mysql.FieldPacket[] = _f;

    console.log(err, result, fields);
  });

  conn.query<mysql.ResultSetHeader>(sql, (_e, _r, _f) => {
    const err: mysql.QueryError | null = _e;
    const result: mysql.ResultSetHeader = _r;
    const fields: mysql.FieldPacket[] = _f;

    console.log(err, result, fields);
  });

  conn.query<mysql.ProcedureCallPacket>(sql, (_e, _r, _f) => {
    const err: mysql.QueryError | null = _e;
    const result:
      | [mysqlp.RowDataPacket[], mysqlp.ResultSetHeader]
      | mysqlp.ResultSetHeader = _r;
    const fields: mysql.FieldPacket[] = _f;

    console.log(err, result, fields);
  });

  conn.query<mysql.ProcedureCallPacket<mysql.RowDataPacket[]>>(
    sql,
    (_e, _r, _f) => {
      const err: mysql.QueryError | null = _e;
      const result: [mysqlp.RowDataPacket[], mysql.ResultSetHeader] = _r;
      const fields: mysql.FieldPacket[] = _f;

      console.log(err, result, fields);
    }
  );

  conn.query<mysql.ProcedureCallPacket<mysql.OkPacket | mysql.ResultSetHeader>>(
    sql,
    (_e, _r, _f) => {
      const err: mysql.QueryError | null = _e;
      const result: mysql.ResultSetHeader = _r;
      const fields: mysql.FieldPacket[] = _f;

      console.log(err, result, fields);
    }
  );
}

// Promise
(async () => {
  const conn = await mysqlp.createConnection(access);

  conn.query<mysqlp.RowDataPacket[]>(sql).then(([_r, _f]) => {
    const result: mysqlp.RowDataPacket[] = _r;
    const fields: mysqlp.FieldPacket[] = _f;

    console.log(result, fields);
  });

  conn.query<mysqlp.RowDataPacket[][]>(sql).then(([_r, _f]) => {
    const result: mysqlp.RowDataPacket[][] = _r;
    const fields: mysqlp.FieldPacket[] = _f;

    console.log(result, fields);
  });

  conn.query<mysqlp.OkPacket>(sql).then(([_r, _f]) => {
    const result: mysqlp.OkPacket = _r;
    const fields: mysqlp.FieldPacket[] = _f;

    console.log(result, fields);
  });

  conn.query<mysqlp.OkPacket[]>(sql).then(([_r, _f]) => {
    const result: mysqlp.OkPacket[] = _r;
    const fields: mysqlp.FieldPacket[] = _f;

    console.log(result, fields);
  });

  conn.query<mysqlp.ResultSetHeader>(sql).then(([_r, _f]) => {
    const result: mysqlp.ResultSetHeader = _r;
    const fields: mysqlp.FieldPacket[] = _f;

    console.log(result, fields);
  });

  conn.query<mysqlp.ProcedureCallPacket>(sql).then(([_r, _f]) => {
    const result:
      | [mysqlp.RowDataPacket[], mysqlp.ResultSetHeader]
      | mysqlp.ResultSetHeader = _r;
    const fields: mysqlp.FieldPacket[] = _f;

    console.log(result, fields);
  });

  conn
    .query<mysqlp.ProcedureCallPacket<mysqlp.RowDataPacket[]>>(sql)
    .then(([_r, _f]) => {
      const result: [mysqlp.RowDataPacket[], mysql.ResultSetHeader] = _r;
      const fields: mysqlp.FieldPacket[] = _f;

      console.log(result, fields);
    });

  conn
    .query<
      mysqlp.ProcedureCallPacket<mysqlp.OkPacket | mysqlp.ResultSetHeader>
    >(sql)
    .then(([_r, _f]) => {
      const result: mysqlp.ResultSetHeader = _r;
      const fields: mysqlp.FieldPacket[] = _f;

      console.log(result, fields);
    });
})();
</file>

<file path="test/tsc-build/strict-checks/typeCast.test.ts">
import { QueryOptions, ConnectionOptions } from '../../../index.js';
import {
  QueryOptions as QueryOptionsP,
  ConnectionOptions as ConnectionOptionsP,
} from '../../../promise.js';
import { access, sql } from '../promise/baseConnection.test.js';

// Callback: QueryOptions
{
  const options1: QueryOptions = {
    sql,
    typeCast: true,
  };

  const options2: QueryOptions = {
    sql,
    typeCast: false,
  };

  const options3: QueryOptions = {
    sql,
    typeCast: (field, next) => {
      const db: string = field.db;
      const length: number = field.length;
      const name: string = field.name;
      const table: string = field.table;
      const type: string = field.type;
      const buffer: Buffer | null = field.buffer();
      const string: string | null = field.string();
      const stringWithEncoding: string | null = field.string('utf-8');
      const geometry:
        | { x: number; y: number }
        | { x: number; y: number }[]
        | null = field.geometry();

      console.log(db, length, name, table, type);
      console.log(buffer, string, stringWithEncoding, geometry);

      return next();
    },
  };

  console.log(options1, options2, options3);
}

// Callback: ConnectionOptions
{
  const options1: ConnectionOptions = {
    ...access,
    typeCast: true,
  };

  const options2: ConnectionOptions = {
    ...access,
    typeCast: false,
  };

  const options3: ConnectionOptions = {
    ...access,
    typeCast: (field, next) => {
      const db: string = field.db;
      const length: number = field.length;
      const name: string = field.name;
      const table: string = field.table;
      const type: string = field.type;
      const buffer: Buffer | null = field.buffer();
      const string: string | null = field.string();
      const stringWithEncoding: string | null = field.string('utf-8');
      const geometry:
        | { x: number; y: number }
        | { x: number; y: number }[]
        | null = field.geometry();

      console.log(db, length, name, table, type);
      console.log(buffer, string, stringWithEncoding, geometry);

      return next();
    },
  };

  console.log(options1, options2, options3);
}

// Promise: QueryOptions
{
  const options1: QueryOptionsP = {
    sql,
    typeCast: true,
  };

  const options2: QueryOptionsP = {
    sql,
    typeCast: false,
  };

  const options3: QueryOptionsP = {
    sql,
    typeCast: (field, next) => {
      const db: string = field.db;
      const length: number = field.length;
      const name: string = field.name;
      const table: string = field.table;
      const type: string = field.type;
      const buffer: Buffer | null = field.buffer();
      const string: string | null = field.string();
      const stringWithEncoding: string | null = field.string('utf-8');
      const geometry:
        | { x: number; y: number }
        | { x: number; y: number }[]
        | null = field.geometry();

      console.log(db, length, name, table, type);
      console.log(buffer, string, stringWithEncoding, geometry);

      return next();
    },
  };

  console.log(options1, options2, options3);
}

// Promise: ConnectionOptions
{
  const options1: ConnectionOptionsP = {
    ...access,
    typeCast: true,
  };

  const options2: ConnectionOptionsP = {
    ...access,
    typeCast: false,
  };

  const options3: ConnectionOptionsP = {
    ...access,
    typeCast: (field, next) => {
      const db: string = field.db;
      const length: number = field.length;
      const name: string = field.name;
      const table: string = field.table;
      const type: string = field.type;
      const buffer: Buffer | null = field.buffer();
      const string: string | null = field.string();
      const stringWithEncoding: string | null = field.string('utf-8');
      const geometry:
        | { x: number; y: number }
        | { x: number; y: number }[]
        | null = field.geometry();

      console.log(db, length, name, table, type);
      console.log(buffer, string, stringWithEncoding, geometry);

      return next();
    },
  };

  console.log(options1, options2, options3);
}
</file>

<file path="test/tsc-build/tsconfig.json">
{
  "include": [
    "index.test.ts",
    "helpers.test.ts",
    "mysql",
    "promise",
    "strict-checks"
  ],
  "compilerOptions": {
    "target": "ES2016",
    "module": "CommonJS",
    "moduleResolution": "Node",
    "esModuleInterop": true,
    "allowSyntheticDefaultImports": true,
    "strict": true,
    "alwaysStrict": true,
    "noImplicitAny": true,
    "strictFunctionTypes": false,
    "skipLibCheck": false,
    "noEmitOnError": true,
    "noEmit": true,
    "noUnusedParameters": true,
    "isolatedModules": true
  }
}
</file>

<file path="test/unit/commands/test-query.test.cjs">
'use strict';

const { assert } = require('poku');
const Query = require('../../../lib/commands/query.js');

const testError = new Error('something happened');
const testQuery = new Query({}, (err, res) => {
  assert.equal(err, testError);
  assert.equal(res, null);
});

testQuery._rowParser = new (class FailingRowParser {
  next() {
    throw testError;
  }
})();

testQuery.row({
  isEOF: () => false,
});
</file>

<file path="test/unit/commands/test-quit.test.cjs">
'use strict';

const { assert } = require('poku');
const Quit = require('../../../lib/commands/quit.js');

const testCallback = (err) => console.info(err.message);
const testQuit = new Quit(testCallback);

assert.strictEqual(testQuit.onResult, testCallback);
</file>

<file path="test/unit/connection/test-connection_config.test.cjs">
'use strict';

const ConnectionConfig = require('../../../lib/connection_config.js');
const { assert } = require('poku');

const expectedMessage = "SSL profile must be an object, instead it's a boolean";

assert.throws(
  () =>
    new ConnectionConfig({
      ssl: true,
    }),
  (err) => err instanceof TypeError && err.message === expectedMessage,
  'Error, the constructor accepts a boolean without throwing the right exception'
);

assert.doesNotThrow(
  () =>
    new ConnectionConfig({
      ssl: {},
    }),
  'Error, the constructor accepts an object but throws an exception'
);

assert.doesNotThrow(() => {
  const SSLProfiles = require('../../../lib/constants/ssl_profiles.js');
  const sslProfile = Object.keys(SSLProfiles)[0];
  new ConnectionConfig({
    ssl: sslProfile,
  });
}, 'Error, the constructor accepts a string but throws an exception');

assert.doesNotThrow(() => {
  new ConnectionConfig({
    flags: '-FOUND_ROWS',
  });
}, 'Error, the constructor threw an exception due to a flags string');

assert.doesNotThrow(() => {
  new ConnectionConfig({
    flags: ['-FOUND_ROWS'],
  });
}, 'Error, the constructor threw an exception due to a flags array');

assert.strictEqual(
  ConnectionConfig.parseUrl(
    String.raw`fml://test:pass!%40%24%25%5E%26*()word%3A@www.example.com/database`
  ).password,
  'pass!@$%^&*()word:'
);

assert.strictEqual(
  ConnectionConfig.parseUrl(
    String.raw`fml://user%40test.com:pass!%40%24%25%5E%26*()word%3A@www.example.com/database`
  ).user,
  'user@test.com'
);

assert.strictEqual(
  ConnectionConfig.parseUrl(
    String.raw`fml://test:pass@wordA@fe80%3A3438%3A7667%3A5c77%3Ace27%2518/database`
  ).host,
  'fe80:3438:7667:5c77:ce27%18'
);

assert.strictEqual(
  ConnectionConfig.parseUrl(
    String.raw`fml://test:pass@wordA@www.example.com/database`
  ).host,
  'www.example.com'
);

assert.strictEqual(
  ConnectionConfig.parseUrl(
    String.raw`fml://test:pass@wordA@www.example.com/database%24`
  ).database,
  'database$'
);
</file>

<file path="test/unit/packets/test-column-definition.test.cjs">
'use strict';

const { assert } = require('poku');
const ColumnDefinition = require('../../../lib/packets/column_definition.js');

const sequenceId = 5;

// simple
let packet = ColumnDefinition.toPacket(
  {
    catalog: 'def',
    schema: 'some_db',
    name: 'some_col',
    orgName: 'some_col',
    table: 'some_tbl',
    orgTable: 'some_tbl',

    characterSet: 0x21,
    columnLength: 500,
    flags: 32896,
    columnType: 0x8,
    decimals: 1,
  },
  sequenceId
);
assert.equal(
  packet.buffer.toString('hex', 4),
  '0364656607736f6d655f646208736f6d655f74626c08736f6d655f74626c08736f6d655f636f6c08736f6d655f636f6c0c2100f4010000088080010000'
);

// Russian
packet = ColumnDefinition.toPacket(
  {
    catalog: 'def',
    schema: 's_погоди',
    name: 'n_погоди',
    orgName: 'on_погоди',
    table: 't_погоди',
    orgTable: 'ot_погоди',
    characterSet: 0x21,
    columnLength: 500,
    flags: 32896,
    columnType: 0x8,
    decimals: 1,
  },
  sequenceId
);
assert.equal(
  packet.buffer.toString('hex', 4),
  '036465660e735fd0bfd0bed0b3d0bed0b4d0b80e745fd0bfd0bed0b3d0bed0b4d0b80f6f745fd0bfd0bed0b3d0bed0b4d0b80e6e5fd0bfd0bed0b3d0bed0b4d0b80f6f6e5fd0bfd0bed0b3d0bed0b4d0b80c2100f4010000088080010000'
);

// Spec (from example: https://dev.mysql.com/doc/internals/en/protocoltext-resultset.html)
const inputColDef = {
  catalog: 'def',
  schema: '',
  name: '@@version_comment',
  orgName: '',
  table: '',
  orgTable: '',

  characterSet: 0x08, // latin1_swedish_ci
  columnLength: 0x1c,
  flags: 0,
  columnType: 0xfd,
  type: 0xfd,
  encoding: 'latin1',
  decimals: 0x1f,
};
packet = ColumnDefinition.toPacket(inputColDef, sequenceId);
assert.equal(
  packet.buffer.toString('hex', 4),
  '0364656600000011404076657273696f6e5f636f6d6d656e74000c08001c000000fd00001f0000'
);

packet.offset = 4;
const colDef = new ColumnDefinition(packet, 'utf8');
// inspect omits the "colulumnType" property because type is an alias for it
// but ColumnDefinition.toPacket reads type from "columnType"
// TODO: think how to make this more consistent
const inspect = { columnType: 253, ...colDef.inspect() };
assert.deepEqual(inspect, inputColDef);
assert.equal(colDef.db, inputColDef.schema);
</file>

<file path="test/unit/packets/test-datetime.test.cjs">
'use strict';

const { assert } = require('poku');
const packets = require('../../../lib/packets/index.js');
const { Buffer } = require('node:buffer');

let buf = Buffer.from('0a000004000007dd070116010203', 'hex');

let packet = new packets.Packet(4, buf, 0, buf.length);
packet.readInt16(); // unused
let d = packet.readDateTime('Z');

assert.equal(+d, 1358816523000);

buf = Buffer.from(
  '18000006000004666f6f310be00702090f01095d7f06000462617231',
  'hex'
);
packet = new packets.Packet(6, buf, 0, buf.length);

packet.readInt16(); // ignore
const s = packet.readLengthCodedString('cesu8');
assert.equal(s, 'foo1');
d = packet.readDateTime('Z');
assert.equal(+d, 1455030069425);

const s1 = packet.readLengthCodedString('cesu8');
assert.equal(s1, 'bar1');
assert.equal(packet.offset, packet.end);
</file>

<file path="test/unit/packets/test-ok-autoinc.test.cjs">
'use strict';

const { assert } = require('poku');
const packets = require('../../../lib/packets/index.js');

const packet = packets.OK.toPacket({ affectedRows: 0, insertId: 1 });

// 5 bytes for an OK packet, plus one byte to store affectedRows plus one byte to store the insertId
assert.equal(
  packet.length(),
  11,
  `${
    'OK packets with 0 affectedRows and a minimal insertId should be ' +
    '11 bytes long, got '
  }${packet.length()} byte(s)`
);
</file>

<file path="test/unit/packets/test-ok-sessiontrack.test.cjs">
'use strict';

const { assert } = require('poku');
const Packet = require('../../../lib/packets/packet.js');
const ResultSetHeader = require('../../../lib/packets/resultset_header.js');
const clientConstants = require('../../../lib/constants/client.js');
const { Buffer } = require('node:buffer');

const mockConnection = {
  config: {},
  serverEncoding: 'utf8',
  _handshakePacket: {
    capabilityFlags:
      clientConstants.PROTOCOL_41 + clientConstants.SESSION_TRACK,
  },
};

const mkpacket = (str) => {
  const buf = Buffer.from(str.split(/[ \n]+/).join(''), 'hex');
  return new Packet(0, buf, 0, buf.length);
};

// regression examples from https://github.com/sidorares/node-mysql2/issues/989

assert.doesNotThrow(() => {
  const packet = mkpacket(
    `1b 00 00 01
           00
           01 fe 65 96 fc 02 00 00 00 00 03 40 00 00 00 0a 14 08 fe 60 63 9b 05 00 00 00
          `
  );
  new ResultSetHeader(packet, mockConnection);
});

assert.doesNotThrow(() => {
  const packet = mkpacket(
    `13 00 00 01 00 01 00 02 40 00 00 00 0a 14 08 fe 18 25 e7 06 00 00 00`
  );
  new ResultSetHeader(packet, mockConnection);
});
</file>

<file path="test/unit/packets/test-text-row.test.cjs">
'use strict';

const { assert } = require('poku');
const TextRow = require('../../../lib/packets/text_row.js');

// simple
let packet = TextRow.toPacket(['Hello', 'World'], 'cesu8');
assert.equal(packet.buffer.toString('hex', 4), '0548656c6c6f05576f726c64');

// Russian (unicode)
packet = TextRow.toPacket(['Ну,', 'погоди!'], 'cesu8');
assert.equal(
  packet.buffer.toString('hex', 4),
  '05d09dd1832c0dd0bfd0bed0b3d0bed0b4d0b821'
);

// Long > 256 byte
packet = TextRow.toPacket(
  [
    'Пушкин родился 26 мая (6 июня) 1799 г. в Москве. В метрической книге церкви Богоявления в Елохове (сейчас на её месте находится Богоявленский собор в Елохове) на дату 8 июня 1799 г.',
  ],
  'cesu8'
);
assert.equal(
  packet.buffer.toString('hex', 4),
  'fc3801d09fd183d188d0bad0b8d0bd20d180d0bed0b4d0b8d0bbd181d18f20323620d0bcd0b0d18f20283620d0b8d18ed0bdd18f29203137393920d0b32e20d0b220d09cd0bed181d0bad0b2d0b52e20d09220d0bcd0b5d182d180d0b8d187d0b5d181d0bad0bed0b920d0bad0bdd0b8d0b3d0b520d186d0b5d180d0bad0b2d0b820d091d0bed0b3d0bed18fd0b2d0bbd0b5d0bdd0b8d18f20d0b220d095d0bbd0bed185d0bed0b2d0b52028d181d0b5d0b9d187d0b0d18120d0bdd0b020d0b5d19120d0bcd0b5d181d182d0b520d0bdd0b0d185d0bed0b4d0b8d182d181d18f20d091d0bed0b3d0bed18fd0b2d0bbd0b5d0bdd181d0bad0b8d0b920d181d0bed0b1d0bed18020d0b220d095d0bbd0bed185d0bed0b2d0b52920d0bdd0b020d0b4d0b0d182d183203820d0b8d18ed0bdd18f203137393920d0b32e'
);
</file>

<file path="test/unit/packets/test-time.test.cjs">
'use strict';

const { assert } = require('poku');
const packets = require('../../../lib/packets/index.js');
const { Buffer } = require('node:buffer');

[
  ['01:23:45', '0b000004000008000000000001172d'], // CONVERT('01:23:45', TIME)
  ['01:23:45.123456', '0f00000400000c000000000001172d40e20100'], // DATE_ADD(CONVERT('01:23:45', TIME), INTERVAL 0.123456 SECOND)
  ['-01:23:44.876544', '0f00000400000c010000000001172c00600d00'], // DATE_ADD(CONVERT('-01:23:45', TIME), INTERVAL 0.123456 SECOND)
  ['-81:23:44.876544', '0f00000400000c010300000009172c00600d00'], // DATE_ADD(CONVERT('-81:23:45', TIME), INTERVAL 0.123456 SECOND)
  ['81:23:45', '0b000004000008000300000009172d'], // CONVERT('81:23:45', TIME)
  ['123:23:45.123456', '0f00000400000c000500000003172d40e20100'], // DATE_ADD(CONVERT('123:23:45', TIME), INTERVAL 0.123456 SECOND)
  ['-121:23:45', '0b000004000008010500000001172d'], // CONVERT('-121:23:45', TIME)
  ['-01:23:44.88', '0f00000400000c010000000001172c806d0d00'], //DATE_ADD(CONVERT('-01:23:45', TIME), INTERVAL 0.12 SECOND)
].forEach(([expected, buffer]) => {
  const buf = Buffer.from(buffer, 'hex');
  const packet = new packets.Packet(4, buf, 0, buf.length);
  packet.readInt16(); // unused
  const d = packet.readTimeString(false);
  assert.equal(d, expected);
});
</file>

<file path="test/unit/parsers/test-text-parser.test.cjs">
'use strict';

const { assert } = require('poku');
const common = require('../../common.test.cjs');

const typeCastWrapper = function (...args) {
  return function (field, next) {
    if (field.type === 'JSON') {
      return JSON.parse(field.string(...args));
    }

    return next();
  };
};

const connection = common.createConnection();
connection.query('CREATE TEMPORARY TABLE t (i JSON)');
connection.query('INSERT INTO t values(\'{ "test": "😀" }\')');

// JSON without encoding options - should result in unexpected behaviors
connection.query(
  {
    sql: 'SELECT * FROM t',
    typeCast: typeCastWrapper(),
  },
  (err, rows) => {
    assert.ifError(err);
    assert.notEqual(rows[0].i.test, '😀');
  }
);

// JSON with encoding explicitly set to utf8
connection.query(
  {
    sql: 'SELECT * FROM t',
    typeCast: typeCastWrapper('utf8'),
  },
  (err, rows) => {
    assert.ifError(err);
    assert.equal(rows[0].i.test, '😀');
  }
);

connection.end();
</file>

<file path="test/unit/pool-cluster/test-connection-error-remove.test.cjs">
'use strict';

const { assert } = require('poku');
const portfinder = require('portfinder');
const common = require('../../common.test.cjs');
const mysql = require('../../../index.js');
const { exit } = require('node:process');
const process = require('node:process');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

// TODO: config poolCluster to work with MYSQL_CONNECTION_URL run
if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

if (process.platform === 'win32') {
  console.log('This test is known to fail on windows. FIXME: investi=gate why');
  exit(0);
}

const cluster = common.createPoolCluster({
  removeNodeErrorCount: 1,
});

let connCount = 0;

const server1 = mysql.createServer();
const server2 = mysql.createServer();

console.log('test pool cluster error remove');

portfinder.getPort((err, port) => {
  cluster.add('SLAVE1', { port: port + 0 });
  cluster.add('SLAVE2', { port: port + 1 });

  server1.listen(port + 0, (err) => {
    assert.ifError(err);

    server2.listen(port + 1, (err) => {
      assert.ifError(err);

      const pool = cluster.of('*', 'ORDER');
      let removedNodeId;

      cluster.on('remove', (nodeId) => {
        removedNodeId = nodeId;
      });

      pool.getConnection((err, connection) => {
        assert.ifError(err);

        assert.equal(connCount, 2);
        assert.equal(connection._clusterId, 'SLAVE2');
        assert.equal(removedNodeId, 'SLAVE1');
        assert.deepEqual(cluster._serviceableNodeIds, ['SLAVE2']);
        console.log('done');

        connection.release();

        cluster.end((err) => {
          assert.ifError(err);
          // throw error if no exit()
          exit();
          // server1.close();
          // server2.close();
        });
      });
    });
  });

  server1.on('connection', (conn) => {
    connCount += 1;
    conn.close();
  });

  server2.on('connection', (conn) => {
    connCount += 1;
    conn.serverHandshake({
      serverVersion: 'node.js rocks',
    });
  });
});
</file>

<file path="test/unit/pool-cluster/test-connection-order.test.cjs">
'use strict';

const { assert } = require('poku');
const common = require('../../common.test.cjs');
const process = require('node:process');

// TODO: config poolCluster to work with MYSQL_CONNECTION_URL run
if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

const cluster = common.createPoolCluster();

const order = [];

const poolConfig = common.getConfig();
cluster.add('SLAVE1', poolConfig);
cluster.add('SLAVE2', poolConfig);

const done = function () {
  assert.deepEqual(order, ['SLAVE1', 'SLAVE1', 'SLAVE1', 'SLAVE1', 'SLAVE1']);
  cluster.end();
  console.log('done');
};

const pool = cluster.of('SLAVE*', 'ORDER');

console.log('test pool cluster connection ORDER');

let count = 0;

function getConnection(i) {
  pool.getConnection((err, conn) => {
    assert.ifError(err);
    order[i] = conn._clusterId;
    conn.release();

    count += 1;

    if (count <= 4) {
      getConnection(count);
    } else {
      done();
    }
  });
}

getConnection(0);
</file>

<file path="test/unit/pool-cluster/test-connection-retry.test.cjs">
'use strict';

const { assert } = require('poku');
const portfinder = require('portfinder');
const common = require('../../common.test.cjs');
const mysql = require('../../../index.js');
const { exit } = require('node:process');
const process = require('node:process');

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

// TODO: config poolCluster to work with MYSQL_CONNECTION_URL run
if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

if (process.platform === 'win32') {
  console.log('This test is known to fail on windows. FIXME: investi=gate why');
  exit(0);
}

const cluster = common.createPoolCluster({
  canRetry: true,
  removeNodeErrorCount: 5,
});

let connCount = 0;

const server = mysql.createServer();

console.log('test pool cluster retry');

portfinder.getPort((err, port) => {
  cluster.add('MASTER', { port });

  server.listen(port + 0, (err) => {
    assert.ifError(err);

    cluster.getConnection('MASTER', (err, connection) => {
      assert.ifError(err);
      assert.equal(connCount, 2);
      assert.equal(connection._clusterId, 'MASTER');

      connection.release();

      cluster.end((err) => {
        assert.ifError(err);
        server.close();
      });
    });
  });

  server.on('connection', (conn) => {
    connCount += 1;

    if (connCount < 2) {
      conn.close();
    } else {
      conn.serverHandshake({
        serverVersion: 'node.js rocks',
      });
      conn.on('error', () => {
        // server side of the connection
        // ignore disconnects
      });
    }
  });
});
</file>

<file path="test/unit/pool-cluster/test-connection-rr.test.cjs">
'use strict';

const { assert } = require('poku');
const common = require('../../common.test.cjs');
const process = require('node:process');

// TODO: config poolCluster to work with MYSQL_CONNECTION_URL run
if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

const cluster = common.createPoolCluster();

const order = [];

const poolConfig = common.getConfig();
cluster.add('SLAVE1', poolConfig);
cluster.add('SLAVE2', poolConfig);

const done = function () {
  assert.deepEqual(order, ['SLAVE1', 'SLAVE2', 'SLAVE1', 'SLAVE2', 'SLAVE1']);
  cluster.end();
  console.log('done');
};

const pool = cluster.of('SLAVE*', 'RR');

console.log('test pool cluster connection RR');

let count = 0;

function getConnection(i) {
  pool.getConnection((err, conn) => {
    assert.ifError(err);
    order[i] = conn._clusterId;
    conn.release();

    count += 1;

    if (count <= 4) {
      getConnection(count);
    } else {
      done();
    }
  });
}

getConnection(0);
</file>

<file path="test/unit/pool-cluster/test-query.test.cjs">
'use strict';

const { assert } = require('poku');
const common = require('../../common.test.cjs');
const process = require('node:process');

// TODO: config poolCluster to work with MYSQL_CONNECTION_URL run
if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

const cluster = common.createPoolCluster();
const poolConfig = common.getConfig();

cluster.add('MASTER', poolConfig);
cluster.add('SLAVE1', poolConfig);
cluster.add('SLAVE2', poolConfig);

const connection = cluster.of('*');

console.log('test pool cluster connection query');

connection.query('SELECT 1', (err, rows) => {
  assert.ifError(err);
  assert.equal(rows.length, 1);
  assert.equal(rows[0]['1'], 1);
  assert.deepEqual(cluster._serviceableNodeIds, ['MASTER', 'SLAVE1', 'SLAVE2']);

  cluster.end();
  console.log('done');
});
</file>

<file path="test/unit/pool-cluster/test-remove-by-name.test.cjs">
'use strict';

const { assert } = require('poku');
const portfinder = require('portfinder');
const common = require('../../common.test.cjs');
const mysql = require('../../../index.js');
const process = require('node:process');

// TODO: config poolCluster to work with MYSQL_CONNECTION_URL run
if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

if (process.platform === 'win32') {
  console.log('This test is known to fail on windows. FIXME: investi=gate why');
  process.exit(0);
}

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

const cluster = common.createPoolCluster();
const server = mysql.createServer();

console.log('test pool cluster remove by name');

portfinder.getPort((err, port) => {
  cluster.add('SLAVE1', { port });
  cluster.add('SLAVE2', { port });

  server.listen(port + 0, (err) => {
    assert.ifError(err);

    const pool = cluster.of('SLAVE*', 'ORDER');

    pool.getConnection((err, conn) => {
      assert.ifError(err);
      assert.strictEqual(conn._clusterId, 'SLAVE1');

      conn.release();
      cluster.remove('SLAVE1');

      pool.getConnection((err, conn) => {
        assert.ifError(err);
        assert.strictEqual(conn._clusterId, 'SLAVE2');

        conn.release();
        cluster.remove('SLAVE2');

        pool.getConnection((err) => {
          assert.ok(err);
          assert.equal(err.code, 'POOL_NOEXIST');

          cluster.remove('SLAVE1');
          cluster.remove('SLAVE2');

          cluster.end((err) => {
            assert.ifError(err);
            server.close();
          });
        });
      });
    });
  });

  server.on('connection', (conn) => {
    conn.serverHandshake({
      serverVersion: 'node.js rocks',
    });
    conn.on('error', () => {
      // server side of the connection
      // ignore disconnects
    });
  });
});
</file>

<file path="test/unit/pool-cluster/test-remove-by-pattern.test.cjs">
'use strict';

const { assert } = require('poku');
const portfinder = require('portfinder');
const common = require('../../common.test.cjs');
const mysql = require('../../../index.js');
const process = require('node:process');

// TODO: config poolCluster to work with MYSQL_CONNECTION_URL run
if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

if (process.platform === 'win32') {
  console.log('This test is known to fail on windows. FIXME: investi=gate why');
  process.exit(0);
}

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

const cluster = common.createPoolCluster();
const server = mysql.createServer();

console.log('test pool cluster remove by pattern');

portfinder.getPort((err, port) => {
  cluster.add('SLAVE1', { port });
  cluster.add('SLAVE2', { port });

  server.listen(port + 0, (err) => {
    assert.ifError(err);

    const pool = cluster.of('SLAVE*', 'ORDER');

    pool.getConnection((err, conn) => {
      assert.ifError(err);
      assert.strictEqual(conn._clusterId, 'SLAVE1');

      conn.release();
      cluster.remove('SLAVE*');

      pool.getConnection((err) => {
        assert.ok(err);
        assert.equal(err.code, 'POOL_NOEXIST');

        cluster.remove('SLAVE*');
        cluster.remove('SLAVE2');

        cluster.end((err) => {
          assert.ifError(err);
          server.close();
        });
      });
    });
  });

  server.on('connection', (conn) => {
    conn.serverHandshake({
      serverVersion: 'node.js rocks',
    });
    conn.on('error', () => {
      // server side of the connection
      // ignore disconnects
    });
  });
});
</file>

<file path="test/unit/pool-cluster/test-restore-events.test.cjs">
'use strict';

const { assert } = require('poku');
const portfinder = require('portfinder');
const common = require('../../common.test.cjs');
const mysql = require('../../../index.js');
const process = require('node:process');

// TODO: config poolCluster to work with MYSQL_CONNECTION_URL run
if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

if (process.platform === 'win32') {
  console.log('This test is known to fail on windows. FIXME: investi=gate why');
  process.exit(0);
}

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

const cluster = common.createPoolCluster({
  canRetry: true,
  removeNodeErrorCount: 2,
  restoreNodeTimeout: 100,
});

let connCount = 0;
let offline = true;
let offlineEvents = 0;
let onlineEvents = 0;

const server = mysql.createServer();

console.log('test pool cluster restore events');

portfinder.getPort((err, port) => {
  cluster.add('MASTER', { port });

  server.listen(port + 0, (err) => {
    assert.ifError(err);

    cluster.on('offline', (id) => {
      assert.equal(++offlineEvents, 1);
      assert.equal(id, 'MASTER');
      assert.equal(connCount, 2);

      cluster.getConnection('MASTER', (err) => {
        assert.ok(err);
        assert.equal(err.code, 'POOL_NONEONLINE');

        offline = false;
      });

      setTimeout(() => {
        cluster.getConnection('MASTER', (err, conn) => {
          assert.ifError(err);
          conn.release();
        });
      }, 200);
    });

    cluster.on('online', (id) => {
      assert.equal(++onlineEvents, 1);
      assert.equal(id, 'MASTER');
      assert.equal(connCount, 3);

      cluster.end((err) => {
        assert.ifError(err);
        server.close();
      });
    });

    cluster.getConnection('MASTER', (err) => {
      assert.ok(err);
      assert.equal(err.code, 'PROTOCOL_CONNECTION_LOST');
      assert.equal(err.fatal, true);
      assert.equal(connCount, 2);
    });
  });

  server.on('connection', (conn) => {
    connCount += 1;

    if (offline) {
      conn.close();
    } else {
      conn.serverHandshake({
        serverVersion: 'node.js rocks',
      });
      conn.on('error', () => {
        // server side of the connection
        // ignore disconnects
      });
    }
  });
});
</file>

<file path="test/unit/pool-cluster/test-restore.test.cjs">
'use strict';

const { assert } = require('poku');
const portfinder = require('portfinder');
const common = require('../../common.test.cjs');
const mysql = require('../../../index.js');
const process = require('node:process');

// TODO: config poolCluster to work with MYSQL_CONNECTION_URL run
if (`${process.env.MYSQL_CONNECTION_URL}`.includes('pscale_pw_')) {
  console.log('skipping test for planetscale');
  process.exit(0);
}

if (process.platform === 'win32') {
  console.log('This test is known to fail on windows. FIXME: investi=gate why');
  process.exit(0);
}

// The process is not terminated in Deno
if (typeof Deno !== 'undefined') process.exit(0);

const cluster = common.createPoolCluster({
  canRetry: true,
  removeNodeErrorCount: 2,
  restoreNodeTimeout: 100,
});

let connCount = 0;
let offline = true;

const server = mysql.createServer();

console.log('test pool cluster restore');

portfinder.getPort((err, port) => {
  cluster.add('MASTER', { port });

  server.listen(port + 0, (err) => {
    assert.ifError(err);

    cluster.getConnection('MASTER', (err) => {
      assert.ok(err);
      assert.equal(err.code, 'PROTOCOL_CONNECTION_LOST');
      assert.equal(err.fatal, true);
      assert.equal(connCount, 2);

      cluster.getConnection('MASTER', (err) => {
        assert.ok(err);
        assert.equal(err.code, 'POOL_NONEONLINE');

        cluster._nodes.MASTER.errorCount = 3;

        offline = false;
      });

      setTimeout(() => {
        cluster.getConnection('MASTER', (err, conn) => {
          assert.ifError(err);
          conn.release();

          cluster.end((err) => {
            assert.ifError(err);
            server.close();
          });
        });
      }, 200);
    });
  });

  server.on('connection', (conn) => {
    connCount += 1;

    if (offline) {
      conn.close();
    } else {
      conn.serverHandshake({
        serverVersion: 'node.js rocks',
      });
      conn.on('error', () => {
        // server side of the connection
        // ignore disconnects
      });
    }
  });
});
</file>

<file path="test/unit/test-packet-parser.test.cjs">
'use strict';

const PacketParser = require('../../lib/packet_parser.js');
const Packet = require('../../lib/packets/packet.js');
const { Buffer } = require('node:buffer');
const { assert } = require('poku');

let pp;
let packets = [];
const handler = function (p) {
  packets.push(p);
};
function reset() {
  pp = new PacketParser(handler);
  packets = [];
}

function execute(str, verify) {
  reset();
  const buffers = str.split('|').map((sb) => sb.split(',').map(Number));
  for (let i = 0; i < buffers.length; ++i) {
    pp.execute(Buffer.from(buffers[i]));
  }
  verify();
}

function p123() {
  assert(packets.length === 1);
  assert(packets[0].length() === 14);
  assert(packets[0].sequenceId === 123);
}

function p120_121() {
  packets.forEach((p) => {
    p.dump;
  });
  assert(packets.length === 2);
  assert(packets[0].length() === 4);
  assert(packets[0].sequenceId === 120);
  assert(packets[1].length() === 4);
  assert(packets[1].sequenceId === 121);
}

execute('10,0,0,123,1,2,3,4,5,6,7,8,9,0', p123);
execute('10,0,0,123|1,2,3,4,5,6,7,8,9,0', p123);
execute('10,0,0|123,1,2,3,4,5,6,7,8,9,0', p123);
execute('10|0,0|123,1,2,3,4,5,6,7,8,9,0', p123);
execute('10,0,0,123,1|2,3,4,5,6|7,8,9,0', p123);
execute('10,0,0,123,1,2|,3,4,5,6|7,8,9,0', p123);

function p42() {
  assert(packets.length === 1);
  assert(packets[0].length() === 4);
  assert(packets[0].sequenceId === 42);
}

execute('0,0,0,42', p42);
execute('0|0,0,42', p42);
execute('0,0|0,42', p42);
execute('0,0|0|42', p42);
execute('0,0,0|42', p42);
execute('0|0|0|42', p42);
execute('0|0,0|42', p42);

// two zero length packets
execute('0,0,0,120,0,0,0,121', p120_121);
execute('0,0,0|120|0|0|0|121', p120_121);

const p122_123 = function () {
  assert(packets.length === 2);
  assert(packets[0].length() === 9);
  assert(packets[0].sequenceId === 122);
  assert(packets[1].length() === 10);
  assert(packets[1].sequenceId === 123);
};
// two non-zero length packets
execute('5,0,0,122,1,2,3,4,5,6,0,0,123,1,2,3,4,5,6', p122_123);
execute('5,0,0,122,1,2,3,4,5|6,0,0,123,1,2,3,4,5,6', p122_123);
execute('5,0,0,122,1,2,3,4|5|6|0,0,123,1,2,3,4,5,6', p122_123);
execute('5,0,0,122,1,2,3,4,5,6|0,0,123,1,2,3,4,5,6', p122_123);
execute('5,0,0,122,1,2,3,4,5,6,0|0,123,1,2,3,4,5,6', p122_123);
execute('5,0,0,122,1,2,3,4,5,6,0,0|123,1,2,3,4,5,6', p122_123);
execute('5,0,0,122,1,2,3,4,5,6,0,0,123|1,2,3,4,5,6', p122_123);
execute('5,0,0,122,1,2,3,4,5,6,0,0,123,1|2,3,4,5,6', p122_123);
execute('5,0,0,122,1,2,3,4,5,6,0,0,123,1|2,3|4,5,6', p122_123);

// test packet > 65536 lengt
// TODO combine with "execute" function

const length = 123000;
const pbuff = Buffer.alloc(length + 4);
pbuff[4] = 123;
pbuff[5] = 124;
pbuff[6] = 125;
const p = new Packet(144, pbuff, 4, pbuff.length - 4);
p.writeHeader(42);

function testBigPackets(chunks, cb) {
  const packets = [];
  const pp = new PacketParser((p) => {
    packets.push(p);
  });
  chunks.forEach((ch) => {
    pp.execute(ch);
  });
  cb(packets);
}

function assert2FullPackets(packets) {
  function assertPacket(p) {
    assert.equal(p.length(), length + 4);
    assert.equal(p.sequenceId, 42);
    assert.equal(p.readInt8(), 123);
    assert.equal(p.readInt8(), 124);
    assert.equal(p.readInt8(), 125);
  }
  // assert.equal(packets[0].buffer.slice(0, 8).toString('hex'), expectation);
  // assert.equal(packets[1].buffer.slice(0, 8).toString('hex'), expectation);
  assert.equal(packets.length, 2);
  assertPacket(packets[0]);
  assertPacket(packets[1]);
}

// 2 full packets in 2 chunks
testBigPackets([pbuff, pbuff], assert2FullPackets);

testBigPackets(
  [pbuff.slice(0, 120000), pbuff.slice(120000, 123004), pbuff],
  assert2FullPackets
);
const frameEnd = 120000;
testBigPackets(
  [
    pbuff.slice(0, frameEnd),
    Buffer.concat([pbuff.slice(frameEnd, 123004), pbuff]),
  ],
  assert2FullPackets
);
for (let frameStart = 1; frameStart < 100; frameStart++) {
  testBigPackets(
    [
      Buffer.concat([pbuff, pbuff.slice(0, frameStart)]),
      pbuff.slice(frameStart, 123004),
    ],
    assert2FullPackets
  );
}
</file>

<file path="tools/.eslintrc">
{
    "rules": {
        "no-console": "off"
    }
}
</file>

<file path="tools/create-db.js">
'use strict';

const conn = require('../test/common.test.cjs').createConnection({
  database: 'mysql',
});
conn.query('CREATE DATABASE IF NOT EXISTS test', (err) => {
  if (err) {
    console.log(err);
    return process.exit(-1);
  }

  conn.end();
});
</file>

<file path="tools/generate-charset-mapping.js">
'use strict';

const mysql = require('../index.js');

const conn = mysql.createConnection({
  user: 'mycause_dev',
  password: 'mycause',
});

const iconv = require('iconv-lite');

const charsets = [];

// TODO: add encodings missing in iconv-lite
// "dec8","hp8","swe7","keybcs2","utf32","geostd8"

// see also https://github.com/ashtuchkin/iconv-lite/issues/125
// https://en.wikipedia.org/wiki/Kamenick%C3%BD_encoding
// https://github.com/twitter/mysql/tree/master/sql/share/charsets
// https://github.com/sidorares/node-mysql2/pull/772

const mysql2iconv = {
  utf8: 'cesu8',
  utf8mb4: 'utf8',
  utf16le: 'utf16-le',
  ujis: 'eucjp',
  // need to check that this is correct mapping
  macce: 'macintosh', // Mac Central European
};

const missing = {};

conn.query('show collation', (err, res) => {
  console.log(res);
  res.forEach((r) => {
    const charset = r.Charset;
    const iconvCharset = mysql2iconv[charset] || charset; // if there is manuall mapping, override
    if (!iconv.encodingExists(iconvCharset)) {
      missing[iconvCharset] = 1;
    }
    charsets[r.Id] = iconvCharset;
  });
  //console.log(JSON.stringify(missing, 4, null));
  //console.log(JSON.stringify(charsets, 4, null));
  for (let i = 0; i < charsets.length; i += 8) {
    console.log(`  '${charsets.slice(i, i + 8).join("', '")}',`);
  }
});

conn.end();
</file>

<file path="tools/parse-field.js">
'use strict';

const Packet = require('./lib/packets/packet.js');
const Packets = require('./lib/packets/index.js');

const compileParser = require('./lib/compile_binary_parser.js');

let fields = [];

function parseC(s) {
  const raw = Buffer.from(s, 'hex');
  const p = new Packet(0, raw, 0, raw.end);
  const c = new Packets.ColumnDefinition(p);
  fields.push(c);
  return c.inspect();
}

console.log(
  parseC(
    '036465660000001a62696c6c696e675f69735f7069636b75705f6c6f636174696f6e000c3f0001000000030100000000'
  )
);
console.log(
  parseC(
    '036465660d6e616d7368695f6465765f6165087368697070696e671373616c65735f6f726465725f61646472657373117368697070696e675f61646472657373310861646472657373310c2100fd020000fd0010000000'
  )
);
console.log(
  parseC(
    '036465660d6e616d7368695f6465765f6165087368697070696e671373616c65735f6f726465725f616464726573731b7368697070696e675f666b5f7069636b75705f6c6f636174696f6e12666b5f7069636b75705f6c6f636174696f6e0c3f000a000000030000000000'
  )
);
console.log(
  parseC(
    '036465660000001a62696c6c696e675f69735f7069636b75705f6c6f636174696f6e000c3f0001000000030100000000'
  )
);

compileParser(fields, {}, { debug: true });

fields = [];

console.log(
  parseC(
    '036465660000001a62696c6c696e675f69735f7069636b75705f6c6f636174696f6e000c3f0001000000088100000000'
  )
);
console.log(
  parseC(
    '036465660d6e616d7368695f6465765f6165087368697070696e671373616c65735f6f726465725f61646472657373117368697070696e675f61646472657373310861646472657373310c2100fd020000fd0010000000'
  )
);
console.log(
  parseC(
    '036465660d6e616d7368695f6465765f6165087368697070696e671373616c65735f6f726465725f616464726573731b7368697070696e675f666b5f7069636b75705f6c6f636174696f6e12666b5f7069636b75705f6c6f636174696f6e0c3f000a000000030000000000'
  )
);
console.log(
  parseC(
    '036465660000001a62696c6c696e675f69735f7069636b75705f6c6f636174696f6e000c3f0001000000088100000000'
  )
);

compileParser(fields, {}, { debug: true });
</file>

<file path="tools/parse-row.js">
'use strict';

const Packet = require('./lib/packets/packet.js');
const Packets = require('./lib/packets/index.js');

const SAParser = (function () {
  return function BinaryRow(packet) {
    packet.readInt8(); // statusByte
    const nullBitmaskByte0 = packet.readInt8();
    // "billing_is_pickup_location": LONGLONG
    console.log('Null bitmap:', nullBitmaskByte0);
    this['billing_is_pickup_location'] = packet.readSInt64();
    // "shipping_address1": VAR_STRING
    if (nullBitmaskByte0 & 8) this['shipping_address1'] = null;
    else this['shipping_address1'] = packet.readLengthCodedString();
    // "shipping_fk_pickup_location": LONG
    if (nullBitmaskByte0 & 16) this['shipping_fk_pickup_location'] = null;
    else this['shipping_fk_pickup_location'] = packet.readSInt32();
    // "billing_is_pickup_location": LONGLONG
    debugger; // eslint-disable-line no-debugger
    this['billing_is_pickup_location'] = packet.readSInt64();
  };
})();

function parse(s) {
  const raw = Buffer.from(s, 'hex');
  const p = new Packet(0, raw, 0, raw.end);
  return new SAParser(p);
}

function parseC(s) {
  const raw = Buffer.from(s, 'hex');
  const p = new Packet(0, raw, 0, raw.end);
  new Packets.ColumnDefinition(p);
}

console.log(
  parseC(
    '036465660000001a62696c6c696e675f69735f7069636b75705f6c6f636174696f6e000c3f0001000000030100000000'
  )
);
console.log(
  parse('0010010000001754657374204176656e756520426c64673a34383137333601000000')
);
console.log(
  parse('0010000000001754657374204176656e756520426c64673a35353830333200000000')
);
</file>

<file path="tools/wait-up.js">
'use strict';

require('../test/common.test.cjs').waitDatabaseReady(() => {
  console.log('ready!');
});
</file>

<file path="tsconfig.json">
{
  "include": ["index.d.ts", "promise.d.ts", "typings"],
  "exclude": ["node_modules", "test/tsc-build"],
  "compilerOptions": {
    "target": "es2016",
    "alwaysStrict": true,
    "noUnusedLocals": true,
    "module": "commonjs",
    "declaration": true,
    "strict": true,
    "noImplicitAny": true,
    "moduleResolution": "node",
    "removeComments": false,
    "noUnusedParameters": true,
    "isolatedModules": true
  }
}
</file>

<file path="website/.gitignore">
# Dependencies
/node_modules

# Production
/build

# Generated files
.docusaurus
.cache-loader
i18n/**/docusaurus-theme-classic/navbar.json
i18n/**/code.json

# Misc
.DS_Store
.env.local
.env.development.local
.env.test.local
.env.production.local

npm-debug.log*
yarn-debug.log*
yarn-error.log*
</file>

<file path="website/.prettierignore">
/build
/.docusaurus
/.cache-loader
# /**/*.mdx
</file>

<file path="website/.prettierrc">
{
  "printWidth": 80,
  "tabWidth": 2,
  "semi": true,
  "singleQuote": true,
  "quoteProps": "as-needed",
  "jsxSingleQuote": true,
  "trailingComma": "es5",
  "bracketSpacing": true,
  "bracketSameLine": false,
  "arrowParens": "always",
  "proseWrap": "preserve",
  "htmlWhitespaceSensitivity": "css",
  "endOfLine": "auto",
  "embeddedLanguageFormatting": "auto",
  "singleAttributePerLine": false
}
</file>

<file path="website/.purc.json">
{
  "overrides": {
    "eslint": {
      "target": "minor"
    }
  }
}
</file>

<file path="website/babel.config.js">
module.exports = {
  presets: [require.resolve('@docusaurus/core/lib/babel/preset')],
};
</file>

<file path="website/biome.json">
{
  "$schema": "https://biomejs.dev/schemas/1.9.4/schema.json",
  "files": {
    "include": ["**/**"],
    "ignore": ["build", ".docusaurus", ".cache-loader"]
  },
  "organizeImports": {
    "enabled": false
  },
  "linter": {
    "enabled": true,
    "rules": {
      "all": true,
      "a11y": {
        "all": true
      },
      "complexity": {
        "noExcessiveCognitiveComplexity": "off"
      },
      "correctness": {
        "all": true,
        "useImportExtensions": "error",
        "noNodejsModules": "off",
        "noUndeclaredDependencies": "off"
      },
      "nursery": {
        "all": true,
        "useImportRestrictions": "off",
        "noProcessEnv": "off",
        "noCommonJs": "off",
        "noSecrets": "off",
        "useExplicitType": "off"
      },
      "performance": {
        "all": true,
        "noAccumulatingSpread": "error",
        "noBarrelFile": "error",
        "noDelete": "error",
        "noReExportAll": "error",
        "useTopLevelRegex": "off"
      },
      "security": {
        "all": true,
        "noGlobalEval": "error"
      },
      "suspicious": {
        "all": true,
        "noAsyncPromiseExecutor": "error",
        "useAwait": "error",
        "useIsArray": "error",
        "noEmptyBlockStatements": "off",
        "noConsoleLog": "off",
        "noMisplacedAssertion": "off",
        "noConsole": "off",
        "noReactSpecificProps": "off",
        "noArrayIndexKey": "off"
      },
      "style": {
        "all": true,
        "noNonNullAssertion": "off",
        "useNamingConvention": "off",
        "useNodeAssertStrict": "off",
        "noNamespaceImport": "off",
        "useBlockStatements": "off",
        "noDefaultExport": "off"
      }
    }
  }
}
</file>

<file path="website/docs/acknowledgements.mdx">
# Acknowledgements

[mysql-native]: https://github.com/sidorares/nodejs-mysql-native
[sidorares]: https://github.com/sidorares
[node-mysql]: https://github.com/mysqljs/mysql
[TooTallNate]: https://gist.github.com/TooTallNate
[starttls.js]: https://gist.github.com/TooTallNate/848444
[node-mariasql]: https://github.com/mscdex/node-mariasql
[contributors]: https://github.com/sidorares/node-mysql2/graphs/contributors

- Internal protocol is written by [@sidorares][sidorares] [MySQL-Native][mysql-native].
- Constants, SQL parameters interpolation, Pooling, `ConnectionConfig` class taken from [Node MySQL][node-mysql].
- SSL upgrade code based on [@TooTallNate][TooTallNate] [code][starttls.js].
- Secure connection / compressed connection api flags compatible to [MariaSQL][node-mariasql] client.
- [Contributors][contributors].
</file>

<file path="website/docs/api-and-configurations.mdx">
# API and Configuration

[node-mysql]: https://github.com/mysqljs/mysql

MySQL2 is mostly API compatible with [Node MySQL][node-mysql].

One known incompatibility is that `DECIMAL` values are returned as strings whereas in [Node MySQL][node-mysql] they are returned as numbers. This includes the result of `SUM()` and `AVG()` functions when applied to `INTEGER` arguments. This is done deliberately to avoid loss of precision - see https://github.com/sidorares/node-mysql2/issues/935.

:::info
If you find any other incompatibility with [Node MySQL][node-mysql], Please report via Issue tracker. We will fix reported incompatibility on priority basis.
:::
</file>

<file path="website/docs/contributing/00-index.mdx">
---
slug: /contributing
title: MySQL2
---

import { PageTitle } from '@site/src/components/PageTitle';

<PageTitle title='Contributing' />

# Contributing

Want to improve something in **MySQL2**?
Please check [Contributing.md](https://github.com/sidorares/node-mysql2/blob/master/Contributing.md) for detailed instruction on how to get started.
</file>

<file path="website/docs/contributing/website.mdx">
---
title: Documentation Site
---

import { FAQ } from '@site/src/components/FAQ';
import { History } from '@site/src/components/History';
import { Stability } from '@site/src/components/Stability';
import { ExternalCodeEmbed } from '@site/src/components/ExternalCodeEmbed';

# Website Contributing Guidelines

This website is built using [Docusaurus 3](https://docusaurus.io/), a modern static website generator.

<hr />

## Environment

You will need these tools installed on your system:

- [Node.js (18.x or higher)](https://nodejs.org/)

<hr />

## Development

1. Fork the [MySQL2](https://github.com/sidorares/node-mysql2) repository.
2. Download your forked repository locally. The website's workspace is the "_website_" directory in **node-mysql2** root.
3. Create a new branch from `master` (optional).
4. Run `cd website` to enter the website workspace.
5. Run `npm ci` to install the dependecies from _package-lock.json_.
6. Run `npm start` to starting the local development.

> It will start a local development server and opens up a browser window. Most changes are reflected live without having to restart the server.

For **Docusaurus** complete documentation, please [see here](https://docusaurus.io/docs).

<FAQ title='CLI example'>

```bash
git clone https://github.com/sidorares/node-mysql2.git
git checkout -b website # optional
cd /path-to/node-mysql2/website
npm ci
npm start
```

</FAQ>

Documentation is auto-generated from **MDX** files placed in these directories:

- _./docs/documentation_
- _./docs/examples_
- _./docs/faq_

:::danger Caution
Note that the website has its own _package.json_.

Please, do not install dependencies for the website in **node-mysql2** root.
:::

<hr />

## Extras Components

Every extra component is thoroughly documented with complete typings descriptions.

> [**Docusaurus Markdown Features:**](https://docusaurus.io/docs/markdown-features) The MDX compiler transforms Markdown files to React components, and allows you to use JSX in your Markdown content. This enables you to easily interleave React components within your content, and create delightful learning experiences.

### History

The `History` component displays version changes in a table format, listing version numbers alongside their changes.

{/* prettier-ignore-start */}
```tsx
import { History } from '@site/src/components/History';

<History
  records={[
    {
      version: '1.0.0',
      changes: ['Some change message.'],
    },
  ]}
/>
```
{/* prettier-ignore-end */}

:::tip
You can also utilize React components in the `changes` option.
:::

<FAQ title='Example'>
  <History
    records={[
      {
        version: '1.0.0',
        changes: ['Some change message.'],
      },
    ]}
  />
</FAQ>

<hr />

### Stability

See the [Stability Badges](/docs/stability-badges) for more detais.

{/* prettier-ignore-start */}
```tsx
import { Stability } from '@site/src/components/Stability';

<Stability level={2} />
<Stability level={2} message='Some message' />
```
{/* prettier-ignore-end */}

:::tip
You can also utilize React components in the `message` option.
:::

Available levels: `0`, `1`, `1.1`, `1.2`, `2` and `3`.

<FAQ title='Example'>
  <Stability level={2} />
  <Stability level={2} message='Some message.' />
</FAQ>

<hr />

### FAQ

{/* prettier-ignore-start */}
```tsx
import { FAQ } from '@site/src/components/FAQ';

<FAQ title='Title'>

  > Some markdown (**MDX**) content.

</FAQ>
```
{/* prettier-ignore-end */}

:::tip

- The **FAQ** component can be utilized in any section or page.
- Code blocks are compatible and can be used within the **FAQ** component.

:::

<FAQ title='Example'>
  <FAQ title='Title'>

    > Some markdown (**MDX**) content.

  </FAQ>
</FAQ>

<hr />

### ExternalCodeEmbed

{/* prettier-ignore-start */}
```tsx
import { ExternalCodeEmbed } from '@site/src/components/ExternalCodeEmbed';

<ExternalCodeEmbed
  url='https://github.com/sidorares/node-mysql2/blob/75b05f0765c9edd0c0be8f18d85be05618770cca/.prettierrc'
  language='json'
/>

<ExternalCodeEmbed
  url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/tools/parse-row.js'
  language='js'
  extractMethod='parseC'
  methodType='function'
/>
```
{/* prettier-ignore-end */}

<FAQ title='Example'>
  <ExternalCodeEmbed
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/.prettierrc'
    language='json'
  />

  <ExternalCodeEmbed
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/tools/parse-row.js'
    language='js'
    extractMethod='parseC'
    methodType='function'
  />
</FAQ>

<hr />

## Running Tests

```bash
npm run test
```

<FAQ title='Check Prettier and ESLint rules for compliance'>

```bash
npm run lintcheck
```

- Included in the **GitHub Actions** workflow.

</FAQ>
<FAQ title='Check for typings errors'>

<Stability
  level={1}
  message={
    <>
      Checks for <strong>MDX</strong> components are missing.
    </>
  }
/>

```bash
npm run typecheck
```

- Included in the **GitHub Actions** workflow.

</FAQ>
<FAQ title='Clear and build the website'>

```bash
npm run clear
npm run build
```

- Included in the **GitHub Actions** workflow.

</FAQ>
<FAQ title='Fix issues from Prettier and ESLint rules' open>

```bash
npm run lint
```

- To prevent lint issues, it is recommended to execute this command before creating your commit.
- Not included in the **GitHub Actions** workflow.

</FAQ>
</file>

<file path="website/docs/documentation/00-index.mdx">
---
slug: /documentation
title: Introduction
---

import { PageTitle } from '@site/src/components/PageTitle';

<PageTitle title='Documentation' />

# Documentation

[node-mysql]: https://github.com/mysqljs/mysql

MySQL2 aims to be a drop in replacement for [Node MySQL][node-mysql].

:::note
_If you see any API incompatibilities with [Node MySQL][node-mysql], please report via github issue._
:::

Not only **MySQL2** offers better performance over [Node MySQL][node-mysql], we also support these additional features:

- [Prepared Statements](/docs/documentation/prepared-statements)
- [Promise Wrapper](/docs/documentation/promise-wrapper)
- [Authentication Switch](/docs/documentation/authentication-switch)
- [More Features](/docs/documentation/extras)
- [MySQL Server](/docs/documentation/mysql-server)
- Pooling
- [SSL](/docs/documentation/ssl)
- MySQL Compression
- Binary Log Protocol Client

<hr />

## Examples

Please check these [examples](/docs/examples) for **MySQL2**.

<hr />

## Known incompatibilities with [Node MySQL][node-mysql]

- `zeroFill` flag is ignored in type conversion.
  You need to check corresponding field's zeroFill flag and convert to string manually if this is of importance to you.

- `DECIMAL` and `NEWDECIMAL` types always returned as `string` unless you pass this config option:

```js
{
  decimalNumbers: true,
}
```

:::note
This option could lose precision on the number as Javascript Number is a Float!
:::

- By default, the `JSON` type is always returned parsed into an object. However, you can modify this behavior by specifying the following configuration:

```js
{
  jsonStrings: true,
}
```

<hr />

## Other Resources

- [Wire protocol documentation](https://dev.mysql.com/doc/internals/en/client-server-protocol.html)
- [Node MySQL][node-mysql] - Most popular node.js mysql client library
- [node-mariasql](https://github.com/mscdex/node-mariasql/) - Bindings to libmariasql. One of the fastest clients
- [node-libmysqlclient](https://github.com/Sannis/node-mysql-libmysqlclient) - Bindings to libmysqlclient
- [go-mysql](https://github.com/siddontang/go-mysql) - MySQL Go client (prepared statements, binlog protocol, server)

<hr />

## Benchmarks

- https://gist.github.com/sidorares/ffe9ee9c423f763e3b6b
- `npm run benchmarks`
- [node-mysql-benchmarks](https://github.com/mscdex/node-mysql-benchmarks)
- try to run example [benchmarks](https://github.com/sidorares/node-mysql2/tree/master/benchmarks) on your system
</file>

<file path="website/docs/documentation/authentication-switch.mdx">
# Authentication Switch Request

During the connection phase the server may ask the client to switch to a different auth method.
If the `authPlugins` connection config option is set, it must be an object where each key
is the name of a potential authentication plugin requested by the server, and the corresponding
value must be a function that optionally receives the connection config options and returns
another function, which in turn, optionally receives the switch request data.

The plugin is loaded with a `({user,password,...})` signature, and each call has a `(pluginData)`
signature. Each call should make the plugin return any additional authentication data (`Buffer`)
that should be sent back to the server, either synchronously or asynchronously using a `Promise`,
or should yield an error accordingly.

Example: (imaginary `ssh-key-auth` plugin) pseudo code

```js
const conn = mysql.createConnection({
  user: 'test_user',
  password: 'test',
  database: 'test_database',
  authPlugins: {
    'ssh-key-auth': function ({ password }) {
      return function (pluginData) {
        return getPrivate(key)
          .then((key) => {
            const response = encrypt(key, password, pluginData);
            // continue handshake by sending response data
            return response;
          })
          .catch((err) => {
            // throw error to propagate error to connect/changeUser handlers
          });
      };
    },
  },
});
```

There is also a deprecated API where if a `authSwitchHandler` connection config option is set
it must be a function that receives switch request data and responds via a callback. In this case,
the first invocation always has a `({pluginName, pluginData})` signature, following calls - `({pluginData})`.
The client replies with an opaque blob matching the requested plugin via `callback(null, data: Buffer)`.

```js
const conn = mysql.createConnection({
  user: 'test_user',
  password: 'test',
  database: 'test_database',
  authSwitchHandler: function ({ pluginName, pluginData }, cb) {
    if (pluginName === 'ssh-key-auth') {
      getPrivateKey((key) => {
        const response = encrypt(key, pluginData);
        // continue handshake by sending response data
        // respond with error to propagate error to connect/changeUser handlers
        cb(null, response);
      });
    } else {
      const err = new Error(
        `Unknown AuthSwitchRequest plugin name ${pluginName}`
      );
      err.fatal = true;
      cb(err);
    }
  },
});
```

The initial handshake is always performed using `mysql_native_password` plugin. This will be possible to override in future versions.

Note that if the `mysql_native_password` method is requested it will be handled internally according
to [Authentication::Native41](https://dev.mysql.com/doc/internals/en/secure-password-authentication.html#packet-Authentication::Native41)
and no `authPlugins` function or the `authSwitchHandler` will be invoked.

These MAY be called multiple times if the plugin algorithm requires multiple roundtrips of data
exchange between client and server.

## Multi-factor authentication

If the user requires multi-factor authentication in the server, the client will receive a `AuthNextFactor`
request, which is similar in structure to the regular authentication switch request and contains the name
and possible initial data for the additional authentication factor plugin (up to 3). Additional passwords
can be provided using the connection config options - `password2` and `password3`. Again, for each
authentication factor, multiple roundtrips of data exchange can be required by the plugin algoritm.

```js
const conn = mysql.createConnection({
  user: 'test_user',
  password: 'secret1',
  password2: 'secret2',
  password3: 'secret3',
  database: 'test_database',
  authPlugins: {
    // password1 === password
    'auth-plugin1': function ({ password1 }) {
      return function (serverPluginData) {
        return clientPluginData(password1, serverPluginData);
      };
    },
    'auth-plugin2': function ({ password2 }) {
      return function (serverPluginData) {
        return clientPluginData(password2, serverPluginData);
      };
    },
    'auth-plugin3': function ({ password3 }) {
      return function (serverPluginData) {
        return clientPluginData(password3, serverPluginData);
      };
    },
  },
});
```
</file>

<file path="website/docs/documentation/connect-on-cloudflare.mdx">
import { History } from '@site/src/components/History';

# Cloudflare Workers

<History
  records={[
    {
      version: '3.13.0',
      changes: [
        <>
          Support for <em>non-eval</em> parsers by using{' '}
          <strong>disableEval</strong> option.
        </>,
      ],
    },
  ]}
/>

## Prerequisites

- A [Cloudflare](https://dash.cloudflare.com/sign-up) account.
- [Wrangler](https://developers.cloudflare.com/workers/wrangler/) installed.
- **MySQL2** version `3.13.0` or higher.

To learn how to create a **Cloudflare Worker** project, please refer to [**Cloudflare Workers Documentation**](https://developers.cloudflare.com/workers/get-started/guide/).

## Setup

### Wrangler

**MySQL2** relies on **Node.js** modules, such as `net`, `events`, `stream`, `tls`, etc. You can enable **Node.js** compatibility for **Cloudflare Workers** by using the `"nodejs_compat"` flag through the `wrangler.jsonc` file:

```json
{
  "compatibility_flags": ["nodejs_compat"]
}
```

:::important
The minimum compatibility date is `2025-02-24`, for example:

```json
{
  "compatibility_date": "2025-02-24",
  "compatibility_flags": ["nodejs_compat"]
}
```

:::

### MySQL2 connection

**MySQL2** uses a code generation-based parser for performance by default, but since **Cloudflare Workers** don't offer support for evaluations, you can disable it by using the `disableEval` option:

```ts
import { createConnection } from 'mysql2/promise';

export default {
  async fetch(): Promise<Response> {
    const conn = await createConnection({
      host: 'localhost',
      user: 'root',
      database: 'test',
      // highlight-start
      disableEval: true,
      // highlight-end
    });

    const [results] = await conn.query('SHOW TABLES;');

    return new Response(JSON.stringify(results));
  },
} satisfies ExportedHandler<Env>;
```

:::tip
For required **SSL** connections, it is recommended to use the [**Cloudflare Hyperdrive**](https://developers.cloudflare.com/hyperdrive/) connection pool.
:::
</file>

<file path="website/docs/documentation/extras.mdx">
# Extra Features

## Named placeholders

You can use named placeholders for parameters by setting `namedPlaceholders` config value or query/execute time option. Named placeholders are converted to unnamed `?` on the client (mysql protocol does not support named parameters). If you reference parameter multiple times under the same name it is sent to server multiple times. Unnamed placeholders can still be used by providing the values as an array instead of an object.

```js
connection.config.namedPlaceholders = true;
connection.execute('select :x + :y as z', { x: 1, y: 2 }, (err, rows) => {
  // statement prepared as "select ? + ? as z" and executed with [1,2] values
  // rows returned: [ { z: 3 } ]
});

connection.execute('select :x + :x as z', { x: 1 }, (err, rows) => {
  // select ? + ? as z, execute with [1, 1]
});

connection.query('select :x + :x as z', { x: 1 }, (err, rows) => {
  // query select 1 + 1 as z
});

// unnamed placeholders are still valid if the values are provided in an array
connection.query('select ? + ? as z', [1, 1], (err, rows) => {
  // query select 1 + 1 as z
});
```

## Receiving rows as array of columns instead of hash with column name as key:

```js
const options = { sql: 'select A,B,C,D from foo', rowsAsArray: true };
connection.query(options, (err, results) => {
  /* results will be an array of arrays like this now:
  [[
     'field A value',
     'field B value',
     'field C value',
     'field D value',
  ], ...]
  */
});
```

## Sending tabular data with 'load infile' and local stream:

In addition to sending local fs files you can send any stream using `infileStreamFactory` query option. If set, it has to be a function that return a readable stream. It gets file path from query as a parameter.

Note: starting from version 2.0 `infileStreamFactory` is required parameter for `LOAD DATA LOCAL INFILE`. Response from server indicates that it wants access to a local file and no `infileStreamFactory` option is provided the query ends with error.

```js
// local file
connection.query(
  'LOAD DATA LOCAL INFILE "/tmp/data.csv" INTO TABLE test FIELDS TERMINATED BY ? (id, title)',
  onInserted1
);
// local stream
const sql =
  'LOAD DATA LOCAL INFILE "mystream" INTO TABLE test FIELDS TERMINATED BY ? (id, title)';
connection.query(
  {
    sql: sql,
    infileStreamFactory: function (path) {
      return getStream();
    },
  },
  onInserted2
);
```

The `infileStreamFactory` option may also be set at a connection-level:

```js
const fs = require('fs');
const mysql = require('mysql2');

const connection = mysql.createConnection({
  user: 'test',
  database: 'test',
  infileStreamFactory: (path) => {
    // Validate file path
    const validPaths = ['/tmp/data.csv'];
    if (!validPaths.includes(path)) {
      throw new Error(
        `invalid file path: ${path}: expected to be one of ${validPaths.join(
          ','
        )}`
      );
    }
    return fs.createReadStream(path);
  },
});

connection.query(
  'LOAD DATA LOCAL INFILE "/tmp/data.csv" INTO TABLE test',
  onInserted
);
```

## Connecting using custom stream:

```js
const net = require('net');
const mysql = require('mysql2');
const shape = require('shaper');
const connection = mysql.createConnection({
  user: 'test',
  database: 'test',
  stream: net.connect('/tmp/mysql.sock').pipe(shape(10)), // emulate 10 bytes/sec link
});
connection.query('SELECT 1+1 as test1', console.log);
```

`stream` also can be a function. In that case function result has to be duplex stream, and it is used for connection transport. This is required if you connect pool using custom transport as new pooled connection needs new stream. [Example](https://github.com/sidorares/node-mysql2/issues/80) connecting over socks5 proxy:

```js
const mysql = require('mysql2');
const SocksConnection = require('socksjs');
const pool = mysql.createPool({
  database: 'test',
  user: 'foo',
  password: 'bar',
  stream: function (cb) {
    const newStream = new SocksConnection(
      { host: 'remote.host', port: 3306 },
      { host: 'localhost', port: 1080 }
    );
    cb(null, newStream);
  },
});
```

In addition to password `createConnection()`, `createPool()` and `changeUser()` accept `passwordSha1` option. This is useful when implementing proxies as plaintext password might be not available.
</file>

<file path="website/docs/documentation/mysql-server.mdx">
# MySQL Server API

## Server

- `createServer()` - creates server instance
- `Server.listen` - listen port / unix socket (same arguments as [net.Server.listen](https://nodejs.org/api/net.html#net_server_listen_port_host_backlog_callback))

### Events

- **connect**
  - new incoming connection.

<hr />

## Connection

- `serverHandshake({ serverVersion, protocolVersion, connectionId, statusFlags, characterSet, capabilityFlags })`
  - send server handshake initialisation packet, wait handshake response and start listening for commands
- `writeOk({ affectedRows: num, insertId: num })`
  - send [OK packet](https://dev.mysql.com/doc/internals/en/overview.html#packet-OK_Packet) to client
- `writeEof(warnings, statusFlags)`
  - send EOF packet
- `writeTextResult(rows, fields)`
  - write query result to client. Rows and fields are in the same format as in `connection.query` callback.
- `writeColumns(fields)`
  - write fields + EOF packets.
- `writeTextRow(row)`
  - write array (not hash!) of values as result row
- **TODO:** binary protocol

### Events

Every command packet received by the server will be emitted as a **packet** event with the parameters:

- **packet:** Packet
  - The packet itself
- **knownCommand:** boolean
  - is this command known to the server
- **\*commandCode:** number
  - the parsed command code (first byte)

In addition special events are emitted for [commands](https://dev.mysql.com/doc/internals/en/text-protocol.html) received from the client. If no listener is present a fallback behavior will be invoked.

- `quit()`
  - Default: close the connection
- `init_db(schemaName: string)`
  - Default: return OK
- `query(sql: string)`
  - Please attach a listener to this. Default: return HA_ERR_INTERNAL_ERROR
- `field_list(table: string, fields: string)`
  - Default: return ER_WARN_DEPRECATED_SYNTAX
- `ping()` - Default: return OK
</file>

<file path="website/docs/documentation/prepared-statements.mdx">
---
tags: [Prepared Statements, execute]
---

# Prepared Statements

## Automatic creation, cached and re-used by connection

Similar to `connection.query()`.

```js
connection.execute('select 1 + ? + ? as result', [5, 6], (err, rows) => {
  // rows: [ { result: 12 } ]
  // internally 'select 1 + ? + ? as result' is prepared first. On subsequent calls cached statement is re-used
});

// close cached statement for 'select 1 + ? + ? as result'. noop if not in cache
connection.unprepare('select 1 + ? + ? as result');
```

Note that `connection.execute()` will cache the prepared statement for better performance, remove the cache with `connection.unprepare()` when you're done.

## Manual prepare / execute

Manually prepared statements doesn't comes with LRU cache and SHOULD be closed using `statement.close()` instead of `connection.unprepare()`.

```js
connection.prepare('select ? + ? as tests', (err, statement) => {
  // statement.parameters - array of column definitions, length === number of params, here 2
  // statement.columns - array of result column definitions. Can be empty if result schema is dynamic / not known
  // statement.id
  // statement.query

  statement.execute([1, 2], (err, rows, columns) => {
    // -> [ { tests: 3 } ]
  });

  // don't use connection.unprepare(), it won't work!
  // note that there is no callback here. There is no statement close ack at protocol level.
  statement.close();
});
```

Note that you should not use statement after connection reset (`changeUser()` or disconnect). Statement scope is connection, you need to prepare statement for each new connection in order to use it.

## Configuration

`maxPreparedStatements` : We keep the cached statements in a [lru-cache](https://github.com/isaacs/node-lru-cache). Default size is `16000` but you can use this option to override it. Any statements that are dropped from cache will be `closed`.

## Serialization of bind parameters

The bind parameter values passed to `execute` are serialized JS -> MySQL as:

- `null` -> `NULL`
- `number` -> `DOUBLE`
- `boolean` -> `TINY` (0 for false, 1 for true)
- `object` -> depending on prototype:
  - `Date` -> `DATETIME`
  - `JSON` like object - `JSON`
  - `Buffer` -> `VAR_STRING`
- Other -> `VAR_STRING`

Passing in `undefined` or a `function` will result in an error.

## Prepared Statements Helper

MySQL2 provides `execute` helper which will prepare and query the statement. You can also manually prepare / unprepare statement with `prepare` / `unprepare` methods.

```js
connection.execute(
  'select ?+1 as qqq, ? as rrr, ? as yyy',
  [1, null, 3],
  (err, rows, fields) => {
    console.log(err, rows, fields);
    connection.execute(
      'select ?+1 as qqq, ? as rrr, ? as yyy',
      [3, null, 3],
      (err, rows, fields) => {
        console.log(err, rows, fields);
        connection.unprepare('select ?+1 as qqq, ? as rrr, ? as yyy');
        connection.execute(
          'select ?+1 as qqq, ? as rrr, ? as yyy',
          [3, null, 3],
          (err, rows, fields) => {
            console.log(err, rows, fields);
          }
        );
      }
    );
  }
);
```

## Examples

For Prepared Statements examples, please see [here](/docs/examples/queries/prepared-statements).
</file>

<file path="website/docs/documentation/promise-wrapper.mdx">
# Promise Wrappers

In addition to errback interface there is thin wrapper to expose Promise-based api

## Basic Promise

```js
/* eslint-env es6 */
const mysql = require('mysql2/promise'); // or require('mysql2').createConnectionPromise
mysql
  .createConnection({
    /* same parameters as for non-promise createConnection */
  })
  .then((conn) => conn.query('select foo from bar'))
  .then(([rows, fields]) => console.log(rows[0].foo));
```

```js
const pool = require('mysql2/promise').createPool({}); // or require('mysql2').createPoolPromise({}) or require('mysql2').createPool({}).promise()
pool
  .getConnection()
  .then((conn) => {
    const res = conn.query('select foo from bar');
    conn.release();
    return res;
  })
  .then((result) => {
    console.log(result[0][0].foo);
  })
  .catch((err) => {
    console.log(err); // any of connection time or query time errors from above
  });
```

## ES7 Async Await

```js
async function example1() {
  const mysql = require('mysql2/promise');
  const conn = await mysql.createConnection({ database: test });
  const [rows, fields] = await conn.execute('select ?+? as sum', [2, 2]);
  await conn.end();
}

async function example2() {
  const mysql = require('mysql2/promise');
  const pool = mysql.createPool({ database: test });
  // execute in parallel, next console.log in 3 seconds
  await Promise.all([
    pool.query('select sleep(2)'),
    pool.query('select sleep(3)'),
  ]);
  console.log('3 seconds after');
  await pool.end();
}
```

## With [CO](https://github.com/tj/co)

```js
const mysql = require('mysql2');
const co = require('co');
co(function* () {
  const c = yield mysql.createConnectionPromise({
    user: 'root',
    namedPlaceholders: true,
  });
  const rows = yield c.query('show databases');
  console.log(rows);
  console.log(yield c.execute('select 1+:toAdd as qqq', { toAdd: 10 }));
  yield c.end();
});
```

Examples in [/examples/promise-co-await](/docs/examples/promise-wrapper/co-await)
</file>

<file path="website/docs/documentation/ssl.mdx">
# SSL

As part of the connection options, you can specify the `ssl` object property or a string containing the SSL profile content (**deprecated**).

```ts
ssl?: string | SslOptions;
```

See full list of [SslOptions](https://github.com/sidorares/node-mysql2/blob/master/typings/mysql/lib/Connection.d.ts#L24-L80), which are in the same format as [tls.createSecureContext](https://nodejs.org/api/tls.html#tls_tls_createsecurecontext_options).

## SSL Options

To enable SSL without manually providing certificates and assuming they are already trusted by the host machine, you can specify an empty object, for example:

```ts
const connection = await mysql.createConnection({
  host: 'localhost',
  ssl: {},
});
```

You can also specify custom certificate(s) as an individual string or array of strings. Please note the arguments expect a string of the certificate, not a file name to the certificate:

```ts
import fs from 'node:fs';

const connection = await mysql.createConnection({
  host: 'localhost',
  ssl: {
    ca: fs.readFileSync(__dirname + '/mysql-ca.crt'),
  },
});
```

When a certificate is read from an environment variable, it's recommended to replace escaped `\n` characters with proper new line characters, for example:

```ts
const connection = await mysql.createConnection({
  host: 'localhost',
  ssl: {
    ca: process.env.DB_SSL_CA?.replace(/\\n/gm, '\n'),
  },
});
```

## SSL Certificate Bundle

Alternatively, you can use a bundle with CA certificates. For example for Amazon RDS you could use:

```ts
import awsCaBundle from 'aws-ssl-profiles';

const connection = await mysql.createConnection({
  host: 'db.id.ap-southeast-2.rds.amazonaws.com',
  ssl: awsCaBundle,
});
```

For detailed instructions, please follow [aws-ssl-profiles](https://github.com/mysqljs/aws-ssl-profiles) documentation.

## SSL Profile (deprecated)

There is also a **deprecated option** allowing to specify a string containing name of SSL profile:

```ts
const connection = await mysql.createConnection({
  host: 'localhost',
  ssl: 'Amazon RDS',
});
```

Following profiles are included in the package:

- `Amazon RDS` - in this case https://s3.amazonaws.com/rds-downloads/mysql-ssl-ca-cert.pem CA cert is used

## Ignoring Unauthorized SSL Errors

You can also connect to a MySQL server without providing an appropriate CA to trust. **This is highly discouraged** as being insecure.

```ts
const connection = await mysql.createConnection({
  host: 'localhost',
  ssl: {
    // Beware, set `rejectUnauthorized` as `false` is strongly discouraged for security reasons:
    rejectUnauthorized: false,
  },
});
```
</file>

<file path="website/docs/documentation/typescript-examples.mdx">
import { History } from '@site/src/components/History';
import { Stability } from '@site/src/components/Stability';

# Using MySQL2 with TypeScript

## Installation

```bash
npm install --save mysql2
npm install --save-dev @types/node
```

> The `@types/node` ensure the proper interaction between **TypeScript** and the **Node.js** modules used by **MySQL2** (_net_, _events_, _stream_, _tls_, etc.).

:::info
Requires **TypeScript** `>=4.5.2`.
:::

<hr />

## Usage

You can import **MySQL2** in two ways:

- By setting the `esModuleInterop` option to `true` in `tsconfig.json`

```ts
import mysql from 'mysql2';
import mysql from 'mysql2/promise';
```

- By setting the `esModuleInterop` option to `false` in `tsconfig.json`

```ts
import * as mysql from 'mysql2';
import * as mysql from 'mysql2/promise';
```

### Connection

```ts
import mysql, { ConnectionOptions } from 'mysql2';

const access: ConnectionOptions = {
  user: 'test',
  database: 'test',
};

const conn = mysql.createConnection(access);
```

### Pool Connection

```ts
import mysql, { PoolOptions } from 'mysql2';

const access: PoolOptions = {
  user: 'test',
  database: 'test',
};

const conn = mysql.createPool(access);
```

### Query and Execute

#### A simple query

```ts
conn.query('SELECT 1 + 1 AS `test`;', (_err, rows) => {
  /**
   * @rows: [ { test: 2 } ]
   */
});

conn.execute('SELECT 1 + 1 AS `test`;', (_err, rows) => {
  /**
   * @rows: [ { test: 2 } ]
   */
});
```

The `rows` output will be these possible types:

- `RowDataPacket[]`
- `RowDataPacket[][]`
- `ResultSetHeader`
- `ResultSetHeader[]`
- `ProcedureCallPacket`

In this example, you need to manually check the output types

<hr />

## Type Specification

### RowDataPacket[]

<Stability level={2} />

An array with the returned rows, for example:

```ts
import mysql, { RowDataPacket } from 'mysql2';

const conn = mysql.createConnection({
  user: 'test',
  database: 'test',
});

// SELECT
conn.query<RowDataPacket[]>('SELECT 1 + 1 AS `test`;', (_err, rows) => {
  console.log(rows);
  /**
   * @rows: [ { test: 2 } ]
   */
});

// SHOW
conn.query<RowDataPacket[]>('SHOW TABLES FROM `test`;', (_err, rows) => {
  console.log(rows);
  /**
   * @rows: [ { Tables_in_test: 'test' } ]
   */
});
```

Using `rowsAsArray` option as `true`:

```ts
import mysql, { RowDataPacket } from 'mysql2';

const conn = mysql.createConnection({
  user: 'test',
  database: 'test',
  rowsAsArray: true,
});

// SELECT
conn.query<RowDataPacket[]>(
  'SELECT 1 + 1 AS test, 2 + 2 AS test;',
  (_err, rows) => {
    console.log(rows);
    /**
     * @rows: [ [ 2, 4 ] ]
     */
  }
);

// SHOW
conn.query<RowDataPacket[]>('SHOW TABLES FROM `test`;', (_err, rows) => {
  console.log(rows);
  /**
   * @rows: [ [ 'test' ] ]
   */
});
```

<hr />

### RowDataPacket[][]

<Stability level={2} />

Using `multipleStatements` option as `true` with multiple queries:

```ts
import mysql, { RowDataPacket } from 'mysql2';

const conn = mysql.createConnection({
  user: 'test',
  database: 'test',
  multipleStatements: true,
});

const sql = `
  SELECT 1 + 1 AS test;
  SELECT 2 + 2 AS test;
`;

conn.query<RowDataPacket[][]>(sql, (_err, rows) => {
  console.log(rows);
  /**
   * @rows: [ [ { test: 2 } ], [ { test: 4 } ] ]
   */
});
```

<hr />

### ResultSetHeader

<Stability level={2} />

<History
  records={[
    {
      version: '3.5.1',
      changes: [
        <>
          <strong>OkPacket</strong> is deprecated and might be removed in the
          future major release.
          <br />
          Please use <strong>ResultSetHeader</strong> instead.
        </>,
        <>
          <strong>changedRows</strong> option is deprecated and might be removed
          in the future major release.
          <br />
          Please use <strong>affectedRows</strong> instead.
        </>,
      ],
    },
  ]}
/>

For `INSERT`, `UPDATE`, `DELETE`, `TRUNCATE`, etc.:

```ts
import mysql, { ResultSetHeader } from 'mysql2';

const conn = mysql.createConnection({
  user: 'test',
  database: 'test',
});

const sql = `
  SET @1 = 1;
`;

conn.query<ResultSetHeader>(sql, (_err, result) => {
  console.log(result);
  /**
   * @result: ResultSetHeader {
      fieldCount: 0,
      affectedRows: 0,
      insertId: 0,
      info: '',
      serverStatus: 2,
      warningStatus: 0,
      changedRows: 0
    }
   */
});
```

<hr />

### ResultSetHeader[]

<Stability level={2} />

<History
  records={[
    {
      version: '3.5.1',
      changes: [
        <>
          Introduce <strong>ResultSetHeader[]</strong>
        </>,
      ],
    },
  ]}
/>

For multiples `INSERT`, `UPDATE`, `DELETE`, `TRUNCATE`, etc. when using `multipleStatements` as `true`:

```ts
import mysql, { ResultSetHeader } from 'mysql2';

const conn = mysql.createConnection({
  user: 'test',
  database: 'test',
  multipleStatements: true,
});

const sql = `
  SET @1 = 1;
  SET @2 = 2;
`;

conn.query<ResultSetHeader[]>(sql, (_err, results) => {
  console.log(results);
  /**
   * @results: [
      ResultSetHeader {
        fieldCount: 0,
        affectedRows: 0,
        insertId: 0,
        info: '',
        serverStatus: 10,
        warningStatus: 0,
        changedRows: 0
      },
      ResultSetHeader {
        fieldCount: 0,
        affectedRows: 0,
        insertId: 0,
        info: '',
        serverStatus: 2,
        warningStatus: 0,
        changedRows: 0
      }
    ]
   */
});
```

<hr />

### ProcedureCallPacket

<Stability level={2} />

<History
  records={[
    {
      version: '3.5.1',
      changes: [
        <>
          Introduce <strong>ProcedureCallPacket</strong>
        </>,
      ],
    },
  ]}
/>

:::tip
By performing a **Call Procedure** using `INSERT`, `UPDATE`, etc., the return will be a `ProcedureCallPacket<ResultSetHeader>` (even if you perform multiples queries and set `multipleStatements` to `true`):
:::

```ts
import mysql, { ProcedureCallPacket, ResultSetHeader } from 'mysql2';

const conn = mysql.createConnection({
  user: 'test',
  database: 'test',
});

/** ResultSetHeader */
conn.query('DROP PROCEDURE IF EXISTS myProcedure');

/** ResultSetHeader */
conn.query(`
    CREATE PROCEDURE myProcedure()
    BEGIN
      SET @1 = 1;
      SET @2 = 2;
    END
  `);

/** ProcedureCallPacket */
const sql = 'CALL myProcedure()';

conn.query<ProcedureCallPacket<ResultSetHeader>>(sql, (_err, result) => {
  console.log(result);
  /**
   * @result: ResultSetHeader {
      fieldCount: 0,
      affectedRows: 0,
      insertId: 0,
      info: '',
      serverStatus: 2,
      warningStatus: 0,
      changedRows: 0
    }
   */
});
```

> For `CREATE PROCEDURE` and `DROP PROCEDURE`, these returns will be the _default_ `ResultSetHeader`.

By using `SELECT` and `SHOW` queries in a **Procedure Call**, it groups the results as:

```tsx
/** ProcedureCallPacket<RowDataPacket[]> */
[RowDataPacket[], ResultSetHeader]
```

For `ProcedureCallPacket<RowDataPacket[]>`, please see the following examples.

<hr />

### OkPacket

<Stability
  level={0}
  message={
    <>
      <strong>OkPacket</strong> is deprecated and might be removed in the future
      major release.
      <br />
      Please use <strong>ResultSetHeader</strong> instead.
    </>
  }
/>

<hr />

## Examples

You can also check some code examples using **MySQL2** and **TypeScript** to understand advanced concepts:

- [Extending and using **Interfaces** with `RowDataPacket`](/docs/examples/typescript/row-data/index)
- [Extending and using **Interfaces** with `RowDataPacket` and `rowAsArray`](/docs/examples/typescript/row-data/row-as-array)
- [Extending and using **Interfaces** with `RowDataPacket` and `multipleStatements`](/docs/examples/typescript/row-data/multi-statements)
- [Extending and using **Interfaces** with `RowDataPacket`, `rowAsArray` and `multipleStatements`](/docs/examples/typescript/row-data/row-as-array-multi-statements)
- [Checking for `ResultSetHeader`, extending and using **Interfaces** with `RowDataPacket` from `ProcedureCallPacket`](/docs/examples/typescript/procedure-call/index)
- [Checking for `ResultSetHeader`, extending and using **Interfaces** with `RowDataPacket` and `rowAsArray` from `ProcedureCallPacket`](/docs/examples/typescript/procedure-call/row-as-array)
- [Creating a basic custom **MySQL2** **Class**](/docs/examples/typescript/basic-custom-class)
</file>

<file path="website/docs/examples/00-index.mdx">
---
slug: /examples
title: Introduction
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { PageTitle } from '@site/src/components/PageTitle';

<PageTitle title='Examples' />

# Examples

:::tip
To explore the examples, please use the **sidebar navigation** on desktop or access the **menu** on mobile devices.
:::

## Examples using MySQL server API

- [MySQL-pg-proxy](https://github.com/sidorares/mysql-pg-proxy) - MySQL to Postgres proxy server.
- [MySQLite.js](https://github.com/sidorares/mysqlite.js) - MySQL server with JS-only (emscripten compiled) sqlite backend.
- [SQL-engine](https://github.com/eugeneware/sql-engine) - MySQL server with LevelDB backend.
- [MySQL-osquery-proxy](https://github.com/sidorares/mysql-osquery-proxy) - Connect to [facebook osquery](https://osquery.io/) using MySQL client
- [PlyQL](https://github.com/implydata/plyql) - Connect to [Druid](https://druid.io/) using MySQL client
</file>

<file path="website/docs/examples/binlog-watcher.mdx">
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Binlog Watcher

<Tabs>
  <TabItem value='index.js' default>

```js
'use strict';

const mysql = require('mysql2');
const through2 = require('through2');

const binlogStream = mysql.createBinlogStream({
  serverId: 123, // slave ID, first field in "show slave hosts" sql response
  // you can also specify slave host, username, password and port
  masterId: 0,
  filename: 'mysql-bin.000007',
  binlogPos: 120,
  flags: 1, // 1 = "non-blocking mode"
});

binlogStream.pipe(
  through2.obj((obj, enc, next) => {
    console.log(obj);
    next();
  })
);
```

  </TabItem>
</Tabs>
</file>

<file path="website/docs/examples/connections/_category_.json">
{
  "label": "Connections",
  "position": 1
}
</file>

<file path="website/docs/examples/connections/create-connection.mdx">
---
sidebar_position: 1
tags: [createConnection, URI, SHA1, RDS, SSL, Socks]
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { FAQ } from '@site/src/components/FAQ';
import { ExternalCodeEmbed } from '@site/src/components/ExternalCodeEmbed';

# createConnection

:::info
For queries please see the [**Simple Queries**](/docs/examples/queries/simple-queries) and [**Prepared Statements**](/docs/examples/queries/prepared-statements) examples.
:::

## createConnection(connectionUri)

> **createConnection(connectionUri: string)**

<Tabs>
  <TabItem value='promise.js' default>

```js
import mysql from 'mysql2/promise';

try {
  // highlight-start
  const connection = await mysql.createConnection(
    'mysql://root:password@localhost:3306/test'
  );
  // highlight-end
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const mysql = require('mysql2');

const connection = mysql.createConnection(
  'mysql://root:password@localhost:3306/test'
);

connection.addListener('error', (err) => {
  console.log(err);
});
```

  </TabItem>
</Tabs>

<hr />

## createConnection(config)

> **createConnection(config: [ConnectionOptions](#connectionoptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
import mysql from 'mysql2/promise';

try {
  // highlight-start
  const connection = await mysql.createConnection({
    host: 'localhost',
    user: 'root',
    database: 'test',
    // port: 3306,
    // password: '',
  });
  // highlight-end
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const mysql = require('mysql2');

const connection = mysql.createConnection({
  host: 'localhost',
  user: 'root',
  database: 'test',
  // port: 3306,
  // password: '',
});

connection.addListener('error', (err) => {
  console.log(err);
});
```

  </TabItem>
</Tabs>

<hr />

## createConnection(config) — SHA1

> **createConnection(config: [ConnectionOptions](#connectionoptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
import mysql from 'mysql2/promise';

try {
  // highlight-start
  const connection = await mysql.createConnection({
    // ...
    passwordSha1: Buffer.from(
      '8bb6118f8fd6935ad0876a3be34a717d32708ffd',
      'hex'
    ),
  });
  // highlight-end
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const mysql = require('mysql2');

const connection = mysql.createConnection({
  // ...
  passwordSha1: Buffer.from('8bb6118f8fd6935ad0876a3be34a717d32708ffd', 'hex'),
});

connection.addListener('error', (err) => {
  console.log(err);
});
```

  </TabItem>
</Tabs>

<hr />

## createConnection(config) — SSL

> **createConnection(config: [ConnectionOptions](#connectionoptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
import mysql from 'mysql2/promise';

try {
  // highlight-start
  const connection = await mysql.createConnection({
    // ...
    ssl: {},
  });
  // highlight-end
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const mysql = require('mysql2');

const connection = mysql.createConnection({
  // ...
  ssl: {},
});

connection.addListener('error', (err) => {
  console.log(err);
});
```

  </TabItem>
</Tabs>

<hr />

## createConnection(config) — SSL Custom Certificate

> **createConnection(config: [ConnectionOptions](#connectionoptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
import mysql from 'mysql2/promise';

try {
  // highlight-start
  const connection = await mysql.createConnection({
    // ...
    ssl: {
      // key: fs.readFileSync('./certs/client-key.pem'),
      // cert: fs.readFileSync('./certs/client-cert.pem')
      ca: fs.readFileSync('./certs/ca-cert.pem'),
    },
  });
  // highlight-end
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const mysql = require('mysql2');

const connection = mysql.createConnection({
  // ...
  ssl: {
    // key: fs.readFileSync('./certs/client-key.pem'),
    // cert: fs.readFileSync('./certs/client-cert.pem')
    ca: fs.readFileSync('./certs/ca-cert.pem'),
  },
});

connection.addListener('error', (err) => {
  console.log(err);
});
```

  </TabItem>
  <TabItem value='certs/ca-cert.pem'>
    <ExternalCodeEmbed
      language='plan'
      url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/test/fixtures/ssl/certs/ca.pem'
    />

    - See [ssl/certs](https://github.com/sidorares/node-mysql2/tree/master/test/fixtures/ssl/certs).

  </TabItem>
</Tabs>

<hr />

## createConnection(config) — RDS SSL

> **createConnection(config: [ConnectionOptions](#connectionoptions))**

You can use **Amazon RDS** string as value to ssl property to connect to **Amazon RDS** MySQL over SSL.

In that case https://s3.amazonaws.com/rds-downloads/mysql-ssl-ca-cert.pem CA cert is used:

```sh
npm install --save aws-ssl-profiles
```

<Tabs>
  <TabItem value='promise.js' default>

```js
import mysql from 'mysql2/promise';
import awsCaBundle from 'aws-ssl-profiles';

try {
  // highlight-start
  const connection = await mysql.createConnection({
    // ...
    host: 'db.id.ap-southeast-2.rds.amazonaws.com',
    ssl: awsCaBundle,
  });
  // highlight-end
} catch (err) {
  console.log(err);
}
```

:::info
For detailed instructions, please follow the [**AWS SSL Profiles documentation**](https://github.com/mysqljs/aws-ssl-profiles?tab=readme-ov-file#readme).
:::

:::tip Testing

```js
try {
  const [res] = await connection.query('SHOW `status` LIKE "Ssl_cipher"');
  await connection.end();

  console.log(res);
} catch (err) {
  console.log(err);
}
```

:::

  </TabItem>
  <TabItem value='callback.js'>

```js
const mysql = require('mysql2');
const awsCaBundle = require('aws-ssl-profiles');

const connection = mysql.createConnection({
  // ...
  host: 'db.id.ap-southeast-2.rds.amazonaws.com',
  ssl: awsCaBundle,
});

connection.addListener('error', (err) => {
  console.log(err);
});
```

:::info
For detailed instructions, please follow the [**AWS SSL Profiles documentation**](https://github.com/mysqljs/aws-ssl-profiles?tab=readme-ov-file#readme).
:::

:::tip Testing

```js
connectionquery('SHOW `status` LIKE "Ssl_cipher"', function (err, res) {
  connection.end();

  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(res);
});
```

:::

  </TabItem>
</Tabs>

<hr />

## createConnection(config) — Socks

> **createConnection(config: [ConnectionOptions](#connectionoptions))**

<Tabs>
  <TabItem value='A.js'>

```js
const mysql = require('mysql2');
const SocksConnection = require('socksjs');

const socksProxy = new SocksConnection({ port: 3306 });
// highlight-start
const connection = mysql.createConnection({
  stream: socksProxy,
});
// highlight-end

connection.addListener('error', (err) => {
  console.log(err);
});
```

  </TabItem>
  <TabItem value='B.js'>

```js
const mysql = require('mysql2');
const SocksConnection = require('socksjs');

// highlight-start
const connection = mysql.createConnection({
  debug: 1,
  stream: function () {
    return new SocksConnection({ port: 3306 });
  },
});
// highlight-end

connection.addListener('error', (err) => {
  console.log(err);
});
```

  </TabItem>
</Tabs>

:::tip Testing

```js
connection.execute('SELECT SLEEP(1.1) AS `www`', (err, rows, fields) => {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(rows, fields);
});

connection.execute('SELECT SLEEP(1) AS `qqq`', (err, rows, fields) => {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(rows, fields);
});

connection.execute('SELECT SLEEP(1) AS `qqq`', (err, rows, fields) => {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(rows, fields);
});
```

:::

<hr />

## Glossary

### ConnectionOptions

<FAQ title='ConnectionOptions Specification'>
  <ExternalCodeEmbed
    language='ts'
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/Connection.d.ts'
    extractMethod='ConnectionOptions'
    methodType='interface'
  />
</FAQ>
</file>

<file path="website/docs/examples/connections/create-pool.mdx">
---
sidebar_position: 2
tags: [createPool, URI, SHA1, RDS, SSL, Socks]
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { FAQ } from '@site/src/components/FAQ';
import { ExternalCodeEmbed } from '@site/src/components/ExternalCodeEmbed';

# createPool

:::info
For queries please see the [**Simple Queries**](/docs/examples/queries/simple-queries) and [**Prepared Statements**](/docs/examples/queries/prepared-statements) examples.
:::

## createPool(connectionUri)

> **createPool(connectionUri: string)**

<Tabs>
  <TabItem value='promise.js' default>

```js
import mysql from 'mysql2/promise';

try {
  // highlight-start
  const pool = mysql.createPool('mysql://root:password@localhost:3306/test');
  const connection = await pool.getConnection();
  // highlight-end
  // ... some query

  // highlight-next-line
  connection.release();
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const mysql = require('mysql2');

const pool = mysql.createPool('mysql://root:password@localhost:3306/test');

pool.getConnection(function (err, connection) {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  // ... some query

  connection.release();
});
```

  </TabItem>
</Tabs>

:::warning

Don't forget to release the connection when finished by using:

- `pool.releaseConnection(connection)`
- `connection.release()`

:::

<hr />

## createPool(config)

> **createPool(config: [PoolOptions](#pooloptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
import mysql from 'mysql2/promise';

try {
  // highlight-start
  const pool = mysql.createPool({
    host: 'localhost',
    user: 'root',
    database: 'test',
    // port: 3306,
    // password: '',
  });
  const connection = await pool.getConnection();
  // highlight-end
  // ... some query

  // highlight-next-line
  connection.release();
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const mysql = require('mysql2');

const pool = mysql.createPool({
  host: 'localhost',
  user: 'root',
  database: 'test',
  // port: 3306,
  // password: '',
});

pool.getConnection(function (err, connection) {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  // ... some query

  connection.release();
});
```

  </TabItem>
</Tabs>

:::warning

Don't forget to release the connection when finished by using:

- `pool.releaseConnection(connection)`
- `connection.release()`

:::

<hr />

## createPool(config) — SHA1

> **createPool(config: [PoolOptions](#pooloptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
import mysql from 'mysql2/promise';

try {
  // highlight-start
  const pool = mysql.createPool({
    // ...
    passwordSha1: Buffer.from(
      '8bb6118f8fd6935ad0876a3be34a717d32708ffd',
      'hex'
    ),
  });
  const connection = await pool.getConnection();
  // highlight-end
  // ... some query

  // highlight-next-line
  connection.release();
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const mysql = require('mysql2');

const pool = mysql.createPool({
  // ...
  passwordSha1: Buffer.from('8bb6118f8fd6935ad0876a3be34a717d32708ffd', 'hex'),
});

pool.getConnection(function (err, connection) {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  // ... some query

  connection.release();
});
```

  </TabItem>
</Tabs>

:::warning

Don't forget to release the connection when finished by using:

- `pool.releaseConnection(connection)`
- `connection.release()`

:::

<hr />

## createPool(config) — SSL

> **createPool(config: [PoolOptions](#pooloptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
import mysql from 'mysql2/promise';

try {
  // highlight-start
  const pool = mysql.createPool({
    // ...
    ssl: {
      // key: fs.readFileSync('./certs/client-key.pem'),
      // cert: fs.readFileSync('./certs/client-cert.pem')
      ca: fs.readFileSync('./certs/ca-cert.pem'),
    },
  });
  const connection = await pool.getConnection();
  // highlight-end
  // ... some query

  // highlight-next-line
  connection.release();
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const mysql = require('mysql2');

const pool = mysql.createPool({
  // ...
  ssl: {
    // key: fs.readFileSync('./certs/client-key.pem'),
    // cert: fs.readFileSync('./certs/client-cert.pem')
    ca: fs.readFileSync('./certs/ca-cert.pem'),
  },
});

pool.getConnection(function (err, connection) {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  // ... some query

  connection.release();
});
```

  </TabItem>
    <TabItem value='certs/ca-cert.pem'>
    <ExternalCodeEmbed
      language='plan'
      url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/test/fixtures/ssl/certs/ca.pem'
    />

    - See [ssl/certs](https://github.com/sidorares/node-mysql2/tree/master/test/fixtures/ssl/certs).

  </TabItem>
</Tabs>

:::warning

Don't forget to release the connection when finished by using:

- `pool.releaseConnection(connection)`
- `connection.release()`

:::

<hr />

## createPool(config) — RDS SSL

> **createPool(config: [PoolOptions](#pooloptions))**

You can use **Amazon RDS** string as value to ssl property to connect to **Amazon RDS** MySQL over SSL.

In that case https://s3.amazonaws.com/rds-downloads/mysql-ssl-ca-cert.pem CA cert is used:

```sh
npm install --save aws-ssl-profiles
```

<Tabs>
  <TabItem value='promise.js' default>

```js
import mysql from 'mysql2/promise';
import awsCaBundle from 'aws-ssl-profiles';

try {
  // highlight-start
  const pool = mysql.createPool({
    // ...
    host: 'db.id.ap-southeast-2.rds.amazonaws.com',
    ssl: awsCaBundle,
  });
  const connection = await pool.getConnection();
  // highlight-end
  // ... some query

  // highlight-next-line
  connection.release();
} catch (err) {
  console.log(err);
}
```

:::info
For detailed instructions, please follow the [**AWS SSL Profiles documentation**](https://github.com/mysqljs/aws-ssl-profiles?tab=readme-ov-file#readme).
:::

:::tip Testing

```js
try {
  const [res] = await connection.query('SHOW `status` LIKE "Ssl_cipher"');
  await pool.end();

  console.log(res);
} catch (err) {
  console.log(err);
}
```

:::

  </TabItem>
  <TabItem value='callback.js'>

```js
const mysql = require('mysql2');
const awsCaBundle = require('aws-ssl-profiles');

const pool = mysql.createPool({
  // ...
  host: 'db.id.ap-southeast-2.rds.amazonaws.com',
  ssl: awsCaBundle,
});

pool.getConnection(function (err, connection) {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  // ... some query

  connection.release();
});
```

:::info
For detailed instructions, please follow the [**AWS SSL Profiles documentation**](https://github.com/mysqljs/aws-ssl-profiles?tab=readme-ov-file#readme).
:::

:::tip Testing

```js
connectionquery('SHOW `status` LIKE "Ssl_cipher"', function (err, res) {
  pool.end();

  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(res);
});
```

:::

  </TabItem>
</Tabs>

:::warning

Don't forget to release the connection when finished by using:

- `pool.releaseConnection(connection)`
- `connection.release()`

:::

<hr />

## createPool(config) — Socks

> **createPool(config: [PoolOptions](#pooloptions))**

<Tabs>
  <TabItem value='A.js'>

```js
const mysql = require('mysql2');
const SocksConnection = require('socksjs');

const socksProxy = new SocksConnection({ port: 3306 });
// highlight-start
const pool = mysql.createPool({
  stream: socksProxy,
});
// highlight-end
```

  </TabItem>
  <TabItem value='B.js'>

```js
const mysql = require('mysql2');
const SocksConnection = require('socksjs');

// highlight-start
const pool = mysql.createPool({
  debug: 1,
  stream: function () {
    return new SocksConnection({ port: 3306 });
  },
});
// highlight-end
```

  </TabItem>
</Tabs>

:::tip Testing

```js
pool.execute('SELECT SLEEP(1.1) AS `www`', (err, rows, fields) => {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(rows, fields);
});

pool.execute('SELECT SLEEP(1) AS `qqq`', (err, rows, fields) => {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(rows, fields);
});

pool.execute('SELECT SLEEP(1) AS `qqq`', (err, rows, fields) => {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(rows, fields);
});
```

:::

<hr />

## Glossary

### PoolOptions

<blockquote>
  **PoolOptions** extends all options from **ConnectionOptions**:

  <FAQ title='ConnectionOptions Specification'>
    <ExternalCodeEmbed
      language='ts'
      url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/Connection.d.ts'
      extractMethod='ConnectionOptions'
      methodType='interface'
    />
  </FAQ>
</blockquote>

<FAQ title='PoolOptions Specification'>
  <ExternalCodeEmbed
    language='ts'
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/Pool.d.ts'
    extractMethod='PoolOptions'
    methodType='interface'
  />
</FAQ>
</file>

<file path="website/docs/examples/connections/createPoolCluster.mdx">
---
sidebar_position: 3
tags: [createPoolCluster, URI, SHA1, RDS, SSL, Socks]
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { FAQ } from '@site/src/components/FAQ';
import { ExternalCodeEmbed } from '@site/src/components/ExternalCodeEmbed';

# createPoolCluster

:::info
For queries please see the [**Simple Queries**](/docs/examples/queries/simple-queries) and [**Prepared Statements**](/docs/examples/queries/prepared-statements) examples.
:::

## add(group, connectionUri)

> **add(group: string, connectionUri: string)**

<Tabs>
  <TabItem value='promise.js' default>

```js
import mysql from 'mysql2/promise';

try {
  // highlight-start
  const poolCluster = mysql.createPoolCluster();

  poolCluster.add('clusterA', 'mysql://root:password@localhost:3306/test');
  // poolCluster.add('clusterB', '...');

  const connection = await poolCluster.getConnection('clusterA');
  // highlight-end
  // ... some query

  // highlight-next-line
  connection.release();
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const mysql = require('mysql2');

const poolCluster = mysql.createPoolCluster();

poolCluster.add('clusterA', 'mysql://root:password@localhost:3306/test');
// poolCluster.add('clusterB', '...');

poolCluster.getConnection('clusterA', function (err, connection) {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  // ... some query

  connection.release();
});
```

  </TabItem>
</Tabs>

:::warning

Don't forget to release the connection when finished by using:

- `connection.release()`

:::

<hr />

## add(group, config)

> **add(group: string, config: [PoolOptions](#pooloptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
import mysql from 'mysql2/promise';

try {
  // highlight-start
  const poolCluster = mysql.createPoolCluster();

  poolCluster.add('clusterA', {
    host: 'localhost',
    user: 'root',
    database: 'test',
    // port: 3306,
    // password: '',
  });
  // poolCluster.add('clusterB', '...');

  const connection = await poolCluster.getConnection('clusterA');
  // highlight-end
  // ... some query

  // highlight-next-line
  connection.release();
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const mysql = require('mysql2');

const poolCluster = mysql.createPoolCluster();

poolCluster.add('clusterA', {
  host: 'localhost',
  user: 'root',
  database: 'test',
  // port: 3306,
  // password: '',
});
// poolCluster.add('clusterB', '...');

poolCluster.getConnection('clusterA', function (err, connection) {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  // ... some query

  connection.release();
});
```

  </TabItem>
</Tabs>

:::warning

Don't forget to release the connection when finished by using:

- `connection.release()`

:::

<hr />

## add(group, config) — SHA1

> **add(group: string, config: [PoolOptions](#pooloptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
import mysql from 'mysql2/promise';

try {
  // highlight-start
  const poolCluster = mysql.createPoolCluster();

  poolCluster.add('clusterA', {
    // ...
    passwordSha1: Buffer.from(
      '8bb6118f8fd6935ad0876a3be34a717d32708ffd',
      'hex'
    ),
  });
  // poolCluster.add('clusterB', '...');

  const connection = await poolCluster.getConnection('clusterA');
  // highlight-end
  // ... some query

  // highlight-next-line
  connection.release();
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const mysql = require('mysql2');

const poolCluster = mysql.createPoolCluster();

poolCluster.add('clusterA', {
  // ...
  passwordSha1: Buffer.from('8bb6118f8fd6935ad0876a3be34a717d32708ffd', 'hex'),
});
// poolCluster.add('clusterB', '...');

poolCluster.getConnection('clusterA', function (err, connection) {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  // ... some query

  connection.release();
});
```

  </TabItem>
</Tabs>

:::warning

Don't forget to release the connection when finished by using:

- `connection.release()`

:::

<hr />

## add(group, config) — SSL

> **add(group: string, config: [PoolOptions](#pooloptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
import mysql from 'mysql2/promise';

try {
  // highlight-start
  const poolCluster = mysql.createPoolCluster();

  poolCluster.add('clusterA', {
    // ...
    ssl: {
      // key: fs.readFileSync('./certs/client-key.pem'),
      // cert: fs.readFileSync('./certs/client-cert.pem')
      ca: fs.readFileSync('./certs/ca-cert.pem'),
    },
  });
  // poolCluster.add('clusterB', '...');

  const connection = await poolCluster.getConnection('clusterA');
  // highlight-end
  // ... some query

  // highlight-next-line
  connection.release();
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const mysql = require('mysql2');

const poolCluster = mysql.createPoolCluster();

poolCluster.add('clusterA', {
  // ...
  ssl: {
    // key: fs.readFileSync('./certs/client-key.pem'),
    // cert: fs.readFileSync('./certs/client-cert.pem')
    ca: fs.readFileSync('./certs/ca-cert.pem'),
  },
});
// poolCluster.add('clusterB', '...');

poolCluster.getConnection('clusterA', function (err, connection) {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  // ... some query

  connection.release();
});
```

  </TabItem>
    <TabItem value='certs/ca-cert.pem'>
    <ExternalCodeEmbed
      language='plan'
      url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/test/fixtures/ssl/certs/ca.pem'
    />

    - See [ssl/certs](https://github.com/sidorares/node-mysql2/tree/master/test/fixtures/ssl/certs).

  </TabItem>
</Tabs>

:::warning

Don't forget to release the connection when finished by using:

- `connection.release()`

:::

<hr />

## add(group, config) — RDS SSL

> **add(group: string, config: [PoolOptions](#pooloptions))**

You can use **Amazon RDS** string as value to ssl property to connect to **Amazon RDS** MySQL over SSL.

In that case https://s3.amazonaws.com/rds-downloads/mysql-ssl-ca-cert.pem CA cert is used:

```sh
npm install --save aws-ssl-profiles
```

<Tabs>
  <TabItem value='promise.js' default>

```js
import mysql from 'mysql2/promise';
import awsCaBundle from 'aws-ssl-profiles';

try {
  // highlight-start
  const poolCluster = mysql.createPoolCluster();

  poolCluster.add('clusterA', {
    // ...
    host: 'db.id.ap-southeast-2.rds.amazonaws.com',
    ssl: awsCaBundle,
  });
  // poolCluster.add('clusterB', '...');

  const connection = await poolCluster.getConnection('clusterA');
  // highlight-end
  // ... some query

  // highlight-next-line
  connection.release();
} catch (err) {
  console.log(err);
}
```

:::info
For detailed instructions, please follow the [**AWS SSL Profiles documentation**](https://github.com/mysqljs/aws-ssl-profiles?tab=readme-ov-file#readme).
:::

:::tip Testing

```js
try {
  const [res] = await connection.query('SHOW `status` LIKE "Ssl_cipher"');
  await poolCluster.end();

  console.log(res);
} catch (err) {
  console.log(err);
}
```

:::

  </TabItem>
  <TabItem value='callback.js'>

```js
const mysql = require('mysql2');
const awsCaBundle = require('aws-ssl-profiles');

const poolCluster = mysql.createPoolCluster();

poolCluster.add('clusterA', {
  // ...
  host: 'db.id.ap-southeast-2.rds.amazonaws.com',
  ssl: awsCaBundle,
});
// poolCluster.add('clusterB', '...');

poolCluster.getConnection('clusterA', function (err, connection) {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  // ... some query

  connection.release();
});
```

:::info
For detailed instructions, please follow the [**AWS SSL Profiles documentation**](https://github.com/mysqljs/aws-ssl-profiles?tab=readme-ov-file#readme).
:::

:::tip Testing

```js
connectionquery('SHOW `status` LIKE "Ssl_cipher"', function (err, res) {
  poolCluster.end();

  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(res);
});
```

:::

  </TabItem>
</Tabs>

:::warning

Don't forget to release the connection when finished by using:

- `connection.release()`

:::

<hr />

## add(group, config) — Socks

> **add(group: string, config: [PoolOptions](#pooloptions))**

<Tabs>
  <TabItem value='A.js'>

```js
const mysql = require('mysql2');
const SocksConnection = require('socksjs');

const socksProxy = new SocksConnection({ port: 3306 });
// highlight-start
const poolCluster = mysql.createPoolCluster();

poolCluster.add('clusterA', {
  stream: socksProxy,
});
// poolCluster.add('clusterB', '...');

const poolNamespace = poolCluster.of('clusterA');
// highlight-end
```

  </TabItem>
  <TabItem value='B.js'>

```js
const mysql = require('mysql2');
const SocksConnection = require('socksjs');

// highlight-start
const poolCluster = mysql.createPoolCluster();

poolCluster.add('clusterA', {
  debug: 1,
  stream: function () {
    return new SocksConnection({ port: 3306 });
  },
});
// poolCluster.add('clusterB', '...');

const poolNamespace = poolCluster.of('clusterA');
// highlight-end
```

  </TabItem>
</Tabs>

:::tip Testing

```js
poolNamespace.execute('SELECT SLEEP(1.1) AS `www`', (err, rows, fields) => {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(rows, fields);
});

poolNamespace.execute('SELECT SLEEP(1) AS `qqq`', (err, rows, fields) => {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(rows, fields);
});

poolNamespace.execute('SELECT SLEEP(1) AS `qqq`', (err, rows, fields) => {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(rows, fields);
});
```

:::

<hr />

## Glossary

### PoolOptions

<blockquote>
  **PoolOptions** extends all options from **ConnectionOptions**:

  <FAQ title='ConnectionOptions Specification'>
    <ExternalCodeEmbed
      language='ts'
      url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/Connection.d.ts'
      extractMethod='ConnectionOptions'
      methodType='interface'
    />
  </FAQ>
</blockquote>

<FAQ title='PoolOptions Specification'>
  <ExternalCodeEmbed
    language='ts'
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/Pool.d.ts'
    extractMethod='PoolOptions'
    methodType='interface'
  />
</FAQ>
</file>

<file path="website/docs/examples/promise-wrapper/_category_.json">
{
  "label": "Promise Wrapper"
}
</file>

<file path="website/docs/examples/promise-wrapper/co-await.mdx">
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# await — co

<Tabs>
  <TabItem value='await.js' default>

```js
'use strict';

const mysql = require('mysql2/promise');

async function test() {
  const c = await mysql.createConnection({
    port: 3306,
    user: 'testuser',
    namedPlaceholders: true,
    password: 'testpassword',
  });
  console.log('connected!');
  const [rows, fields] = await c.query('show databases');
  console.log(rows);

  try {
    const [rows, fields] = await c.query('some invalid sql here');
  } catch (e) {
    console.log('caught exception!', e);
  }

  console.log(await c.execute('select sleep(0.5)'));
  console.log('after first sleep');
  console.log(await c.execute('select sleep(0.5)'));
  console.log('after second sleep');
  let start = +new Date();
  console.log(
    await Promise.all([
      c.execute('select sleep(2.5)'),
      c.execute('select sleep(2.5)'),
    ])
  );
  console.log(
    'after 2+3 parallel sleep which is in fact not parallel because commands are queued per connection'
  );
  let end = +new Date();
  console.log(end - start);
  await c.end();

  const p = mysql.createPool({
    port: 3306,
    user: 'testuser',
    namedPlaceholders: true,
    password: 'testpassword',
  });
  console.log(await p.execute('select sleep(0.5)'));
  console.log('after first pool sleep');
  start = +new Date();
  console.log(
    await Promise.all([
      p.execute('select sleep(2.5)'),
      p.execute('select sleep(2.5)'),
    ])
  );
  console.log('after 2+3 parallel pool sleep');
  end = +new Date();
  console.log(end - start);
  await p.end();
}

test()
  .then(() => {
    console.log('done');
  })
  .catch((err) => {
    console.log('error!', err);
    throw err;
  });
```

  </TabItem>
  <TabItem value='co.js' default>

```js
'use strict';

const mysql = require('mysql2/promise');
const co = require('co');

co(function* () {
  const c = yield mysql.createConnection({
    port: 3306,
    user: 'root',
    namedPlaceholders: true,
  });
  const rows = yield c.query('show databases');
  console.log(rows);
  console.log(yield c.execute('select 1+:toAdd as qqq', { toAdd: 10 }));
  yield c.end();
})
  .then(function () {
    console.log('done');
  })
  .catch(function (err) {
    console.log(err);
    throw err;
  });
```

  </TabItem>
  <TabItem value='.babelrc' default>

```json
{
  "plugins": ["transform-async-to-generator"]
}
```

  </TabItem>
  <TabItem value='package.json' default>

```json
{
  "name": "promise-co-await",
  "version": "1.0.0",
  "description": "",
  "main": "await.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "author": "",
  "license": "ISC",
  "dependencies": {
    "babel-cli": "^6.9.0"
  }
}
```

  </TabItem>
</Tabs>
</file>

<file path="website/docs/examples/queries/_category_.json">
{
  "label": "Queries",
  "position": 2
}
</file>

<file path="website/docs/examples/queries/prepared-statements/_category_.json">
{
  "label": "Prepared Statements",
  "position": 2
}
</file>

<file path="website/docs/examples/queries/prepared-statements/delete.mdx">
---
sidebar_position: 3
tags: [Prepared Statements, Placeholders, Parameters, execute]
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { FAQ } from '@site/src/components/FAQ';
import { ExternalCodeEmbed } from '@site/src/components/ExternalCodeEmbed';

# DELETE

## execute(sql, values)

> **execute(sql: string, values: any[])**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'DELETE FROM `users` WHERE `name` = ? LIMIT 1';
  const values = ['Page'];

  // highlight-next-line
  const [result, fields] = await connection.execute(sql, values);

  console.log(result);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'DELETE FROM `users` WHERE `name` = ? LIMIT 1';
const values = ['Page'];

connection.execute(sql, values, (err, result, fields) => {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(result);
  console.log(fields);
});
```

  </TabItem>
</Tabs>

- **result**: contains a [ResultSetHeader](#resultsetheader) object, which provides details about the operation executed by the server.
- **fields** contains extra meta data about the operation, if available

:::info
The connection used for the query (`execute`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## execute(options)

> **execute(options: [QueryOptions](#queryoptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'DELETE FROM `users` WHERE `name` = ? LIMIT 1';
  const values = ['Page'];

  // highlight-start
  const [result, fields] = await connection.execute({
    sql,
    values,
    // ... other options
  });
  // highlight-end

  console.log(result);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'DELETE FROM `users` WHERE `name` = ? LIMIT 1';
const values = ['Page'];

connection.execute(
  {
    sql,
    values,
    // ... other options
  },
  (err, result, fields) => {
    if (err instanceof Error) {
      console.log(err);
      return;
    }

    console.log(result);
    console.log(fields);
  }
);
```

  </TabItem>
</Tabs>

- **result**: contains a [ResultSetHeader](#resultsetheader) object, which provides details about the operation executed by the server.
- **fields** contains extra meta data about the operation, if available

:::info
The connection used for the query (`execute`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## execute(options, values)

> **execute(options: [QueryOptions](#queryoptions), values: any[])**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'DELETE FROM `users` WHERE `name` = ? LIMIT 1';
  const values = ['Page'];

  // highlight-start
  const [result, fields] = await connection.execute(
    {
      sql,
      // ... other options
    },
    values
  );
  // highlight-end

  console.log(result);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'DELETE FROM `users` WHERE `name` = ? LIMIT 1';
const values = ['Page'];

connection.execute(
  {
    sql,
    // ... other options
  },
  values,
  (err, result, fields) => {
    if (err instanceof Error) {
      console.log(err);
      return;
    }

    console.log(result);
    console.log(fields);
  }
);
```

  </TabItem>
</Tabs>

- **result**: contains a [ResultSetHeader](#resultsetheader) object, which provides details about the operation executed by the server.
- **fields** contains extra meta data about the operation, if available

:::info
The connection used for the query (`execute`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## Glossary

### ResultSetHeader

<FAQ title='ResultSetHeader Specification'>
  <ExternalCodeEmbed
    language='ts'
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/protocol/packets/ResultSetHeader.d.ts'
    extractMethod='ResultSetHeader'
    methodType='interface'
  />
</FAQ>

### QueryOptions

<FAQ title='QueryOptions Specification'>
  <ExternalCodeEmbed
    language='ts'
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/protocol/sequences/Query.d.ts'
    extractMethod='QueryOptions'
    methodType='interface'
  />
</FAQ>
</file>

<file path="website/docs/examples/queries/prepared-statements/index.mdx">
# Prepared Statements

MySQL2 provides `execute` helper which will prepare and query the statement.
You can also manually prepare / unprepare statement with `prepare` / `unprepare` methods.

See detailed documentaion in [Prepared Statements](/docs/documentation/prepared-statements).

:::tip
If you execute same statement again, it will be picked form a **LRU cache** which will save query preparation time and give better performance.
:::

<hr />

Usage examples:

- [x] [**INSERT**](/docs/examples/queries/prepared-statements/insert)
- [x] [**SELECT**](/docs/examples/queries/prepared-statements/select)
- [x] [**UPDATE**](/docs/examples/queries/prepared-statements/update)
- [x] [**DELETE**](/docs/examples/queries/prepared-statements/delete)
</file>

<file path="website/docs/examples/queries/prepared-statements/insert.mdx">
---
sidebar_position: 0
tags: [Prepared Statements, Placeholders, Parameters, execute]
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { FAQ } from '@site/src/components/FAQ';
import { ExternalCodeEmbed } from '@site/src/components/ExternalCodeEmbed';

# INSERT

## execute(sql, values)

> **execute(sql: string, values: any[])**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'INSERT INTO `users`(`name`, `age`) VALUES (?, ?), (?,?)';
  const values = ['Josh', 19, 'Page', 45];

  // highlight-next-line
  const [result, fields] = await connection.execute(sql, values);

  console.log(result);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'INSERT INTO `users`(`name`, `age`) VALUES (?, ?), (?,?)';
const values = ['Josh', 19, 'Page', 45];

connection.execute(sql, values, (err, result, fields) => {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(result);
  console.log(fields);
});
```

  </TabItem>
</Tabs>

- **result**: contains a [ResultSetHeader](#resultsetheader) object, which provides details about the operation executed by the server.
- **fields** contains extra meta data about the operation, if available

:::info
The connection used for the query (`execute`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## execute(options)

> **execute(options: [QueryOptions](#queryoptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'INSERT INTO `users`(`name`, `age`) VALUES (?, ?), (?,?)';
  const values = ['Josh', 19, 'Page', 45];

  // highlight-start
  const [result, fields] = await connection.execute({
    sql,
    values,
    // ... other options
  });
  // highlight-end

  console.log(result);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'INSERT INTO `users`(`name`, `age`) VALUES (?, ?), (?,?)';
const values = ['Josh', 19, 'Page', 45];

connection.execute(
  {
    sql,
    values,
    // ... other options
  },
  (err, result, fields) => {
    if (err instanceof Error) {
      console.log(err);
      return;
    }

    console.log(result);
    console.log(fields);
  }
);
```

  </TabItem>
</Tabs>

- **result**: contains a [ResultSetHeader](#resultsetheader) object, which provides details about the operation executed by the server.
- **fields** contains extra meta data about the operation, if available

:::info
The connection used for the query (`execute`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## execute(options, values)

> **execute(options: [QueryOptions](#queryoptions), values: any[])**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'INSERT INTO `users`(`name`, `age`) VALUES (?, ?), (?,?)';
  const values = ['Josh', 19, 'Page', 45];

  // highlight-start
  const [result, fields] = await connection.execute(
    {
      sql,
      // ... other options
    },
    values
  );
  // highlight-end

  console.log(result);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'INSERT INTO `users`(`name`, `age`) VALUES (?, ?), (?,?)';
const values = ['Josh', 19, 'Page', 45];

connection.execute(
  {
    sql,
    // ... other options
  },
  values,
  (err, result, fields) => {
    if (err instanceof Error) {
      console.log(err);
      return;
    }

    console.log(result);
    console.log(fields);
  }
);
```

  </TabItem>
</Tabs>

- **result**: contains a [ResultSetHeader](#resultsetheader) object, which provides details about the operation executed by the server.
- **fields** contains extra meta data about the operation, if available

:::info
The connection used for the query (`execute`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## Glossary

### ResultSetHeader

<FAQ title='ResultSetHeader Specification'>
  <ExternalCodeEmbed
    language='ts'
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/protocol/packets/ResultSetHeader.d.ts'
    extractMethod='ResultSetHeader'
    methodType='interface'
  />
</FAQ>

### QueryOptions

<FAQ title='QueryOptions Specification'>
  <ExternalCodeEmbed
    language='ts'
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/protocol/sequences/Query.d.ts'
    extractMethod='QueryOptions'
    methodType='interface'
  />
</FAQ>
</file>

<file path="website/docs/examples/queries/prepared-statements/select.mdx">
---
sidebar_position: 1
tags: [Prepared Statements, Placeholders, Parameters, execute]
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { FAQ } from '@site/src/components/FAQ';
import { ExternalCodeEmbed } from '@site/src/components/ExternalCodeEmbed';

# SELECT

## execute(sql, values)

> **execute(sql: string, values: any[])**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'SELECT * FROM `users` WHERE `name` = ? AND `age` > ?';
  const values = ['Page', 45];

  // highlight-next-line
  const [rows, fields] = await connection.execute(sql, values);

  console.log(rows);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'SELECT * FROM `users` WHERE `name` = ? AND `age` > ?';
const values = ['Page', 45];

connection.execute(sql, values, (err, rows, fields) => {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(rows);
  console.log(fields);
});
```

  </TabItem>
</Tabs>

- **rows** contains rows returned by server
- **fields** contains extra meta data about rows, if available

:::info
The connection used for the query (`execute`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## execute(options)

> **execute(options: [QueryOptions](#queryoptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'SELECT * FROM `users` WHERE `name` = ? AND `age` > ?';
  const values = ['Page', 45];

  // highlight-start
  const [rows, fields] = await connection.execute({
    sql,
    values,
    // ... other options
  });
  // highlight-end

  console.log(rows);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'SELECT * FROM `users` WHERE `name` = ? AND `age` > ?';
const values = ['Page', 45];

connection.execute(
  {
    sql,
    values,
    // ... other options
  },
  (err, rows, fields) => {
    if (err instanceof Error) {
      console.log(err);
      return;
    }

    console.log(rows);
    console.log(fields);
  }
);
```

  </TabItem>
</Tabs>

- **rows** contains rows returned by server
- **fields** contains extra meta data about rows, if available

:::info
The connection used for the query (`execute`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## execute(options, values)

> **execute(options: [QueryOptions](#queryoptions), values: any[])**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'SELECT * FROM `users` WHERE `name` = ? AND `age` > ?';
  const values = ['Page', 45];

  // highlight-start
  const [rows, fields] = await connection.execute(
    {
      sql,
      // ... other options
    },
    values
  );
  // highlight-end

  console.log(rows);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'SELECT * FROM `users` WHERE `name` = ? AND `age` > ?';
const values = ['Page', 45];

connection.execute(
  {
    sql,
    // ... other options
  },
  values,
  (err, rows, fields) => {
    if (err instanceof Error) {
      console.log(err);
      return;
    }

    console.log(rows);
    console.log(fields);
  }
);
```

  </TabItem>
</Tabs>

- **rows** contains rows returned by server
- **fields** contains extra meta data about rows, if available

:::info
The connection used for the query (`execute`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## Glossary

### QueryOptions

<FAQ title={'QueryOptions Specification'}>
  <ExternalCodeEmbed
    language='ts'
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/protocol/sequences/Query.d.ts'
    extractMethod='QueryOptions'
    methodType='interface'
  />
</FAQ>
</file>

<file path="website/docs/examples/queries/prepared-statements/update.mdx">
---
sidebar_position: 2
tags: [Prepared Statements, Placeholders, Parameters, execute]
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { FAQ } from '@site/src/components/FAQ';
import { ExternalCodeEmbed } from '@site/src/components/ExternalCodeEmbed';

# UPDATE

## execute(sql, values)

> **execute(sql: string, values: any[])**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'UPDATE `users` SET `age` = ? WHERE `name` = ? LIMIT 1';
  const values = [20, 'Josh'];

  // highlight-next-line
  const [result, fields] = await connection.execute(sql, values);

  console.log(result);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'UPDATE `users` SET `age` = ? WHERE `name` = ? LIMIT 1';
const values = [20, 'Josh'];

connection.execute(sql, values, (err, result, fields) => {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(result);
  console.log(fields);
});
```

  </TabItem>
</Tabs>

- **result**: contains a [ResultSetHeader](#resultsetheader) object, which provides details about the operation executed by the server.
- **fields** contains extra meta data about the operation, if available

:::info
The connection used for the query (`execute`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## execute(options)

> **execute(options: [QueryOptions](#queryoptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'UPDATE `users` SET `age` = ? WHERE `name` = ? LIMIT 1';
  const values = [20, 'Josh'];

  // highlight-start
  const [result, fields] = await connection.execute({
    sql,
    values,
    // ... other options
  });
  // highlight-end

  console.log(result);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'UPDATE `users` SET `age` = ? WHERE `name` = ? LIMIT 1';
const values = [20, 'Josh'];

connection.execute(
  {
    sql,
    values,
    // ... other options
  },
  (err, result, fields) => {
    if (err instanceof Error) {
      console.log(err);
      return;
    }

    console.log(result);
    console.log(fields);
  }
);
```

  </TabItem>
</Tabs>

- **result**: contains a [ResultSetHeader](#resultsetheader) object, which provides details about the operation executed by the server.
- **fields** contains extra meta data about the operation, if available

:::info
The connection used for the query (`execute`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## execute(options, values)

> **execute(options: [QueryOptions](#queryoptions), values: any[])**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'UPDATE `users` SET `age` = ? WHERE `name` = ? LIMIT 1';
  const values = [20, 'Josh'];

  // highlight-start
  const [result, fields] = await connection.execute(
    {
      sql,
      // ... other options
    },
    values
  );
  // highlight-end

  console.log(result);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'UPDATE `users` SET `age` = ? WHERE `name` = ? LIMIT 1';
const values = [20, 'Josh'];

connection.execute(
  {
    sql,
    // ... other options
  },
  values,
  (err, result, fields) => {
    if (err instanceof Error) {
      console.log(err);
      return;
    }

    console.log(result);
    console.log(fields);
  }
);
```

  </TabItem>
</Tabs>

- **result**: contains a [ResultSetHeader](#resultsetheader) object, which provides details about the operation executed by the server.
- **fields** contains extra meta data about the operation, if available

:::info
The connection used for the query (`execute`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## Glossary

### ResultSetHeader

<FAQ title='ResultSetHeader Specification'>
  <ExternalCodeEmbed
    language='ts'
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/protocol/packets/ResultSetHeader.d.ts'
    extractMethod='ResultSetHeader'
    methodType='interface'
  />
</FAQ>

### QueryOptions

<FAQ title='QueryOptions Specification'>
  <ExternalCodeEmbed
    language='ts'
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/protocol/sequences/Query.d.ts'
    extractMethod='QueryOptions'
    methodType='interface'
  />
</FAQ>
</file>

<file path="website/docs/examples/queries/simple-queries/_category_.json">
{
  "label": "Simple Queries",
  "position": 1
}
</file>

<file path="website/docs/examples/queries/simple-queries/delete.mdx">
---
sidebar_position: 3
tags: [query]
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { FAQ } from '@site/src/components/FAQ';
import { ExternalCodeEmbed } from '@site/src/components/ExternalCodeEmbed';

# DELETE

The examples below also work for the [`execute`](/docs/examples/queries/prepared-statements/delete) method.

## query(sql)

> **query(sql: string)**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'DELETE FROM `users` WHERE `name` = "Page" LIMIT 1';

  // highlight-next-line
  const [result, fields] = await connection.query(sql);

  console.log(result);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'DELETE FROM `users` WHERE `name` = "Page" LIMIT 1';

connection.query(sql, (err, result, fields) => {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(result);
  console.log(fields);
});
```

  </TabItem>
</Tabs>

- **result**: contains a [ResultSetHeader](#resultsetheader) object, which provides details about the operation executed by the server.
- **fields** contains extra meta data about the operation, if available

:::info
The connection used for the query (`.query()`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## query(options)

> **query(options: [QueryOptions](#queryoptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'DELETE FROM `users` WHERE `name` = "Page" LIMIT 1';

  // highlight-start
  const [result, fields] = await connection.query({
    sql,
    // ... other options
  });
  // highlight-end

  console.log(result);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'DELETE FROM `users` WHERE `name` = "Page" LIMIT 1';

connection.query(
  {
    sql,
    // ... other options
  },
  (err, result, fields) => {
    if (err instanceof Error) {
      console.log(err);
      return;
    }

    console.log(result);
    console.log(fields);
  }
);
```

  </TabItem>
</Tabs>

- **result**: contains a [ResultSetHeader](#resultsetheader) object, which provides details about the operation executed by the server.
- **fields** contains extra meta data about the operation, if available

:::info
The connection used for the query (`.query()`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## Glossary

### ResultSetHeader

<FAQ title='ResultSetHeader Specification'>
  <ExternalCodeEmbed
    language='ts'
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/protocol/packets/ResultSetHeader.d.ts'
    extractMethod='ResultSetHeader'
    methodType='interface'
  />
</FAQ>

### QueryOptions

<FAQ title='QueryOptions Specification'>
  <ExternalCodeEmbed
    language='ts'
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/protocol/sequences/Query.d.ts'
    extractMethod='QueryOptions'
    methodType='interface'
  />
</FAQ>
</file>

<file path="website/docs/examples/queries/simple-queries/index.mdx">
# Simple Queries

:::info
For **Prepared Statements** or **Placeholders** / **Parameters** examples, please see [here](/docs/examples/queries/prepared-statements).
:::

<hr />

Usage examples:

- [x] [**INSERT**](/docs/examples/queries/simple-queries/insert)
- [x] [**SELECT**](/docs/examples/queries/simple-queries/select)
- [x] [**UPDATE**](/docs/examples/queries/simple-queries/update)
- [x] [**DELETE**](/docs/examples/queries/simple-queries/delete)
</file>

<file path="website/docs/examples/queries/simple-queries/insert.mdx">
---
sidebar_position: 0
tags: [query]
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { FAQ } from '@site/src/components/FAQ';
import { ExternalCodeEmbed } from '@site/src/components/ExternalCodeEmbed';

# INSERT

The examples below also work for the [`execute`](/docs/examples/queries/prepared-statements/insert) method.

## query(sql)

> **query(sql: string)**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql =
    'INSERT INTO `users`(`name`, `age`) VALUES ("Josh", 19), ("Page", 45)';

  // highlight-next-line
  const [result, fields] = await connection.query(sql);

  console.log(result);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql =
  'INSERT INTO `users`(`name`, `age`) VALUES ("Josh", 19), ("Page", 45)';

connection.query(sql, (err, result, fields) => {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(result);
  console.log(fields);
});
```

  </TabItem>
</Tabs>

- **result**: contains a [ResultSetHeader](#resultsetheader) object, which provides details about the operation executed by the server.
- **fields** contains extra meta data about the operation, if available

:::info
The connection used for the query (`.query()`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

---

## query(options)

> **query(options: [QueryOptions](#queryoptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql =
    'INSERT INTO `users`(`name`, `age`) VALUES ("Josh", 19), ("Page", 45)';

  // highlight-start
  const [result, fields] = await connection.query({
    sql,
    // ... other options
  });
  // highlight-end

  console.log(result);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql =
  'INSERT INTO `users`(`name`, `age`) VALUES ("Josh", 19), ("Page", 45)';

connection.query(
  {
    sql,
    // ... other options
  },
  (err, result, fields) => {
    if (err instanceof Error) {
      console.log(err);
      return;
    }

    console.log(result);
    console.log(fields);
  }
);
```

  </TabItem>
</Tabs>

- **result**: contains a [ResultSetHeader](#resultsetheader) object, which provides details about the operation executed by the server.
- **fields** contains extra meta data about the operation, if available

:::info
The connection used for the query (`.query()`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

---

## Glossary

### ResultSetHeader

<FAQ title='ResultSetHeader Specification'>
  <ExternalCodeEmbed
    language='ts'
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/protocol/packets/ResultSetHeader.d.ts'
    extractMethod='ResultSetHeader'
    methodType='interface'
  />
</FAQ>

### QueryOptions

<FAQ title='QueryOptions Specification'>
  <ExternalCodeEmbed
    language='ts'
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/protocol/sequences/Query.d.ts'
    extractMethod='QueryOptions'
    methodType='interface'
  />
</FAQ>
</file>

<file path="website/docs/examples/queries/simple-queries/select.mdx">
---
sidebar_position: 1
tags: [query]
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { FAQ } from '@site/src/components/FAQ';
import { ExternalCodeEmbed } from '@site/src/components/ExternalCodeEmbed';

# SELECT

The examples below also work for the [`execute`](/docs/examples/queries/prepared-statements/select) method.

## query(sql)

> **query(sql: string)**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'SELECT * FROM `users` WHERE `name` = "Page" AND `age` > 45';

  // highlight-next-line
  const [rows, fields] = await connection.query(sql);

  console.log(rows);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'SELECT * FROM `users` WHERE `name` = "Page" AND `age` > 45';

connection.query(sql, (err, rows, fields) => {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(rows);
  console.log(fields);
});
```

  </TabItem>
</Tabs>

- **rows** contains rows returned by server
- **fields** contains extra meta data about rows, if available

:::info
The connection used for the query (`.query()`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## query(options)

> **query(options: [QueryOptions](#queryoptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'SELECT * FROM `users` WHERE `name` = "Page" AND `age` > 45';

  // highlight-start
  const [rows, fields] = await connection.query({
    sql,
    // ... other options
  });
  // highlight-end

  console.log(rows);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'SELECT * FROM `users` WHERE `name` = "Page" AND `age` > 45';

connection.query(
  {
    sql,
    // ... other options
  },
  (err, rows, fields) => {
    if (err instanceof Error) {
      console.log(err);
      return;
    }

    console.log(rows);
    console.log(fields);
  }
);
```

  </TabItem>
</Tabs>

- **rows** contains rows returned by server
- **fields** contains extra meta data about rows, if available

:::info
The connection used for the query (`.query()`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## query(options) — Row as Array

> **query(options: [QueryOptions](#queryoptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'SELECT * FROM `users` WHERE `name` = "Page" AND `age` > 45';

  // highlight-start
  const [rows, fields] = await connection.query({
    sql,
    rowsAsArray: true,
    // ... other options
  });
  // highlight-end

  console.log(rows);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'SELECT * FROM `users` WHERE `name` = "Page" AND `age` > 45';

connection.query(
  {
    sql,
    rowsAsArray: true,
    // ... other options
  },
  (err, rows, fields) => {
    if (err instanceof Error) {
      console.log(err);
      return;
    }

    console.log(rows);
    console.log(fields);
  }
);
```

  </TabItem>
</Tabs>

- **rows** contains rows returned by server as array
- **fields** contains extra meta data about rows, if available

:::info
The connection used for the query (`.query()`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## Glossary

### QueryOptions

<FAQ title={'QueryOptions Specification'}>
  <ExternalCodeEmbed
    language='ts'
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/protocol/sequences/Query.d.ts'
    extractMethod='QueryOptions'
    methodType='interface'
  />
</FAQ>
</file>

<file path="website/docs/examples/queries/simple-queries/update.mdx">
---
sidebar_position: 2
tags: [query]
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { FAQ } from '@site/src/components/FAQ';
import { ExternalCodeEmbed } from '@site/src/components/ExternalCodeEmbed';

# UPDATE

The examples below also work for the [`execute`](/docs/examples/queries/prepared-statements/update) method.

## query(sql)

> **query(sql: string)**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'UPDATE `users` SET `age` = 20 WHERE `name` = "Josh" LIMIT 1';

  // highlight-next-line
  const [result, fields] = await connection.query(sql);

  console.log(result);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'UPDATE `users` SET `age` = 20 WHERE `name` = "Josh" LIMIT 1';

connection.query(sql, (err, result, fields) => {
  if (err instanceof Error) {
    console.log(err);
    return;
  }

  console.log(result);
  console.log(fields);
});
```

  </TabItem>
</Tabs>

- **result**: contains a [ResultSetHeader](#resultsetheader) object, which provides details about the operation executed by the server.
- **fields** contains extra meta data about the operation, if available

:::info
The connection used for the query (`.query()`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## query(options)

> **query(options: [QueryOptions](#queryoptions))**

<Tabs>
  <TabItem value='promise.js' default>

```js
try {
  const sql = 'UPDATE `users` SET `age` = 20 WHERE `name` = "Josh" LIMIT 1';

  // highlight-start
  const [result, fields] = await connection.query({
    sql,
    // ... other options
  });
  // highlight-end

  console.log(result);
  console.log(fields);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='callback.js'>

```js
const sql = 'UPDATE `users` SET `age` = 20 WHERE `name` = "Josh" LIMIT 1';

connection.query(
  {
    sql,
    // ... other options
  },
  (err, result, fields) => {
    if (err instanceof Error) {
      console.log(err);
      return;
    }

    console.log(result);
    console.log(fields);
  }
);
```

  </TabItem>
</Tabs>

- **result**: contains a [ResultSetHeader](#resultsetheader) object, which provides details about the operation executed by the server.
- **fields** contains extra meta data about the operation, if available

:::info
The connection used for the query (`.query()`) can be obtained through the `createConnection`, `createPool` or `createPoolCluster` methods.
:::

<hr />

## Glossary

### ResultSetHeader

<FAQ title='ResultSetHeader Specification'>
  <ExternalCodeEmbed
    language='ts'
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/protocol/packets/ResultSetHeader.d.ts'
    extractMethod='ResultSetHeader'
    methodType='interface'
  />
</FAQ>

### QueryOptions

<FAQ title='QueryOptions Specification'>
  <ExternalCodeEmbed
    language='ts'
    url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/typings/mysql/lib/protocol/sequences/Query.d.ts'
    extractMethod='QueryOptions'
    methodType='interface'
  />
</FAQ>
</file>

<file path="website/docs/examples/tests/_category_.json">
{
  "label": "Tests"
}
</file>

<file path="website/docs/examples/tests/mysql-proxy.mdx">
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# MySQL Proxy

<Tabs>
  <TabItem value='index.js' default>

```js
'use strict';

const mysql = require('mysql2');
const ClientFlags = require('mysql2/lib/constants/client.js');

const server = mysql.createServer();
server.listen(3307);

server.on('connection', (conn) => {
  console.log('connection');

  conn.serverHandshake({
    protocolVersion: 10,
    serverVersion: 'node.js rocks',
    connectionId: 1234,
    statusFlags: 2,
    characterSet: 8,
    capabilityFlags: 0xffffff ^ ClientFlags.COMPRESS,
  });

  conn.on('field_list', (table, fields) => {
    console.log('field list:', table, fields);
    conn.writeEof();
  });

  const remote = mysql.createConnection({
    user: 'root',
    database: 'dbname',
    host: 'server.example.com',
    password: 'secret',
  });

  conn.on('query', (sql) => {
    console.log(`proxying query: ${sql}`);
    remote.query(sql, function (err) {
      // overloaded args, either (err, result :object)
      // or (err, rows :array, columns :array)
      if (Array.isArray(arguments[1])) {
        // response to a 'select', 'show' or similar
        const rows = arguments[1],
          columns = arguments[2];
        console.log('rows', rows);
        console.log('columns', columns);
        conn.writeTextResult(rows, columns);
      } else {
        // response to an 'insert', 'update' or 'delete'
        const result = arguments[1];
        console.log('result', result);
        conn.writeOk(result);
      }
    });
  });

  conn.on('end', remote.end.bind(remote));
});
```

  </TabItem>
</Tabs>
</file>

<file path="website/docs/examples/tests/pool.mdx">
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Pool

<Tabs>
  <TabItem value='index.js' default>

```js
'use strict';

const pool = require('mysql2').createPool({
  host: 'localhost',
  user: 'root',
  database: 'test',
  password: 'root',
});

setInterval(() => {
  for (let i = 0; i < 5; ++i) {
    pool.query((err, rows, fields) => {
      console.log(rows, fields);
      // Connection is automatically released once query resolves
    });
  }
}, 1000);

setInterval(() => {
  for (let i = 0; i < 5; ++i) {
    pool.getConnection((err, db) => {
      db.query('select sleep(0.5) as qqq', (err, rows, fields) => {
        console.log(rows, fields);
        db.release();
      });
    });
  }
}, 1000);
```

  </TabItem>
</Tabs>
</file>

<file path="website/docs/examples/tests/server.mdx">
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Server

<Tabs>
  <TabItem value='index.js' default>

```js
'use strict';

const mysql = require('mysql2');
const flags = require('mysql2/lib/constants/client.js');
const auth = require('mysql2/lib/auth_41.js');

function authenticate(params, cb) {
  console.log(params);
  const doubleSha = auth.doubleSha1('pass123');
  const isValid = auth.verifyToken(
    params.authPluginData1,
    params.authPluginData2,
    params.authToken,
    doubleSha
  );
  if (isValid) {
    cb(null);
  } else {
    // for list of codes lib/constants/errors.js
    cb(null, { message: 'wrong password dude', code: 1045 });
  }
}

const server = mysql.createServer();
server.listen(3333);
server.on('connection', (conn) => {
  // we can deny connection here:
  // conn.writeError({ message: 'secret', code: 123 });
  // conn.close();
  conn.serverHandshake({
    protocolVersion: 10,
    serverVersion: '5.6.10', // 'node.js rocks',
    connectionId: 1234,
    statusFlags: 2,
    characterSet: 8,
    // capabilityFlags: 0xffffff,
    // capabilityFlags: -2113931265,
    capabilityFlags: 2181036031,
    authCallback: authenticate,
  });

  conn.on('field_list', (table, fields) => {
    console.log('FIELD LIST:', table, fields);
    conn.writeEof();
  });

  conn.on('query', (query) => {
    conn.writeColumns([
      {
        catalog: 'def',
        schema: 'test',
        table: 'test_table',
        orgTable: 'test_table',
        name: 'beta',
        orgName: 'beta',
        characterSet: 33,
        columnLength: 384,
        columnType: 253,
        flags: 0,
        decimals: 0,
      },
    ]);
    conn.writeTextRow(['test тест テスト փորձարկում পরীক্ষা kiểm tra ']);
    conn.writeTextRow(['ტესტი પરીક્ષણ  מבחן פּרובירן اختبار परीक्षण']);
    conn.writeEof();
    conn.close();
  });
});
```

  </TabItem>
</Tabs>
</file>

<file path="website/docs/examples/typescript/_category_.json">
{
  "label": "TypeScript"
}
</file>

<file path="website/docs/examples/typescript/basic-custom-class.mdx">
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Basic Custom Class

<Tabs>
  <TabItem value='index.ts' default>

```ts
/**
 * The types are explicity for learning purpose
 */

import { PoolOptions } from 'mysql2/promise';
import { MySQL } from './db.js';

interface User extends RowDataPacket {
  id: number;
  name: string;
}

const access: PoolOptions = {
  host: '',
  user: '',
  password: '',
  database: '',
};

(async () => {
  const mysql = new MySQL(access);

  /** Deleting the `users` table, if it exists */
  await mysql.queryResult('DROP TABLE IF EXISTS `users`;');

  /** Creating a minimal user table */
  await mysql.queryResult(
    'CREATE TABLE `users` (`id` INT(11) AUTO_INCREMENT, `name` VARCHAR(50), PRIMARY KEY (`id`));'
  );

  /** Inserting some users */
  const [inserted] = await mysql.executeResult(
    'INSERT INTO `users`(`name`) VALUES(?), (?), (?), (?);',
    ['Josh', 'John', 'Marie', 'Gween']
  );

  console.log('Inserted:', inserted.affectedRows);

  /** Getting users */
  const [users] = await mysql.queryRows(
    'SELECT * FROM `users` ORDER BY `name` ASC;'
  );

  users.forEach((user: User) => {
    console.log('-----------');
    console.log('id:  ', user.id);
    console.log('name:', user.name);
  });

  await mysql.connection.end();
})();

/** Output
 *
 * Inserted: 4
 * -----------
 * id:   4
 * name: Gween
 * -----------
 * id:   2
 * name: John
 * -----------
 * id:   1
 * name: Josh
 * -----------
 * id:   3
 * name: Marie
 */
```

  </TabItem>
  <TabItem value='db.ts'>

```ts
/**
 * The types are explicity for learning purpose
 */

import {
  createPool,
  PoolOptions,
  Pool,
  ResultSetHeader,
  RowDataPacket,
} from 'mysql2/promise';

export class MySQL {
  private conn: Pool;
  private credentials: PoolOptions;

  constructor(credentials: PoolOptions) {
    this.credentials = credentials;
    this.conn = createPool(this.credentials);
  }

  /** A random method to simulate a step before to get the class methods */
  private ensureConnection() {
    if (!this?.conn) this.conn = createPool(this.credentials);
  }

  /** For `SELECT` and `SHOW` */
  get queryRows() {
    this.ensureConnection();
    return this.conn.query.bind(this.conn)<RowDataPacket[]>;
  }

  /** For `SELECT` and `SHOW` with `rowAsArray` as `true` */
  get queryRowsAsArray() {
    this.ensureConnection();
    return this.conn.query.bind(this.conn)<RowDataPacket[][]>;
  }

  /** For `INSERT`, `UPDATE`, etc. */
  get queryResult() {
    this.ensureConnection();
    return this.conn.query.bind(this.conn)<ResultSetHeader>;
  }

  /** For multiple `INSERT`, `UPDATE`, etc. with `multipleStatements` as `true` */
  get queryResults() {
    this.ensureConnection();
    return this.conn.query.bind(this.conn)<ResultSetHeader[]>;
  }

  /** For `SELECT` and `SHOW` */
  get executeRows() {
    this.ensureConnection();
    return this.conn.execute.bind(this.conn)<RowDataPacket[]>;
  }

  /** For `SELECT` and `SHOW` with `rowAsArray` as `true` */
  get executeRowsAsArray() {
    this.ensureConnection();
    return this.conn.execute.bind(this.conn)<RowDataPacket[][]>;
  }

  /** For `INSERT`, `UPDATE`, etc. */
  get executeResult() {
    this.ensureConnection();
    return this.conn.execute.bind(this.conn)<ResultSetHeader>;
  }

  /** For multiple `INSERT`, `UPDATE`, etc. with `multipleStatements` as `true` */
  get executeResults() {
    this.ensureConnection();
    return this.conn.execute.bind(this.conn)<ResultSetHeader[]>;
  }

  /** Expose the Pool Connection */
  get connection() {
    return this.conn;
  }
}
```

  </TabItem>
</Tabs>
</file>

<file path="website/docs/examples/typescript/procedure-call/_category_.json">
{
  "label": "Procedure Call"
}
</file>

<file path="website/docs/examples/typescript/procedure-call/00-index.mdx">
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Procedure Call Packet

<Tabs>
  <TabItem value='index.ts' default>

```js
/**
 * The types are explicity for learning purpose
 * By extending the `RowDataPacket`, you can use your Interface in `query` and `execute`
 */

import mysql, {
  ConnectionOptions,
  ProcedureCallPacket,
  ResultSetHeader,
  RowDataPacket,
} from 'mysql2/promise';

interface User extends RowDataPacket {
  id: number;
  name: string;
}

const isResultSetHeader = (data: unknown): data is ResultSetHeader => {
  if (!data || typeof data !== 'object') return false;

  const keys = [
    'fieldCount',
    'affectedRows',
    'insertId',
    'info',
    'serverStatus',
    'warningStatus',
    'changedRows',
  ];

  return keys.every((key) => key in data);
};

(async () => {
  const access: ConnectionOptions = {
    host: '',
    user: '',
    password: '',
    database: '',
  };

  const conn = await mysql.createConnection(access);

  /** Deleting the `users` table, if it exists */
  await conn.query<ResultSetHeader>('DROP TABLE IF EXISTS `users`;');

  /** Creating a minimal user table */
  await conn.query<ResultSetHeader>(
    'CREATE TABLE `users` (`id` INT(11) AUTO_INCREMENT, `name` VARCHAR(50), PRIMARY KEY (`id`));'
  );

  /** Inserting some users */
  const [inserted] = await conn.execute<ResultSetHeader>(
    'INSERT INTO `users`(`name`) VALUES(?), (?), (?), (?);',
    ['Josh', 'John', 'Marie', 'Gween']
  );

  console.log('Inserted:', inserted.affectedRows);

  /** Deleting the `getUsers` procedure, if it exists */
  await conn.query<ResultSetHeader>('DROP PROCEDURE IF EXISTS getUsers');

  /** Creating a procedure to get the users */
  await conn.query<ResultSetHeader>(`
    CREATE PROCEDURE getUsers()
    BEGIN
      SELECT * FROM users ORDER BY name ASC;
    END
  `);

  /** Getting users */
  // highlight-start
  const [procedureResult] =
    await conn.query<ProcedureCallPacket<User[]>>('CALL getUsers()');

  procedureResult.forEach((users) => {
    /** By perform a `SELECT` or `SHOW`, The last item of `procedureResult` always be a `ResultSetHeader` */
    if (isResultSetHeader(users)) {
      console.log('----------------');
      console.log('Affected Rows:', users.affectedRows);
    } else {
      users.forEach((user) => {
        console.log('----------------');
        console.log('id:  ', user.id);
        console.log('name:', user.name);
      });
    }
  });
  // highlight-end

  await conn.end();
})();

/** Output
 *
 * Inserted: 4
 * ----------------
 * id:   4
 * name: Gween
 * ----------------
 * id:   2
 * name: John
 * ----------------
 * id:   1
 * name: Josh
 * ----------------
 * id:   3
 * name: Marie
 * ----------------
 * Affected Rows: 0
 */
```

  </TabItem>
</Tabs>
</file>

<file path="website/docs/examples/typescript/procedure-call/01-row-as-array.mdx">
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Procedure Call Packet (Row as Array)

<Tabs>
  <TabItem value='index.ts' default>

```ts
/**
 * The types are explicity for learning purpose
 * By extending the `RowDataPacket`, you can use your Interface in `query` and `execute`
 */

import mysql, {
  ConnectionOptions,
  ProcedureCallPacket,
  ResultSetHeader,
  RowDataPacket,
} from 'mysql2/promise';

interface User extends RowDataPacket {
  /** id */
  0: number;
  /** name */
  1: string;
}

const isResultSetHeader = (data: unknown): data is ResultSetHeader => {
  if (!data || typeof data !== 'object') return false;

  const keys = [
    'fieldCount',
    'affectedRows',
    'insertId',
    'info',
    'serverStatus',
    'warningStatus',
    'changedRows',
  ];

  return keys.every((key) => key in data);
};

(async () => {
  const access: ConnectionOptions = {
    host: '',
    user: '',
    password: '',
    database: '',
    rowsAsArray: true,
  };

  const conn = await mysql.createConnection(access);

  /** Deleting the `users` table, if it exists */
  await conn.query<ResultSetHeader>('DROP TABLE IF EXISTS `users`;');

  /** Creating a minimal user table */
  await conn.query<ResultSetHeader>(
    'CREATE TABLE `users` (`id` INT(11) AUTO_INCREMENT, `name` VARCHAR(50), PRIMARY KEY (`id`));'
  );

  /** Inserting some users */
  const [inserted] = await conn.execute<ResultSetHeader>(
    'INSERT INTO `users`(`name`) VALUES(?), (?), (?), (?);',
    ['Josh', 'John', 'Marie', 'Gween']
  );

  console.log('Inserted:', inserted.affectedRows);

  /** Deleting the `getUsers` procedure, if it exists */
  await conn.query<ResultSetHeader>('DROP PROCEDURE IF EXISTS getUsers');

  /** Creating a procedure to get the users */
  await conn.query<ResultSetHeader>(`
    CREATE PROCEDURE getUsers()
    BEGIN
      SELECT * FROM users ORDER BY name ASC;
    END
  `);

  /** Getting users */
  // highlight-start
  const [procedureResult] =
    await conn.query<ProcedureCallPacket<User[]>>('CALL getUsers()');

  procedureResult.forEach((users) => {
    /** By perform a `SELECT` or `SHOW`, The last item of `procedureResult` always be a `ResultSetHeader` */
    if (isResultSetHeader(users)) {
      console.log('----------------');
      console.log('Affected Rows:', users.affectedRows);
    } else {
      users.forEach((user) => {
        console.log('----------------');
        console.log('id:  ', user[0]);
        console.log('name:', user[1]);
      });
    }
  });
  // highlight-end

  await conn.end();
})();

/** Output
 *
 * Inserted: 4
 * ----------------
 * id:   4
 * name: Gween
 * ----------------
 * id:   2
 * name: John
 * ----------------
 * id:   1
 * name: Josh
 * ----------------
 * id:   3
 * name: Marie
 * ----------------
 * Affected Rows: 0
 */
```

  </TabItem>
</Tabs>
</file>

<file path="website/docs/examples/typescript/row-data/_category_.json">
{
  "label": "Row Data"
}
</file>

<file path="website/docs/examples/typescript/row-data/00-index.mdx">
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Row Data Packet

<Tabs>
  <TabItem value='index.ts' default>

```ts
/**
 * The types are explicity for learning purpose
 * By extending the `RowDataPacket`, you can use your Interface in `query` and `execute`
 */

import mysql, {
  ConnectionOptions,
  ResultSetHeader,
  RowDataPacket,
} from 'mysql2/promise';

interface User extends RowDataPacket {
  id: number;
  name: string;
}

(async () => {
  const access: ConnectionOptions = {
    host: '',
    user: '',
    password: '',
    database: '',
  };

  const conn = await mysql.createConnection(access);

  /** Deleting the `users` table, if it exists */
  await conn.query<ResultSetHeader>('DROP TABLE IF EXISTS `users`;');

  /** Creating a minimal user table */
  await conn.query<ResultSetHeader>(
    'CREATE TABLE `users` (`id` INT(11) AUTO_INCREMENT, `name` VARCHAR(50), PRIMARY KEY (`id`));'
  );

  /** Inserting some users */
  const [inserted] = await conn.execute<ResultSetHeader>(
    'INSERT INTO `users`(`name`) VALUES(?), (?), (?), (?);',
    ['Josh', 'John', 'Marie', 'Gween']
  );

  console.log('Inserted:', inserted.affectedRows);

  /** Getting users */
  const [users] = await conn.query<User[]>(
    'SELECT * FROM `users` ORDER BY `name` ASC;'
  );

  users.forEach((user) => {
    console.log('-----------');
    console.log('id:  ', user.id);
    console.log('name:', user.name);
  });

  await conn.end();
})();

/** Output
 *
 * Inserted: 4
 * -----------
 * id:   4
 * name: Gween
 * -----------
 * id:   2
 * name: John
 * -----------
 * id:   1
 * name: Josh
 * -----------
 * id:   3
 * name: Marie
 */
```

  </TabItem>
</Tabs>
</file>

<file path="website/docs/examples/typescript/row-data/01-row-as-array.mdx">
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Row Data Packet (Row as Array)

<Tabs>
  <TabItem value='index.ts' default>

```ts
/**
 * The types are explicity for learning purpose
 * By extending the `RowDataPacket`, you can use your Interface in `query` and `execute`
 */

import mysql, {
  ConnectionOptions,
  ResultSetHeader,
  RowDataPacket,
} from 'mysql2/promise';

interface User extends RowDataPacket {
  /** id */
  0: number;
  /** name */
  1: string;
}

(async () => {
  const access: ConnectionOptions = {
    host: '',
    user: '',
    password: '',
    database: '',
    rowsAsArray: true,
  };

  const conn = await mysql.createConnection(access);

  /** Deleting the `users` table, if it exists */
  await conn.query<ResultSetHeader>('DROP TABLE IF EXISTS `users`;');

  /** Creating a minimal user table */
  await conn.query<ResultSetHeader>(
    'CREATE TABLE `users` (`id` INT(11) AUTO_INCREMENT, `name` VARCHAR(50), PRIMARY KEY (`id`));'
  );

  /** Inserting some users */
  const [inserted] = await conn.execute<ResultSetHeader>(
    'INSERT INTO `users`(`name`) VALUES(?), (?), (?), (?);',
    ['Josh', 'John', 'Marie', 'Gween']
  );

  console.log('Inserted:', inserted.affectedRows);

  /** Getting users */
  const [users] = await conn.query<User[]>(
    'SELECT * FROM `users` ORDER BY `name` ASC;'
  );

  users.forEach((user) => {
    console.log('-----------');
    console.log('id:  ', user[0]);
    console.log('name:', user[1]);
  });

  await conn.end();
})();

/** Output
 *
 * Inserted: 4
 * -----------
 * id:   4
 * name: Gween
 * -----------
 * id:   2
 * name: John
 * -----------
 * id:   1
 * name: Josh
 * -----------
 * id:   3
 * name: Marie
 */
```

  </TabItem>
</Tabs>
</file>

<file path="website/docs/examples/typescript/row-data/02-multi-statements.mdx">
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Row Data Packet (Multi Statements)

<Tabs>
  <TabItem value='index.ts' default>

```ts
/**
 * The types are explicity for learning purpose
 * By extending the `RowDataPacket`, you can use your Interface in `query` and `execute`
 */

import mysql, {
  ConnectionOptions,
  ResultSetHeader,
  RowDataPacket,
} from 'mysql2/promise';

interface User extends RowDataPacket {
  id: number;
  name: string;
}

(async () => {
  const access: ConnectionOptions = {
    host: '',
    user: '',
    password: '',
    database: '',
    multipleStatements: true,
  };

  const conn = await mysql.createConnection(access);

  /** Deleting the `users` table, if it exists */
  await conn.query<ResultSetHeader>('DROP TABLE IF EXISTS `users`;');

  /** Creating a minimal user table */
  await conn.query<ResultSetHeader>(
    'CREATE TABLE `users` (`id` INT(11) AUTO_INCREMENT, `name` VARCHAR(50), PRIMARY KEY (`id`));'
  );

  /** Inserting some users */
  const [inserted] = await conn.execute<ResultSetHeader>(
    'INSERT INTO `users`(`name`) VALUES(?), (?), (?), (?);',
    ['Josh', 'John', 'Marie', 'Gween']
  );

  console.log('Inserted:', inserted.affectedRows);

  /** Getting users */
  const [rows] = await conn.query<User[][]>(
    [
      'SELECT * FROM `users` ORDER BY `name` ASC LIMIT 2;',
      'SELECT * FROM `users` ORDER BY `name` ASC LIMIT 2 OFFSET 2;',
    ].join(' ')
  );

  rows.forEach((users) => {
    users.forEach((user) => {
      console.log('-----------');
      console.log('id:  ', user.id);
      console.log('name:', user.name);
    });
  });

  await conn.end();
})();

/** Output
 *
 * Inserted: 4
 * -----------
 * id:   4
 * name: Gween
 * -----------
 * id:   2
 * name: John
 * -----------
 * id:   1
 * name: Josh
 * -----------
 * id:   3
 * name: Marie
 */
```

  </TabItem>
</Tabs>
</file>

<file path="website/docs/examples/typescript/row-data/03-row-as-array-multi-statements.mdx">
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Row Data Packet (Multi Statements and Row as Array)

<Tabs>
  <TabItem value='index.ts' default>

```ts
/**
 * The types are explicity for learning purpose
 * By extending the `RowDataPacket`, you can use your Interface in `query` and `execute`
 */

import mysql, {
  ConnectionOptions,
  ResultSetHeader,
  RowDataPacket,
} from 'mysql2/promise';

interface User extends RowDataPacket {
  /** id */
  0: number;
  /** name */
  1: string;
}

(async () => {
  const access: ConnectionOptions = {
    host: '',
    user: '',
    password: '',
    database: '',
    multipleStatements: true,
    rowsAsArray: true,
  };

  const conn = await mysql.createConnection(access);

  /** Deleting the `users` table, if it exists */
  await conn.query<ResultSetHeader>('DROP TABLE IF EXISTS `users`;');

  /** Creating a minimal user table */
  await conn.query<ResultSetHeader>(
    'CREATE TABLE `users` (`id` INT(11) AUTO_INCREMENT, `name` VARCHAR(50), PRIMARY KEY (`id`));'
  );

  /** Inserting some users */
  const [inserted] = await conn.execute<ResultSetHeader>(
    'INSERT INTO `users`(`name`) VALUES(?), (?), (?), (?);',
    ['Josh', 'John', 'Marie', 'Gween']
  );

  console.log('Inserted:', inserted.affectedRows);

  /** Getting users */
  const [rows] = await conn.query<User[][]>(
    [
      'SELECT * FROM `users` ORDER BY `name` ASC LIMIT 2;',
      'SELECT * FROM `users` ORDER BY `name` ASC LIMIT 2 OFFSET 2;',
    ].join(' ')
  );

  rows.forEach((users) => {
    users.forEach((user) => {
      console.log('-----------');
      console.log('id:  ', user[0]);
      console.log('name:', user[1]);
    });
  });

  await conn.end();
})();

/** Output
 *
 * Inserted: 4
 * -----------
 * id:   4
 * name: Gween
 * -----------
 * id:   2
 * name: John
 * -----------
 * id:   1
 * name: Josh
 * -----------
 * id:   3
 * name: Marie
 */
```

  </TabItem>
</Tabs>
</file>

<file path="website/docs/faq/00-index.mdx">
---
slug: /faq
title: Introduction
---

import { PageTitle } from '@site/src/components/PageTitle';

<PageTitle title='FAQ' />

# Frequently Asked Questions

This section provides answers to commonly asked questions about [MySQL2](https://github.com/sidorares/node-mysql2/discussions).

:::tip
To explore the FAQs, please use the **sidebar navigation** on desktop or access the **menu** on mobile devices.
:::
</file>

<file path="website/docs/faq/how-to-handle-errors.mdx">
import { FAQ } from '@site/src/components/FAQ';
import { Stability } from '@site/src/components/Stability';

# How to handle errors?

This section details error handling techniques in MySQL2. It covers essential error management strategies for methods such as `createConnection`, `createPool`, `createPoolCluster`, `execute` and `query`.

## Using callbacks

<FAQ title='createConnection'>

<Stability
  level={2}
  message='This solution has been tested and confirmed as the correct answer.'
/>

Handling connection errors by adding an error event listener:

```js
const mysql = require('mysql2');

connection = mysql.createConnection({
  host: '',
  user: '',
  database: '',
});

// highlight-start
connection.addListener('error', (err) => {
  if (err instanceof Error) {
    console.log(`createConnection error:`, err);
  }
});
// highlight-end
```

</FAQ>

<FAQ title='createPool'>

<Stability level={2} message='This solution has been tested.' />

Handling connection errors through callback's `err` parameter:

```js
const mysql = require('mysql2');

const pool = mysql.createPool({
  host: '',
  user: '',
  database: '',
});

pool.getConnection((err, connection) => {
  // highlight-start
  if (err instanceof Error) {
    console.log('pool.getConnection error:', err);
    return;
  }
  // highlight-end
});
```

</FAQ>

<FAQ title='createPoolCluster'>

<Stability level={2} message='This solution has been tested.' />

Handling connection errors through callback's `err` parameter:

```js
const mysql = require('mysql2');

const poolCluster = mysql.createPoolCluster();

poolCluster.add('NodeI', {
  host: '',
  user: '',
  database: '',
});

poolCluster.getConnection('NodeI', (err, connection) => {
  // highlight-start
  if (err instanceof Error) {
    console.log('poolCluster.getConnection error:', err);
    return;
  }
  // highlight-end
});
```

</FAQ>

<FAQ title='execute'>

<Stability level={2} message='This solution has been tested.' />

Handling `execute` errors through callback's `err` parameter:

```js
connection.execute('SELEC 1 + 1', (err, rows) => {
  // highlight-start
  if (err instanceof Error) {
    console.log('execute error:', err);
    return;
  }
  // highlight-end

  console.log(rows);
});
```

- It will work for both **createConnection**, **createPool** and **createPoolCluster** connections.

</FAQ>

<FAQ title='query'>

<Stability level={2} message='This solution has been tested.' />

Handling `query` errors through callback's `err` parameter:

```js
connection.query('SELEC 1 + 1', (err, rows) => {
  // highlight-start
  if (err instanceof Error) {
    console.log('query error:', err);
    return;
  }
  // highlight-end

  console.log(rows);
});
```

- It will work for both **createConnection**, **createPool** and **createPoolCluster** connections.

</FAQ>

## Using promises

<FAQ title='createConnection'>

<Stability
  level={2}
  message='This solution has been tested and confirmed as the correct answer.'
/>

Handling connection errors through `try-catch` block:

```js
import mysql from 'mysql2/promise';

try {
  const connection = await mysql.createConnection({
    host: '',
    user: '',
    database: '',
  });
  // highlight-start
} catch (err) {
  if (err instanceof Error) {
    console.log(err);
  }
}
// highlight-end
```

</FAQ>

<FAQ title='createPool'>

<Stability level={2} message='This solution has been tested.' />

Handling connection errors through `try-catch` block:

```js
import mysql from 'mysql2/promise';

const pool = mysql.createPool({
  host: '',
  user: '',
  database: '',
});

try {
  const connection = await pool.getConnection();
  // highlight-start
} catch (err) {
  if (err instanceof Error) {
    console.log(err);
  }
}
// highlight-end
```

</FAQ>

<FAQ title='createPoolCluster'>

<Stability level={2} message='This solution has been tested.' />

Handling connection errors through `try-catch` block:

```js
import mysql from 'mysql2/promise';

const poolCluster = mysql.createPoolCluster();

poolCluster.add('NodeI', {
  host: '',
  user: '',
  database: '',
});

try {
  await poolCluster.getConnection('NodeI');
  // highlight-start
} catch (err) {
  if (err instanceof Error) {
    console.log('createConnection error:', err);
  }
}
// highlight-end
```

</FAQ>

<FAQ title='execute'>

<Stability level={2} message='This solution has been tested.' />

Handling `execute` errors through `try-catch` block:

```js
try {
  const [rows] = await connection.execute('SELEC 1 + 1');
  console.log(rows);
  // highlight-start
} catch (err) {
  if (err instanceof Error) {
    console.log('execute error:', err);
  }
}
// highlight-end
```

- It will work for both **createConnection**, **createPool** and **createPoolCluster** connections.

</FAQ>

<FAQ title='query'>

<Stability level={2} message='This solution has been tested.' />

Handling `query` errors through `try-catch` block:

```js
try {
  const [rows] = await connection.query('SELEC 1 + 1');
  console.log(rows);
  // highlight-start
} catch (err) {
  if (err instanceof Error) {
    console.log('query error:', err);
  }
}
// highlight-end
```

- It will work for both **createConnection**, **createPool** and **createPoolCluster** connections.

</FAQ>

<hr />

## Related Links

- Discussions
  - [#1998](https://github.com/sidorares/node-mysql2/discussions/1998)
  - [#2282](https://github.com/sidorares/node-mysql2/discussions/2282)
</file>

<file path="website/docs/history-and-why-mysq2.mdx">
# History and Why MySQL2

[node-mysql]: https://github.com/mysqljs/mysql
[mysql-native]: https://github.com/sidorares/nodejs-mysql-native
[mysqljs]: https://github.com/mysqljs

MySQL2 project is a continuation of [MySQL-Native][mysql-native]. Protocol parser code was rewritten from scratch and api changed to match popular [Node MySQL][node-mysql]. MySQL2 team is working together with [Node MySQL][node-mysql] team to factor out shared code and move it under [mysqljs][mysqljs] organization.

MySQL2 is mostly API compatible with [Node MySQL][node-mysql] and supports majority of features. MySQL2 also offers these additional features:

- Faster / Better Performance
- [Prepared Statements](/docs/documentation/prepared-statements)
- MySQL Binary Log Protocol
- [MySQL Server](/docs/documentation/mysql-server)
- Extended support for Encoding and Collation
- [Promise Wrapper](/docs/documentation/promise-wrapper)
- Compression
- SSL and [Authentication Switch](/docs/documentation/authentication-switch)
- [Custom Streams](/docs/documentation/extras#connecting-using-custom-stream)
- [Pooling](/docs/#using-connection-pools)
</file>

<file path="website/docs/index.mdx">
---
slug: /
position: 1
title: Quickstart
description: MySQL client for Node.js with focus on performance
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { PageTitle } from '@site/src/components/PageTitle';

<PageTitle title='MySQL2 | Quickstart' />

[npm-image]: https://img.shields.io/npm/v/mysql2.svg
[npm-url]: https://npmjs.org/package/mysql2
[node-version-image]: https://img.shields.io/node/v/mysql2.svg
[node-version-url]: https://nodejs.org/download/
[downloads-image]: https://img.shields.io/npm/dm/mysql2.svg
[downloads-url]: https://npmjs.org/package/mysql2
[license-url]: https://github.com/sidorares/node-mysql2/blob/master/License
[license-image]: https://img.shields.io/npm/l/mysql2.svg?maxAge=2592000
[node-mysql]: https://github.com/mysqljs/mysql
[coverage]: https://img.shields.io/codecov/c/github/sidorares/node-mysql2
[coverage-url]: https://app.codecov.io/github/sidorares/node-mysql2
[ci-url]: https://github.com/sidorares/node-mysql2/actions/workflows/ci-coverage.yml?query=branch%3Amaster
[ci-image]: https://img.shields.io/github/actions/workflow/status/sidorares/node-mysql2/ci-coverage.yml?event=push&style=flat&label=CI&branch=master

# MySQL2

{/* <Logo className='logo' width={150} height={150} /> */}

MySQL client for Node.js with focus on performance. Supports prepared statements, non-utf8 encodings, binary log protocol, compression, ssl much more.

[![NPM Version][npm-image]][npm-url]
[![NPM Downloads][downloads-image]][downloads-url]
[![Node.js Version][node-version-image]][node-version-url]
[![GitHub Workflow Status (with event)][ci-image]][ci-url]
[![Codecov][coverage]][coverage-url]
[![License][license-image]][license-url]

## Installation

MySQL2 is free from native bindings and can be installed on Linux, Mac OS or Windows without any issues.

<Tabs>
  <TabItem value='JavaScript' default>

```bash
npm install --save mysql2
```

  </TabItem>
  <TabItem value='TypeScript'>

```bash
npm install --save mysql2
npm install --save-dev @types/node
```

    For TypeScript documentation and examples, see [here](/docs/documentation/typescript-examples).

  </TabItem>
</Tabs>

<hr />

### First Query

> To explore more queries examples, please visit the example sections [**Simple Queries**](/docs/examples/queries/simple-queries) and [**Prepared Statements**](/docs/examples/queries/prepared-statements).

<Tabs>
  <TabItem value='Promise' default>

```js
// Get the client
import mysql from 'mysql2/promise';

// Create the connection to database
const connection = await mysql.createConnection({
  host: 'localhost',
  user: 'root',
  database: 'test',
});

// A simple SELECT query
try {
  const [results, fields] = await connection.query(
    'SELECT * FROM `table` WHERE `name` = "Page" AND `age` > 45'
  );

  console.log(results); // results contains rows returned by server
  console.log(fields); // fields contains extra meta data about results, if available
} catch (err) {
  console.log(err);
}

// Using placeholders
try {
  const [results] = await connection.query(
    'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
    ['Page', 45]
  );

  console.log(results);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='Callback'>

```js
// Get the client
const mysql = require('mysql2');

// Create the connection to database
const connection = mysql.createConnection({
  host: 'localhost',
  user: 'root',
  database: 'test',
});

// A simple SELECT query
connection.query(
  'SELECT * FROM `table` WHERE `name` = "Page" AND `age` > 45',
  function (err, results, fields) {
    console.log(results); // results contains rows returned by server
    console.log(fields); // fields contains extra meta data about results, if available
  }
);

// Using placeholders
connection.query(
  'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
  ['Page', 45],
  function (err, results) {
    console.log(results);
  }
);
```

</TabItem>
</Tabs>

<hr />

### Using Prepared Statements

With MySQL2 you also get the prepared statements. With prepared statements MySQL doesn't have to prepare plan for same query every time, this results in better performance. If you don't know why they are important, please check these discussions:

- [How prepared statements can protect from SQL Injection attacks](https://stackoverflow.com/questions/8263371/how-can-prepared-statements-protect-from-sql-injection-attacks)

MySQL2 provides `execute` helper which will prepare and query the statement. You can also manually prepare / unprepare statement with `prepare` / `unprepare` methods.

> To explore more Prepared Statements and Placeholders examples, please visit the example section [**Prepared Statements**](/docs/examples/queries/prepared-statements).

<Tabs>
  <TabItem value='Promise' default>

```js
import mysql from 'mysql2/promise';

try {
  // create the connection to database
  const connection = await mysql.createConnection({
    host: 'localhost',
    user: 'root',
    database: 'test',
  });

  // execute will internally call prepare and query
  const [results, fields] = await connection.execute(
    'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
    ['Rick C-137', 53]
  );

  console.log(results); // results contains rows returned by server
  console.log(fields); // fields contains extra meta data about results, if available
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='Callback'>

```js
const mysql = require('mysql2');

// create the connection to database
const connection = mysql.createConnection({
  host: 'localhost',
  user: 'root',
  database: 'test',
});

// execute will internally call prepare and query
connection.execute(
  'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
  ['Rick C-137', 53],
  function (err, results, fields) {
    console.log(results); // results contains rows returned by server
    console.log(fields); // fields contains extra meta data about results, if available
  }
);
```

  </TabItem>
</Tabs>

:::tip
If you execute same statement again, it will be picked from a LRU cache which will save query preparation time and give better performance.
:::

<hr />

### Using Connection Pools

Connection pools help reduce the time spent connecting to the MySQL server by reusing a previous connection, leaving them open instead of closing when you are done with them.

This improves the latency of queries as you avoid all of the overhead that comes with establishing a new connection.

> To explore more Connection Pools examples, please visit the example section [**createPool**](/docs/examples/connections/create-pool).

<Tabs>
  <TabItem value='Promise' default>

```js
import mysql from 'mysql2/promise';

// Create the connection pool. The pool-specific settings are the defaults
const pool = mysql.createPool({
  host: 'localhost',
  user: 'root',
  database: 'test',
  waitForConnections: true,
  connectionLimit: 10,
  maxIdle: 10, // max idle connections, the default value is the same as `connectionLimit`
  idleTimeout: 60000, // idle connections timeout, in milliseconds, the default value 60000
  queueLimit: 0,
  enableKeepAlive: true,
  keepAliveInitialDelay: 0,
});
```

    </TabItem>
    <TabItem value='Callback'>

```js
const mysql = require('mysql2');

// Create the connection pool. The pool-specific settings are the defaults
const pool = mysql.createPool({
  host: 'localhost',
  user: 'root',
  database: 'test',
  waitForConnections: true,
  connectionLimit: 10,
  maxIdle: 10, // max idle connections, the default value is the same as `connectionLimit`
  idleTimeout: 60000, // idle connections timeout, in milliseconds, the default value 60000
  queueLimit: 0,
  enableKeepAlive: true,
  keepAliveInitialDelay: 0,
});
```

  </TabItem>
</Tabs>

:::note
The pool does not create all connections upfront but creates them on demand until the connection limit is reached.
:::

<hr />

You can use the pool in the same way as connections (using `pool.query()` and `pool.execute()`):

<Tabs>
  <TabItem value='Promise' default>

```js
try {
  // For pool initialization, see above
  const [rows, fields] = await pool.query('SELECT `field` FROM `table`');
  // Connection is automatically released when query resolves
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='Callback'>

```js
// For pool initialization, see above
pool.query('SELECT `field` FROM `table`', function (err, rows, fields) {
  // Connection is automatically released when query resolves
});
```

  </TabItem>
</Tabs>

Alternatively, there is also the possibility of manually acquiring a connection from the pool and returning it later:

<Tabs>
  <TabItem value='Promise' default>

```js
// For pool initialization, see above
const conn = await pool.getConnection();

// Do something with the connection
await conn.query(/* ... */);

// Don't forget to release the connection when finished!
pool.releaseConnection(conn);
```

  </TabItem>
  <TabItem value='Callback'>

```js
// For pool initialization, see above
pool.getConnection(function (err, conn) {
  // Do something with the connection
  conn.query(/* ... */);

  // Don't forget to release the connection when finished!
  pool.releaseConnection(conn);
});
```

  </TabItem>
</Tabs>

- Additionally, directly release the connection using the `connection` object:

```js
conn.release();
```

<hr />

### Using Promise Wrapper

MySQL2 also support Promise API. Which works very well with ES7 async await.

```js
import mysql from 'mysql2/promise';

async function main() {
  // create the connection
  const connection = await mysql.createConnection({
    host: 'localhost',
    user: 'root',
    database: 'test',
  });

  // query database
  const [rows, fields] = await connection.execute(
    'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
    ['Morty', 14]
  );
}
```

MySQL2 use default `Promise` object available in scope. But you can choose which `Promise` implementation you want to use.

```js
// get the client
import mysql from 'mysql2/promise';

// get the promise implementation, we will use bluebird
import bluebird from 'bluebird';

// create the connection, specify bluebird as Promise
const connection = await mysql.createConnection({
  host: 'localhost',
  user: 'root',
  database: 'test',
  Promise: bluebird,
});

// query database
const [rows, fields] = await connection.execute(
  'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
  ['Morty', 14]
);
```

MySQL2 also exposes a `.promise()` function on Pools, so you can create a promise/non-promise connections from the same pool.

```js
import mysql from 'mysql2';

async function main() {
  // create the pool
  const pool = mysql.createPool({
    host: 'localhost',
    user: 'root',
    database: 'test',
  });

  // now get a Promise wrapped instance of that pool
  const promisePool = pool.promise();

  // query database using promises
  const [rows, fields] = await promisePool.query('SELECT 1');
}
```

MySQL2 exposes a `.promise()` function on Connections, to "upgrade" an existing non-promise connection to use promise.

```js {11}
const mysql = require('mysql2');

// create the connection
const conn = mysql.createConnection({
  host: 'localhost',
  user: 'root',
  database: 'test',
});

conn
  .promise()
  .query('SELECT 1')
  .then(([rows, fields]) => {
    console.log(rows);
  })
  .catch(console.log)
  .then(() => conn.end());
```

<hr />

### Array Results

If you have two columns with the same name, you might want to get results as an array rather than an object to prevent them from clashing. This is a deviation from the [Node MySQL][node-mysql] library.

For example: `` SELECT 1 AS `foo`, 2 AS `foo` ``.

You can enable this setting at either the connection level (applies to all queries), or at the query level (applies only to that specific query).

#### Connection Level

<Tabs>
  <TabItem value='Promise' default>

```js {5}
const conn = await mysql.createConnection({
  host: 'localhost',
  database: 'test',
  user: 'root',
  rowsAsArray: true,
});
```

  </TabItem>
  <TabItem value='Callback'>

```js {5}
const conn = mysql.createConnection({
  host: 'localhost',
  database: 'test',
  user: 'root',
  rowsAsArray: true,
});
```

  </TabItem>
</Tabs>

#### Query Level

<Tabs>
  <TabItem value='Promise' default>

```js {4}
try {
  const [results, fields] = await conn.query({
    sql: 'SELECT 1 AS `foo`, 2 AS `foo`',
    rowsAsArray: true,
  });

  console.log(results); // in this query, results will be an array of arrays rather than an array of objects
  console.log(fields); // fields are unchanged
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='Callback'>

```js {4}
conn.query(
  {
    sql: 'SELECT 1 AS `foo`, 2 AS `foo`',
    rowsAsArray: true,
  },
  function (err, results, fields) {
    console.log(results); // in this query, results will be an array of arrays rather than an array of objects
    console.log(fields); // fields are unchanged
  }
);
```

  </TabItem>
</Tabs>

<hr />

:::tip Getting Help
Need help? Ask your question on [Stack Overflow](https://stackoverflow.com/questions/tagged/mysql2) or [GitHub](https://github.com/sidorares/node-mysql2/discussions).
If you've encountered an issue, please [file it on GitHub](https://github.com/sidorares/node-mysql2/issues).
:::
</file>

<file path="website/docs/stability-badges.mdx">
import { Stability } from '@site/src/components/Stability';

# Stability Badges

The **Stability Badges** are indications of a section's stability.

The stability indices are as follows:

<Stability
  level={0}
  message='The feature might generate warnings and does not assure backward compatibility.'
/>

<hr />

**Experimental**: These features are not bound by semantic versioning. They may undergo non-backward compatible changes or be removed in future releases. Their use in production is discouraged.

> Use caution with Experimental features, especially in libraries. Users might not expect changes from these unstable features. To reduce surprises, consider using a command-line flag for Experimental features.

Experimental features are classified into stages:

<Stability
  level={1}
  message='Experimental features at this stage are currently in development and prone to considerable changes.'
/>

<Stability
  level={1.1}
  message='Experimental features at this stage are approaching minimum viability.'
/>

<Stability
  level={1.2}
  message='Experimental features are close to reaching stability. Major changes are not expected, but they could still occur based on user feedback. Testing and feedback are important to ascertain the readiness of these features for stable classification.'
/>

<hr />

<Stability
  level={2}
  message='Compatibility with the MySQL ecosystem is a high priority.'
/>

<hr />

<Stability
  level={3}
  message='This feature, while not likely to be removed and still subject to semantic versioning, is not under active maintenance and other options are available.'
/>

- Features are classified as legacy instead of deprecated when they cause no harm and have widespread use in the MySQL ecosystem. It's unlikely that bugs in legacy features will be addressed.
</file>

<file path="website/docusaurus.config.ts">
import { themes as prismThemes } from 'prism-react-renderer';
import type { Config } from '@docusaurus/types';
import type * as Preset from '@docusaurus/preset-classic';
import { navbarLocalePlugin, getLocaleURL } from './plugins/locale.js';

const config: Config = {
  title: 'Quickstart',
  url: 'https://sidorares.github.io/',
  baseUrl: '/node-mysql2/',
  organizationName: 'sidorares',
  projectName: 'node-mysql2',
  trailingSlash: false,
  favicon: 'img/favicon.svg',

  onBrokenLinks: 'throw',
  onBrokenMarkdownLinks: 'throw',
  onBrokenAnchors: 'throw',

  i18n: {
    defaultLocale: 'en',
    locales: ['en', 'zh-CN', 'pt-BR'],
    localeConfigs: {
      en: {
        label: '🇺🇸 English',
      },
      'zh-CN': {
        label: '🇨🇳 简体中文',
      },
      'pt-BR': {
        label: '🇧🇷 Português (Brasil)',
      },
    },
  },

  presets: [
    [
      'classic',
      {
        docs: {
          sidebarPath: './sidebars.ts',
          editUrl:
            'https://github.com/sidorares/node-mysql2/tree/master/website/',
        },
        theme: {
          customCss: './src/css/custom.scss',
        },
        blog: false,
      } satisfies Preset.Options,
    ],
  ],

  themeConfig: {
    // image: 'img/mysql2-social-card.jpg',
    navbar: {
      // logo: {
      //    alt: 'MySQL2 Logo',
      //    src: 'img/logo.svg',
      // },
      items: [
        {
          to: getLocaleURL(),
          label: 'MySQL2',
          position: 'left',
          className: 'navbar__brand navbar__manual--title text--truncate',
          activeBaseRegex: '^/$',
        },
        {
          to: '/docs/documentation',
          label: 'Docs',
          position: 'left',
        },
        {
          to: '/docs/examples',
          label: 'Examples',
          position: 'left',
        },
        {
          to: '/docs/faq',
          label: 'FAQ',
          position: 'left',
        },
        {
          href: 'https://github.com/sidorares/node-mysql2',
          label: 'GitHub',
          position: 'right',
        },
        {
          href: 'https://stackoverflow.com/questions/tagged/mysql2',
          label: 'Stack Overflow',
          position: 'right',
        },
        {
          href: 'https://github.com/sponsors/sidorares',
          label: 'Donate',
          position: 'right',
        },
        { type: 'search', position: 'right' },
        {
          type: 'localeDropdown',
          position: 'right',
        },
      ],
    },
    prism: {
      theme: prismThemes.github,
      darkTheme: prismThemes.dracula,
      additionalLanguages: ['json', 'bash', 'tsx'],
    },
  } satisfies Preset.ThemeConfig,

  plugins: [
    'docusaurus-plugin-sass',
    '@easyops-cn/docusaurus-search-local',
    navbarLocalePlugin,
  ],
};

export default config;
</file>

<file path="website/helpers/extract-method-content.ts">
export type MethodType = 'class' | 'interface' | 'type' | 'function' | 'const';

export const extractMethodContent = (
  text: string,
  methodName: string,
  type: MethodType
): string => {
  const lines = text.split('\n');
  const startPattern = `${type} ${methodName}`;

  let insideSegment = false;
  let depth = 0;
  let extractedCode = '';

  for (const line of lines) {
    if (line.includes(startPattern)) insideSegment = true;

    if (insideSegment) {
      if (line.includes('{')) depth++;

      extractedCode += `${line}\n`;

      if (line.includes('}')) {
        depth--;

        if (depth === 0) break;
      }
    }
  }

  return extractedCode.trim() || text;
};
</file>

<file path="website/i18n/pt-BR/docusaurus-plugin-content-docs/current.json">
{
  "sidebar.docs.category.Documentation": {
    "message": "Documentação"
  },
  "sidebar.docs.category.Examples": {
    "message": "Exemplos"
  },
  "sidebar.docs.category.Contributing": {
    "message": "Contribuições"
  }
}
</file>

<file path="website/i18n/pt-BR/docusaurus-plugin-content-docs/current/acknowledgements.mdx">
# Agradecimentos

- O protocolo interno é escrito por @sidorares [MySQL-Native](https://github.com/sidorares/nodejs-mysql-native)
- _Constants_, interpolação de parâmetros SQL, _Pooling_ e a classe `ConnectionConfig` foram retirados do [node-mysql](https://github.com/mysqljs/mysql)
- O Código de atualização SSL é baseado no [código](https://gist.github.com/TooTallNate/848444) feito por @TooTallNate
- _Flags_ de API de conexão segura / comprimida compatíveis com o cliente [MariaSQL](https://github.com/mscdex/node-mariasql/).
- [Contribuidores](https://github.com/sidorares/node-mysql2/graphs/contributors)
</file>

<file path="website/i18n/pt-BR/docusaurus-plugin-content-docs/current/api-and-configurations.mdx">
# API e Configuração

O MySQL2 é maioritariamente compatível com a API do [Node MySQL][node-mysql].

Uma incompatibilidade conhecida é que os valores em `DECIMAL` são retornados como _strings_, enquanto no [Node MySQL][node-mysql] eles são retornados como números. Isso inclui o resultado das funções `SUM()` e `AVG()` quando aplicadas a argumentos `INTEGER`. Isso é feito deliberadamente para evitar a perda de precisão - veja https://github.com/sidorares/node-mysql2/issues/935.

:::info
Se você encontrar qualquer outra incompatibilidade com o [Node MySQL][node-mysql], por favor, reporte através do acompanhamento de _Issues_. Nós corrigiremos a incompatibilidade relatada como uma prioridade.
:::

[node-mysql]: https://github.com/mysqljs/mysql
</file>

<file path="website/i18n/pt-BR/docusaurus-plugin-content-docs/current/contributing/00-index.mdx">
---
slug: /contributing
title: MySQL2
---

import { PageTitle } from '@site/src/components/PageTitle';

<PageTitle title='Contribuições' />

# Contribuições

Quer melhorar algo no **MySQL2**?
Consulte o arquivo [Contributing.md](https://github.com/sidorares/node-mysql2/blob/master/Contributing.md) para instruções detalhadas sobre como começar.
</file>

<file path="website/i18n/pt-BR/docusaurus-plugin-content-docs/current/history-and-why-mysq2.mdx">
# História e Porque o MySQL2

O projeto MySQL2 é uma continuação do [MySQL-Native][mysql-native]. O código do analisador de protocolo (_protocol parser_) foi reescrito do zero e a API foi alterada para corresponder ao popular [mysqljs/mysql][node-mysql]. A equipe do MySQL2 está trabalhando em conjunto com a equipe do [mysqljs/mysql][node-mysql] para _fatorar_ o código compartilhado e movê-lo para a organização [mysqljs][node-mysql].

O MySQL2 é maioritariamente compatível com a API do [mysqljs][node-mysql] e suporta a maioria de suas funcionalidades. O MySQL2 também oferece essas funcionalidades adicionais:

- Desempenho mais rápido / melhor
- [Instruções Preparadas (_Prepared Statements_)](/docs/documentation/prepared-statements)
- Protocolo de log binário MySQL (_MySQL Binary Log Protocol_)
- [Servidor MySQL](/docs/documentation/mysql-server)
- Estende o suporte para _Encoding_ and _Collation_
- [_Promise Wrapper_](/docs/documentation/promise-wrapper)
- Compressão
- SSL e [_Authentication Switch_](/docs/documentation/authentication-switch)
- [_Streams_ Personalizados](/docs/documentation/extras#connecting-using-custom-stream)
- [Conjunto de Conexões (_Pooling_)](/docs/#using-connection-pools)

[node-mysql]: https://github.com/mysqljs/mysql
[mysql-native]: https://github.com/sidorares/nodejs-mysql-native
</file>

<file path="website/i18n/pt-BR/docusaurus-plugin-content-docs/current/index.mdx">
---
slug: /
position: 1
title: Guia Rápido
description: Cliente MySQL para Node.js com foco em performance
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { PageTitle } from '@site/src/components/PageTitle';

<PageTitle title='MySQL2 | Guia Rápido' />

# MySQL2

{/* <Logo className='logo' width={150} height={150} /> */}

Cliente MySQL para Node.js com foco em performance. Suporta instruções preparadas (_prepared statements_), Codificações _non-utf8_, protocolo de log binário (_binary log protocol_), compressão, SSL e muito mais.

[![NPM Version][npm-image]][npm-url]
[![NPM Downloads][downloads-image]][downloads-url]
[![Node.js Version][node-version-image]][node-version-url]
[![GitHub Workflow Status (with event)][ci-image]][ci-url]
[![Codecov][coverage]][coverage-url]
[![License][license-image]][license-url]

## Instalação

O MySQL2 não tem restrições nativas e pode ser instalado no Linux, Mac OS ou Windows sem qualquer problema.

<Tabs>
  <TabItem value='JavaScript' default>

    ```bash
    npm install --save mysql2
    ```

  </TabItem>
  <TabItem value='TypeScript'>

    ```bash
    npm install --save mysql2
    npm install --save-dev @types/node
    ```

    Para documentação e exemplos usando TypeScript, veja [aqui](/docs/documentation/typescript-examples).

  </TabItem>
</Tabs>

<hr />

### Primeira Consulta (_Query_)

> Para explorar mais exemplos de consulta (queries), visite a seção de exemplos [**Consultas Simples**](/docs/examples/queries/simple-queries) e [**Instruções Preparadas (_Prepared Statements_)**](/docs/examples/queries/prepared-statements).

<Tabs>
  <TabItem value='Promise' default>

```js
// Obtém o cliente
import mysql from 'mysql2/promise';

// Cria a conexão com o Banco de Dados
const connection = await mysql.createConnection({
  host: 'localhost',
  user: 'root',
  database: 'test',
});

// Consulta simples
try {
  const [results, fields] = await connection.query(
    'SELECT * FROM `table` WHERE `name` = "Page" AND `age` > 45'
  );

  console.log(results); // "results" contêm as linhas retornadas pelo servidor
  console.log(fields); // "fields" contêm metadados adicionais sobre os resultados, quando disponíveis
} catch (err) {
  console.log(err);
}

// Utilizando espaços reservados (placeholders)
try {
  const [results] = await connection.query(
    'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
    ['Page', 45]
  );

  console.log(results);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='Callback'>

```js
// Obtém o cliente
const mysql = require('mysql2');

// Cria a conexão com o Banco de Dados
const connection = mysql.createConnection({
  host: 'localhost',
  user: 'root',
  database: 'test',
});

// Consulta simples
connection.query(
  'SELECT * FROM `table` WHERE `name` = "Page" AND `age` > 45',
  function (err, results, fields) {
    console.log(results); // "results" contêm as linhas retornadas pelo servidor
    console.log(fields); // "fields" contêm metadados adicionais sobre os resultados, quando disponíveis
  }
);

// Utilizando espaços reservados (placeholders)
connection.query(
  'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
  ['Page', 45],
  function (err, results) {
    console.log(results);
  }
);
```

  </TabItem>
</Tabs>

<hr />

### Usando Instruções Preparadas (_Prepared Statements_)

Com o MySQL2 você também pode obter Instruções Preparadas (Prepared Statements). Dessa forma o MySQL não precisa preparar um plano para a mesma consulta todas as vezes, resultando em um melhor desempenho. Se você não sabe por que isso é importante, veja essa discussão:

- [Como as instruções preparadas (_prepared statements_) podem proteger contra ataques de injeção SQL](https://stackoverflow.com/questions/8263371/how-can-prepared-statements-protect-from-sql-injection-attacks)

O MySQL2 fornece o método auxiliar `execute` que irá preparar e consultar as declarações (_statements_) SQL. Além disso, você também pode usar os métodos `prepare` e `unprepare` para preparar ou desfazer a preparação de declarações (_statements_) manualmente, se necessário.

> Para explorar mais exemplos de Instruções Preparadas (_Prepared Statements_), visite a seção de exemplos [**Instruções Preparadas (_Prepared Statements_)**](/docs/examples/queries/prepared-statements).

<Tabs>
  <TabItem value='Promise' default>

```js
import mysql from 'mysql2/promise';

try {
  // Cria a conexão com o Banco de Dados
  const connection = await mysql.createConnection({
    host: 'localhost',
    user: 'root',
    database: 'test',
  });

  // "execute" irá chamar internamente a preparação e a consulta (query)
  const [results, fields] = await connection.execute(
    'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
    ['Rick C-137', 53]
  );

  console.log(results); // "results" contêm as linhas retornadas pelo servidor
  console.log(fields); // "fields" contêm metadados adicionais sobre os resultados, quando disponíveis
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='Callback'>

```js
const mysql = require('mysql2');

// Cria a conexão com o Banco de Dados
const connection = mysql.createConnection({
  host: 'localhost',
  user: 'root',
  database: 'test',
});

// "execute" irá chamar internamente a preparação e a consulta (query)
connection.execute(
  'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
  ['Rick C-137', 53],
  function (err, results, fields) {
    console.log(results); // "results" contêm as linhas retornadas pelo servidor
    console.log(fields); // "fields" contêm metadados adicionais sobre os resultados, quando disponíveis
  }
);
```

  </TabItem>
</Tabs>

:::tip
Se você executar a mesma declaração novamente, ela será selecionada a partir do LRU Cache, o que economizará tempo de preparação da consulta e proporcionará melhor desempenho.
:::

<hr />

### Usando Conjunto de Conexões (_pools_) {#using-connection-pools}

O conjunto de conexões (_pools_) ajuda a reduzir o tempo gasto na conexão com o servidor MySQL, reutilizando uma conexão anterior e deixando-as abertas ao invés de fechá-las quando você termina de usá-las.

Isto melhora a latência das consultas (_queries_), pois evita toda a sobrecarga associada à criação de uma nova conexão.

> Para explorar mais exemplos de Conjunto de Conexões (_pools_), visite a seção de exemplos [**createPool**](/docs/examples/connections/create-pool).

<Tabs>
  <TabItem value='Promise' default>

```js
import mysql from 'mysql2/promise';

// Cria a conexão (pool). As definições específicadas do "createPool" são as predefinições padrões
const pool = mysql.createPool({
  host: 'localhost',
  user: 'root',
  database: 'test',
  waitForConnections: true,
  connectionLimit: 10,
  maxIdle: 10, // Máximo de conexões inativas; o valor padrão é o mesmo que "connectionLimit"
  idleTimeout: 60000, // Tempo limite das conexões inativas em milissegundos; o valor padrão é "60000"
  queueLimit: 0,
  enableKeepAlive: true,
  keepAliveInitialDelay: 0,
});
```

  </TabItem>
  <TabItem value='Callback'>

```js
const mysql = require('mysql2');

// Cria a conexão (pool). As definições específicadas do "createPool" são as predefinições padrões
const pool = mysql.createPool({
  host: 'localhost',
  user: 'root',
  database: 'test',
  waitForConnections: true,
  connectionLimit: 10,
  maxIdle: 10, // Máximo de conexões inativas; o valor padrão é o mesmo que "connectionLimit"
  idleTimeout: 60000, // Tempo limite das conexões inativas em milissegundos; o valor padrão é "60000"
  queueLimit: 0,
  enableKeepAlive: true,
  keepAliveInitialDelay: 0,
});
```

  </TabItem>
</Tabs>

:::note
O _pool_ não estabelece todas as conexões previamente, mas as cria sob demanda até que o limite de conexões seja atingido.
:::

<hr />

Você pode usar o _pool_ da mesma maneira como em uma conexão (usando `pool.query()` e `pool.execute()`):

<Tabs>
  <TabItem value='Promise' default>

```js
try {
  // Para a inicialização do "pool", veja acima
  const [rows, fields] = await pool.query('SELECT `field` FROM `table`');
  // A conexão é automaticamente liberada quando a consulta (query) é resolvida
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='Callback'>

```js
// Para a inicialização do "pool", veja acima
pool.query('SELECT `field` FROM `table`', function (err, rows, fields) {
  // A conexão é automaticamente liberada quando a consulta (query) é resolvida
});
```

  </TabItem>
</Tabs>

Alternativamente, também existe a possibilidade de adquirir manualmente uma conexão do pool e liberá-la posteriormente:

<Tabs>
  <TabItem value='Promise' default>

```js
// Para a inicialização do "pool", veja acima
const conn = await pool.getConnection();

// Fazer algo com a conexão
await conn.query(/* ... */);

// Não se esqueça de liberar a conexão quando terminar!
pool.releaseConnection(conn);
```

  </TabItem>
  <TabItem value='Callback'>

```js
// Para a inicialização do "pool", veja acima
pool.getConnection(function (err, conn) {
  // Fazer algo com a conexão
  conn.query(/* ... */);

  // Não se esqueça de liberar a conexão quando terminar!
  pool.releaseConnection(conn);
});
```

  </TabItem>
</Tabs>

- Adicionalmente, você pode liberar a conexão usando o objeto `connection`:

  ```js
  conn.release();
  ```

<hr />

### Usando o _Promise Wrapper_

O MySQL2 também suporta _Promise_ API. O que funciona muito bem com o ES7 _async await_.

```js
import mysql from 'mysql2/promise';

async function main() {
  // Cria a conexão com o Banco de Dados
  const connection = await mysql.createConnection({
    host: 'localhost',
    user: 'root',
    database: 'test',
  });

  // Consulta no Banco de Dados
  const [rows, fields] = await connection.execute(
    'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
    ['Morty', 14]
  );
}
```

O MySQL2 usa o objeto _`Promise`_ padrão disponível no escopo. Mas você pode escolher qual implementação de _`Promise`_ deseja usar.

```js
// Obtém o cliente
import mysql from 'mysql2/promise';

// Obtém a implementação de "Promise" (nós usaremos o "bluebird")
import bluebird from 'bluebird';

// Cria a conexão, especificando o "bluebird" como "Promise"
const connection = await mysql.createConnection({
  host: 'localhost',
  user: 'root',
  database: 'test',
  Promise: bluebird,
});

// Consulta no Banco de Dados
const [rows, fields] = await connection.execute(
  'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
  ['Morty', 14]
);
```

MySQL2 also exposes a `.promise()` function on Pools, so you can create a promise/non-promise connections from the same pool.

```js
import mysql from 'mysql2';

async function main() {
  // create the pool
  const pool = mysql.createPool({
    host: 'localhost',
    user: 'root',
    database: 'test',
  });

  // now get a Promise wrapped instance of that pool
  const promisePool = pool.promise();

  // query database using promises
  const [rows, fields] = await promisePool.query('SELECT 1');
}
```

O MySQL2 também expõe o método .promise() em _Pools_, então você pode criar conexões "_promise/non-promise_" para o mesmo _pool_.

```js {11}
const mysql = require('mysql2');

// Cria a conexão
const conn = mysql.createConnection({
  host: 'localhost',
  user: 'root',
  database: 'test',
});

conn
  .promise()
  .query('SELECT 1')
  .then(([rows, fields]) => {
    console.log(rows);
  })
  .catch(console.log)
  .then(() => conn.end());
```

<hr />

### Resultados em _Array_

Se você tiver duas colunas com o mesmo nome, pode preferir receber os resultados como um _array_, em vez de um objeto, para evitar conflitos. Isso é uma divergência da biblioteca [Node MySQL][node-mysql].

Por exemplo: `` SELECT 1 AS `foo`, 2 AS `foo` ``.

Você pode habilitar essa configuração tanto no nível de conexão (aplica-se a todas as consultas), quanto no nível de consulta (aplica-se apenas a essa consulta específica).

#### Connection Level

<Tabs>
  <TabItem value='Promise' default>

```js {5}
const conn = await mysql.createConnection({
  host: 'localhost',
  database: 'test',
  user: 'root',
  rowsAsArray: true,
});
```

  </TabItem>
  <TabItem value='Callback'>

```js {5}
const conn = mysql.createConnection({
  host: 'localhost',
  database: 'test',
  user: 'root',
  rowsAsArray: true,
});
```

  </TabItem>
</Tabs>

#### Query Level

<Tabs>
  <TabItem value='Promise' default>

```js {4}
try {
  const [results, fields] = await conn.query({
    sql: 'SELECT 1 AS `foo`, 2 AS `foo`',
    rowsAsArray: true,
  });

  console.log(results); // nessa consulta, "results" contêm um array de arrays ao invés de um array de objetos
  console.log(fields); // "fields" mantêm-se inalterados
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='Callback'>

```js {4}
conn.query(
  {
    sql: 'SELECT 1 AS `foo`, 2 AS `foo`',
    rowsAsArray: true,
  },
  function (err, results, fields) {
    console.log(results); // nessa consulta, "results" contêm um array de arrays ao invés de um array de objetos
    console.log(fields); // "fields" mantêm-se inalterados
  }
);
```

  </TabItem>
</Tabs>

<hr />

:::tip Obtendo Ajuda
Precisa de ajuda? Faça sua pergunta no [Stack Overflow](https://stackoverflow.com/questions/tagged/mysql2) ou [GitHub](https://github.com/sidorares/node-mysql2/discussions).
Se você encontrou um erro, [registre-o no GitHub](https://github.com/sidorares/node-mysql2/issues).
:::

[npm-image]: https://img.shields.io/npm/v/mysql2.svg
[npm-url]: https://npmjs.org/package/mysql2
[node-version-image]: https://img.shields.io/node/v/mysql2.svg
[node-version-url]: https://nodejs.org/download/
[downloads-image]: https://img.shields.io/npm/dm/mysql2.svg
[downloads-url]: https://npmjs.org/package/mysql2
[license-url]: https://github.com/sidorares/node-mysql2/blob/master/License
[license-image]: https://img.shields.io/npm/l/mysql2.svg?maxAge=2592000
[node-mysql]: https://github.com/mysqljs/mysql
[coverage]: https://img.shields.io/codecov/c/github/sidorares/node-mysql2
[coverage-url]: https://app.codecov.io/github/sidorares/node-mysql2
[ci-url]: https://github.com/sidorares/node-mysql2/actions/workflows/ci-coverage.yml?query=branch%3Amaster
[ci-image]: https://img.shields.io/github/actions/workflow/status/sidorares/node-mysql2/ci-coverage.yml?event=push&style=flat&label=CI&branch=master
</file>

<file path="website/i18n/zh-CN/docusaurus-plugin-content-docs/current.json">
{
  "sidebar.docs.category.Documentation": {
    "message": "文档"
  },
  "sidebar.docs.category.Examples": {
    "message": "示例"
  },
  "sidebar.docs.category.Contributing": {
    "message": "贡献"
  }
}
</file>

<file path="website/i18n/zh-CN/docusaurus-plugin-content-docs/current/acknowledgements.mdx">
# 鸣谢

- 内部协议由@sidorares编写 [MySQL-Native](https://github.com/sidorares/nodejs-mysql-native)
- 常量、SQL参数插值、连接池、`ConnectionConfig` 类取自[node-mysql](https://github.com/mysqljs/mysql)
- 基于@TooTallNate的SSL代码升级[代码地址](https://gist.github.com/TooTallNate/848444)
- 与[MariaSQL](https://github.com/mscdex/node-mariasql/)客户端兼容安全连接/压缩连接 API。
- [贡献者](https://github.com/sidorares/node-mysql2/graphs/contributors)
</file>

<file path="website/i18n/zh-CN/docusaurus-plugin-content-docs/current/api-and-configurations.mdx">
# API配置项

MySQL2大部分的API与 [Node MySQL][node-mysql] 基本上相同，你应该查看他们的API文档来知道更多的API选项。

One known incompatibility is that `DECIMAL` values are returned as strings whereas in [Node MySQL][node-mysql] they are returned as numbers. This includes the result of `SUM()` and `AVG()` functions when applied to `INTEGER` arguments. This is done deliberately to avoid loss of precision - see https://github.com/sidorares/node-mysql2/issues/935.

:::info
如果您发现与 [Node MySQL][node-mysql] 的任何不兼容问题，请通过`issue`报告。 我们将优先修复报告的不兼容问题。
:::

[node-mysql]: https://github.com/mysqljs/mysql
</file>

<file path="website/i18n/zh-CN/docusaurus-plugin-content-docs/current/contributing/00-index.mdx">
---
slug: /contributing
title: MySQL2
---

import { PageTitle } from '@site/src/components/PageTitle';

<PageTitle title='贡献' />

# 贡献

如果要为`node-mysql2`做些贡献.请查阅 [Contributing.md](https://github.com/sidorares/node-mysql2/blob/master/Contributing.md) 来获得更多详细信息。
</file>

<file path="website/i18n/zh-CN/docusaurus-plugin-content-docs/current/history-and-why-mysq2.mdx">
# MySQL2的历史以及选择原因

MySQL2 项目是 [MySQL-Native][mysql-native] 的延续。 协议解析器代码从头开始重写，api 更改为匹配流行的 [mysqljs/mysql][node-mysql]。 MySQL2 团队正在与 [mysqljs/mysql][node-mysql] 团队合作，将共享代码分解并移至 [mysqljs][node-mysql] 组织下。

MySQL2 大部分 API 与 [mysqljs][node-mysql] 兼容，并支持大部分功能。 MySQL2 还提供了更多的附加功能：

- 更快、更好的性能
- [支持预处理](/docs/documentation/prepared-statements)
- MySQL二进制日志协议
- [MySQL Server](/docs/documentation/mysql-server)
- 对编码和排序规则有很好的支持
- [Promise封装](/docs/documentation/promise-wrapper)
- 支持压缩
- SSL 和 [Authentication Switch](/docs/documentation/authentication-switch)
- [自定义流](/docs/documentation/extras#connecting-using-custom-stream)
- [连接池](/docs/#using-connection-pools)

[node-mysql]: https://github.com/mysqljs/mysql
[mysql-native]: https://github.com/sidorares/nodejs-mysql-native
</file>

<file path="website/i18n/zh-CN/docusaurus-plugin-content-docs/current/index.mdx">
---
slug: /
position: 1
title: Quickstart
description: 适用于Node.js的MySQL客户端，专注于性能优化
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import { PageTitle } from '@site/src/components/PageTitle';

<PageTitle title='MySQL2 | Quickstart' />

# MySQL2

{/* <Logo className='logo' width={150} height={150} /> */}

适用于Node.js的MySQL客户端，专注于性能优化。支持SQL预处理、非UTF-8编码支持、二进制文件编码支持、压缩和SSL等等 查看更多。

[![NPM Version][npm-image]][npm-url]
[![NPM Downloads][downloads-image]][downloads-url]
[![Node.js Version][node-version-image]][node-version-url]
[![GitHub Workflow Status (with event)][ci-image]][ci-url]
[![Codecov][coverage]][coverage-url]
[![License][license-image]][license-url]

## 安装

MySQL2 可以跨平台使用，毫无疑问可以安装在 Linux、Mac OS 或 Windows 上。

<Tabs>
  <TabItem value='JavaScript' default>

```bash
npm install --save mysql2
```

  </TabItem>
  <TabItem value='TypeScript'>

```bash
npm install --save mysql2
npm install --save-dev @types/node
```

    更多关于`TypeScript`相关文档内容，请点击 [这里](/docs/documentation/typescript-examples) 查看。

  </TabItem>
</Tabs>

<hr />

### 查询数据

> 更多查询语法内容，请点击 [**简单查询**](/docs/examples/queries/simple-queries) 和 [**预处理**](/docs/examples/queries/prepared-statements)。

<Tabs>
  <TabItem value='Promise' default>

```js
// 导入模块
import mysql from 'mysql2/promise';

// 创建一个数据库连接
const connection = await mysql.createConnection({
  host: 'localhost',
  user: 'root',
  database: 'test',
});

// 简单查询
try {
  const [results, fields] = await connection.query(
    'SELECT * FROM `table` WHERE `name` = "Page" AND `age` > 45'
  );

  console.log(results); // 结果集
  console.log(fields); // 额外的元数据（如果有的话）
} catch (err) {
  console.log(err);
}

// 使用占位符
try {
  const [results] = await connection.query(
    'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
    ['Page', 45]
  );

  console.log(results);
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='Callback'>

```js
// 导入模块
const mysql = require('mysql2');

// 创建一个数据库连接
const connection = mysql.createConnection({
  host: 'localhost',
  user: 'root',
  database: 'test',
});

// 简单查询
connection.query(
  'SELECT * FROM `table` WHERE `name` = "Page" AND `age` > 45',
  function (err, results, fields) {
    console.log(results); // 结果集
    console.log(fields); // 额外的元数据（如果有的话）
  }
);

// 使用占位符
connection.query(
  'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
  ['Page', 45],
  function (err, results) {
    console.log(results);
  }
);
```

  </TabItem>
</Tabs>

<hr />

### SQL预处理的使用

使用 MySQL2，您还可以提前准备好SQL预处理语句。 使用准备好的SQL预处理语句，MySQL 不必每次都为相同的查询做准备，这会带来更好的性能。 如果您不知道为什么它们很重要，请查看这些讨论：

- [如何防止预处理语句SQL注入攻击](https://stackoverflow.com/questions/8263371/how-can-prepared-statements-protect-from-sql-injection-attacks)

MySQL2 提供了 `execute` 辅助函数，它将准备和查询语句。 您还可以使用 `prepare` / `unprepare` 方法手动准备/取消准备。

> 更多关于预处理和占位符相关内容，请点击 [**预处理**](/docs/examples/queries/prepared-statements)。

<Tabs>
  <TabItem value='Promise' default>

```js
import mysql from 'mysql2/promise';

try {
  // 创建一个数据库连接
  const connection = await mysql.createConnection({
    host: 'localhost',
    user: 'root',
    database: 'test',
  });

  // execute 将在内部调用 prepare 和 query
  const [results, fields] = await connection.execute(
    'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
    ['Rick C-137', 53]
  );

  console.log(results); // 结果集
  console.log(fields); // 额外的元数据（如果有的话）
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='Callback'>

```js
const mysql = require('mysql2');

// 创建一个数据库连接
const connection = mysql.createConnection({
  host: 'localhost',
  user: 'root',
  database: 'test',
});

// execute 将在内部调用 prepare 和 query
connection.execute(
  'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
  ['Rick C-137', 53],
  function (err, results, fields) {
    console.log(results); // 结果集
    console.log(fields); // 额外的元数据（如果有的话）
  }
);
```

  </TabItem>
</Tabs>

:::tip
如果再次执行相同的语句，他将从缓存中选取，这能有效的节省准备查询时间获得更好的性能。
:::

<hr />

### 连接池的使用 {#using-connection-pools}

连接池通过重用以前的连接来帮助减少连接到 MySQL 服务器所花费的时间，当你完成它们时让它们保持打开而不是关闭。

这改善了查询的延迟，因为您避免了建立新连接所带来的所有开销。

> 更多关于连接池等相关内容，请点击 [**创建连接池**](/docs/examples/connections/create-pool).

<Tabs>
  <TabItem value='Promise' default>

```js
import mysql from 'mysql2/promise';

// 创建连接池，设置连接池的参数
const pool = mysql.createPool({
  host: 'localhost',
  user: 'root',
  database: 'test',
  waitForConnections: true,
  connectionLimit: 10,
  maxIdle: 10, // 最大空闲连接数，默认等于 `connectionLimit`
  idleTimeout: 60000, // 空闲连接超时，以毫秒为单位，默认值为 60000 ms
  queueLimit: 0,
  enableKeepAlive: true,
  keepAliveInitialDelay: 0,
});
```

  </TabItem>
  <TabItem value='Callback'>

```js
const mysql = require('mysql2');

// 创建连接池，设置连接池的参数
const pool = mysql.createPool({
  host: 'localhost',
  user: 'root',
  database: 'test',
  waitForConnections: true,
  connectionLimit: 10,
  maxIdle: 10, // 最大空闲连接数，默认等于 `connectionLimit`
  idleTimeout: 60000, // 空闲连接超时，以毫秒为单位，默认值为 60000 ms
  queueLimit: 0,
  enableKeepAlive: true,
  keepAliveInitialDelay: 0,
});
```

  </TabItem>
</Tabs>

:::note
该池不会预先创建所有连接，而是根据需要创建它们，直到达到连接限制。
:::

<hr />

您可以像直接连接一样使用池（使用 `pool.query()` 和 `pool.execute()`）：

<Tabs>
  <TabItem value='Promise' default>

```js
try {
  // 关于连接池初始化，请参阅上文
  const [rows, fields] = await pool.query('SELECT `field` FROM `table`');
  // 查询解析时，连接会自动释放
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='Callback'>

```js
// 关于连接池初始化，请参阅上文
pool.query('SELECT `field` FROM `table`', function (err, rows, fields) {
  // 查询解析时，连接会自动释放
});
```

  </TabItem>
</Tabs>

或者，也可以手动从池中获取连接并稍后返回：

<Tabs>
  <TabItem value='Promise' default>

```js
// 关于连接池初始化，请参阅上文
const conn = await pool.getConnection();

// 对连接执行某些操作
await conn.query(/* ... */);

// 不要忘记释放连接！
pool.releaseConnection(conn);
```

  </TabItem>
  <TabItem value='Callback'>

```js
// 关于连接池初始化，请参阅上文
pool.getConnection(function (err, conn) {
  // 对连接执行某些操作
  conn.query(/* ... */);

  // 不要忘记释放连接！
  pool.releaseConnection(conn);
});
```

  </TabItem>
</Tabs>

- 此外，使用`connection`对象直接释放连接:

  ```js
  conn.release();
  ```

<hr />

### Promise封装

MySQL2 也支持 Promise API。 这与 ES7 异步等待非常有效。

```js
import mysql from 'mysql2/promise';

async function main() {
  // 创建链接
  const connection = await mysql.createConnection({
    host: 'localhost',
    user: 'root',
    database: 'test',
  });

  // 查询数据库
  const [rows, fields] = await connection.execute(
    'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
    ['Morty', 14]
  );
}
```

MySQL2 使用范围内可用的默认 `Promise` 对象。 但是你可以选择你想使用的 `Promise` 实现。

```js
// 导入模块
import mysql from 'mysql2/promise';

// 获取 promise 实现，这里我们将使用 bluebird 这个库来实现
import bluebird from 'bluebird';

// 创建连接，将 bluebird 指定为 Promise
const connection = await mysql.createConnection({
  host: 'localhost',
  user: 'root',
  database: 'test',
  Promise: bluebird,
});

// 查询数据
const [rows, fields] = await connection.execute(
  'SELECT * FROM `table` WHERE `name` = ? AND `age` > ?',
  ['Morty', 14]
);
```

MySQL2 还在 Pools 上公开了一个 `.promise()`函数，因此您可以从同一个池创建一个 promise/non-promise 连接。

```js
import mysql from 'mysql2';

async function main() {
  // 创建连接池
  const pool = mysql.createPool({
    host: 'localhost',
    user: 'root',
    database: 'test',
  });

  // now get a Promise wrapped instance of that pool
  // 现在获取一个链接池的 Promise 包装实例
  const promisePool = pool.promise();

  // 使用 Promise 查询数据库
  const [rows, fields] = await promisePool.query('SELECT 1');
}
```

MySQL2 在 Connections 上公开了一个 `.promise()`函数，以“升级”现有的 non-promise 连接以使用 Promise。

```js {11}
const mysql = require('mysql2');

// 创建连接
const conn = mysql.createConnection({
  host: 'localhost',
  user: 'root',
  database: 'test',
});

conn
  .promise()
  .query('SELECT 1')
  .then(([rows, fields]) => {
    console.log(rows);
  })
  .catch(console.log)
  .then(() => conn.end());
```

<hr />

### 结果返回

如果你有两个相同名称的列，你可能希望以数组而不是对象的形式获取结果，为了防止冲突，这是与 [Node MySQL][node-mysql] 库的区别。

例如： `` SELECT 1 AS `foo`, 2 AS `foo` ``.

您可以在连接级别（适用于所有查询）或查询级别（仅适用于该特定查询）启用此设置。

#### 连接级别

<Tabs>
  <TabItem value='Promise' default>

```js {5}
const conn = await mysql.createConnection({
  host: 'localhost',
  database: 'test',
  user: 'root',
  rowsAsArray: true,
});
```

  </TabItem>
  <TabItem value='Callback'>

```js {5}
const conn = mysql.createConnection({
  host: 'localhost',
  database: 'test',
  user: 'root',
  rowsAsArray: true,
});
```

  </TabItem>
</Tabs>

#### 查询级别

<Tabs>
  <TabItem value='Promise' default>

```js {4}
try {
  const [results, fields] = await conn.query({
    sql: 'SELECT 1 AS `foo`, 2 AS `foo`',
    rowsAsArray: true,
  });

  console.log(results); // 返回数组而不是数组对象
  console.log(fields); // 无变化
} catch (err) {
  console.log(err);
}
```

  </TabItem>
  <TabItem value='Callback'>

```js {4}
conn.query(
  {
    sql: 'SELECT 1 AS `foo`, 2 AS `foo`',
    rowsAsArray: true,
  },
  function (err, results, fields) {
    console.log(results); // 在此查询中，结果将是数组数组，而不是对象数组
    console.log(fields); // 字段保持不变
  }
);
```

  </TabItem>
</Tabs>

<hr />

:::tip Getting Help
需要帮助吗？请在这里提问 [Stack Overflow](https://stackoverflow.com/questions/tagged/mysql2) 或 [GitHub](https://github.com/sidorares/node-mysql2/discussions).
如果您遇到问题，请 [在 GitHub 上提交 issues](https://github.com/sidorares/node-mysql2/issues).
:::

[npm-image]: https://img.shields.io/npm/v/mysql2.svg
[npm-url]: https://npmjs.org/package/mysql2
[node-version-image]: https://img.shields.io/node/v/mysql2.svg
[node-version-url]: https://nodejs.org/download/
[downloads-image]: https://img.shields.io/npm/dm/mysql2.svg
[downloads-url]: https://npmjs.org/package/mysql2
[license-url]: https://github.com/sidorares/node-mysql2/blob/master/License
[license-image]: https://img.shields.io/npm/l/mysql2.svg?maxAge=2592000
[node-mysql]: https://github.com/mysqljs/mysql
[coverage]: https://img.shields.io/codecov/c/github/sidorares/node-mysql2
[coverage-url]: https://app.codecov.io/github/sidorares/node-mysql2
[ci-url]: https://github.com/sidorares/node-mysql2/actions/workflows/ci-coverage.yml?query=branch%3Amaster
[ci-image]: https://img.shields.io/github/actions/workflow/status/sidorares/node-mysql2/ci-coverage.yml?event=push&style=flat&label=CI&branch=master
</file>

<file path="website/package.json">
{
  "name": "website",
  "version": "0.0.0",
  "private": true,
  "scripts": {
    "docusaurus": "docusaurus",
    "start": "docusaurus start",
    "build": "docusaurus build",
    "swizzle": "docusaurus swizzle",
    "clear": "docusaurus clear",
    "serve": "docusaurus serve",
    "write-translations": "docusaurus write-translations",
    "write-heading-ids": "docusaurus write-heading-ids",
    "typecheck": "tsc",
    "lintcheck": "biome lint --error-on-warnings && prettier --check .",
    "lint": "biome lint --write . && prettier --write .",
    "test:unit": "npx poku test/unit",
    "test": "npm run typecheck && npm run lintcheck && npm run test:unit && npm run clear && npm run build",
    "update": "pu minor; npm i; npm run lint"
  },
  "dependencies": {
    "@docusaurus/core": "^3.8.0",
    "@docusaurus/preset-classic": "^3.8.0",
    "@easyops-cn/docusaurus-search-local": "^0.49.2",
    "@mdx-js/react": "^3.1.0",
    "clsx": "^2.1.1",
    "docusaurus-plugin-sass": "^0.2.6",
    "lucide-react": "^0.511.0",
    "prism-react-renderer": "^2.4.1",
    "react": "^19.1.0",
    "react-dom": "^19.1.0",
    "sass": "^1.89.0"
  },
  "devDependencies": {
    "@biomejs/biome": "^1.9.4",
    "@docusaurus/module-type-aliases": "^3.8.0",
    "@docusaurus/tsconfig": "^3.8.0",
    "@docusaurus/types": "^3.8.0",
    "@types/node": "^22.15.23",
    "packages-update": "^2.0.0",
    "poku": "^3.0.2",
    "prettier": "^3.5.3",
    "tsx": "^4.19.4",
    "typescript": "^5.8.3"
  },
  "browserslist": {
    "production": [
      ">0.5%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 3 chrome version",
      "last 3 firefox version",
      "last 5 safari version"
    ]
  },
  "engines": {
    "node": ">=18.0"
  }
}
</file>

<file path="website/plugins/locale.ts">
import type { Plugin } from '@docusaurus/types';

export const navbarLocalePlugin = (): Plugin => ({
  name: 'navbar-locale-plugin',
  contentLoaded({ actions }) {
    const { setGlobalData } = actions;
    setGlobalData({ currentLocale: process.env.LOCALE });
  },
});

export const useLocale =
  typeof process.env?.LOCALE === 'string' &&
  process.env.LOCALE.trim().length > 0;

export const getLocaleURL = (): string =>
  useLocale ? `/${process.env.LOCALE}/docs` : '/docs';
</file>

<file path="website/README.md">
# Website

This [website](https://sidorares.github.io/node-mysql2/docs) is built using [Docusaurus 3](https://docusaurus.io/), a modern static website generator.

# Contributing

Want to improve something in **MySQL2 Documentation Website**?  
Please visit the [Website Contributing Guidelines](https://sidorares.github.io/node-mysql2/docs/contributing/website) for detailed instruction on how to get started.
</file>

<file path="website/sidebars.ts">
import type { SidebarsConfig } from '@docusaurus/plugin-content-docs';

const sidebars: SidebarsConfig = {
  docs: [
    'index',
    'history-and-why-mysq2',
    'stability-badges',
    {
      type: 'category',
      label: 'Documentation',
      items: [{ type: 'autogenerated', dirName: 'documentation' }],
    },
    'api-and-configurations',
    'acknowledgements',
    {
      type: 'category',
      label: 'Contributing',
      items: [{ type: 'autogenerated', dirName: 'contributing' }],
    },
  ],
  examples: [{ type: 'autogenerated', dirName: 'examples' }],
  faq: [{ type: 'autogenerated', dirName: 'faq' }],
};

export default sidebars;
</file>

<file path="website/src/components/ExternalCodeEmbed.tsx">
import { useState, useEffect, type FC } from 'react';
import useDocusaurusContext from '@docusaurus/useDocusaurusContext';
import CodeBlock from '@theme/CodeBlock';
import { Loading } from '@site/src/components/Loading';
import {
  type MethodType,
  extractMethodContent,
} from '@site/helpers/extract-method-content';

export type ExternalCodeEmbedProps = {
  /** Raw URL from GitHub */
  url: string;
  /** `js`, `ts`, `json`, etc. */
  language: string;
  extractMethod?: string;
  methodType?: MethodType;
};

/**
 * Experimental
 *
 *
 * **Usage Example:**
 *
 * ```tsx
 * <ExternalCodeEmbed
 *   url='/examples/queries/select.js'
 *   language='js'
 * />
 * ```
 *
 * ---
 *
 * ```tsx
 * <ExternalCodeEmbed
 *   url='https://raw.githubusercontent.com/sidorares/node-mysql2/master/index.js'
 *   language='js'
 * />
 * ```
 */
export const ExternalCodeEmbed: FC<ExternalCodeEmbedProps> = ({
  url,
  language,
  extractMethod,
  methodType,
}) => {
  const [code, setCode] = useState<string>('');
  const [loading, setLoading] = useState<boolean>(true);
  const [error, setError] = useState<boolean>(true);
  const { siteConfig } = useDocusaurusContext();
  const baseUrl = siteConfig.baseUrl.replace(/\/$/, '');
  const finalURL = /^\//.test(url) ? `${baseUrl}${url}` : url;

  useEffect(() => {
    const controller = new AbortController();
    const signal = controller.signal;

    fetch(finalURL, { signal })
      .then((response) => response.text())
      .then((text) => {
        const extractedCode =
          extractMethod && methodType
            ? extractMethodContent(text, extractMethod, methodType)
            : text;

        setCode(extractedCode || text);
        setLoading(false);
        setError(false);
      })
      .catch(() => {
        setError(true);
        setLoading(false);
      });

    return () => {
      controller.abort();
    };
  }, [finalURL, extractMethod, methodType]);

  return (
    <>
      {loading ? (
        <Loading />
      ) : (
        <>
          {error ? (
            <div>
              Unable to access the requested link: <code>{finalURL}</code>.
              Please verify the link or try again later.
            </div>
          ) : (
            <CodeBlock className={`language-${language}`}>{code}</CodeBlock>
          )}
        </>
      )}
    </>
  );
};
</file>

<file path="website/src/components/FAQ.tsx">
import type { FC, ReactNode } from 'react';
import Details from '@theme/Details';

export type FAQProps = {
  children: ReactNode;
  open?: boolean;
  title: string;
};

/**
 * Usage example:
 *
 * ```mdx
 * <FAQ title='Title'>
 *
 * > Some markdown (**MDX**) content.
 *
 * </FAQ>
 * ```
 */
export const FAQ: FC<FAQProps> = ({ children, open, title }) => {
  return (
    <Details
      open={open}
      className='faq'
      summary={
        <summary>
          <strong>{title}</strong>
        </summary>
      }
    >
      <section>{children}</section>
    </Details>
  );
};
</file>

<file path="website/src/components/History.tsx">
import type { FC, JSX } from 'react';
import Details from '@theme/Details';
import { FileClock as HistoryIcon } from 'lucide-react';

export type HistoryRecords = {
  /** **Examples:**
   *
   * - `3.x`
   * - `3.2.x`
   * - `3.2.6`
   */
  version: string;
  /**
   * Examples:
   *
   * ---
   *
   * - string
   * ```plain
   * Indicate your changes
   * ```
   *
   * ---
   *
   * - JSX
   * ```tsx
   * <>
   *   <code>Method Name</code> and your changes
   * </>
   * ```
   */
  changes: (string | JSX.Element)[];
};

export type HistoryProps = {
  records: HistoryRecords[];
  open?: boolean;
};

/**
 * **Usage Example:**
 *
 * ```tsx
 * <History
 *   records={[
 *     {
 *       version: '3.5.1',
 *       changes: [
 *         // Using strings
 *         'Indicate your changes'
 *         // You also can use JSX Elements
 *         <>
 *           <code>Method Name</code> and your changes
 *         </>,
 *       ],
 *     },
 *   ]}
 * />
 * ```
 */
export const History: FC<HistoryProps> = ({ records, open }) => {
  return (
    <Details
      open={open}
      summary={
        <summary>
          <HistoryIcon /> History
        </summary>
      }
      className='history'
    >
      <table>
        <thead>
          <tr>
            <th>Version</th>
            <th>Changes</th>
          </tr>
        </thead>
        <tbody>
          {records.map((record, index) => (
            <tr key={`record:${index}`}>
              <td>
                <strong>v{record.version.replace(/[^0-9.]/g, '')}</strong>
              </td>
              <td>
                <div className='changes'>
                  {record.changes.map((change, index) => (
                    <section key={`change:${index}`}>{change}</section>
                  ))}
                </div>
              </td>
            </tr>
          ))}
        </tbody>
      </table>
    </Details>
  );
};
</file>

<file path="website/src/components/Loading.tsx">
/**
 * Credits: https://cssloaders.github.io/
 */
export const Loading = () => <span className='loader' />;
</file>

<file path="website/src/components/PageTitle.tsx">
import type { FC } from 'react';
import Head from '@docusaurus/Head';

export type PageTitleProps = {
  title: string;
};

/**
 * **Force a custom Tab Title:** this component sets a specific title for the browser tab.
 *
 * Use it to override the default title derived from the document or page content.
 *
 * ℹ️ Ideal for situations where the tab title needs to be different from the page's main heading or `.mdx` title.
 *
 * ---
 *
 * **Usage:**
 *
 * ```tsx
 * <PageTitle title='Custom Browser Tab Title' />
 * ```
 */
export const PageTitle: FC<PageTitleProps> = ({ title }) => {
  return (
    <Head>
      <title>{title}</title>
    </Head>
  );
};
</file>

<file path="website/src/components/Stability.tsx">
import type { FC, JSX } from 'react';
import Link from '@docusaurus/Link';
import {
  AlertTriangle,
  Lightbulb,
  LightbulbOff,
  Microscope,
  PackageSearch,
  PackageCheck,
} from 'lucide-react';

export type StabilityProps = {
  /**
   * - `0`: Deprecated
   * - `1`: Experimental
   * - `1.1`: Early Development
   * - `1.2`: Release Candidate
   * - `2`: Stable
   * - `3`: Legacy
   */
  level: 0 | 1 | 1.1 | 1.2 | 2 | 3;
  /**
   * An optional message
   */
  message?: string | JSX.Element;
};

/**
 * **Usage Examples:**
 *
 * ```tsx
 * <Stability level={2} />
 * ```
 *
 * ---
 *
 * ```tsx
 * <Stability level={2} message='An optional message' />
 * ```
 *
 * ---
 *
 * ```tsx
 * <Stability level={2} message={<>An optional message</>} />
 * ```
 */
export const Stability: FC<StabilityProps> = ({ level, message }) => {
  const styles: Record<
    StabilityProps['level'],
    { title: string; icon: JSX.Element }
  > = {
    0: {
      title: 'Deprecated',
      icon: <AlertTriangle />,
    },
    1: {
      title: 'Experimental',
      icon: <Lightbulb />,
    },
    1.1: {
      title: 'Early Development',
      icon: <Microscope />,
    },
    1.2: {
      title: 'Release Candidate',
      icon: <PackageSearch />,
    },
    2: {
      title: 'Stable',
      icon: <PackageCheck />,
    },
    3: {
      title: 'Legacy',
      icon: <LightbulbOff />,
    },
  };

  return (
    <section className='stability' data-level={level}>
      <Link to='/docs/stability-badges'>
        <header>
          <strong>{level}</strong>
          <span>{styles[level].title}</span>
          {styles[level].icon}
        </header>
      </Link>
      {message ? <p>{message}</p> : null}
    </section>
  );
};
</file>

<file path="website/src/css/_faq.scss">
details {
  &.faq {
    background-color: var(--faq-background);
    border-color: var(--faq-border-color);

    pre {
      code {
        border: 0.0625rem solid var(--faq-code-border-color);
      }
    }
  }
}

[data-theme='light'] {
  details {
    &.faq {
      --docusaurus-details-decoration-color: var(--ifm-color-primary);
      --faq-background: #f8fcff;
      --faq-border-color: var(--ifm-color-primary);
      --faq-code-border-color: #add2eb;

      code[class*='language-'],
      pre[class*='language-'] {
        background-color: #fbfdff !important;
      }
    }
  }
}

[data-theme='dark'] {
  details {
    &.faq {
      --docusaurus-details-decoration-color: #7230d6;
      --faq-background: #151518;
      --faq-border-color: #36284b;
      --faq-code-border-color: #38225a;
    }
  }
}
</file>

<file path="website/src/css/_history.scss">
@use 'mixins' as *;

details {
  &.history {
    // Reset Docusaurus styles
    background-color: unset !important;
    border: none !important;
    box-shadow: none !important;
    padding: 0 !important;
    margin-bottom: 1.5625rem !important;

    summary {
      @include flex(row, center);
      gap: 0.35rem;
      color: var(--history-summary-color);
      font-weight: 500;

      svg {
        width: 1.125rem;
        height: 1.125rem;
        stroke: var(--history-summary-icon);
      }
    }

    table {
      width: 100%;

      thead {
        th {
          text-align: left;
        }
      }

      tbody {
        tr {
          td:nth-child(2) {
            width: 100%;

            .changes {
              width: 100%;

              section {
                width: 100%;

                code {
                  background-color: var(--history-code-background);
                }

                & + section {
                  padding-top: 0.46875rem;
                  margin-top: 0.46875rem;
                  border-top: var(--ifm-table-border-width) solid
                    var(--history-separator);
                }
              }
            }
          }
        }
      }
    }
  }
}

[data-theme='light'] {
  details {
    &.history {
      --ifm-alert-background-color: #f9fafb;
      --ifm-alert-border-color: var(--ifm-menu-color-active);
      --ifm-table-border-color: #bcd7ff;
      --history-summary-color: #3a85ba;
      --history-summary-icon: var(--docusaurus-details-decoration-color);
      --history-code-background: #ecf4ff;
      --history-separator: var(--ifm-table-border-color);
    }
  }
}

[data-theme='dark'] {
  details {
    &.history {
      --ifm-alert-background-color: #18181b;
      --ifm-alert-border-color: #7f53bc;
      --ifm-table-border-color: #4a267c;
      --history-summary-color: #ddc7ff;
      --history-summary-icon: var(--docusaurus-details-decoration-color);
      --history-code-background: #382358;
      --history-separator: var(--ifm-table-border-color);
    }
  }
}
</file>

<file path="website/src/css/_loading.scss">
/**
 * Credits: https://cssloaders.github.io/
 */

.loader {
  width: 0.8rem;
  height: 0.8rem;
  border-radius: 50%;
  display: block;
  margin: 2.375rem 1.1875rem;
  position: relative;
  color: var(--ifm-color-primary-lightest);
  box-sizing: border-box;
  animation: animloader 1s linear infinite alternate;
  transform: scale(0.5);
}

@keyframes animloader {
  0% {
    box-shadow:
      -2.375rem -0.35rem,
      -0.875rem 0.35rem,
      0.875rem -0.35rem;
  }
  33% {
    box-shadow:
      -2.375rem 0.35rem,
      -0.875rem -0.35rem,
      0.875rem 0.35rem;
  }
  66% {
    box-shadow:
      -2.375rem -0.35rem,
      -0.875rem 0.35rem,
      0.875rem -0.35rem;
  }
  100% {
    box-shadow:
      -2.375rem 0.35rem,
      -0.875rem -0.35rem,
      0.875rem 0.35rem;
  }
}
</file>

<file path="website/src/css/_mixins.scss">
@mixin flex($direction: unset, $align: unset, $justify: unset, $wrap: unset) {
  display: flex;

  @if ($direction != unset) {
    flex-direction: $direction;
  }

  @if ($align != unset) {
    align-items: $align;
  }

  @if ($justify != unset) {
    justify-content: $justify;
  }

  @if ($wrap != unset) {
    flex-wrap: $wrap;
  }
}
</file>

<file path="website/src/css/custom.scss">
@use 'sass:meta' as *;
@use 'mixins' as *;

:root {
  --ifm-color-primary: #45aaf2;
  --ifm-color-primary-dark: #3d98d1;
  --ifm-color-primary-darker: #3788bf;
  --ifm-color-primary-darkest: #2d6e99;
  --ifm-color-primary-light: #66b5f8;
  --ifm-color-primary-lighter: #80bff9;
  --ifm-color-primary-lightest: #99c9fa;
  --ifm-code-font-size: 95%;
  --docusaurus-highlighted-code-line-bg: #21657e0d;
  --ifm-table-stripe-background: #c6ddff !important;
  --ifm-table-background: #fdfdfd7a !important;
}

// Dracula Theme
[data-theme='dark'] {
  --ifm-color-primary: #7a77ff;
  --ifm-color-primary-dark: #5552ff;
  --ifm-color-primary-darker: #433fff;
  --ifm-color-primary-darkest: #0c07ff;
  --ifm-color-primary-light: #9f9cff;
  --ifm-color-primary-lighter: #b1afff;
  --ifm-color-primary-lightest: #b1afff;
  --docusaurus-highlighted-code-line-bg: #0c0d152b;
  --ifm-table-stripe-background: #5e30a0 !important;
  --ifm-table-background: transparent !important;
}

[data-theme='light'] {
  code[class*='language-'],
  pre[class*='language-'] {
    background-color: #f9fafb !important;

    .token {
      &.comment {
        color: #6e7781 !important;
      }

      &.string {
        color: #0a3069 !important;
      }

      &.keyword {
        color: #cf222e !important;
      }

      &.method {
        color: #6639ba !important;
      }

      &.property,
      &.number {
        color: #0550ae !important;
      }
    }
  }
}

code[class*='language-'],
pre[class*='language-'] {
  font-size: 0.85em;

  .token {
    &.comment {
      font-size: 0.9em;
      font-style: normal !important;
    }
  }
}

.navbar__brand {
  margin-right: 0;
}

.navbar__manual--title {
  padding: 0;
  margin-right: 1rem;
  font-weight: bold;
}

.navbar.navbar--fixed-top {
  .navbar__item.dropdown.dropdown--hoverable {
    svg {
      display: none;
    }
  }
}

[title='<ExternalCodeEmbed'] {
  visibility: hidden;
}

// Components
@include load-css('loading');
@include load-css('history');
@include load-css('stability/main');
@include load-css('faq');
</file>

<file path="website/src/css/stability/_dark.scss">
[data-theme='dark'] {
  section {
    &.stability {
      &[data-level='0'] {
        --stability-background: #e70a4c;
        --stability-border: #b43643;
        --stability-title-background: #fff;
        --stability-title-color: #e70a4c;
        --stability-text: #ffe0e6;
        --stability-description: #ffe0e6;
        --stability-separator: #b43643;
      }

      &[data-level='1'],
      &[data-level='1.0'],
      &[data-level='1.1'],
      &[data-level='1.2'] {
        --stability-background: #e7840a;
        --stability-border: #806700;
        --stability-title-background: #fff;
        --stability-title-color: #e7840a;
        --stability-text: #fff7ee;
        --stability-description: #fff7ee;
        --stability-separator: #806700;
      }

      &[data-level='2'] {
        --stability-background: #2d8210;
        --stability-border: #2a5e03;
        --stability-title-background: #fff;
        --stability-title-color: #2d8210;
        --stability-text: #e8ffe0;
        --stability-description: #e8ffe0;
        --stability-separator: #2a5e03;
      }

      &[data-level='3'] {
        --stability-background: #0a8be7;
        --stability-border: #2a6996;
        --stability-title-background: #fff;
        --stability-title-color: #0a8be7;
        --stability-text: #e0f2ff;
        --stability-description: #e0f2ff;
        --stability-separator: #2a6996;
      }
    }
  }
}
</file>

<file path="website/src/css/stability/_light.scss">
[data-theme='light'] {
  section {
    &.stability {
      &[data-level='0'] {
        --stability-background: #ffe0e6;
        --stability-border: #ff89a6;
        --stability-title-background: #e70a4c;
        --stability-title-color: #fff;
        --stability-text: #e70a5b;
        --stability-description: #b43643;
        --stability-separator: #ffbeca;
      }

      &[data-level='1'],
      &[data-level='1.0'],
      &[data-level='1.1'],
      &[data-level='1.2'] {
        --stability-background: #fff1e0;
        --stability-border: #ffa689;
        --stability-title-background: #e7840a;
        --stability-title-color: #fff;
        --stability-text: #e7800a;
        --stability-description: #b46636;
        --stability-separator: #ffe169;
      }

      &[data-level='2'] {
        --stability-background: #e6f6e6;
        --stability-border: #85cb86;
        --stability-title-background: #50af50;
        --stability-title-color: #fff;
        --stability-text: #3e893f;
        --stability-description: #579b23;
        --stability-separator: #ceefcd;
      }

      &[data-level='3'] {
        --stability-background: #e0f2ff;
        --stability-border: #89ceff;
        --stability-title-background: #0a8be7;
        --stability-title-color: #fff;
        --stability-text: #0a8be7;
        --stability-description: #3680b4;
        --stability-separator: #cde2ef;
      }
    }
  }
}
</file>

<file path="website/src/css/stability/_main.scss">
@use 'sass:meta' as *;
@use '../mixins' as *;

section {
  &.stability {
    @include flex(column);
    gap: 0.625rem;
    width: 100%;
    padding: 0.46875rem 0.625rem;
    color: var(--prism-color);
    margin-bottom: var(--ifm-leading);
    box-shadow: var(--ifm-global-shadow-lw);
    border-radius: var(--ifm-code-border-radius);
    border: 0.0625rem solid var(--stability-border);
    background-color: var(--stability-background);

    a {
      text-decoration: none !important;

      header {
        @include flex(row, center);
        gap: 0.46875rem;

        strong {
          display: block;
          padding: 0 0.46875rem;
          border-radius: var(--ifm-code-border-radius);
          font-size: 0.875rem;
          background-color: var(--stability-title-background);
          color: var(--stability-title-color);
        }

        span {
          flex-grow: 1;
          @include flex(row, center);
          gap: 0.125rem;
          font-weight: 600;
          color: var(--stability-text);
        }

        svg {
          width: 1.25rem;
          height: 1.25rem;
          stroke: var(--stability-text);
        }
      }
    }

    p {
      width: 100%;
      margin: 0;
      padding-top: 0.3125rem;
      border-top: 0.0625rem solid var(--stability-separator);
      font-size: 0.91rem;
      color: var(--stability-description);
    }
  }
}

// Themes
@include load-css('light');
@include load-css('dark');
</file>

<file path="website/src/pages/index.tsx">
import { Redirect } from '@docusaurus/router';
import useDocusaurusContext from '@docusaurus/useDocusaurusContext';

function Home() {
  const { i18n, siteConfig } = useDocusaurusContext();
  const { baseUrl } = siteConfig;
  const currentLocale = i18n.currentLocale;
  const setLocaleRedirectMap = () =>
    currentLocale === 'en' || baseUrl.includes(currentLocale)
      ? `${baseUrl}docs`
      : `${baseUrl}${currentLocale}/docs`;
  const redirectUrl = setLocaleRedirectMap();

  return <Redirect to={redirectUrl} />;
}

export default Home;
</file>

<file path="website/static/img/favicon.svg">
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 495.49 495.49">
  <rect x="0" width="495.49" height="495.49" rx="87.17" ry="87.17" style="fill: #fff; stroke-width: 0px;"/>
  <path d="m154.04,397.19v-42.96l82.07-108.49c6.2-8.01,12.06-15.77,17.56-23.3,5.5-7.52,10.01-15.17,13.54-22.94,3.52-7.76,5.29-15.89,5.29-24.39s-1.98-14.8-5.92-18.93c-3.95-4.12-9.31-6.19-16.08-6.19-7.62,0-13.54,1.82-17.77,5.46s-7.13,8.5-8.67,14.56c-1.55,6.07-2.33,12.87-2.33,20.39v14.56h-68.53v-15.66c0-17.47,3.24-33.07,9.73-46.78,6.48-13.71,16.78-24.51,30.88-32.4,14.1-7.88,32.57-11.83,55.42-11.83,30.74,0,53.94,6.86,69.59,20.57,15.65,13.71,23.48,32.83,23.48,57.34,0,11.89-2.19,22.94-6.56,33.13-4.38,10.19-10.15,20.09-17.34,29.67-7.19,9.59-14.88,19.6-23.06,30.04l-62.61,80.46h100.26v47.69h-178.95Z" style="fill: #45aaf2; stroke-width: 0px;"/>
</svg>
</file>

<file path="website/test/fixtures/external-code-embed/handleCompressedPacket.txt">
function handleCompressedPacket(packet) {
  // eslint-disable-next-line consistent-this, no-invalid-this
  const connection = this;
  const deflatedLength = packet.readInt24();
  const body = packet.readBuffer();

  if (deflatedLength !== 0) {
    connection.inflateQueue.push(task => {
      zlib.inflate(body, (err, data) => {
        if (err) {
          connection._handleNetworkError(err);
          return;
        }
        connection._bumpCompressedSequenceId(packet.numPackets);
        connection._inflatedPacketsParser.execute(data);
        task.done();
      });
    });
  } else {
    connection.inflateQueue.push(task => {
      connection._bumpCompressedSequenceId(packet.numPackets);
      connection._inflatedPacketsParser.execute(body);
      task.done();
    });
  }
}
</file>

<file path="website/test/fixtures/external-code-embed/handler.txt">
function handler(packet) {
  //console.log(packet.length(), packet.sequenceId);
  cc += packet.sequenceId;
  count++;
}
</file>

<file path="website/test/fixtures/external-code-embed/HistoryRecords.txt">
export type HistoryRecords = {
  /** **Examples:**
   *
   * - `3.x`
   * - `3.2.x`
   * - `3.2.6`
   */
  version: string;
  /**
   * Examples:
   *
   * ---
   *
   * - string
   * ```plain
   * Indicate your changes
   * ```
   *
   * ---
   *
   * - JSX
   * ```tsx
   * <>
   *   <code>Method Name</code> and your changes
   * </>
   * ```
   */
  changes: (string | JSX.Element)[];
};
</file>

<file path="website/test/fixtures/external-code-embed/makeSelector.txt">
const makeSelector = {
  RR() {
    let index = 0;
    return clusterIds => clusterIds[index++ % clusterIds.length];
  },
  RANDOM() {
    return clusterIds =>
      clusterIds[Math.floor(Math.random() * clusterIds.length)];
  },
  ORDER() {
    return clusterIds => clusterIds[0];
  }
};
</file>

<file path="website/test/fixtures/external-code-embed/Pool.txt">
class Pool extends EventEmitter {
  constructor(options) {
    super();
    this.config = options.config;
    this.config.connectionConfig.pool = this;
    this._allConnections = new Queue();
    this._freeConnections = new Queue();
    this._connectionQueue = new Queue();
    this._closed = false;
    if (this.config.maxIdle < this.config.connectionLimit) {
      // create idle connection timeout automatically release job
      this._removeIdleTimeoutConnections();
    }
  }

  promise(promiseImpl) {
    const PromisePool = require('../promise').PromisePool;
    return new PromisePool(this, promiseImpl);
  }

  getConnection(cb) {
    if (this._closed) {
      return process.nextTick(() => cb(new Error('Pool is closed.')));
    }
    let connection;
    if (this._freeConnections.length > 0) {
      connection = this._freeConnections.pop();
      this.emit('acquire', connection);
      return process.nextTick(() => cb(null, connection));
    }
    if (
      this.config.connectionLimit === 0 ||
      this._allConnections.length < this.config.connectionLimit
    ) {
      connection = new PoolConnection(this, {
        config: this.config.connectionConfig,
      });
      this._allConnections.push(connection);
      return connection.connect((err) => {
        if (this._closed) {
          return cb(new Error('Pool is closed.'));
        }
        if (err) {
          return cb(err);
        }
        this.emit('connection', connection);
        this.emit('acquire', connection);
        return cb(null, connection);
      });
    }
    if (!this.config.waitForConnections) {
      return process.nextTick(() => cb(new Error('No connections available.')));
    }
    if (
      this.config.queueLimit &&
      this._connectionQueue.length >= this.config.queueLimit
    ) {
      return cb(new Error('Queue limit reached.'));
    }
    this.emit('enqueue');
    return this._connectionQueue.push(cb);
  }

  releaseConnection(connection) {
    let cb;
    if (!connection._pool) {
      // The connection has been removed from the pool and is no longer good.
      if (this._connectionQueue.length) {
        cb = this._connectionQueue.shift();
        process.nextTick(this.getConnection.bind(this, cb));
      }
    } else if (this._connectionQueue.length) {
      cb = this._connectionQueue.shift();
      process.nextTick(cb.bind(null, null, connection));
    } else {
      this._freeConnections.push(connection);
      this.emit('release', connection);
    }
  }

  end(cb) {
    this._closed = true;
    if (typeof cb !== 'function') {
      cb = function (err) {
        if (err) {
          throw err;
        }
      };
    }
    let calledBack = false;
    let closedConnections = 0;
    let connection;
    const endCB = function (err) {
      if (calledBack) {
        return;
      }
      if (err || ++closedConnections >= this._allConnections.length) {
        calledBack = true;
        cb(err);
        return;
      }
    }.bind(this);
    if (this._allConnections.length === 0) {
      endCB();
      return;
    }
    for (let i = 0; i < this._allConnections.length; i++) {
      connection = this._allConnections.get(i);
      connection._realEnd(endCB);
    }
  }

  query(sql, values, cb) {
    const cmdQuery = Connection.createQuery(
      sql,
      values,
      cb,
      this.config.connectionConfig
    );
    if (typeof cmdQuery.namedPlaceholders === 'undefined') {
      cmdQuery.namedPlaceholders =
        this.config.connectionConfig.namedPlaceholders;
    }
    this.getConnection((err, conn) => {
      if (err) {
        if (typeof cmdQuery.onResult === 'function') {
          cmdQuery.onResult(err);
        } else {
          cmdQuery.emit('error', err);
        }
        return;
      }
      try {
        conn.query(cmdQuery).once('end', () => {
          conn.release();
        });
      } catch (e) {
        conn.release();
        throw e;
      }
    });
    return cmdQuery;
  }

  execute(sql, values, cb) {
    // TODO construct execute command first here and pass it to connection.execute
    // so that polymorphic arguments logic is there in one place
    if (typeof values === 'function') {
      cb = values;
      values = [];
    }
    this.getConnection((err, conn) => {
      if (err) {
        return cb(err);
      }
      try {
        conn.execute(sql, values, cb).once('end', () => {
          conn.release();
        });
      } catch (e) {
        conn.release();
        return cb(e);
      }
    });
  }

  _removeConnection(connection) {
    // Remove connection from all connections
    spliceConnection(this._allConnections, connection);
    // Remove connection from free connections
    spliceConnection(this._freeConnections, connection);
    this.releaseConnection(connection);
  }

  _removeIdleTimeoutConnections() {
    if (this._removeIdleTimeoutConnectionsTimer) {
      clearTimeout(this._removeIdleTimeoutConnectionsTimer);
    }

    this._removeIdleTimeoutConnectionsTimer = setTimeout(() => {
      try {
        while (
          this._freeConnections.length > this.config.maxIdle &&
          Date.now() - this._freeConnections.get(0).lastActiveTime >
            this.config.idleTimeout
        ) {
          this._freeConnections.get(0).destroy();
        }
      } finally {
        this._removeIdleTimeoutConnections();
      }
    }, 1000);
  }

  format(sql, values) {
    return mysql.format(
      sql,
      values,
      this.config.connectionConfig.stringifyObjects,
      this.config.connectionConfig.timezone
    );
  }

  escape(value) {
    return mysql.escape(
      value,
      this.config.connectionConfig.stringifyObjects,
      this.config.connectionConfig.timezone
    );
  }

  escapeId(value) {
    return mysql.escapeId(value, false);
  }
}
</file>

<file path="website/test/fixtures/external-code-embed/QueryOptions.txt">
export interface QueryOptions {
  /**
   * The SQL for the query
   */
  sql: string;

  /**
   * The values for the query
   */
  values?: any | any[] | { [param: string]: any };

  /**
   * This overrides the namedPlaceholders option set at the connection level.
   */
  namedPlaceholders?: boolean;

  /**
   * Every operation takes an optional inactivity timeout option. This allows you to specify appropriate timeouts for
   * operations. It is important to note that these timeouts are not part of the MySQL protocol, and rather timeout
   * operations through the client. This means that when a timeout is reached, the connection it occurred on will be
   * destroyed and no further operations can be performed.
   */
  timeout?: number;

  /**
   * Either a boolean or string. If true, tables will be nested objects. If string (e.g. '_'), tables will be
   * nested as tableName_fieldName
   */
  nestTables?: any;

  /**
   * Determines if column values should be converted to native JavaScript types. It is not recommended (and may go away / change in the future)
   * to disable type casting, but you can currently do so on either the connection or query level. (Default: true)
   *
   * You can also specify a function (field: any, next: () => void) => {} to do the type casting yourself.
   *
   * WARNING: YOU MUST INVOKE the parser using one of these three field functions in your custom typeCast callback. They can only be called once.
   *
   * field.string()
   * field.buffer()
   * field.geometry()
   *
   * are aliases for
   *
   * parser.parseLengthCodedString()
   * parser.parseLengthCodedBuffer()
   * parser.parseGeometryValue()
   *
   * You can find which field function you need to use by looking at: RowDataPacket.prototype._typeCast
   */
  typeCast?: any;

  /**
   * This overrides the same option set at the connection level.
   *
   */
  rowsAsArray?: boolean;

  /**
   * By specifying a function that returns a readable stream, an arbitrary stream can be sent when sending a local fs file.
   */
  infileStreamFactory?: (path: string) => Readable;
}
</file>

<file path="website/test/resources/external-code-embed/random-methods.txt">
/**
 * This file is for testing purposes only.
 * Please see the ExternalCodeEmbed component and extractMethodContent for more context.
 */

import { Sequence } from './Sequence.js';
import { OkPacket, RowDataPacket, FieldPacket } from '../packets/index.js';
import { Readable } from 'stream';

export interface QueryOptions {
  /**
   * The SQL for the query
   */
  sql: string;

  /**
   * The values for the query
   */
  values?: any | any[] | { [param: string]: any };

  /**
   * This overrides the namedPlaceholders option set at the connection level.
   */
  namedPlaceholders?: boolean;

  /**
   * Every operation takes an optional inactivity timeout option. This allows you to specify appropriate timeouts for
   * operations. It is important to note that these timeouts are not part of the MySQL protocol, and rather timeout
   * operations through the client. This means that when a timeout is reached, the connection it occurred on will be
   * destroyed and no further operations can be performed.
   */
  timeout?: number;

  /**
   * Either a boolean or string. If true, tables will be nested objects. If string (e.g. '_'), tables will be
   * nested as tableName_fieldName
   */
  nestTables?: any;

  /**
   * Determines if column values should be converted to native JavaScript types. It is not recommended (and may go away / change in the future)
   * to disable type casting, but you can currently do so on either the connection or query level. (Default: true)
   *
   * You can also specify a function (field: any, next: () => void) => {} to do the type casting yourself.
   *
   * WARNING: YOU MUST INVOKE the parser using one of these three field functions in your custom typeCast callback. They can only be called once.
   *
   * field.string()
   * field.buffer()
   * field.geometry()
   *
   * are aliases for
   *
   * parser.parseLengthCodedString()
   * parser.parseLengthCodedBuffer()
   * parser.parseGeometryValue()
   *
   * You can find which field function you need to use by looking at: RowDataPacket.prototype._typeCast
   */
  typeCast?: any;

  /**
   * This overrides the same option set at the connection level.
   *
   */
  rowsAsArray?: boolean;

  /**
   * By specifying a function that returns a readable stream, an arbitrary stream can be sent when sending a local fs file.
   */
  infileStreamFactory?: (path: string) => Readable;
}

class Pool extends EventEmitter {
  constructor(options) {
    super();
    this.config = options.config;
    this.config.connectionConfig.pool = this;
    this._allConnections = new Queue();
    this._freeConnections = new Queue();
    this._connectionQueue = new Queue();
    this._closed = false;
    if (this.config.maxIdle < this.config.connectionLimit) {
      // create idle connection timeout automatically release job
      this._removeIdleTimeoutConnections();
    }
  }

  promise(promiseImpl) {
    const PromisePool = require('../promise').PromisePool;
    return new PromisePool(this, promiseImpl);
  }

  getConnection(cb) {
    if (this._closed) {
      return process.nextTick(() => cb(new Error('Pool is closed.')));
    }
    let connection;
    if (this._freeConnections.length > 0) {
      connection = this._freeConnections.pop();
      this.emit('acquire', connection);
      return process.nextTick(() => cb(null, connection));
    }
    if (
      this.config.connectionLimit === 0 ||
      this._allConnections.length < this.config.connectionLimit
    ) {
      connection = new PoolConnection(this, {
        config: this.config.connectionConfig,
      });
      this._allConnections.push(connection);
      return connection.connect((err) => {
        if (this._closed) {
          return cb(new Error('Pool is closed.'));
        }
        if (err) {
          return cb(err);
        }
        this.emit('connection', connection);
        this.emit('acquire', connection);
        return cb(null, connection);
      });
    }
    if (!this.config.waitForConnections) {
      return process.nextTick(() => cb(new Error('No connections available.')));
    }
    if (
      this.config.queueLimit &&
      this._connectionQueue.length >= this.config.queueLimit
    ) {
      return cb(new Error('Queue limit reached.'));
    }
    this.emit('enqueue');
    return this._connectionQueue.push(cb);
  }

  releaseConnection(connection) {
    let cb;
    if (!connection._pool) {
      // The connection has been removed from the pool and is no longer good.
      if (this._connectionQueue.length) {
        cb = this._connectionQueue.shift();
        process.nextTick(this.getConnection.bind(this, cb));
      }
    } else if (this._connectionQueue.length) {
      cb = this._connectionQueue.shift();
      process.nextTick(cb.bind(null, null, connection));
    } else {
      this._freeConnections.push(connection);
      this.emit('release', connection);
    }
  }

  end(cb) {
    this._closed = true;
    if (typeof cb !== 'function') {
      cb = function (err) {
        if (err) {
          throw err;
        }
      };
    }
    let calledBack = false;
    let closedConnections = 0;
    let connection;
    const endCB = function (err) {
      if (calledBack) {
        return;
      }
      if (err || ++closedConnections >= this._allConnections.length) {
        calledBack = true;
        cb(err);
        return;
      }
    }.bind(this);
    if (this._allConnections.length === 0) {
      endCB();
      return;
    }
    for (let i = 0; i < this._allConnections.length; i++) {
      connection = this._allConnections.get(i);
      connection._realEnd(endCB);
    }
  }

  query(sql, values, cb) {
    const cmdQuery = Connection.createQuery(
      sql,
      values,
      cb,
      this.config.connectionConfig
    );
    if (typeof cmdQuery.namedPlaceholders === 'undefined') {
      cmdQuery.namedPlaceholders =
        this.config.connectionConfig.namedPlaceholders;
    }
    this.getConnection((err, conn) => {
      if (err) {
        if (typeof cmdQuery.onResult === 'function') {
          cmdQuery.onResult(err);
        } else {
          cmdQuery.emit('error', err);
        }
        return;
      }
      try {
        conn.query(cmdQuery).once('end', () => {
          conn.release();
        });
      } catch (e) {
        conn.release();
        throw e;
      }
    });
    return cmdQuery;
  }

  execute(sql, values, cb) {
    // TODO construct execute command first here and pass it to connection.execute
    // so that polymorphic arguments logic is there in one place
    if (typeof values === 'function') {
      cb = values;
      values = [];
    }
    this.getConnection((err, conn) => {
      if (err) {
        return cb(err);
      }
      try {
        conn.execute(sql, values, cb).once('end', () => {
          conn.release();
        });
      } catch (e) {
        conn.release();
        return cb(e);
      }
    });
  }

  _removeConnection(connection) {
    // Remove connection from all connections
    spliceConnection(this._allConnections, connection);
    // Remove connection from free connections
    spliceConnection(this._freeConnections, connection);
    this.releaseConnection(connection);
  }

  _removeIdleTimeoutConnections() {
    if (this._removeIdleTimeoutConnectionsTimer) {
      clearTimeout(this._removeIdleTimeoutConnectionsTimer);
    }

    this._removeIdleTimeoutConnectionsTimer = setTimeout(() => {
      try {
        while (
          this._freeConnections.length > this.config.maxIdle &&
          Date.now() - this._freeConnections.get(0).lastActiveTime >
            this.config.idleTimeout
        ) {
          this._freeConnections.get(0).destroy();
        }
      } finally {
        this._removeIdleTimeoutConnections();
      }
    }, 1000);
  }

  format(sql, values) {
    return mysql.format(
      sql,
      values,
      this.config.connectionConfig.stringifyObjects,
      this.config.connectionConfig.timezone
    );
  }

  escape(value) {
    return mysql.escape(
      value,
      this.config.connectionConfig.stringifyObjects,
      this.config.connectionConfig.timezone
    );
  }

  escapeId(value) {
    return mysql.escapeId(value, false);
  }
}

const makeSelector = {
  RR() {
    let index = 0;
    return clusterIds => clusterIds[index++ % clusterIds.length];
  },
  RANDOM() {
    return clusterIds =>
      clusterIds[Math.floor(Math.random() * clusterIds.length)];
  },
  ORDER() {
    return clusterIds => clusterIds[0];
  }
};

function handleCompressedPacket(packet) {
  // eslint-disable-next-line consistent-this, no-invalid-this
  const connection = this;
  const deflatedLength = packet.readInt24();
  const body = packet.readBuffer();

  if (deflatedLength !== 0) {
    connection.inflateQueue.push(task => {
      zlib.inflate(body, (err, data) => {
        if (err) {
          connection._handleNetworkError(err);
          return;
        }
        connection._bumpCompressedSequenceId(packet.numPackets);
        connection._inflatedPacketsParser.execute(data);
        task.done();
      });
    });
  } else {
    connection.inflateQueue.push(task => {
      connection._bumpCompressedSequenceId(packet.numPackets);
      connection._inflatedPacketsParser.execute(body);
      task.done();
    });
  }
}

export type HistoryRecords = {
  /** **Examples:**
   *
   * - `3.x`
   * - `3.2.x`
   * - `3.2.6`
   */
  version: string;
  /**
   * Examples:
   *
   * ---
   *
   * - string
   * ```plain
   * Indicate your changes
   * ```
   *
   * ---
   *
   * - JSX
   * ```tsx
   * <>
   *   <code>Method Name</code> and your changes
   * </>
   * ```
   */
  changes: (string | JSX.Element)[];
};

function handler(packet) {
  //console.log(packet.length(), packet.sequenceId);
  cc += packet.sequenceId;
  count++;
}
</file>

<file path="website/test/unit/check-extensions.test.ts">
import { EOL } from 'node:os';
import { listFiles, test, assert } from 'poku';

const invalidFiles: string[] = [];
const message = [
  'Check for invalid file types found in restricted directories',
];

const checkExtensions = async (
  dirs: string[],
  allowedExtensions: RegExp,
  ignoreList: RegExp = /\.DS_Store/
) => {
  for (const dir of dirs) {
    const files = await listFiles(dir, { filter: /\./ });

    for (const file of files) {
      if (!(ignoreList.test(file) || allowedExtensions.test(file))) {
        invalidFiles.push(file);
        message.push(`${EOL}${String(allowedExtensions)}`);
        message.push(`- ${file}`);
      }
    }
  }
};

test(async () => {
  await checkExtensions(['docs', 'i18n'], /\.(mdx|json)$/);
  await checkExtensions(['helpers', 'plugins'], /\.ts$/);
  await checkExtensions(['test/unit', 'test/utils'], /\.test\.ts$/);
  await checkExtensions(['src/components', 'src/pages'], /\.tsx$/);
  await checkExtensions(['src/css'], /\.scss$/);

  assert.deepStrictEqual(
    invalidFiles.length,
    0,
    Array.from(new Set(message)).join(EOL)
  );
});
</file>

<file path="website/test/unit/external-code-embed.test.ts">
/**
 * Fixtures generated using './test/utils/gen-expected-extract-results.ts'
 */

import fs from 'node:fs';
import path from 'node:path';
import { assert } from 'poku';
import {
  extractMethodContent,
  type MethodType,
} from '@site/helpers/extract-method-content';

const resource = fs.readFileSync(
  path.resolve('./test/resources/external-code-embed/random-methods.txt'),
  'utf-8'
);

const checkResult = (methodName: string, methodType: MethodType) => {
  if (
    fs.readFileSync(
      path.resolve(`./test/fixtures/external-code-embed/${methodName}.txt`),
      'utf-8'
    ) !== extractMethodContent(resource, methodName, methodType)
  )
    assert.fail(`${methodName} example failed`);
};

// Valid methods
checkResult('QueryOptions', 'interface');
checkResult('Pool', 'class');
checkResult('makeSelector', 'const');
checkResult('handleCompressedPacket', 'function');
checkResult('HistoryRecords', 'type');
checkResult('handler', 'function');

// Invalid method
if (resource !== extractMethodContent(resource, 'invalidMethod', 'function')) {
  assert.fail(
    "Invalid method example failed. It should return the original content when it didn't find the requested method."
  );
}
</file>

<file path="website/test/utils/gen-expected-extract-results.test.ts">
/**
 * This file is not included in the tests and can be triggered manually using the command:
 * `npx tsx test/utils/gen-expected-extract-results.ts`
 */

import fs from 'node:fs';
import path from 'node:path';
import { extractMethodContent } from '@site/helpers/extract-method-content';

const resource = fs.readFileSync(
  path.resolve('./test/resources/external-code-embed/random-methods.txt'),
  'utf-8'
);

fs.writeFileSync(
  path.resolve('./test/fixtures/external-code-embed/QueryOptions.txt'),
  extractMethodContent(resource, 'QueryOptions', 'interface')
);

fs.writeFileSync(
  path.resolve('./test/fixtures/external-code-embed/Pool.txt'),
  extractMethodContent(resource, 'Pool', 'class')
);

fs.writeFileSync(
  path.resolve('./test/fixtures/external-code-embed/makeSelector.txt'),
  extractMethodContent(resource, 'makeSelector', 'const')
);

fs.writeFileSync(
  path.resolve(
    './test/fixtures/external-code-embed/handleCompressedPacket.txt'
  ),
  extractMethodContent(resource, 'handleCompressedPacket', 'function')
);

fs.writeFileSync(
  path.resolve('./test/fixtures/external-code-embed/HistoryRecords.txt'),
  extractMethodContent(resource, 'HistoryRecords', 'type')
);

fs.writeFileSync(
  path.resolve('./test/fixtures/external-code-embed/handler.txt'),
  extractMethodContent(resource, 'handler', 'function')
);
</file>

<file path="website/tsconfig.json">
{
  // This file is not used in compilation. It is here just for a nice editor experience.
  "extends": "@docusaurus/tsconfig",
  "compilerOptions": {
    "baseUrl": ".",
    "isolatedModules": true,
    "allowJs": false,
    "strict": true,
    "alwaysStrict": true,
    "strictFunctionTypes": true,
    "noUnusedLocals": true
  },
  "exclude": ["static", "build", ".docusaurus"]
}
</file>

</files>
